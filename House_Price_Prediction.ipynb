{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJRSrY4gy/qDFPkh4613Td",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonikaBalasubramaniam/TNSDC/blob/main/House_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U_qlpQY6O_Wt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing = pd.read_csv(\"housing.csv\")\n",
        "housing.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "LwcrNLOMPDVT",
        "outputId": "df156b1f-af3d-4dd7-dc0b-cc59f7d83f12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value ocean_proximity  \n",
              "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
              "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
              "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
              "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
              "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-761ad6d0-946c-430b-a31c-7163a8ce086f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-761ad6d0-946c-430b-a31c-7163a8ce086f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-761ad6d0-946c-430b-a31c-7163a8ce086f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-761ad6d0-946c-430b-a31c-7163a8ce086f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6df0b149-421e-4a47-8cf7-3c8f9b03d682\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6df0b149-421e-4a47-8cf7-3c8f9b03d682')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6df0b149-421e-4a47-8cf7-3c8f9b03d682 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "housing",
              "summary": "{\n  \"name\": \"housing\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0035317235025882,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571153,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.58555761211165,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582795,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.3850700740323,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1923,\n        \"samples\": [\n          1538.0,\n          1298.0,\n          1578.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132.462121765341,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          4169.0,\n          636.0,\n          3367.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.32975283161073,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452688,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          5.0286,\n          2.0433,\n          6.1228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115395.61587441387,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3842,\n        \"samples\": [\n          194300.0,\n          379000.0,\n          230100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<1H OCEAN\",\n          \"ISLAND\",\n          \"INLAND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPbdqVTOQsC2",
        "outputId": "f3f868ac-b177-4a42-e159-1c8001fa335e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20640, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jrPAhE9QvTj",
        "outputId": "47cb0e9a-c45d-4ddd-b4bd-52bb7c931bf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "longitude               0\n",
              "latitude                0\n",
              "housing_median_age      0\n",
              "total_rooms             0\n",
              "total_bedrooms        207\n",
              "population              0\n",
              "households              0\n",
              "median_income           0\n",
              "median_house_value      0\n",
              "ocean_proximity         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing['total_bedrooms'].fillna((housing['total_bedrooms'].mean()), inplace=True)\n",
        "housing.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwpqvFNEQzJD",
        "outputId": "cc6573bd-70db-4476-aaba-33886b2dc2b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "longitude             0\n",
              "latitude              0\n",
              "housing_median_age    0\n",
              "total_rooms           0\n",
              "total_bedrooms        0\n",
              "population            0\n",
              "households            0\n",
              "median_income         0\n",
              "median_house_value    0\n",
              "ocean_proximity       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"ocean_proximity\"].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO_sMUyXQ0q0",
        "outputId": "17228a38-3b63-45b4-a18a-63e48cdc9f96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1H OCEAN     9136\n",
              "INLAND        6551\n",
              "NEAR OCEAN    2658\n",
              "NEAR BAY      2290\n",
              "ISLAND           5\n",
              "Name: ocean_proximity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns=['ocean_proximity'] # must be a list\n",
        "housing = pd.get_dummies(housing, columns=categorical_columns)\n",
        "housing.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ylwKZInLQ3-V",
        "outputId": "29f83e52-b148-4fde-b471-105129e06526"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \\\n",
              "0       322.0       126.0         8.3252            452600.0   \n",
              "1      2401.0      1138.0         8.3014            358500.0   \n",
              "2       496.0       177.0         7.2574            352100.0   \n",
              "3       558.0       219.0         5.6431            341300.0   \n",
              "4       565.0       259.0         3.8462            342200.0   \n",
              "\n",
              "   ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  ocean_proximity_ISLAND  \\\n",
              "0                          0                       0                       0   \n",
              "1                          0                       0                       0   \n",
              "2                          0                       0                       0   \n",
              "3                          0                       0                       0   \n",
              "4                          0                       0                       0   \n",
              "\n",
              "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
              "0                         1                           0  \n",
              "1                         1                           0  \n",
              "2                         1                           0  \n",
              "3                         1                           0  \n",
              "4                         1                           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-874423c8-c2de-495d-a32b-62897981dfed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
              "      <th>ocean_proximity_INLAND</th>\n",
              "      <th>ocean_proximity_ISLAND</th>\n",
              "      <th>ocean_proximity_NEAR BAY</th>\n",
              "      <th>ocean_proximity_NEAR OCEAN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-874423c8-c2de-495d-a32b-62897981dfed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-874423c8-c2de-495d-a32b-62897981dfed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-874423c8-c2de-495d-a32b-62897981dfed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4f6a5dc-980b-403f-b86f-142b8ddabad9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4f6a5dc-980b-403f-b86f-142b8ddabad9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4f6a5dc-980b-403f-b86f-142b8ddabad9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "housing",
              "summary": "{\n  \"name\": \"housing\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0035317235025882,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571153,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.58555761211165,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582795,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 419.26659232552373,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1924,\n        \"samples\": [\n          1126.0,\n          1842.0,\n          1116.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132.462121765341,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          4169.0,\n          636.0,\n          3367.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.32975283161073,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452688,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          5.0286,\n          2.0433,\n          6.1228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115395.61587441387,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3842,\n        \"samples\": [\n          194300.0,\n          379000.0,\n          230100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_<1H OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_INLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_ISLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR BAY\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=housing.drop(['median_house_value'], axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "vTBmxrULQ787",
        "outputId": "c60514ee-308e-435d-9ecb-18e2d18b93c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
              "0       322.0       126.0         8.3252                          0   \n",
              "1      2401.0      1138.0         8.3014                          0   \n",
              "2       496.0       177.0         7.2574                          0   \n",
              "3       558.0       219.0         5.6431                          0   \n",
              "4       565.0       259.0         3.8462                          0   \n",
              "\n",
              "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
              "0                       0                       0                         1   \n",
              "1                       0                       0                         1   \n",
              "2                       0                       0                         1   \n",
              "3                       0                       0                         1   \n",
              "4                       0                       0                         1   \n",
              "\n",
              "   ocean_proximity_NEAR OCEAN  \n",
              "0                           0  \n",
              "1                           0  \n",
              "2                           0  \n",
              "3                           0  \n",
              "4                           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-312347a4-516a-4a4b-ac4a-cbb618ace6f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
              "      <th>ocean_proximity_INLAND</th>\n",
              "      <th>ocean_proximity_ISLAND</th>\n",
              "      <th>ocean_proximity_NEAR BAY</th>\n",
              "      <th>ocean_proximity_NEAR OCEAN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-312347a4-516a-4a4b-ac4a-cbb618ace6f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-312347a4-516a-4a4b-ac4a-cbb618ace6f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-312347a4-516a-4a4b-ac4a-cbb618ace6f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32a1cc22-f581-459e-95e3-622acd27e230\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32a1cc22-f581-459e-95e3-622acd27e230')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32a1cc22-f581-459e-95e3-622acd27e230 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0035317235025882,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571153,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.58555761211165,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582795,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 419.26659232552373,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1924,\n        \"samples\": [\n          1126.0,\n          1842.0,\n          1116.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132.462121765341,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          4169.0,\n          636.0,\n          3367.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.32975283161073,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452688,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          5.0286,\n          2.0433,\n          6.1228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_<1H OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_INLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_ISLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR BAY\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=housing['median_house_value']\n",
        "Y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws8qTHx2RE2r",
        "outputId": "1ce0ff05-234e-4c99-ef82-0ed3b364207d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    452600.0\n",
              "1    358500.0\n",
              "2    352100.0\n",
              "3    341300.0\n",
              "4    342200.0\n",
              "Name: median_house_value, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_columns=X.columns #store the column names\n",
        "X=X.values.astype('float32')\n",
        "Y=Y.values.astype('float32')"
      ],
      "metadata": {
        "id": "vva0whHXRIBs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "#split X_train and Y_train into a 'pure' training set and a validation set\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
        "print('train:', X_train.shape, Y_train.shape)\n",
        "print('validation:', X_val.shape, Y_val.shape)\n",
        "print('test:', X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G73a4OWaRLED",
        "outputId": "7d2f88cd-ae97-4441-b65d-601d514887b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (14860, 13) (14860,)\n",
            "validation: (1652, 13) (1652,)\n",
            "test: (4128, 13) (4128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalerX=MinMaxScaler()\n",
        "scalerX.fit(X_train) # think about why fit to X_train, not X ?\n",
        "X_train=scalerX.transform(X_train)\n",
        "X_val=scalerX.transform(X_val)\n",
        "X_test=scalerX.transform(X_test)"
      ],
      "metadata": {
        "id": "IbfUr_AhRNUw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_v8U9yRPR5",
        "outputId": "d8a8fb7b-a120-4bba-f228-3067dbe84423"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5786848 , 0.38044596, 0.19607843, 0.12570114, 0.13671634,\n",
              "       0.00983827, 0.02795593, 0.11055019, 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_max=Y_train.max()\n",
        "Y_train/=Y_train_max\n",
        "Y_val/=Y_train_max\n",
        "Y_test/=Y_train_max"
      ],
      "metadata": {
        "id": "VC04ysP5RRPE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linear_model = LinearRegression(fit_intercept=True)"
      ],
      "metadata": {
        "id": "IBiPnJYvRTo5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "FU3_GlLrRV-7",
        "outputId": "dbfec9b7-2454-4c2f-d913-06cbc7bb68a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.coef_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miLZtAlyRZ0M",
        "outputId": "04963305-558b-402f-bbdc-ec9378dec048"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.52667564, -0.47057658,  0.1107004 , -0.3135661 ,  0.87252295,\n",
              "       -2.8026843 ,  1.0090173 ,  1.130491  , -0.04725003, -0.12498039,\n",
              "        0.26538345, -0.05612981, -0.037025  ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.intercept_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPGVmrDRRb-V",
        "outputId": "45fdbe99-6217-40aa-aa07-4a1d8f70ba18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.54965425"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_pred = linear_model.predict(X_train)\n",
        "Y_test_pred = linear_model.predict(X_test)\n",
        "print('Evaluate model on testing set')\n",
        "MSE = np.mean((Y_test - Y_test_pred)**2)\n",
        "MAE = np.mean(np.abs(Y_test - Y_test_pred))\n",
        "MAPE =  np.mean(np.abs(Y_test - Y_test_pred)/Y_test)\n",
        "print('MSE=', MSE)\n",
        "print('MAE=', MAE)\n",
        "print('MAPE=', MAPE)\n",
        "#step6:\n",
        "# the red line is the 45-degree line\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title('Y_test_pred vs Y_test')\n",
        "ax.plot(Y_test, Y_test_pred, '.')\n",
        "ymax=np.max([Y_test.max(), Y_test_pred.max()])\n",
        "ax.plot(np.linspace(0,ymax, 3), np.linspace(0, ymax, 3), '-r')\n",
        "ax.set_xlabel('Y_test')\n",
        "ax.set_ylabel('Y_test_pred')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "6ZCGG0mdRemK",
        "outputId": "92780fd7-1f15-446c-93fe-51b8f7ecec88"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on testing set\n",
            "MSE= 0.018863905\n",
            "MAE= 0.09931183\n",
            "MAPE= 0.28951442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Y_test_pred')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset as torch_dataset\n",
        "class MyDataset(torch_dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X=X\n",
        "        self.Y=Y.reshape(-1, 1) #this is very important\n",
        "    def __len__(self):\n",
        "        #return the number of data points\n",
        "        return self.X.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        # use the notation DatasetName[idx]\n",
        "        # to get a data point (x,y) by idx\n",
        "        # we need to convert numpy array to torch tensor\n",
        "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y=torch.tensor(self.Y[idx], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "My20IOF0Ritc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train= MyDataset(X_train,Y_train)\n",
        "dataset_val = MyDataset(X_val, Y_val)\n",
        "dataset_test = MyDataset(X_test, Y_test)"
      ],
      "metadata": {
        "id": "coK7XfDpRl9l"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train) # get the number of data points in the training set\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R566BOm-RoKc",
        "outputId": "49b410b8-e038-4e27-e2f0-1cf205536dff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14860"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset as torch_dataset\n",
        "from torch.utils.data import DataLoader as torch_dataloader\n",
        "\n",
        "dataloader_train = torch_dataloader(dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
        "dataloader_val = torch_dataloader(dataset_val, batch_size=128, shuffle=False, num_workers=0)\n",
        "dataloader_test = torch_dataloader(dataset_test, batch_size=128, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "u76lSNQjRqIh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odexDKm-RsSQ",
        "outputId": "7d71d817-7283-4ce5-b492-93d7a1e2fd4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (X, Y) in enumerate(dataloader_train):\n",
        "    print(batch_idx, X.size(), Y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcDbaYkHRuru",
        "outputId": "2e4510d9-fc3a-4bbe-c14b-5af8aa42ec1e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "1 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "2 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "3 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "4 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "5 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "6 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "7 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "8 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "9 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "10 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "11 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "12 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "13 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "14 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "15 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "16 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "17 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "18 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "19 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "20 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "21 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "22 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "23 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "24 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "25 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "26 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "27 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "28 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "29 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "30 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "31 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "32 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "33 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "34 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "35 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "36 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "37 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "38 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "39 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "40 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "41 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "42 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "43 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "44 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "45 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "46 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "47 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "48 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "49 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "50 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "51 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "52 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "53 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "54 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "55 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "56 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "57 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "58 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "59 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "60 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "61 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "62 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "63 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "64 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "65 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "66 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "67 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "68 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "69 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "70 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "71 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "72 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "73 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "74 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "75 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "76 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "77 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "78 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "79 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "80 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "81 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "82 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "83 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "84 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "85 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "86 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "87 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "88 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "89 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "90 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "91 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "92 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "93 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "94 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "95 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "96 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "97 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "98 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "99 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "100 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "101 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "102 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "103 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "104 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "105 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "106 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "107 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "108 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "109 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "110 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "111 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "112 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "113 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "114 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "115 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "116 torch.Size([12, 13]) torch.Size([12, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnF\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, n_units):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, n_units)\n",
        "        self.layer2 = nn.Linear(n_units, n_units)\n",
        "        self.layer3 = nn.Linear(n_units, output_dim)\n",
        "    def forward(self, x):\n",
        "        x=self.layer1(x)\n",
        "        x=nnF.softplus(x)\n",
        "        x=self.layer2(x)\n",
        "        x=nnF.softplus(x)\n",
        "        y=self.layer3(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "BgGRMNQ8RyGH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net(input_dim=13, output_dim=1, n_units=128)\n"
      ],
      "metadata": {
        "id": "Hv04c0FyR0xC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h5Lor-_R2s7",
        "outputId": "db429ab1-e027-4573-b8e9-722d53944966"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer1): Linear(in_features=13, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer3): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    loss_train=0\n",
        "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        Yp = model(X)\n",
        "        loss = torch.mean((Yp-Y)**2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_train+=loss.item()\n",
        "        if batch_idx % 1 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * X.size(0), len(dataloader.dataset),\n",
        "                    100. * batch_idx / len(dataloader), loss.item()))\n",
        "    loss_train/=len(dataloader)\n",
        "    return loss_train"
      ],
      "metadata": {
        "id": "TOju2jz2R5Tr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, device):\n",
        "    model.eval()#set model to evaluation mode\n",
        "    loss_test=0\n",
        "    mae_test=0\n",
        "    mape_test=0\n",
        "    sample_count=0\n",
        "    with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
        "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            Yp = model(X)#forward pass\n",
        "            loss_test+=torch.sum((Yp-Y)**2).item()\n",
        "            mae_test+= torch.sum((Yp-Y).abs()).item()\n",
        "            mape_test+= torch.sum(((Yp-Y)/Yp).abs()).item()\n",
        "            sample_count+=X.size(0)\n",
        "    loss_test/=sample_count\n",
        "    mae_test/=sample_count\n",
        "    mape_test/=sample_count\n",
        "    return loss_test, mae_test ,mape_test"
      ],
      "metadata": {
        "id": "f00RomgpR6kl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "ku26a-21R9LD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_list=[]\n",
        "loss_val_list=[]"
      ],
      "metadata": {
        "id": "-2bb22NMSBMN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 100):\n",
        "\n",
        "    loss_train=train(model, optimizer, dataloader_train, device, epoch)\n",
        "    loss_train_list.append(loss_train)\n",
        "    print('epoch', epoch, 'training loss:', loss_train)\n",
        "\n",
        "\n",
        "    loss_val, mae_val,mape_test = test(model, dataloader_val, device)\n",
        "    loss_val_list.append(loss_val)\n",
        "    print('epoch', epoch, 'validation loss:', loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeOx8XWmSDX-",
        "outputId": "a904f7c5-5dab-40cb-b6e1-3c526326b5c8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch 57 training loss: 0.01945167702710272\n",
            "epoch 57 validation loss: 0.02016325190338615\n",
            "Train Epoch: 58 [0/14860 (0%)]\tLoss: 0.021028\n",
            "Train Epoch: 58 [128/14860 (1%)]\tLoss: 0.021340\n",
            "Train Epoch: 58 [256/14860 (2%)]\tLoss: 0.023559\n",
            "Train Epoch: 58 [384/14860 (3%)]\tLoss: 0.015124\n",
            "Train Epoch: 58 [512/14860 (3%)]\tLoss: 0.018895\n",
            "Train Epoch: 58 [640/14860 (4%)]\tLoss: 0.023489\n",
            "Train Epoch: 58 [768/14860 (5%)]\tLoss: 0.026734\n",
            "Train Epoch: 58 [896/14860 (6%)]\tLoss: 0.015049\n",
            "Train Epoch: 58 [1024/14860 (7%)]\tLoss: 0.019627\n",
            "Train Epoch: 58 [1152/14860 (8%)]\tLoss: 0.018974\n",
            "Train Epoch: 58 [1280/14860 (9%)]\tLoss: 0.014207\n",
            "Train Epoch: 58 [1408/14860 (9%)]\tLoss: 0.020627\n",
            "Train Epoch: 58 [1536/14860 (10%)]\tLoss: 0.015835\n",
            "Train Epoch: 58 [1664/14860 (11%)]\tLoss: 0.027593\n",
            "Train Epoch: 58 [1792/14860 (12%)]\tLoss: 0.031617\n",
            "Train Epoch: 58 [1920/14860 (13%)]\tLoss: 0.020956\n",
            "Train Epoch: 58 [2048/14860 (14%)]\tLoss: 0.019503\n",
            "Train Epoch: 58 [2176/14860 (15%)]\tLoss: 0.019897\n",
            "Train Epoch: 58 [2304/14860 (15%)]\tLoss: 0.011565\n",
            "Train Epoch: 58 [2432/14860 (16%)]\tLoss: 0.024726\n",
            "Train Epoch: 58 [2560/14860 (17%)]\tLoss: 0.015629\n",
            "Train Epoch: 58 [2688/14860 (18%)]\tLoss: 0.022451\n",
            "Train Epoch: 58 [2816/14860 (19%)]\tLoss: 0.023301\n",
            "Train Epoch: 58 [2944/14860 (20%)]\tLoss: 0.025580\n",
            "Train Epoch: 58 [3072/14860 (21%)]\tLoss: 0.017854\n",
            "Train Epoch: 58 [3200/14860 (21%)]\tLoss: 0.022684\n",
            "Train Epoch: 58 [3328/14860 (22%)]\tLoss: 0.015630\n",
            "Train Epoch: 58 [3456/14860 (23%)]\tLoss: 0.023376\n",
            "Train Epoch: 58 [3584/14860 (24%)]\tLoss: 0.019125\n",
            "Train Epoch: 58 [3712/14860 (25%)]\tLoss: 0.013945\n",
            "Train Epoch: 58 [3840/14860 (26%)]\tLoss: 0.020833\n",
            "Train Epoch: 58 [3968/14860 (26%)]\tLoss: 0.027543\n",
            "Train Epoch: 58 [4096/14860 (27%)]\tLoss: 0.020613\n",
            "Train Epoch: 58 [4224/14860 (28%)]\tLoss: 0.021539\n",
            "Train Epoch: 58 [4352/14860 (29%)]\tLoss: 0.021553\n",
            "Train Epoch: 58 [4480/14860 (30%)]\tLoss: 0.016709\n",
            "Train Epoch: 58 [4608/14860 (31%)]\tLoss: 0.024090\n",
            "Train Epoch: 58 [4736/14860 (32%)]\tLoss: 0.020950\n",
            "Train Epoch: 58 [4864/14860 (32%)]\tLoss: 0.018115\n",
            "Train Epoch: 58 [4992/14860 (33%)]\tLoss: 0.022389\n",
            "Train Epoch: 58 [5120/14860 (34%)]\tLoss: 0.015844\n",
            "Train Epoch: 58 [5248/14860 (35%)]\tLoss: 0.016891\n",
            "Train Epoch: 58 [5376/14860 (36%)]\tLoss: 0.030437\n",
            "Train Epoch: 58 [5504/14860 (37%)]\tLoss: 0.019742\n",
            "Train Epoch: 58 [5632/14860 (38%)]\tLoss: 0.019856\n",
            "Train Epoch: 58 [5760/14860 (38%)]\tLoss: 0.013922\n",
            "Train Epoch: 58 [5888/14860 (39%)]\tLoss: 0.022848\n",
            "Train Epoch: 58 [6016/14860 (40%)]\tLoss: 0.031811\n",
            "Train Epoch: 58 [6144/14860 (41%)]\tLoss: 0.024961\n",
            "Train Epoch: 58 [6272/14860 (42%)]\tLoss: 0.022578\n",
            "Train Epoch: 58 [6400/14860 (43%)]\tLoss: 0.014501\n",
            "Train Epoch: 58 [6528/14860 (44%)]\tLoss: 0.018521\n",
            "Train Epoch: 58 [6656/14860 (44%)]\tLoss: 0.015547\n",
            "Train Epoch: 58 [6784/14860 (45%)]\tLoss: 0.017205\n",
            "Train Epoch: 58 [6912/14860 (46%)]\tLoss: 0.018585\n",
            "Train Epoch: 58 [7040/14860 (47%)]\tLoss: 0.024475\n",
            "Train Epoch: 58 [7168/14860 (48%)]\tLoss: 0.016770\n",
            "Train Epoch: 58 [7296/14860 (49%)]\tLoss: 0.027301\n",
            "Train Epoch: 58 [7424/14860 (50%)]\tLoss: 0.017311\n",
            "Train Epoch: 58 [7552/14860 (50%)]\tLoss: 0.018424\n",
            "Train Epoch: 58 [7680/14860 (51%)]\tLoss: 0.016987\n",
            "Train Epoch: 58 [7808/14860 (52%)]\tLoss: 0.015471\n",
            "Train Epoch: 58 [7936/14860 (53%)]\tLoss: 0.017338\n",
            "Train Epoch: 58 [8064/14860 (54%)]\tLoss: 0.017650\n",
            "Train Epoch: 58 [8192/14860 (55%)]\tLoss: 0.015654\n",
            "Train Epoch: 58 [8320/14860 (56%)]\tLoss: 0.012520\n",
            "Train Epoch: 58 [8448/14860 (56%)]\tLoss: 0.021953\n",
            "Train Epoch: 58 [8576/14860 (57%)]\tLoss: 0.022704\n",
            "Train Epoch: 58 [8704/14860 (58%)]\tLoss: 0.023098\n",
            "Train Epoch: 58 [8832/14860 (59%)]\tLoss: 0.016415\n",
            "Train Epoch: 58 [8960/14860 (60%)]\tLoss: 0.017838\n",
            "Train Epoch: 58 [9088/14860 (61%)]\tLoss: 0.023182\n",
            "Train Epoch: 58 [9216/14860 (62%)]\tLoss: 0.017731\n",
            "Train Epoch: 58 [9344/14860 (62%)]\tLoss: 0.019796\n",
            "Train Epoch: 58 [9472/14860 (63%)]\tLoss: 0.019405\n",
            "Train Epoch: 58 [9600/14860 (64%)]\tLoss: 0.018637\n",
            "Train Epoch: 58 [9728/14860 (65%)]\tLoss: 0.018494\n",
            "Train Epoch: 58 [9856/14860 (66%)]\tLoss: 0.017455\n",
            "Train Epoch: 58 [9984/14860 (67%)]\tLoss: 0.019951\n",
            "Train Epoch: 58 [10112/14860 (68%)]\tLoss: 0.021004\n",
            "Train Epoch: 58 [10240/14860 (68%)]\tLoss: 0.014895\n",
            "Train Epoch: 58 [10368/14860 (69%)]\tLoss: 0.023229\n",
            "Train Epoch: 58 [10496/14860 (70%)]\tLoss: 0.029766\n",
            "Train Epoch: 58 [10624/14860 (71%)]\tLoss: 0.025616\n",
            "Train Epoch: 58 [10752/14860 (72%)]\tLoss: 0.017936\n",
            "Train Epoch: 58 [10880/14860 (73%)]\tLoss: 0.023092\n",
            "Train Epoch: 58 [11008/14860 (74%)]\tLoss: 0.013774\n",
            "Train Epoch: 58 [11136/14860 (74%)]\tLoss: 0.020702\n",
            "Train Epoch: 58 [11264/14860 (75%)]\tLoss: 0.023143\n",
            "Train Epoch: 58 [11392/14860 (76%)]\tLoss: 0.019383\n",
            "Train Epoch: 58 [11520/14860 (77%)]\tLoss: 0.019268\n",
            "Train Epoch: 58 [11648/14860 (78%)]\tLoss: 0.016798\n",
            "Train Epoch: 58 [11776/14860 (79%)]\tLoss: 0.020769\n",
            "Train Epoch: 58 [11904/14860 (79%)]\tLoss: 0.026185\n",
            "Train Epoch: 58 [12032/14860 (80%)]\tLoss: 0.017268\n",
            "Train Epoch: 58 [12160/14860 (81%)]\tLoss: 0.022170\n",
            "Train Epoch: 58 [12288/14860 (82%)]\tLoss: 0.020067\n",
            "Train Epoch: 58 [12416/14860 (83%)]\tLoss: 0.017056\n",
            "Train Epoch: 58 [12544/14860 (84%)]\tLoss: 0.019411\n",
            "Train Epoch: 58 [12672/14860 (85%)]\tLoss: 0.021039\n",
            "Train Epoch: 58 [12800/14860 (85%)]\tLoss: 0.013194\n",
            "Train Epoch: 58 [12928/14860 (86%)]\tLoss: 0.021820\n",
            "Train Epoch: 58 [13056/14860 (87%)]\tLoss: 0.022994\n",
            "Train Epoch: 58 [13184/14860 (88%)]\tLoss: 0.019374\n",
            "Train Epoch: 58 [13312/14860 (89%)]\tLoss: 0.022042\n",
            "Train Epoch: 58 [13440/14860 (90%)]\tLoss: 0.016771\n",
            "Train Epoch: 58 [13568/14860 (91%)]\tLoss: 0.013174\n",
            "Train Epoch: 58 [13696/14860 (91%)]\tLoss: 0.017013\n",
            "Train Epoch: 58 [13824/14860 (92%)]\tLoss: 0.012146\n",
            "Train Epoch: 58 [13952/14860 (93%)]\tLoss: 0.021715\n",
            "Train Epoch: 58 [14080/14860 (94%)]\tLoss: 0.016909\n",
            "Train Epoch: 58 [14208/14860 (95%)]\tLoss: 0.022150\n",
            "Train Epoch: 58 [14336/14860 (96%)]\tLoss: 0.017383\n",
            "Train Epoch: 58 [14464/14860 (97%)]\tLoss: 0.023319\n",
            "Train Epoch: 58 [14592/14860 (97%)]\tLoss: 0.018875\n",
            "Train Epoch: 58 [14720/14860 (98%)]\tLoss: 0.023587\n",
            "Train Epoch: 58 [1392/14860 (99%)]\tLoss: 0.015429\n",
            "epoch 58 training loss: 0.019953249014404595\n",
            "epoch 58 validation loss: 0.02034164889384124\n",
            "Train Epoch: 59 [0/14860 (0%)]\tLoss: 0.017786\n",
            "Train Epoch: 59 [128/14860 (1%)]\tLoss: 0.016833\n",
            "Train Epoch: 59 [256/14860 (2%)]\tLoss: 0.021185\n",
            "Train Epoch: 59 [384/14860 (3%)]\tLoss: 0.024984\n",
            "Train Epoch: 59 [512/14860 (3%)]\tLoss: 0.020119\n",
            "Train Epoch: 59 [640/14860 (4%)]\tLoss: 0.025054\n",
            "Train Epoch: 59 [768/14860 (5%)]\tLoss: 0.011810\n",
            "Train Epoch: 59 [896/14860 (6%)]\tLoss: 0.021308\n",
            "Train Epoch: 59 [1024/14860 (7%)]\tLoss: 0.015488\n",
            "Train Epoch: 59 [1152/14860 (8%)]\tLoss: 0.016765\n",
            "Train Epoch: 59 [1280/14860 (9%)]\tLoss: 0.019644\n",
            "Train Epoch: 59 [1408/14860 (9%)]\tLoss: 0.022796\n",
            "Train Epoch: 59 [1536/14860 (10%)]\tLoss: 0.018559\n",
            "Train Epoch: 59 [1664/14860 (11%)]\tLoss: 0.029387\n",
            "Train Epoch: 59 [1792/14860 (12%)]\tLoss: 0.025264\n",
            "Train Epoch: 59 [1920/14860 (13%)]\tLoss: 0.016321\n",
            "Train Epoch: 59 [2048/14860 (14%)]\tLoss: 0.020889\n",
            "Train Epoch: 59 [2176/14860 (15%)]\tLoss: 0.016905\n",
            "Train Epoch: 59 [2304/14860 (15%)]\tLoss: 0.017631\n",
            "Train Epoch: 59 [2432/14860 (16%)]\tLoss: 0.020295\n",
            "Train Epoch: 59 [2560/14860 (17%)]\tLoss: 0.018602\n",
            "Train Epoch: 59 [2688/14860 (18%)]\tLoss: 0.013949\n",
            "Train Epoch: 59 [2816/14860 (19%)]\tLoss: 0.019691\n",
            "Train Epoch: 59 [2944/14860 (20%)]\tLoss: 0.017674\n",
            "Train Epoch: 59 [3072/14860 (21%)]\tLoss: 0.019134\n",
            "Train Epoch: 59 [3200/14860 (21%)]\tLoss: 0.016109\n",
            "Train Epoch: 59 [3328/14860 (22%)]\tLoss: 0.026561\n",
            "Train Epoch: 59 [3456/14860 (23%)]\tLoss: 0.015145\n",
            "Train Epoch: 59 [3584/14860 (24%)]\tLoss: 0.014278\n",
            "Train Epoch: 59 [3712/14860 (25%)]\tLoss: 0.018288\n",
            "Train Epoch: 59 [3840/14860 (26%)]\tLoss: 0.020626\n",
            "Train Epoch: 59 [3968/14860 (26%)]\tLoss: 0.018309\n",
            "Train Epoch: 59 [4096/14860 (27%)]\tLoss: 0.018157\n",
            "Train Epoch: 59 [4224/14860 (28%)]\tLoss: 0.023542\n",
            "Train Epoch: 59 [4352/14860 (29%)]\tLoss: 0.017240\n",
            "Train Epoch: 59 [4480/14860 (30%)]\tLoss: 0.012737\n",
            "Train Epoch: 59 [4608/14860 (31%)]\tLoss: 0.017398\n",
            "Train Epoch: 59 [4736/14860 (32%)]\tLoss: 0.015171\n",
            "Train Epoch: 59 [4864/14860 (32%)]\tLoss: 0.024113\n",
            "Train Epoch: 59 [4992/14860 (33%)]\tLoss: 0.020867\n",
            "Train Epoch: 59 [5120/14860 (34%)]\tLoss: 0.020579\n",
            "Train Epoch: 59 [5248/14860 (35%)]\tLoss: 0.027295\n",
            "Train Epoch: 59 [5376/14860 (36%)]\tLoss: 0.017174\n",
            "Train Epoch: 59 [5504/14860 (37%)]\tLoss: 0.016015\n",
            "Train Epoch: 59 [5632/14860 (38%)]\tLoss: 0.021618\n",
            "Train Epoch: 59 [5760/14860 (38%)]\tLoss: 0.017783\n",
            "Train Epoch: 59 [5888/14860 (39%)]\tLoss: 0.014020\n",
            "Train Epoch: 59 [6016/14860 (40%)]\tLoss: 0.019520\n",
            "Train Epoch: 59 [6144/14860 (41%)]\tLoss: 0.027733\n",
            "Train Epoch: 59 [6272/14860 (42%)]\tLoss: 0.020115\n",
            "Train Epoch: 59 [6400/14860 (43%)]\tLoss: 0.016108\n",
            "Train Epoch: 59 [6528/14860 (44%)]\tLoss: 0.015805\n",
            "Train Epoch: 59 [6656/14860 (44%)]\tLoss: 0.021646\n",
            "Train Epoch: 59 [6784/14860 (45%)]\tLoss: 0.020087\n",
            "Train Epoch: 59 [6912/14860 (46%)]\tLoss: 0.013100\n",
            "Train Epoch: 59 [7040/14860 (47%)]\tLoss: 0.022463\n",
            "Train Epoch: 59 [7168/14860 (48%)]\tLoss: 0.015745\n",
            "Train Epoch: 59 [7296/14860 (49%)]\tLoss: 0.027750\n",
            "Train Epoch: 59 [7424/14860 (50%)]\tLoss: 0.017851\n",
            "Train Epoch: 59 [7552/14860 (50%)]\tLoss: 0.021560\n",
            "Train Epoch: 59 [7680/14860 (51%)]\tLoss: 0.019843\n",
            "Train Epoch: 59 [7808/14860 (52%)]\tLoss: 0.013132\n",
            "Train Epoch: 59 [7936/14860 (53%)]\tLoss: 0.017144\n",
            "Train Epoch: 59 [8064/14860 (54%)]\tLoss: 0.015933\n",
            "Train Epoch: 59 [8192/14860 (55%)]\tLoss: 0.021950\n",
            "Train Epoch: 59 [8320/14860 (56%)]\tLoss: 0.018182\n",
            "Train Epoch: 59 [8448/14860 (56%)]\tLoss: 0.018713\n",
            "Train Epoch: 59 [8576/14860 (57%)]\tLoss: 0.023444\n",
            "Train Epoch: 59 [8704/14860 (58%)]\tLoss: 0.014059\n",
            "Train Epoch: 59 [8832/14860 (59%)]\tLoss: 0.021722\n",
            "Train Epoch: 59 [8960/14860 (60%)]\tLoss: 0.033886\n",
            "Train Epoch: 59 [9088/14860 (61%)]\tLoss: 0.017524\n",
            "Train Epoch: 59 [9216/14860 (62%)]\tLoss: 0.018919\n",
            "Train Epoch: 59 [9344/14860 (62%)]\tLoss: 0.019800\n",
            "Train Epoch: 59 [9472/14860 (63%)]\tLoss: 0.017244\n",
            "Train Epoch: 59 [9600/14860 (64%)]\tLoss: 0.018499\n",
            "Train Epoch: 59 [9728/14860 (65%)]\tLoss: 0.017468\n",
            "Train Epoch: 59 [9856/14860 (66%)]\tLoss: 0.019663\n",
            "Train Epoch: 59 [9984/14860 (67%)]\tLoss: 0.022999\n",
            "Train Epoch: 59 [10112/14860 (68%)]\tLoss: 0.019497\n",
            "Train Epoch: 59 [10240/14860 (68%)]\tLoss: 0.016719\n",
            "Train Epoch: 59 [10368/14860 (69%)]\tLoss: 0.020487\n",
            "Train Epoch: 59 [10496/14860 (70%)]\tLoss: 0.024154\n",
            "Train Epoch: 59 [10624/14860 (71%)]\tLoss: 0.028565\n",
            "Train Epoch: 59 [10752/14860 (72%)]\tLoss: 0.015524\n",
            "Train Epoch: 59 [10880/14860 (73%)]\tLoss: 0.023033\n",
            "Train Epoch: 59 [11008/14860 (74%)]\tLoss: 0.021880\n",
            "Train Epoch: 59 [11136/14860 (74%)]\tLoss: 0.024433\n",
            "Train Epoch: 59 [11264/14860 (75%)]\tLoss: 0.024221\n",
            "Train Epoch: 59 [11392/14860 (76%)]\tLoss: 0.018165\n",
            "Train Epoch: 59 [11520/14860 (77%)]\tLoss: 0.027364\n",
            "Train Epoch: 59 [11648/14860 (78%)]\tLoss: 0.028588\n",
            "Train Epoch: 59 [11776/14860 (79%)]\tLoss: 0.021161\n",
            "Train Epoch: 59 [11904/14860 (79%)]\tLoss: 0.025606\n",
            "Train Epoch: 59 [12032/14860 (80%)]\tLoss: 0.018364\n",
            "Train Epoch: 59 [12160/14860 (81%)]\tLoss: 0.018024\n",
            "Train Epoch: 59 [12288/14860 (82%)]\tLoss: 0.022044\n",
            "Train Epoch: 59 [12416/14860 (83%)]\tLoss: 0.026183\n",
            "Train Epoch: 59 [12544/14860 (84%)]\tLoss: 0.014311\n",
            "Train Epoch: 59 [12672/14860 (85%)]\tLoss: 0.017781\n",
            "Train Epoch: 59 [12800/14860 (85%)]\tLoss: 0.020071\n",
            "Train Epoch: 59 [12928/14860 (86%)]\tLoss: 0.013859\n",
            "Train Epoch: 59 [13056/14860 (87%)]\tLoss: 0.020448\n",
            "Train Epoch: 59 [13184/14860 (88%)]\tLoss: 0.009105\n",
            "Train Epoch: 59 [13312/14860 (89%)]\tLoss: 0.024302\n",
            "Train Epoch: 59 [13440/14860 (90%)]\tLoss: 0.023400\n",
            "Train Epoch: 59 [13568/14860 (91%)]\tLoss: 0.021119\n",
            "Train Epoch: 59 [13696/14860 (91%)]\tLoss: 0.018307\n",
            "Train Epoch: 59 [13824/14860 (92%)]\tLoss: 0.024603\n",
            "Train Epoch: 59 [13952/14860 (93%)]\tLoss: 0.019614\n",
            "Train Epoch: 59 [14080/14860 (94%)]\tLoss: 0.021011\n",
            "Train Epoch: 59 [14208/14860 (95%)]\tLoss: 0.023028\n",
            "Train Epoch: 59 [14336/14860 (96%)]\tLoss: 0.014029\n",
            "Train Epoch: 59 [14464/14860 (97%)]\tLoss: 0.028399\n",
            "Train Epoch: 59 [14592/14860 (97%)]\tLoss: 0.017530\n",
            "Train Epoch: 59 [14720/14860 (98%)]\tLoss: 0.016215\n",
            "Train Epoch: 59 [1392/14860 (99%)]\tLoss: 0.018443\n",
            "epoch 59 training loss: 0.019831596738380246\n",
            "epoch 59 validation loss: 0.02649703686808847\n",
            "Train Epoch: 60 [0/14860 (0%)]\tLoss: 0.022498\n",
            "Train Epoch: 60 [128/14860 (1%)]\tLoss: 0.018879\n",
            "Train Epoch: 60 [256/14860 (2%)]\tLoss: 0.024118\n",
            "Train Epoch: 60 [384/14860 (3%)]\tLoss: 0.020825\n",
            "Train Epoch: 60 [512/14860 (3%)]\tLoss: 0.018453\n",
            "Train Epoch: 60 [640/14860 (4%)]\tLoss: 0.019538\n",
            "Train Epoch: 60 [768/14860 (5%)]\tLoss: 0.031764\n",
            "Train Epoch: 60 [896/14860 (6%)]\tLoss: 0.018127\n",
            "Train Epoch: 60 [1024/14860 (7%)]\tLoss: 0.018087\n",
            "Train Epoch: 60 [1152/14860 (8%)]\tLoss: 0.026102\n",
            "Train Epoch: 60 [1280/14860 (9%)]\tLoss: 0.016856\n",
            "Train Epoch: 60 [1408/14860 (9%)]\tLoss: 0.012962\n",
            "Train Epoch: 60 [1536/14860 (10%)]\tLoss: 0.021239\n",
            "Train Epoch: 60 [1664/14860 (11%)]\tLoss: 0.022128\n",
            "Train Epoch: 60 [1792/14860 (12%)]\tLoss: 0.020228\n",
            "Train Epoch: 60 [1920/14860 (13%)]\tLoss: 0.021589\n",
            "Train Epoch: 60 [2048/14860 (14%)]\tLoss: 0.017187\n",
            "Train Epoch: 60 [2176/14860 (15%)]\tLoss: 0.018242\n",
            "Train Epoch: 60 [2304/14860 (15%)]\tLoss: 0.019021\n",
            "Train Epoch: 60 [2432/14860 (16%)]\tLoss: 0.023277\n",
            "Train Epoch: 60 [2560/14860 (17%)]\tLoss: 0.015747\n",
            "Train Epoch: 60 [2688/14860 (18%)]\tLoss: 0.026498\n",
            "Train Epoch: 60 [2816/14860 (19%)]\tLoss: 0.020827\n",
            "Train Epoch: 60 [2944/14860 (20%)]\tLoss: 0.016178\n",
            "Train Epoch: 60 [3072/14860 (21%)]\tLoss: 0.015511\n",
            "Train Epoch: 60 [3200/14860 (21%)]\tLoss: 0.017567\n",
            "Train Epoch: 60 [3328/14860 (22%)]\tLoss: 0.017778\n",
            "Train Epoch: 60 [3456/14860 (23%)]\tLoss: 0.021500\n",
            "Train Epoch: 60 [3584/14860 (24%)]\tLoss: 0.024292\n",
            "Train Epoch: 60 [3712/14860 (25%)]\tLoss: 0.019487\n",
            "Train Epoch: 60 [3840/14860 (26%)]\tLoss: 0.014258\n",
            "Train Epoch: 60 [3968/14860 (26%)]\tLoss: 0.023878\n",
            "Train Epoch: 60 [4096/14860 (27%)]\tLoss: 0.018265\n",
            "Train Epoch: 60 [4224/14860 (28%)]\tLoss: 0.012243\n",
            "Train Epoch: 60 [4352/14860 (29%)]\tLoss: 0.015527\n",
            "Train Epoch: 60 [4480/14860 (30%)]\tLoss: 0.015945\n",
            "Train Epoch: 60 [4608/14860 (31%)]\tLoss: 0.016796\n",
            "Train Epoch: 60 [4736/14860 (32%)]\tLoss: 0.016495\n",
            "Train Epoch: 60 [4864/14860 (32%)]\tLoss: 0.021079\n",
            "Train Epoch: 60 [4992/14860 (33%)]\tLoss: 0.021162\n",
            "Train Epoch: 60 [5120/14860 (34%)]\tLoss: 0.020219\n",
            "Train Epoch: 60 [5248/14860 (35%)]\tLoss: 0.016806\n",
            "Train Epoch: 60 [5376/14860 (36%)]\tLoss: 0.028418\n",
            "Train Epoch: 60 [5504/14860 (37%)]\tLoss: 0.016989\n",
            "Train Epoch: 60 [5632/14860 (38%)]\tLoss: 0.020724\n",
            "Train Epoch: 60 [5760/14860 (38%)]\tLoss: 0.019975\n",
            "Train Epoch: 60 [5888/14860 (39%)]\tLoss: 0.016839\n",
            "Train Epoch: 60 [6016/14860 (40%)]\tLoss: 0.016211\n",
            "Train Epoch: 60 [6144/14860 (41%)]\tLoss: 0.023809\n",
            "Train Epoch: 60 [6272/14860 (42%)]\tLoss: 0.017346\n",
            "Train Epoch: 60 [6400/14860 (43%)]\tLoss: 0.024717\n",
            "Train Epoch: 60 [6528/14860 (44%)]\tLoss: 0.018156\n",
            "Train Epoch: 60 [6656/14860 (44%)]\tLoss: 0.025492\n",
            "Train Epoch: 60 [6784/14860 (45%)]\tLoss: 0.031269\n",
            "Train Epoch: 60 [6912/14860 (46%)]\tLoss: 0.015310\n",
            "Train Epoch: 60 [7040/14860 (47%)]\tLoss: 0.022850\n",
            "Train Epoch: 60 [7168/14860 (48%)]\tLoss: 0.019707\n",
            "Train Epoch: 60 [7296/14860 (49%)]\tLoss: 0.024943\n",
            "Train Epoch: 60 [7424/14860 (50%)]\tLoss: 0.014768\n",
            "Train Epoch: 60 [7552/14860 (50%)]\tLoss: 0.017296\n",
            "Train Epoch: 60 [7680/14860 (51%)]\tLoss: 0.026079\n",
            "Train Epoch: 60 [7808/14860 (52%)]\tLoss: 0.011655\n",
            "Train Epoch: 60 [7936/14860 (53%)]\tLoss: 0.020836\n",
            "Train Epoch: 60 [8064/14860 (54%)]\tLoss: 0.016719\n",
            "Train Epoch: 60 [8192/14860 (55%)]\tLoss: 0.014922\n",
            "Train Epoch: 60 [8320/14860 (56%)]\tLoss: 0.025575\n",
            "Train Epoch: 60 [8448/14860 (56%)]\tLoss: 0.014566\n",
            "Train Epoch: 60 [8576/14860 (57%)]\tLoss: 0.013332\n",
            "Train Epoch: 60 [8704/14860 (58%)]\tLoss: 0.015084\n",
            "Train Epoch: 60 [8832/14860 (59%)]\tLoss: 0.015055\n",
            "Train Epoch: 60 [8960/14860 (60%)]\tLoss: 0.019046\n",
            "Train Epoch: 60 [9088/14860 (61%)]\tLoss: 0.015833\n",
            "Train Epoch: 60 [9216/14860 (62%)]\tLoss: 0.015973\n",
            "Train Epoch: 60 [9344/14860 (62%)]\tLoss: 0.017209\n",
            "Train Epoch: 60 [9472/14860 (63%)]\tLoss: 0.025740\n",
            "Train Epoch: 60 [9600/14860 (64%)]\tLoss: 0.021761\n",
            "Train Epoch: 60 [9728/14860 (65%)]\tLoss: 0.023718\n",
            "Train Epoch: 60 [9856/14860 (66%)]\tLoss: 0.018341\n",
            "Train Epoch: 60 [9984/14860 (67%)]\tLoss: 0.023980\n",
            "Train Epoch: 60 [10112/14860 (68%)]\tLoss: 0.018594\n",
            "Train Epoch: 60 [10240/14860 (68%)]\tLoss: 0.020243\n",
            "Train Epoch: 60 [10368/14860 (69%)]\tLoss: 0.018647\n",
            "Train Epoch: 60 [10496/14860 (70%)]\tLoss: 0.020043\n",
            "Train Epoch: 60 [10624/14860 (71%)]\tLoss: 0.020360\n",
            "Train Epoch: 60 [10752/14860 (72%)]\tLoss: 0.013726\n",
            "Train Epoch: 60 [10880/14860 (73%)]\tLoss: 0.015351\n",
            "Train Epoch: 60 [11008/14860 (74%)]\tLoss: 0.033451\n",
            "Train Epoch: 60 [11136/14860 (74%)]\tLoss: 0.025294\n",
            "Train Epoch: 60 [11264/14860 (75%)]\tLoss: 0.018576\n",
            "Train Epoch: 60 [11392/14860 (76%)]\tLoss: 0.014594\n",
            "Train Epoch: 60 [11520/14860 (77%)]\tLoss: 0.018427\n",
            "Train Epoch: 60 [11648/14860 (78%)]\tLoss: 0.013657\n",
            "Train Epoch: 60 [11776/14860 (79%)]\tLoss: 0.019575\n",
            "Train Epoch: 60 [11904/14860 (79%)]\tLoss: 0.019892\n",
            "Train Epoch: 60 [12032/14860 (80%)]\tLoss: 0.013877\n",
            "Train Epoch: 60 [12160/14860 (81%)]\tLoss: 0.020891\n",
            "Train Epoch: 60 [12288/14860 (82%)]\tLoss: 0.020630\n",
            "Train Epoch: 60 [12416/14860 (83%)]\tLoss: 0.021419\n",
            "Train Epoch: 60 [12544/14860 (84%)]\tLoss: 0.026352\n",
            "Train Epoch: 60 [12672/14860 (85%)]\tLoss: 0.022245\n",
            "Train Epoch: 60 [12800/14860 (85%)]\tLoss: 0.014185\n",
            "Train Epoch: 60 [12928/14860 (86%)]\tLoss: 0.020171\n",
            "Train Epoch: 60 [13056/14860 (87%)]\tLoss: 0.020726\n",
            "Train Epoch: 60 [13184/14860 (88%)]\tLoss: 0.022468\n",
            "Train Epoch: 60 [13312/14860 (89%)]\tLoss: 0.023473\n",
            "Train Epoch: 60 [13440/14860 (90%)]\tLoss: 0.022593\n",
            "Train Epoch: 60 [13568/14860 (91%)]\tLoss: 0.020317\n",
            "Train Epoch: 60 [13696/14860 (91%)]\tLoss: 0.026174\n",
            "Train Epoch: 60 [13824/14860 (92%)]\tLoss: 0.020482\n",
            "Train Epoch: 60 [13952/14860 (93%)]\tLoss: 0.019232\n",
            "Train Epoch: 60 [14080/14860 (94%)]\tLoss: 0.014586\n",
            "Train Epoch: 60 [14208/14860 (95%)]\tLoss: 0.028900\n",
            "Train Epoch: 60 [14336/14860 (96%)]\tLoss: 0.020208\n",
            "Train Epoch: 60 [14464/14860 (97%)]\tLoss: 0.016885\n",
            "Train Epoch: 60 [14592/14860 (97%)]\tLoss: 0.020760\n",
            "Train Epoch: 60 [14720/14860 (98%)]\tLoss: 0.024631\n",
            "Train Epoch: 60 [1392/14860 (99%)]\tLoss: 0.006898\n",
            "epoch 60 training loss: 0.019726119430051144\n",
            "epoch 60 validation loss: 0.026547832725700396\n",
            "Train Epoch: 61 [0/14860 (0%)]\tLoss: 0.023094\n",
            "Train Epoch: 61 [128/14860 (1%)]\tLoss: 0.023216\n",
            "Train Epoch: 61 [256/14860 (2%)]\tLoss: 0.019442\n",
            "Train Epoch: 61 [384/14860 (3%)]\tLoss: 0.022862\n",
            "Train Epoch: 61 [512/14860 (3%)]\tLoss: 0.023698\n",
            "Train Epoch: 61 [640/14860 (4%)]\tLoss: 0.024668\n",
            "Train Epoch: 61 [768/14860 (5%)]\tLoss: 0.021559\n",
            "Train Epoch: 61 [896/14860 (6%)]\tLoss: 0.019246\n",
            "Train Epoch: 61 [1024/14860 (7%)]\tLoss: 0.025010\n",
            "Train Epoch: 61 [1152/14860 (8%)]\tLoss: 0.030838\n",
            "Train Epoch: 61 [1280/14860 (9%)]\tLoss: 0.025232\n",
            "Train Epoch: 61 [1408/14860 (9%)]\tLoss: 0.021515\n",
            "Train Epoch: 61 [1536/14860 (10%)]\tLoss: 0.018757\n",
            "Train Epoch: 61 [1664/14860 (11%)]\tLoss: 0.014141\n",
            "Train Epoch: 61 [1792/14860 (12%)]\tLoss: 0.019629\n",
            "Train Epoch: 61 [1920/14860 (13%)]\tLoss: 0.020881\n",
            "Train Epoch: 61 [2048/14860 (14%)]\tLoss: 0.018114\n",
            "Train Epoch: 61 [2176/14860 (15%)]\tLoss: 0.018654\n",
            "Train Epoch: 61 [2304/14860 (15%)]\tLoss: 0.021249\n",
            "Train Epoch: 61 [2432/14860 (16%)]\tLoss: 0.014606\n",
            "Train Epoch: 61 [2560/14860 (17%)]\tLoss: 0.026298\n",
            "Train Epoch: 61 [2688/14860 (18%)]\tLoss: 0.024853\n",
            "Train Epoch: 61 [2816/14860 (19%)]\tLoss: 0.017816\n",
            "Train Epoch: 61 [2944/14860 (20%)]\tLoss: 0.023719\n",
            "Train Epoch: 61 [3072/14860 (21%)]\tLoss: 0.016202\n",
            "Train Epoch: 61 [3200/14860 (21%)]\tLoss: 0.016802\n",
            "Train Epoch: 61 [3328/14860 (22%)]\tLoss: 0.020698\n",
            "Train Epoch: 61 [3456/14860 (23%)]\tLoss: 0.022997\n",
            "Train Epoch: 61 [3584/14860 (24%)]\tLoss: 0.017482\n",
            "Train Epoch: 61 [3712/14860 (25%)]\tLoss: 0.025460\n",
            "Train Epoch: 61 [3840/14860 (26%)]\tLoss: 0.021120\n",
            "Train Epoch: 61 [3968/14860 (26%)]\tLoss: 0.021607\n",
            "Train Epoch: 61 [4096/14860 (27%)]\tLoss: 0.019642\n",
            "Train Epoch: 61 [4224/14860 (28%)]\tLoss: 0.021339\n",
            "Train Epoch: 61 [4352/14860 (29%)]\tLoss: 0.017269\n",
            "Train Epoch: 61 [4480/14860 (30%)]\tLoss: 0.024858\n",
            "Train Epoch: 61 [4608/14860 (31%)]\tLoss: 0.026471\n",
            "Train Epoch: 61 [4736/14860 (32%)]\tLoss: 0.023894\n",
            "Train Epoch: 61 [4864/14860 (32%)]\tLoss: 0.015617\n",
            "Train Epoch: 61 [4992/14860 (33%)]\tLoss: 0.017300\n",
            "Train Epoch: 61 [5120/14860 (34%)]\tLoss: 0.025336\n",
            "Train Epoch: 61 [5248/14860 (35%)]\tLoss: 0.022162\n",
            "Train Epoch: 61 [5376/14860 (36%)]\tLoss: 0.016776\n",
            "Train Epoch: 61 [5504/14860 (37%)]\tLoss: 0.019897\n",
            "Train Epoch: 61 [5632/14860 (38%)]\tLoss: 0.022036\n",
            "Train Epoch: 61 [5760/14860 (38%)]\tLoss: 0.019302\n",
            "Train Epoch: 61 [5888/14860 (39%)]\tLoss: 0.020174\n",
            "Train Epoch: 61 [6016/14860 (40%)]\tLoss: 0.028646\n",
            "Train Epoch: 61 [6144/14860 (41%)]\tLoss: 0.016862\n",
            "Train Epoch: 61 [6272/14860 (42%)]\tLoss: 0.021283\n",
            "Train Epoch: 61 [6400/14860 (43%)]\tLoss: 0.023323\n",
            "Train Epoch: 61 [6528/14860 (44%)]\tLoss: 0.015085\n",
            "Train Epoch: 61 [6656/14860 (44%)]\tLoss: 0.018330\n",
            "Train Epoch: 61 [6784/14860 (45%)]\tLoss: 0.021869\n",
            "Train Epoch: 61 [6912/14860 (46%)]\tLoss: 0.023211\n",
            "Train Epoch: 61 [7040/14860 (47%)]\tLoss: 0.018537\n",
            "Train Epoch: 61 [7168/14860 (48%)]\tLoss: 0.016099\n",
            "Train Epoch: 61 [7296/14860 (49%)]\tLoss: 0.021078\n",
            "Train Epoch: 61 [7424/14860 (50%)]\tLoss: 0.018756\n",
            "Train Epoch: 61 [7552/14860 (50%)]\tLoss: 0.022533\n",
            "Train Epoch: 61 [7680/14860 (51%)]\tLoss: 0.015559\n",
            "Train Epoch: 61 [7808/14860 (52%)]\tLoss: 0.020108\n",
            "Train Epoch: 61 [7936/14860 (53%)]\tLoss: 0.016225\n",
            "Train Epoch: 61 [8064/14860 (54%)]\tLoss: 0.021242\n",
            "Train Epoch: 61 [8192/14860 (55%)]\tLoss: 0.019493\n",
            "Train Epoch: 61 [8320/14860 (56%)]\tLoss: 0.019109\n",
            "Train Epoch: 61 [8448/14860 (56%)]\tLoss: 0.021742\n",
            "Train Epoch: 61 [8576/14860 (57%)]\tLoss: 0.016529\n",
            "Train Epoch: 61 [8704/14860 (58%)]\tLoss: 0.017944\n",
            "Train Epoch: 61 [8832/14860 (59%)]\tLoss: 0.031711\n",
            "Train Epoch: 61 [8960/14860 (60%)]\tLoss: 0.020514\n",
            "Train Epoch: 61 [9088/14860 (61%)]\tLoss: 0.020653\n",
            "Train Epoch: 61 [9216/14860 (62%)]\tLoss: 0.023031\n",
            "Train Epoch: 61 [9344/14860 (62%)]\tLoss: 0.020228\n",
            "Train Epoch: 61 [9472/14860 (63%)]\tLoss: 0.030394\n",
            "Train Epoch: 61 [9600/14860 (64%)]\tLoss: 0.020660\n",
            "Train Epoch: 61 [9728/14860 (65%)]\tLoss: 0.019889\n",
            "Train Epoch: 61 [9856/14860 (66%)]\tLoss: 0.018659\n",
            "Train Epoch: 61 [9984/14860 (67%)]\tLoss: 0.021589\n",
            "Train Epoch: 61 [10112/14860 (68%)]\tLoss: 0.019220\n",
            "Train Epoch: 61 [10240/14860 (68%)]\tLoss: 0.013267\n",
            "Train Epoch: 61 [10368/14860 (69%)]\tLoss: 0.022632\n",
            "Train Epoch: 61 [10496/14860 (70%)]\tLoss: 0.018730\n",
            "Train Epoch: 61 [10624/14860 (71%)]\tLoss: 0.019429\n",
            "Train Epoch: 61 [10752/14860 (72%)]\tLoss: 0.017343\n",
            "Train Epoch: 61 [10880/14860 (73%)]\tLoss: 0.017523\n",
            "Train Epoch: 61 [11008/14860 (74%)]\tLoss: 0.017790\n",
            "Train Epoch: 61 [11136/14860 (74%)]\tLoss: 0.014995\n",
            "Train Epoch: 61 [11264/14860 (75%)]\tLoss: 0.022038\n",
            "Train Epoch: 61 [11392/14860 (76%)]\tLoss: 0.019704\n",
            "Train Epoch: 61 [11520/14860 (77%)]\tLoss: 0.020555\n",
            "Train Epoch: 61 [11648/14860 (78%)]\tLoss: 0.024765\n",
            "Train Epoch: 61 [11776/14860 (79%)]\tLoss: 0.013128\n",
            "Train Epoch: 61 [11904/14860 (79%)]\tLoss: 0.014928\n",
            "Train Epoch: 61 [12032/14860 (80%)]\tLoss: 0.027616\n",
            "Train Epoch: 61 [12160/14860 (81%)]\tLoss: 0.015173\n",
            "Train Epoch: 61 [12288/14860 (82%)]\tLoss: 0.017132\n",
            "Train Epoch: 61 [12416/14860 (83%)]\tLoss: 0.012362\n",
            "Train Epoch: 61 [12544/14860 (84%)]\tLoss: 0.017294\n",
            "Train Epoch: 61 [12672/14860 (85%)]\tLoss: 0.014483\n",
            "Train Epoch: 61 [12800/14860 (85%)]\tLoss: 0.025640\n",
            "Train Epoch: 61 [12928/14860 (86%)]\tLoss: 0.016019\n",
            "Train Epoch: 61 [13056/14860 (87%)]\tLoss: 0.017441\n",
            "Train Epoch: 61 [13184/14860 (88%)]\tLoss: 0.017419\n",
            "Train Epoch: 61 [13312/14860 (89%)]\tLoss: 0.017668\n",
            "Train Epoch: 61 [13440/14860 (90%)]\tLoss: 0.022030\n",
            "Train Epoch: 61 [13568/14860 (91%)]\tLoss: 0.018804\n",
            "Train Epoch: 61 [13696/14860 (91%)]\tLoss: 0.020763\n",
            "Train Epoch: 61 [13824/14860 (92%)]\tLoss: 0.018103\n",
            "Train Epoch: 61 [13952/14860 (93%)]\tLoss: 0.016421\n",
            "Train Epoch: 61 [14080/14860 (94%)]\tLoss: 0.019703\n",
            "Train Epoch: 61 [14208/14860 (95%)]\tLoss: 0.019498\n",
            "Train Epoch: 61 [14336/14860 (96%)]\tLoss: 0.015632\n",
            "Train Epoch: 61 [14464/14860 (97%)]\tLoss: 0.019096\n",
            "Train Epoch: 61 [14592/14860 (97%)]\tLoss: 0.015768\n",
            "Train Epoch: 61 [14720/14860 (98%)]\tLoss: 0.022731\n",
            "Train Epoch: 61 [1392/14860 (99%)]\tLoss: 0.010586\n",
            "epoch 61 training loss: 0.02006714969363987\n",
            "epoch 61 validation loss: 0.020943684020862163\n",
            "Train Epoch: 62 [0/14860 (0%)]\tLoss: 0.020573\n",
            "Train Epoch: 62 [128/14860 (1%)]\tLoss: 0.016763\n",
            "Train Epoch: 62 [256/14860 (2%)]\tLoss: 0.018648\n",
            "Train Epoch: 62 [384/14860 (3%)]\tLoss: 0.017880\n",
            "Train Epoch: 62 [512/14860 (3%)]\tLoss: 0.034591\n",
            "Train Epoch: 62 [640/14860 (4%)]\tLoss: 0.013984\n",
            "Train Epoch: 62 [768/14860 (5%)]\tLoss: 0.015167\n",
            "Train Epoch: 62 [896/14860 (6%)]\tLoss: 0.018321\n",
            "Train Epoch: 62 [1024/14860 (7%)]\tLoss: 0.023747\n",
            "Train Epoch: 62 [1152/14860 (8%)]\tLoss: 0.023033\n",
            "Train Epoch: 62 [1280/14860 (9%)]\tLoss: 0.015384\n",
            "Train Epoch: 62 [1408/14860 (9%)]\tLoss: 0.016038\n",
            "Train Epoch: 62 [1536/14860 (10%)]\tLoss: 0.022689\n",
            "Train Epoch: 62 [1664/14860 (11%)]\tLoss: 0.019362\n",
            "Train Epoch: 62 [1792/14860 (12%)]\tLoss: 0.023447\n",
            "Train Epoch: 62 [1920/14860 (13%)]\tLoss: 0.021914\n",
            "Train Epoch: 62 [2048/14860 (14%)]\tLoss: 0.017802\n",
            "Train Epoch: 62 [2176/14860 (15%)]\tLoss: 0.021908\n",
            "Train Epoch: 62 [2304/14860 (15%)]\tLoss: 0.022360\n",
            "Train Epoch: 62 [2432/14860 (16%)]\tLoss: 0.024656\n",
            "Train Epoch: 62 [2560/14860 (17%)]\tLoss: 0.029458\n",
            "Train Epoch: 62 [2688/14860 (18%)]\tLoss: 0.022570\n",
            "Train Epoch: 62 [2816/14860 (19%)]\tLoss: 0.016510\n",
            "Train Epoch: 62 [2944/14860 (20%)]\tLoss: 0.022524\n",
            "Train Epoch: 62 [3072/14860 (21%)]\tLoss: 0.011083\n",
            "Train Epoch: 62 [3200/14860 (21%)]\tLoss: 0.017421\n",
            "Train Epoch: 62 [3328/14860 (22%)]\tLoss: 0.019739\n",
            "Train Epoch: 62 [3456/14860 (23%)]\tLoss: 0.021452\n",
            "Train Epoch: 62 [3584/14860 (24%)]\tLoss: 0.016418\n",
            "Train Epoch: 62 [3712/14860 (25%)]\tLoss: 0.027302\n",
            "Train Epoch: 62 [3840/14860 (26%)]\tLoss: 0.027973\n",
            "Train Epoch: 62 [3968/14860 (26%)]\tLoss: 0.020686\n",
            "Train Epoch: 62 [4096/14860 (27%)]\tLoss: 0.018714\n",
            "Train Epoch: 62 [4224/14860 (28%)]\tLoss: 0.020650\n",
            "Train Epoch: 62 [4352/14860 (29%)]\tLoss: 0.017971\n",
            "Train Epoch: 62 [4480/14860 (30%)]\tLoss: 0.019375\n",
            "Train Epoch: 62 [4608/14860 (31%)]\tLoss: 0.026568\n",
            "Train Epoch: 62 [4736/14860 (32%)]\tLoss: 0.016668\n",
            "Train Epoch: 62 [4864/14860 (32%)]\tLoss: 0.018129\n",
            "Train Epoch: 62 [4992/14860 (33%)]\tLoss: 0.015134\n",
            "Train Epoch: 62 [5120/14860 (34%)]\tLoss: 0.023304\n",
            "Train Epoch: 62 [5248/14860 (35%)]\tLoss: 0.014716\n",
            "Train Epoch: 62 [5376/14860 (36%)]\tLoss: 0.021414\n",
            "Train Epoch: 62 [5504/14860 (37%)]\tLoss: 0.013473\n",
            "Train Epoch: 62 [5632/14860 (38%)]\tLoss: 0.023335\n",
            "Train Epoch: 62 [5760/14860 (38%)]\tLoss: 0.019524\n",
            "Train Epoch: 62 [5888/14860 (39%)]\tLoss: 0.023399\n",
            "Train Epoch: 62 [6016/14860 (40%)]\tLoss: 0.015716\n",
            "Train Epoch: 62 [6144/14860 (41%)]\tLoss: 0.018154\n",
            "Train Epoch: 62 [6272/14860 (42%)]\tLoss: 0.026291\n",
            "Train Epoch: 62 [6400/14860 (43%)]\tLoss: 0.016575\n",
            "Train Epoch: 62 [6528/14860 (44%)]\tLoss: 0.023386\n",
            "Train Epoch: 62 [6656/14860 (44%)]\tLoss: 0.017099\n",
            "Train Epoch: 62 [6784/14860 (45%)]\tLoss: 0.020645\n",
            "Train Epoch: 62 [6912/14860 (46%)]\tLoss: 0.016109\n",
            "Train Epoch: 62 [7040/14860 (47%)]\tLoss: 0.021998\n",
            "Train Epoch: 62 [7168/14860 (48%)]\tLoss: 0.022008\n",
            "Train Epoch: 62 [7296/14860 (49%)]\tLoss: 0.014523\n",
            "Train Epoch: 62 [7424/14860 (50%)]\tLoss: 0.024341\n",
            "Train Epoch: 62 [7552/14860 (50%)]\tLoss: 0.020663\n",
            "Train Epoch: 62 [7680/14860 (51%)]\tLoss: 0.023029\n",
            "Train Epoch: 62 [7808/14860 (52%)]\tLoss: 0.018287\n",
            "Train Epoch: 62 [7936/14860 (53%)]\tLoss: 0.022416\n",
            "Train Epoch: 62 [8064/14860 (54%)]\tLoss: 0.021921\n",
            "Train Epoch: 62 [8192/14860 (55%)]\tLoss: 0.020925\n",
            "Train Epoch: 62 [8320/14860 (56%)]\tLoss: 0.020865\n",
            "Train Epoch: 62 [8448/14860 (56%)]\tLoss: 0.019475\n",
            "Train Epoch: 62 [8576/14860 (57%)]\tLoss: 0.015375\n",
            "Train Epoch: 62 [8704/14860 (58%)]\tLoss: 0.021529\n",
            "Train Epoch: 62 [8832/14860 (59%)]\tLoss: 0.018353\n",
            "Train Epoch: 62 [8960/14860 (60%)]\tLoss: 0.019453\n",
            "Train Epoch: 62 [9088/14860 (61%)]\tLoss: 0.016149\n",
            "Train Epoch: 62 [9216/14860 (62%)]\tLoss: 0.016954\n",
            "Train Epoch: 62 [9344/14860 (62%)]\tLoss: 0.018582\n",
            "Train Epoch: 62 [9472/14860 (63%)]\tLoss: 0.023296\n",
            "Train Epoch: 62 [9600/14860 (64%)]\tLoss: 0.014690\n",
            "Train Epoch: 62 [9728/14860 (65%)]\tLoss: 0.017651\n",
            "Train Epoch: 62 [9856/14860 (66%)]\tLoss: 0.023373\n",
            "Train Epoch: 62 [9984/14860 (67%)]\tLoss: 0.022338\n",
            "Train Epoch: 62 [10112/14860 (68%)]\tLoss: 0.017455\n",
            "Train Epoch: 62 [10240/14860 (68%)]\tLoss: 0.022386\n",
            "Train Epoch: 62 [10368/14860 (69%)]\tLoss: 0.014915\n",
            "Train Epoch: 62 [10496/14860 (70%)]\tLoss: 0.023049\n",
            "Train Epoch: 62 [10624/14860 (71%)]\tLoss: 0.013875\n",
            "Train Epoch: 62 [10752/14860 (72%)]\tLoss: 0.025362\n",
            "Train Epoch: 62 [10880/14860 (73%)]\tLoss: 0.030395\n",
            "Train Epoch: 62 [11008/14860 (74%)]\tLoss: 0.022805\n",
            "Train Epoch: 62 [11136/14860 (74%)]\tLoss: 0.019929\n",
            "Train Epoch: 62 [11264/14860 (75%)]\tLoss: 0.022625\n",
            "Train Epoch: 62 [11392/14860 (76%)]\tLoss: 0.023174\n",
            "Train Epoch: 62 [11520/14860 (77%)]\tLoss: 0.022041\n",
            "Train Epoch: 62 [11648/14860 (78%)]\tLoss: 0.021222\n",
            "Train Epoch: 62 [11776/14860 (79%)]\tLoss: 0.029308\n",
            "Train Epoch: 62 [11904/14860 (79%)]\tLoss: 0.018127\n",
            "Train Epoch: 62 [12032/14860 (80%)]\tLoss: 0.026568\n",
            "Train Epoch: 62 [12160/14860 (81%)]\tLoss: 0.019915\n",
            "Train Epoch: 62 [12288/14860 (82%)]\tLoss: 0.017205\n",
            "Train Epoch: 62 [12416/14860 (83%)]\tLoss: 0.016110\n",
            "Train Epoch: 62 [12544/14860 (84%)]\tLoss: 0.021396\n",
            "Train Epoch: 62 [12672/14860 (85%)]\tLoss: 0.027707\n",
            "Train Epoch: 62 [12800/14860 (85%)]\tLoss: 0.020831\n",
            "Train Epoch: 62 [12928/14860 (86%)]\tLoss: 0.015220\n",
            "Train Epoch: 62 [13056/14860 (87%)]\tLoss: 0.028869\n",
            "Train Epoch: 62 [13184/14860 (88%)]\tLoss: 0.016403\n",
            "Train Epoch: 62 [13312/14860 (89%)]\tLoss: 0.022382\n",
            "Train Epoch: 62 [13440/14860 (90%)]\tLoss: 0.021843\n",
            "Train Epoch: 62 [13568/14860 (91%)]\tLoss: 0.017637\n",
            "Train Epoch: 62 [13696/14860 (91%)]\tLoss: 0.022237\n",
            "Train Epoch: 62 [13824/14860 (92%)]\tLoss: 0.020054\n",
            "Train Epoch: 62 [13952/14860 (93%)]\tLoss: 0.020694\n",
            "Train Epoch: 62 [14080/14860 (94%)]\tLoss: 0.022751\n",
            "Train Epoch: 62 [14208/14860 (95%)]\tLoss: 0.024246\n",
            "Train Epoch: 62 [14336/14860 (96%)]\tLoss: 0.016506\n",
            "Train Epoch: 62 [14464/14860 (97%)]\tLoss: 0.017487\n",
            "Train Epoch: 62 [14592/14860 (97%)]\tLoss: 0.019256\n",
            "Train Epoch: 62 [14720/14860 (98%)]\tLoss: 0.029930\n",
            "Train Epoch: 62 [1392/14860 (99%)]\tLoss: 0.003365\n",
            "epoch 62 training loss: 0.0203523826924686\n",
            "epoch 62 validation loss: 0.02111000500926094\n",
            "Train Epoch: 63 [0/14860 (0%)]\tLoss: 0.019669\n",
            "Train Epoch: 63 [128/14860 (1%)]\tLoss: 0.021559\n",
            "Train Epoch: 63 [256/14860 (2%)]\tLoss: 0.022482\n",
            "Train Epoch: 63 [384/14860 (3%)]\tLoss: 0.019824\n",
            "Train Epoch: 63 [512/14860 (3%)]\tLoss: 0.019523\n",
            "Train Epoch: 63 [640/14860 (4%)]\tLoss: 0.022933\n",
            "Train Epoch: 63 [768/14860 (5%)]\tLoss: 0.017857\n",
            "Train Epoch: 63 [896/14860 (6%)]\tLoss: 0.015552\n",
            "Train Epoch: 63 [1024/14860 (7%)]\tLoss: 0.015231\n",
            "Train Epoch: 63 [1152/14860 (8%)]\tLoss: 0.025812\n",
            "Train Epoch: 63 [1280/14860 (9%)]\tLoss: 0.019804\n",
            "Train Epoch: 63 [1408/14860 (9%)]\tLoss: 0.016345\n",
            "Train Epoch: 63 [1536/14860 (10%)]\tLoss: 0.013752\n",
            "Train Epoch: 63 [1664/14860 (11%)]\tLoss: 0.024572\n",
            "Train Epoch: 63 [1792/14860 (12%)]\tLoss: 0.018371\n",
            "Train Epoch: 63 [1920/14860 (13%)]\tLoss: 0.020577\n",
            "Train Epoch: 63 [2048/14860 (14%)]\tLoss: 0.023813\n",
            "Train Epoch: 63 [2176/14860 (15%)]\tLoss: 0.023850\n",
            "Train Epoch: 63 [2304/14860 (15%)]\tLoss: 0.020312\n",
            "Train Epoch: 63 [2432/14860 (16%)]\tLoss: 0.023763\n",
            "Train Epoch: 63 [2560/14860 (17%)]\tLoss: 0.018251\n",
            "Train Epoch: 63 [2688/14860 (18%)]\tLoss: 0.017087\n",
            "Train Epoch: 63 [2816/14860 (19%)]\tLoss: 0.012101\n",
            "Train Epoch: 63 [2944/14860 (20%)]\tLoss: 0.032824\n",
            "Train Epoch: 63 [3072/14860 (21%)]\tLoss: 0.028026\n",
            "Train Epoch: 63 [3200/14860 (21%)]\tLoss: 0.022474\n",
            "Train Epoch: 63 [3328/14860 (22%)]\tLoss: 0.020385\n",
            "Train Epoch: 63 [3456/14860 (23%)]\tLoss: 0.016902\n",
            "Train Epoch: 63 [3584/14860 (24%)]\tLoss: 0.016135\n",
            "Train Epoch: 63 [3712/14860 (25%)]\tLoss: 0.026646\n",
            "Train Epoch: 63 [3840/14860 (26%)]\tLoss: 0.021805\n",
            "Train Epoch: 63 [3968/14860 (26%)]\tLoss: 0.017668\n",
            "Train Epoch: 63 [4096/14860 (27%)]\tLoss: 0.027531\n",
            "Train Epoch: 63 [4224/14860 (28%)]\tLoss: 0.020277\n",
            "Train Epoch: 63 [4352/14860 (29%)]\tLoss: 0.021709\n",
            "Train Epoch: 63 [4480/14860 (30%)]\tLoss: 0.027595\n",
            "Train Epoch: 63 [4608/14860 (31%)]\tLoss: 0.017017\n",
            "Train Epoch: 63 [4736/14860 (32%)]\tLoss: 0.012416\n",
            "Train Epoch: 63 [4864/14860 (32%)]\tLoss: 0.029493\n",
            "Train Epoch: 63 [4992/14860 (33%)]\tLoss: 0.025765\n",
            "Train Epoch: 63 [5120/14860 (34%)]\tLoss: 0.018059\n",
            "Train Epoch: 63 [5248/14860 (35%)]\tLoss: 0.019150\n",
            "Train Epoch: 63 [5376/14860 (36%)]\tLoss: 0.013227\n",
            "Train Epoch: 63 [5504/14860 (37%)]\tLoss: 0.014014\n",
            "Train Epoch: 63 [5632/14860 (38%)]\tLoss: 0.020949\n",
            "Train Epoch: 63 [5760/14860 (38%)]\tLoss: 0.022545\n",
            "Train Epoch: 63 [5888/14860 (39%)]\tLoss: 0.017155\n",
            "Train Epoch: 63 [6016/14860 (40%)]\tLoss: 0.016006\n",
            "Train Epoch: 63 [6144/14860 (41%)]\tLoss: 0.022756\n",
            "Train Epoch: 63 [6272/14860 (42%)]\tLoss: 0.020315\n",
            "Train Epoch: 63 [6400/14860 (43%)]\tLoss: 0.021136\n",
            "Train Epoch: 63 [6528/14860 (44%)]\tLoss: 0.017442\n",
            "Train Epoch: 63 [6656/14860 (44%)]\tLoss: 0.021034\n",
            "Train Epoch: 63 [6784/14860 (45%)]\tLoss: 0.016028\n",
            "Train Epoch: 63 [6912/14860 (46%)]\tLoss: 0.010470\n",
            "Train Epoch: 63 [7040/14860 (47%)]\tLoss: 0.012057\n",
            "Train Epoch: 63 [7168/14860 (48%)]\tLoss: 0.020995\n",
            "Train Epoch: 63 [7296/14860 (49%)]\tLoss: 0.017521\n",
            "Train Epoch: 63 [7424/14860 (50%)]\tLoss: 0.013371\n",
            "Train Epoch: 63 [7552/14860 (50%)]\tLoss: 0.021635\n",
            "Train Epoch: 63 [7680/14860 (51%)]\tLoss: 0.017611\n",
            "Train Epoch: 63 [7808/14860 (52%)]\tLoss: 0.018010\n",
            "Train Epoch: 63 [7936/14860 (53%)]\tLoss: 0.019090\n",
            "Train Epoch: 63 [8064/14860 (54%)]\tLoss: 0.021868\n",
            "Train Epoch: 63 [8192/14860 (55%)]\tLoss: 0.021037\n",
            "Train Epoch: 63 [8320/14860 (56%)]\tLoss: 0.014508\n",
            "Train Epoch: 63 [8448/14860 (56%)]\tLoss: 0.017830\n",
            "Train Epoch: 63 [8576/14860 (57%)]\tLoss: 0.017790\n",
            "Train Epoch: 63 [8704/14860 (58%)]\tLoss: 0.016580\n",
            "Train Epoch: 63 [8832/14860 (59%)]\tLoss: 0.016510\n",
            "Train Epoch: 63 [8960/14860 (60%)]\tLoss: 0.017011\n",
            "Train Epoch: 63 [9088/14860 (61%)]\tLoss: 0.017819\n",
            "Train Epoch: 63 [9216/14860 (62%)]\tLoss: 0.024214\n",
            "Train Epoch: 63 [9344/14860 (62%)]\tLoss: 0.013683\n",
            "Train Epoch: 63 [9472/14860 (63%)]\tLoss: 0.017092\n",
            "Train Epoch: 63 [9600/14860 (64%)]\tLoss: 0.033689\n",
            "Train Epoch: 63 [9728/14860 (65%)]\tLoss: 0.016828\n",
            "Train Epoch: 63 [9856/14860 (66%)]\tLoss: 0.018436\n",
            "Train Epoch: 63 [9984/14860 (67%)]\tLoss: 0.012427\n",
            "Train Epoch: 63 [10112/14860 (68%)]\tLoss: 0.031602\n",
            "Train Epoch: 63 [10240/14860 (68%)]\tLoss: 0.025562\n",
            "Train Epoch: 63 [10368/14860 (69%)]\tLoss: 0.018359\n",
            "Train Epoch: 63 [10496/14860 (70%)]\tLoss: 0.029338\n",
            "Train Epoch: 63 [10624/14860 (71%)]\tLoss: 0.022895\n",
            "Train Epoch: 63 [10752/14860 (72%)]\tLoss: 0.016769\n",
            "Train Epoch: 63 [10880/14860 (73%)]\tLoss: 0.029244\n",
            "Train Epoch: 63 [11008/14860 (74%)]\tLoss: 0.013427\n",
            "Train Epoch: 63 [11136/14860 (74%)]\tLoss: 0.022002\n",
            "Train Epoch: 63 [11264/14860 (75%)]\tLoss: 0.011911\n",
            "Train Epoch: 63 [11392/14860 (76%)]\tLoss: 0.017588\n",
            "Train Epoch: 63 [11520/14860 (77%)]\tLoss: 0.015810\n",
            "Train Epoch: 63 [11648/14860 (78%)]\tLoss: 0.018081\n",
            "Train Epoch: 63 [11776/14860 (79%)]\tLoss: 0.019606\n",
            "Train Epoch: 63 [11904/14860 (79%)]\tLoss: 0.021356\n",
            "Train Epoch: 63 [12032/14860 (80%)]\tLoss: 0.020571\n",
            "Train Epoch: 63 [12160/14860 (81%)]\tLoss: 0.015018\n",
            "Train Epoch: 63 [12288/14860 (82%)]\tLoss: 0.026617\n",
            "Train Epoch: 63 [12416/14860 (83%)]\tLoss: 0.023140\n",
            "Train Epoch: 63 [12544/14860 (84%)]\tLoss: 0.014687\n",
            "Train Epoch: 63 [12672/14860 (85%)]\tLoss: 0.021342\n",
            "Train Epoch: 63 [12800/14860 (85%)]\tLoss: 0.017661\n",
            "Train Epoch: 63 [12928/14860 (86%)]\tLoss: 0.019018\n",
            "Train Epoch: 63 [13056/14860 (87%)]\tLoss: 0.014957\n",
            "Train Epoch: 63 [13184/14860 (88%)]\tLoss: 0.026141\n",
            "Train Epoch: 63 [13312/14860 (89%)]\tLoss: 0.016953\n",
            "Train Epoch: 63 [13440/14860 (90%)]\tLoss: 0.015586\n",
            "Train Epoch: 63 [13568/14860 (91%)]\tLoss: 0.022447\n",
            "Train Epoch: 63 [13696/14860 (91%)]\tLoss: 0.015733\n",
            "Train Epoch: 63 [13824/14860 (92%)]\tLoss: 0.024863\n",
            "Train Epoch: 63 [13952/14860 (93%)]\tLoss: 0.010593\n",
            "Train Epoch: 63 [14080/14860 (94%)]\tLoss: 0.024583\n",
            "Train Epoch: 63 [14208/14860 (95%)]\tLoss: 0.018239\n",
            "Train Epoch: 63 [14336/14860 (96%)]\tLoss: 0.018395\n",
            "Train Epoch: 63 [14464/14860 (97%)]\tLoss: 0.018982\n",
            "Train Epoch: 63 [14592/14860 (97%)]\tLoss: 0.017696\n",
            "Train Epoch: 63 [14720/14860 (98%)]\tLoss: 0.018526\n",
            "Train Epoch: 63 [1392/14860 (99%)]\tLoss: 0.016862\n",
            "epoch 63 training loss: 0.019639053931220982\n",
            "epoch 63 validation loss: 0.023672215442103278\n",
            "Train Epoch: 64 [0/14860 (0%)]\tLoss: 0.018224\n",
            "Train Epoch: 64 [128/14860 (1%)]\tLoss: 0.021882\n",
            "Train Epoch: 64 [256/14860 (2%)]\tLoss: 0.023054\n",
            "Train Epoch: 64 [384/14860 (3%)]\tLoss: 0.019079\n",
            "Train Epoch: 64 [512/14860 (3%)]\tLoss: 0.016698\n",
            "Train Epoch: 64 [640/14860 (4%)]\tLoss: 0.019558\n",
            "Train Epoch: 64 [768/14860 (5%)]\tLoss: 0.019538\n",
            "Train Epoch: 64 [896/14860 (6%)]\tLoss: 0.018627\n",
            "Train Epoch: 64 [1024/14860 (7%)]\tLoss: 0.019135\n",
            "Train Epoch: 64 [1152/14860 (8%)]\tLoss: 0.016387\n",
            "Train Epoch: 64 [1280/14860 (9%)]\tLoss: 0.016281\n",
            "Train Epoch: 64 [1408/14860 (9%)]\tLoss: 0.019535\n",
            "Train Epoch: 64 [1536/14860 (10%)]\tLoss: 0.015691\n",
            "Train Epoch: 64 [1664/14860 (11%)]\tLoss: 0.022493\n",
            "Train Epoch: 64 [1792/14860 (12%)]\tLoss: 0.013862\n",
            "Train Epoch: 64 [1920/14860 (13%)]\tLoss: 0.019551\n",
            "Train Epoch: 64 [2048/14860 (14%)]\tLoss: 0.015179\n",
            "Train Epoch: 64 [2176/14860 (15%)]\tLoss: 0.019519\n",
            "Train Epoch: 64 [2304/14860 (15%)]\tLoss: 0.023837\n",
            "Train Epoch: 64 [2432/14860 (16%)]\tLoss: 0.016031\n",
            "Train Epoch: 64 [2560/14860 (17%)]\tLoss: 0.013499\n",
            "Train Epoch: 64 [2688/14860 (18%)]\tLoss: 0.026039\n",
            "Train Epoch: 64 [2816/14860 (19%)]\tLoss: 0.017809\n",
            "Train Epoch: 64 [2944/14860 (20%)]\tLoss: 0.027127\n",
            "Train Epoch: 64 [3072/14860 (21%)]\tLoss: 0.020398\n",
            "Train Epoch: 64 [3200/14860 (21%)]\tLoss: 0.019937\n",
            "Train Epoch: 64 [3328/14860 (22%)]\tLoss: 0.016610\n",
            "Train Epoch: 64 [3456/14860 (23%)]\tLoss: 0.015835\n",
            "Train Epoch: 64 [3584/14860 (24%)]\tLoss: 0.018044\n",
            "Train Epoch: 64 [3712/14860 (25%)]\tLoss: 0.017503\n",
            "Train Epoch: 64 [3840/14860 (26%)]\tLoss: 0.015193\n",
            "Train Epoch: 64 [3968/14860 (26%)]\tLoss: 0.022436\n",
            "Train Epoch: 64 [4096/14860 (27%)]\tLoss: 0.018555\n",
            "Train Epoch: 64 [4224/14860 (28%)]\tLoss: 0.030088\n",
            "Train Epoch: 64 [4352/14860 (29%)]\tLoss: 0.022063\n",
            "Train Epoch: 64 [4480/14860 (30%)]\tLoss: 0.017895\n",
            "Train Epoch: 64 [4608/14860 (31%)]\tLoss: 0.026055\n",
            "Train Epoch: 64 [4736/14860 (32%)]\tLoss: 0.026615\n",
            "Train Epoch: 64 [4864/14860 (32%)]\tLoss: 0.017834\n",
            "Train Epoch: 64 [4992/14860 (33%)]\tLoss: 0.019250\n",
            "Train Epoch: 64 [5120/14860 (34%)]\tLoss: 0.021132\n",
            "Train Epoch: 64 [5248/14860 (35%)]\tLoss: 0.023914\n",
            "Train Epoch: 64 [5376/14860 (36%)]\tLoss: 0.026889\n",
            "Train Epoch: 64 [5504/14860 (37%)]\tLoss: 0.020681\n",
            "Train Epoch: 64 [5632/14860 (38%)]\tLoss: 0.015055\n",
            "Train Epoch: 64 [5760/14860 (38%)]\tLoss: 0.021619\n",
            "Train Epoch: 64 [5888/14860 (39%)]\tLoss: 0.016638\n",
            "Train Epoch: 64 [6016/14860 (40%)]\tLoss: 0.030905\n",
            "Train Epoch: 64 [6144/14860 (41%)]\tLoss: 0.012771\n",
            "Train Epoch: 64 [6272/14860 (42%)]\tLoss: 0.021006\n",
            "Train Epoch: 64 [6400/14860 (43%)]\tLoss: 0.018269\n",
            "Train Epoch: 64 [6528/14860 (44%)]\tLoss: 0.017192\n",
            "Train Epoch: 64 [6656/14860 (44%)]\tLoss: 0.020166\n",
            "Train Epoch: 64 [6784/14860 (45%)]\tLoss: 0.020021\n",
            "Train Epoch: 64 [6912/14860 (46%)]\tLoss: 0.014546\n",
            "Train Epoch: 64 [7040/14860 (47%)]\tLoss: 0.013282\n",
            "Train Epoch: 64 [7168/14860 (48%)]\tLoss: 0.032519\n",
            "Train Epoch: 64 [7296/14860 (49%)]\tLoss: 0.019613\n",
            "Train Epoch: 64 [7424/14860 (50%)]\tLoss: 0.019917\n",
            "Train Epoch: 64 [7552/14860 (50%)]\tLoss: 0.019618\n",
            "Train Epoch: 64 [7680/14860 (51%)]\tLoss: 0.019907\n",
            "Train Epoch: 64 [7808/14860 (52%)]\tLoss: 0.024772\n",
            "Train Epoch: 64 [7936/14860 (53%)]\tLoss: 0.018877\n",
            "Train Epoch: 64 [8064/14860 (54%)]\tLoss: 0.022172\n",
            "Train Epoch: 64 [8192/14860 (55%)]\tLoss: 0.020343\n",
            "Train Epoch: 64 [8320/14860 (56%)]\tLoss: 0.015315\n",
            "Train Epoch: 64 [8448/14860 (56%)]\tLoss: 0.015826\n",
            "Train Epoch: 64 [8576/14860 (57%)]\tLoss: 0.014844\n",
            "Train Epoch: 64 [8704/14860 (58%)]\tLoss: 0.020462\n",
            "Train Epoch: 64 [8832/14860 (59%)]\tLoss: 0.015835\n",
            "Train Epoch: 64 [8960/14860 (60%)]\tLoss: 0.019717\n",
            "Train Epoch: 64 [9088/14860 (61%)]\tLoss: 0.014429\n",
            "Train Epoch: 64 [9216/14860 (62%)]\tLoss: 0.017467\n",
            "Train Epoch: 64 [9344/14860 (62%)]\tLoss: 0.013749\n",
            "Train Epoch: 64 [9472/14860 (63%)]\tLoss: 0.019523\n",
            "Train Epoch: 64 [9600/14860 (64%)]\tLoss: 0.022037\n",
            "Train Epoch: 64 [9728/14860 (65%)]\tLoss: 0.020980\n",
            "Train Epoch: 64 [9856/14860 (66%)]\tLoss: 0.019207\n",
            "Train Epoch: 64 [9984/14860 (67%)]\tLoss: 0.020491\n",
            "Train Epoch: 64 [10112/14860 (68%)]\tLoss: 0.014737\n",
            "Train Epoch: 64 [10240/14860 (68%)]\tLoss: 0.022457\n",
            "Train Epoch: 64 [10368/14860 (69%)]\tLoss: 0.020632\n",
            "Train Epoch: 64 [10496/14860 (70%)]\tLoss: 0.019965\n",
            "Train Epoch: 64 [10624/14860 (71%)]\tLoss: 0.016824\n",
            "Train Epoch: 64 [10752/14860 (72%)]\tLoss: 0.014403\n",
            "Train Epoch: 64 [10880/14860 (73%)]\tLoss: 0.016417\n",
            "Train Epoch: 64 [11008/14860 (74%)]\tLoss: 0.022062\n",
            "Train Epoch: 64 [11136/14860 (74%)]\tLoss: 0.017906\n",
            "Train Epoch: 64 [11264/14860 (75%)]\tLoss: 0.027777\n",
            "Train Epoch: 64 [11392/14860 (76%)]\tLoss: 0.020340\n",
            "Train Epoch: 64 [11520/14860 (77%)]\tLoss: 0.025330\n",
            "Train Epoch: 64 [11648/14860 (78%)]\tLoss: 0.016700\n",
            "Train Epoch: 64 [11776/14860 (79%)]\tLoss: 0.016372\n",
            "Train Epoch: 64 [11904/14860 (79%)]\tLoss: 0.014668\n",
            "Train Epoch: 64 [12032/14860 (80%)]\tLoss: 0.011010\n",
            "Train Epoch: 64 [12160/14860 (81%)]\tLoss: 0.016503\n",
            "Train Epoch: 64 [12288/14860 (82%)]\tLoss: 0.023338\n",
            "Train Epoch: 64 [12416/14860 (83%)]\tLoss: 0.018526\n",
            "Train Epoch: 64 [12544/14860 (84%)]\tLoss: 0.019010\n",
            "Train Epoch: 64 [12672/14860 (85%)]\tLoss: 0.018933\n",
            "Train Epoch: 64 [12800/14860 (85%)]\tLoss: 0.027841\n",
            "Train Epoch: 64 [12928/14860 (86%)]\tLoss: 0.018551\n",
            "Train Epoch: 64 [13056/14860 (87%)]\tLoss: 0.017367\n",
            "Train Epoch: 64 [13184/14860 (88%)]\tLoss: 0.023303\n",
            "Train Epoch: 64 [13312/14860 (89%)]\tLoss: 0.020953\n",
            "Train Epoch: 64 [13440/14860 (90%)]\tLoss: 0.018057\n",
            "Train Epoch: 64 [13568/14860 (91%)]\tLoss: 0.025736\n",
            "Train Epoch: 64 [13696/14860 (91%)]\tLoss: 0.023150\n",
            "Train Epoch: 64 [13824/14860 (92%)]\tLoss: 0.013167\n",
            "Train Epoch: 64 [13952/14860 (93%)]\tLoss: 0.022102\n",
            "Train Epoch: 64 [14080/14860 (94%)]\tLoss: 0.017989\n",
            "Train Epoch: 64 [14208/14860 (95%)]\tLoss: 0.024072\n",
            "Train Epoch: 64 [14336/14860 (96%)]\tLoss: 0.018197\n",
            "Train Epoch: 64 [14464/14860 (97%)]\tLoss: 0.014923\n",
            "Train Epoch: 64 [14592/14860 (97%)]\tLoss: 0.023180\n",
            "Train Epoch: 64 [14720/14860 (98%)]\tLoss: 0.013467\n",
            "Train Epoch: 64 [1392/14860 (99%)]\tLoss: 0.008423\n",
            "epoch 64 training loss: 0.019393518511365112\n",
            "epoch 64 validation loss: 0.02061685234236082\n",
            "Train Epoch: 65 [0/14860 (0%)]\tLoss: 0.019684\n",
            "Train Epoch: 65 [128/14860 (1%)]\tLoss: 0.018839\n",
            "Train Epoch: 65 [256/14860 (2%)]\tLoss: 0.022958\n",
            "Train Epoch: 65 [384/14860 (3%)]\tLoss: 0.017182\n",
            "Train Epoch: 65 [512/14860 (3%)]\tLoss: 0.016379\n",
            "Train Epoch: 65 [640/14860 (4%)]\tLoss: 0.018599\n",
            "Train Epoch: 65 [768/14860 (5%)]\tLoss: 0.014743\n",
            "Train Epoch: 65 [896/14860 (6%)]\tLoss: 0.024218\n",
            "Train Epoch: 65 [1024/14860 (7%)]\tLoss: 0.014931\n",
            "Train Epoch: 65 [1152/14860 (8%)]\tLoss: 0.016117\n",
            "Train Epoch: 65 [1280/14860 (9%)]\tLoss: 0.021554\n",
            "Train Epoch: 65 [1408/14860 (9%)]\tLoss: 0.023048\n",
            "Train Epoch: 65 [1536/14860 (10%)]\tLoss: 0.021852\n",
            "Train Epoch: 65 [1664/14860 (11%)]\tLoss: 0.018957\n",
            "Train Epoch: 65 [1792/14860 (12%)]\tLoss: 0.019091\n",
            "Train Epoch: 65 [1920/14860 (13%)]\tLoss: 0.016677\n",
            "Train Epoch: 65 [2048/14860 (14%)]\tLoss: 0.020950\n",
            "Train Epoch: 65 [2176/14860 (15%)]\tLoss: 0.021537\n",
            "Train Epoch: 65 [2304/14860 (15%)]\tLoss: 0.019708\n",
            "Train Epoch: 65 [2432/14860 (16%)]\tLoss: 0.024297\n",
            "Train Epoch: 65 [2560/14860 (17%)]\tLoss: 0.014516\n",
            "Train Epoch: 65 [2688/14860 (18%)]\tLoss: 0.018946\n",
            "Train Epoch: 65 [2816/14860 (19%)]\tLoss: 0.019842\n",
            "Train Epoch: 65 [2944/14860 (20%)]\tLoss: 0.020001\n",
            "Train Epoch: 65 [3072/14860 (21%)]\tLoss: 0.020628\n",
            "Train Epoch: 65 [3200/14860 (21%)]\tLoss: 0.014155\n",
            "Train Epoch: 65 [3328/14860 (22%)]\tLoss: 0.020452\n",
            "Train Epoch: 65 [3456/14860 (23%)]\tLoss: 0.021597\n",
            "Train Epoch: 65 [3584/14860 (24%)]\tLoss: 0.023102\n",
            "Train Epoch: 65 [3712/14860 (25%)]\tLoss: 0.028476\n",
            "Train Epoch: 65 [3840/14860 (26%)]\tLoss: 0.020448\n",
            "Train Epoch: 65 [3968/14860 (26%)]\tLoss: 0.023706\n",
            "Train Epoch: 65 [4096/14860 (27%)]\tLoss: 0.015722\n",
            "Train Epoch: 65 [4224/14860 (28%)]\tLoss: 0.016301\n",
            "Train Epoch: 65 [4352/14860 (29%)]\tLoss: 0.021548\n",
            "Train Epoch: 65 [4480/14860 (30%)]\tLoss: 0.027630\n",
            "Train Epoch: 65 [4608/14860 (31%)]\tLoss: 0.027847\n",
            "Train Epoch: 65 [4736/14860 (32%)]\tLoss: 0.017659\n",
            "Train Epoch: 65 [4864/14860 (32%)]\tLoss: 0.015683\n",
            "Train Epoch: 65 [4992/14860 (33%)]\tLoss: 0.023919\n",
            "Train Epoch: 65 [5120/14860 (34%)]\tLoss: 0.025009\n",
            "Train Epoch: 65 [5248/14860 (35%)]\tLoss: 0.024753\n",
            "Train Epoch: 65 [5376/14860 (36%)]\tLoss: 0.014843\n",
            "Train Epoch: 65 [5504/14860 (37%)]\tLoss: 0.016216\n",
            "Train Epoch: 65 [5632/14860 (38%)]\tLoss: 0.021552\n",
            "Train Epoch: 65 [5760/14860 (38%)]\tLoss: 0.020029\n",
            "Train Epoch: 65 [5888/14860 (39%)]\tLoss: 0.019694\n",
            "Train Epoch: 65 [6016/14860 (40%)]\tLoss: 0.019758\n",
            "Train Epoch: 65 [6144/14860 (41%)]\tLoss: 0.015629\n",
            "Train Epoch: 65 [6272/14860 (42%)]\tLoss: 0.016115\n",
            "Train Epoch: 65 [6400/14860 (43%)]\tLoss: 0.015126\n",
            "Train Epoch: 65 [6528/14860 (44%)]\tLoss: 0.019169\n",
            "Train Epoch: 65 [6656/14860 (44%)]\tLoss: 0.019175\n",
            "Train Epoch: 65 [6784/14860 (45%)]\tLoss: 0.018025\n",
            "Train Epoch: 65 [6912/14860 (46%)]\tLoss: 0.016865\n",
            "Train Epoch: 65 [7040/14860 (47%)]\tLoss: 0.016361\n",
            "Train Epoch: 65 [7168/14860 (48%)]\tLoss: 0.014921\n",
            "Train Epoch: 65 [7296/14860 (49%)]\tLoss: 0.016240\n",
            "Train Epoch: 65 [7424/14860 (50%)]\tLoss: 0.021138\n",
            "Train Epoch: 65 [7552/14860 (50%)]\tLoss: 0.015185\n",
            "Train Epoch: 65 [7680/14860 (51%)]\tLoss: 0.022112\n",
            "Train Epoch: 65 [7808/14860 (52%)]\tLoss: 0.018336\n",
            "Train Epoch: 65 [7936/14860 (53%)]\tLoss: 0.018650\n",
            "Train Epoch: 65 [8064/14860 (54%)]\tLoss: 0.023530\n",
            "Train Epoch: 65 [8192/14860 (55%)]\tLoss: 0.021636\n",
            "Train Epoch: 65 [8320/14860 (56%)]\tLoss: 0.015593\n",
            "Train Epoch: 65 [8448/14860 (56%)]\tLoss: 0.016960\n",
            "Train Epoch: 65 [8576/14860 (57%)]\tLoss: 0.019609\n",
            "Train Epoch: 65 [8704/14860 (58%)]\tLoss: 0.020855\n",
            "Train Epoch: 65 [8832/14860 (59%)]\tLoss: 0.025947\n",
            "Train Epoch: 65 [8960/14860 (60%)]\tLoss: 0.015456\n",
            "Train Epoch: 65 [9088/14860 (61%)]\tLoss: 0.014087\n",
            "Train Epoch: 65 [9216/14860 (62%)]\tLoss: 0.012996\n",
            "Train Epoch: 65 [9344/14860 (62%)]\tLoss: 0.018391\n",
            "Train Epoch: 65 [9472/14860 (63%)]\tLoss: 0.016573\n",
            "Train Epoch: 65 [9600/14860 (64%)]\tLoss: 0.014393\n",
            "Train Epoch: 65 [9728/14860 (65%)]\tLoss: 0.017026\n",
            "Train Epoch: 65 [9856/14860 (66%)]\tLoss: 0.019962\n",
            "Train Epoch: 65 [9984/14860 (67%)]\tLoss: 0.018648\n",
            "Train Epoch: 65 [10112/14860 (68%)]\tLoss: 0.016945\n",
            "Train Epoch: 65 [10240/14860 (68%)]\tLoss: 0.022925\n",
            "Train Epoch: 65 [10368/14860 (69%)]\tLoss: 0.016981\n",
            "Train Epoch: 65 [10496/14860 (70%)]\tLoss: 0.018482\n",
            "Train Epoch: 65 [10624/14860 (71%)]\tLoss: 0.017923\n",
            "Train Epoch: 65 [10752/14860 (72%)]\tLoss: 0.012697\n",
            "Train Epoch: 65 [10880/14860 (73%)]\tLoss: 0.020497\n",
            "Train Epoch: 65 [11008/14860 (74%)]\tLoss: 0.023574\n",
            "Train Epoch: 65 [11136/14860 (74%)]\tLoss: 0.019619\n",
            "Train Epoch: 65 [11264/14860 (75%)]\tLoss: 0.012533\n",
            "Train Epoch: 65 [11392/14860 (76%)]\tLoss: 0.018979\n",
            "Train Epoch: 65 [11520/14860 (77%)]\tLoss: 0.016740\n",
            "Train Epoch: 65 [11648/14860 (78%)]\tLoss: 0.016817\n",
            "Train Epoch: 65 [11776/14860 (79%)]\tLoss: 0.017681\n",
            "Train Epoch: 65 [11904/14860 (79%)]\tLoss: 0.026851\n",
            "Train Epoch: 65 [12032/14860 (80%)]\tLoss: 0.019737\n",
            "Train Epoch: 65 [12160/14860 (81%)]\tLoss: 0.017900\n",
            "Train Epoch: 65 [12288/14860 (82%)]\tLoss: 0.028291\n",
            "Train Epoch: 65 [12416/14860 (83%)]\tLoss: 0.017558\n",
            "Train Epoch: 65 [12544/14860 (84%)]\tLoss: 0.022719\n",
            "Train Epoch: 65 [12672/14860 (85%)]\tLoss: 0.021701\n",
            "Train Epoch: 65 [12800/14860 (85%)]\tLoss: 0.018553\n",
            "Train Epoch: 65 [12928/14860 (86%)]\tLoss: 0.019879\n",
            "Train Epoch: 65 [13056/14860 (87%)]\tLoss: 0.019354\n",
            "Train Epoch: 65 [13184/14860 (88%)]\tLoss: 0.033900\n",
            "Train Epoch: 65 [13312/14860 (89%)]\tLoss: 0.016720\n",
            "Train Epoch: 65 [13440/14860 (90%)]\tLoss: 0.020136\n",
            "Train Epoch: 65 [13568/14860 (91%)]\tLoss: 0.018259\n",
            "Train Epoch: 65 [13696/14860 (91%)]\tLoss: 0.015211\n",
            "Train Epoch: 65 [13824/14860 (92%)]\tLoss: 0.017904\n",
            "Train Epoch: 65 [13952/14860 (93%)]\tLoss: 0.021630\n",
            "Train Epoch: 65 [14080/14860 (94%)]\tLoss: 0.024688\n",
            "Train Epoch: 65 [14208/14860 (95%)]\tLoss: 0.023507\n",
            "Train Epoch: 65 [14336/14860 (96%)]\tLoss: 0.024497\n",
            "Train Epoch: 65 [14464/14860 (97%)]\tLoss: 0.017559\n",
            "Train Epoch: 65 [14592/14860 (97%)]\tLoss: 0.029036\n",
            "Train Epoch: 65 [14720/14860 (98%)]\tLoss: 0.027747\n",
            "Train Epoch: 65 [1392/14860 (99%)]\tLoss: 0.023105\n",
            "epoch 65 training loss: 0.01964870104009015\n",
            "epoch 65 validation loss: 0.023168609303943183\n",
            "Train Epoch: 66 [0/14860 (0%)]\tLoss: 0.021400\n",
            "Train Epoch: 66 [128/14860 (1%)]\tLoss: 0.022111\n",
            "Train Epoch: 66 [256/14860 (2%)]\tLoss: 0.016881\n",
            "Train Epoch: 66 [384/14860 (3%)]\tLoss: 0.026249\n",
            "Train Epoch: 66 [512/14860 (3%)]\tLoss: 0.016091\n",
            "Train Epoch: 66 [640/14860 (4%)]\tLoss: 0.022473\n",
            "Train Epoch: 66 [768/14860 (5%)]\tLoss: 0.022060\n",
            "Train Epoch: 66 [896/14860 (6%)]\tLoss: 0.017093\n",
            "Train Epoch: 66 [1024/14860 (7%)]\tLoss: 0.020629\n",
            "Train Epoch: 66 [1152/14860 (8%)]\tLoss: 0.018338\n",
            "Train Epoch: 66 [1280/14860 (9%)]\tLoss: 0.023359\n",
            "Train Epoch: 66 [1408/14860 (9%)]\tLoss: 0.019088\n",
            "Train Epoch: 66 [1536/14860 (10%)]\tLoss: 0.024733\n",
            "Train Epoch: 66 [1664/14860 (11%)]\tLoss: 0.021688\n",
            "Train Epoch: 66 [1792/14860 (12%)]\tLoss: 0.013991\n",
            "Train Epoch: 66 [1920/14860 (13%)]\tLoss: 0.015379\n",
            "Train Epoch: 66 [2048/14860 (14%)]\tLoss: 0.014321\n",
            "Train Epoch: 66 [2176/14860 (15%)]\tLoss: 0.024677\n",
            "Train Epoch: 66 [2304/14860 (15%)]\tLoss: 0.018203\n",
            "Train Epoch: 66 [2432/14860 (16%)]\tLoss: 0.018429\n",
            "Train Epoch: 66 [2560/14860 (17%)]\tLoss: 0.021218\n",
            "Train Epoch: 66 [2688/14860 (18%)]\tLoss: 0.020136\n",
            "Train Epoch: 66 [2816/14860 (19%)]\tLoss: 0.014394\n",
            "Train Epoch: 66 [2944/14860 (20%)]\tLoss: 0.031267\n",
            "Train Epoch: 66 [3072/14860 (21%)]\tLoss: 0.028616\n",
            "Train Epoch: 66 [3200/14860 (21%)]\tLoss: 0.021421\n",
            "Train Epoch: 66 [3328/14860 (22%)]\tLoss: 0.019045\n",
            "Train Epoch: 66 [3456/14860 (23%)]\tLoss: 0.017890\n",
            "Train Epoch: 66 [3584/14860 (24%)]\tLoss: 0.013543\n",
            "Train Epoch: 66 [3712/14860 (25%)]\tLoss: 0.020186\n",
            "Train Epoch: 66 [3840/14860 (26%)]\tLoss: 0.019173\n",
            "Train Epoch: 66 [3968/14860 (26%)]\tLoss: 0.018709\n",
            "Train Epoch: 66 [4096/14860 (27%)]\tLoss: 0.018234\n",
            "Train Epoch: 66 [4224/14860 (28%)]\tLoss: 0.016695\n",
            "Train Epoch: 66 [4352/14860 (29%)]\tLoss: 0.025030\n",
            "Train Epoch: 66 [4480/14860 (30%)]\tLoss: 0.018301\n",
            "Train Epoch: 66 [4608/14860 (31%)]\tLoss: 0.019177\n",
            "Train Epoch: 66 [4736/14860 (32%)]\tLoss: 0.022110\n",
            "Train Epoch: 66 [4864/14860 (32%)]\tLoss: 0.025124\n",
            "Train Epoch: 66 [4992/14860 (33%)]\tLoss: 0.015761\n",
            "Train Epoch: 66 [5120/14860 (34%)]\tLoss: 0.022063\n",
            "Train Epoch: 66 [5248/14860 (35%)]\tLoss: 0.021466\n",
            "Train Epoch: 66 [5376/14860 (36%)]\tLoss: 0.017222\n",
            "Train Epoch: 66 [5504/14860 (37%)]\tLoss: 0.020724\n",
            "Train Epoch: 66 [5632/14860 (38%)]\tLoss: 0.018501\n",
            "Train Epoch: 66 [5760/14860 (38%)]\tLoss: 0.020301\n",
            "Train Epoch: 66 [5888/14860 (39%)]\tLoss: 0.016419\n",
            "Train Epoch: 66 [6016/14860 (40%)]\tLoss: 0.016439\n",
            "Train Epoch: 66 [6144/14860 (41%)]\tLoss: 0.014616\n",
            "Train Epoch: 66 [6272/14860 (42%)]\tLoss: 0.020700\n",
            "Train Epoch: 66 [6400/14860 (43%)]\tLoss: 0.016777\n",
            "Train Epoch: 66 [6528/14860 (44%)]\tLoss: 0.019753\n",
            "Train Epoch: 66 [6656/14860 (44%)]\tLoss: 0.022544\n",
            "Train Epoch: 66 [6784/14860 (45%)]\tLoss: 0.022373\n",
            "Train Epoch: 66 [6912/14860 (46%)]\tLoss: 0.018181\n",
            "Train Epoch: 66 [7040/14860 (47%)]\tLoss: 0.018841\n",
            "Train Epoch: 66 [7168/14860 (48%)]\tLoss: 0.018993\n",
            "Train Epoch: 66 [7296/14860 (49%)]\tLoss: 0.020881\n",
            "Train Epoch: 66 [7424/14860 (50%)]\tLoss: 0.019892\n",
            "Train Epoch: 66 [7552/14860 (50%)]\tLoss: 0.016332\n",
            "Train Epoch: 66 [7680/14860 (51%)]\tLoss: 0.026720\n",
            "Train Epoch: 66 [7808/14860 (52%)]\tLoss: 0.013802\n",
            "Train Epoch: 66 [7936/14860 (53%)]\tLoss: 0.024873\n",
            "Train Epoch: 66 [8064/14860 (54%)]\tLoss: 0.024403\n",
            "Train Epoch: 66 [8192/14860 (55%)]\tLoss: 0.014520\n",
            "Train Epoch: 66 [8320/14860 (56%)]\tLoss: 0.023020\n",
            "Train Epoch: 66 [8448/14860 (56%)]\tLoss: 0.017874\n",
            "Train Epoch: 66 [8576/14860 (57%)]\tLoss: 0.020168\n",
            "Train Epoch: 66 [8704/14860 (58%)]\tLoss: 0.022636\n",
            "Train Epoch: 66 [8832/14860 (59%)]\tLoss: 0.018721\n",
            "Train Epoch: 66 [8960/14860 (60%)]\tLoss: 0.022447\n",
            "Train Epoch: 66 [9088/14860 (61%)]\tLoss: 0.016726\n",
            "Train Epoch: 66 [9216/14860 (62%)]\tLoss: 0.014097\n",
            "Train Epoch: 66 [9344/14860 (62%)]\tLoss: 0.021753\n",
            "Train Epoch: 66 [9472/14860 (63%)]\tLoss: 0.011320\n",
            "Train Epoch: 66 [9600/14860 (64%)]\tLoss: 0.019750\n",
            "Train Epoch: 66 [9728/14860 (65%)]\tLoss: 0.015603\n",
            "Train Epoch: 66 [9856/14860 (66%)]\tLoss: 0.020843\n",
            "Train Epoch: 66 [9984/14860 (67%)]\tLoss: 0.021680\n",
            "Train Epoch: 66 [10112/14860 (68%)]\tLoss: 0.015876\n",
            "Train Epoch: 66 [10240/14860 (68%)]\tLoss: 0.021347\n",
            "Train Epoch: 66 [10368/14860 (69%)]\tLoss: 0.016423\n",
            "Train Epoch: 66 [10496/14860 (70%)]\tLoss: 0.024957\n",
            "Train Epoch: 66 [10624/14860 (71%)]\tLoss: 0.013751\n",
            "Train Epoch: 66 [10752/14860 (72%)]\tLoss: 0.015659\n",
            "Train Epoch: 66 [10880/14860 (73%)]\tLoss: 0.024075\n",
            "Train Epoch: 66 [11008/14860 (74%)]\tLoss: 0.015092\n",
            "Train Epoch: 66 [11136/14860 (74%)]\tLoss: 0.021679\n",
            "Train Epoch: 66 [11264/14860 (75%)]\tLoss: 0.024990\n",
            "Train Epoch: 66 [11392/14860 (76%)]\tLoss: 0.020657\n",
            "Train Epoch: 66 [11520/14860 (77%)]\tLoss: 0.022926\n",
            "Train Epoch: 66 [11648/14860 (78%)]\tLoss: 0.015289\n",
            "Train Epoch: 66 [11776/14860 (79%)]\tLoss: 0.027868\n",
            "Train Epoch: 66 [11904/14860 (79%)]\tLoss: 0.023418\n",
            "Train Epoch: 66 [12032/14860 (80%)]\tLoss: 0.025393\n",
            "Train Epoch: 66 [12160/14860 (81%)]\tLoss: 0.026809\n",
            "Train Epoch: 66 [12288/14860 (82%)]\tLoss: 0.014849\n",
            "Train Epoch: 66 [12416/14860 (83%)]\tLoss: 0.018667\n",
            "Train Epoch: 66 [12544/14860 (84%)]\tLoss: 0.017904\n",
            "Train Epoch: 66 [12672/14860 (85%)]\tLoss: 0.017036\n",
            "Train Epoch: 66 [12800/14860 (85%)]\tLoss: 0.015362\n",
            "Train Epoch: 66 [12928/14860 (86%)]\tLoss: 0.015678\n",
            "Train Epoch: 66 [13056/14860 (87%)]\tLoss: 0.018049\n",
            "Train Epoch: 66 [13184/14860 (88%)]\tLoss: 0.013295\n",
            "Train Epoch: 66 [13312/14860 (89%)]\tLoss: 0.021672\n",
            "Train Epoch: 66 [13440/14860 (90%)]\tLoss: 0.013319\n",
            "Train Epoch: 66 [13568/14860 (91%)]\tLoss: 0.018924\n",
            "Train Epoch: 66 [13696/14860 (91%)]\tLoss: 0.024845\n",
            "Train Epoch: 66 [13824/14860 (92%)]\tLoss: 0.016240\n",
            "Train Epoch: 66 [13952/14860 (93%)]\tLoss: 0.021351\n",
            "Train Epoch: 66 [14080/14860 (94%)]\tLoss: 0.016283\n",
            "Train Epoch: 66 [14208/14860 (95%)]\tLoss: 0.017574\n",
            "Train Epoch: 66 [14336/14860 (96%)]\tLoss: 0.017571\n",
            "Train Epoch: 66 [14464/14860 (97%)]\tLoss: 0.024922\n",
            "Train Epoch: 66 [14592/14860 (97%)]\tLoss: 0.017635\n",
            "Train Epoch: 66 [14720/14860 (98%)]\tLoss: 0.016436\n",
            "Train Epoch: 66 [1392/14860 (99%)]\tLoss: 0.044418\n",
            "epoch 66 training loss: 0.019790050987568166\n",
            "epoch 66 validation loss: 0.02227225113145953\n",
            "Train Epoch: 67 [0/14860 (0%)]\tLoss: 0.022083\n",
            "Train Epoch: 67 [128/14860 (1%)]\tLoss: 0.018793\n",
            "Train Epoch: 67 [256/14860 (2%)]\tLoss: 0.022681\n",
            "Train Epoch: 67 [384/14860 (3%)]\tLoss: 0.016520\n",
            "Train Epoch: 67 [512/14860 (3%)]\tLoss: 0.012839\n",
            "Train Epoch: 67 [640/14860 (4%)]\tLoss: 0.022968\n",
            "Train Epoch: 67 [768/14860 (5%)]\tLoss: 0.019466\n",
            "Train Epoch: 67 [896/14860 (6%)]\tLoss: 0.024485\n",
            "Train Epoch: 67 [1024/14860 (7%)]\tLoss: 0.018135\n",
            "Train Epoch: 67 [1152/14860 (8%)]\tLoss: 0.021754\n",
            "Train Epoch: 67 [1280/14860 (9%)]\tLoss: 0.019477\n",
            "Train Epoch: 67 [1408/14860 (9%)]\tLoss: 0.016834\n",
            "Train Epoch: 67 [1536/14860 (10%)]\tLoss: 0.023648\n",
            "Train Epoch: 67 [1664/14860 (11%)]\tLoss: 0.018311\n",
            "Train Epoch: 67 [1792/14860 (12%)]\tLoss: 0.013728\n",
            "Train Epoch: 67 [1920/14860 (13%)]\tLoss: 0.018403\n",
            "Train Epoch: 67 [2048/14860 (14%)]\tLoss: 0.016419\n",
            "Train Epoch: 67 [2176/14860 (15%)]\tLoss: 0.018313\n",
            "Train Epoch: 67 [2304/14860 (15%)]\tLoss: 0.016888\n",
            "Train Epoch: 67 [2432/14860 (16%)]\tLoss: 0.014821\n",
            "Train Epoch: 67 [2560/14860 (17%)]\tLoss: 0.021517\n",
            "Train Epoch: 67 [2688/14860 (18%)]\tLoss: 0.014484\n",
            "Train Epoch: 67 [2816/14860 (19%)]\tLoss: 0.022131\n",
            "Train Epoch: 67 [2944/14860 (20%)]\tLoss: 0.026812\n",
            "Train Epoch: 67 [3072/14860 (21%)]\tLoss: 0.021290\n",
            "Train Epoch: 67 [3200/14860 (21%)]\tLoss: 0.017824\n",
            "Train Epoch: 67 [3328/14860 (22%)]\tLoss: 0.019909\n",
            "Train Epoch: 67 [3456/14860 (23%)]\tLoss: 0.015490\n",
            "Train Epoch: 67 [3584/14860 (24%)]\tLoss: 0.015082\n",
            "Train Epoch: 67 [3712/14860 (25%)]\tLoss: 0.023601\n",
            "Train Epoch: 67 [3840/14860 (26%)]\tLoss: 0.017518\n",
            "Train Epoch: 67 [3968/14860 (26%)]\tLoss: 0.017947\n",
            "Train Epoch: 67 [4096/14860 (27%)]\tLoss: 0.020439\n",
            "Train Epoch: 67 [4224/14860 (28%)]\tLoss: 0.028417\n",
            "Train Epoch: 67 [4352/14860 (29%)]\tLoss: 0.018760\n",
            "Train Epoch: 67 [4480/14860 (30%)]\tLoss: 0.021471\n",
            "Train Epoch: 67 [4608/14860 (31%)]\tLoss: 0.018942\n",
            "Train Epoch: 67 [4736/14860 (32%)]\tLoss: 0.023408\n",
            "Train Epoch: 67 [4864/14860 (32%)]\tLoss: 0.014347\n",
            "Train Epoch: 67 [4992/14860 (33%)]\tLoss: 0.013515\n",
            "Train Epoch: 67 [5120/14860 (34%)]\tLoss: 0.019075\n",
            "Train Epoch: 67 [5248/14860 (35%)]\tLoss: 0.018561\n",
            "Train Epoch: 67 [5376/14860 (36%)]\tLoss: 0.017011\n",
            "Train Epoch: 67 [5504/14860 (37%)]\tLoss: 0.019995\n",
            "Train Epoch: 67 [5632/14860 (38%)]\tLoss: 0.015457\n",
            "Train Epoch: 67 [5760/14860 (38%)]\tLoss: 0.018607\n",
            "Train Epoch: 67 [5888/14860 (39%)]\tLoss: 0.019688\n",
            "Train Epoch: 67 [6016/14860 (40%)]\tLoss: 0.015515\n",
            "Train Epoch: 67 [6144/14860 (41%)]\tLoss: 0.022929\n",
            "Train Epoch: 67 [6272/14860 (42%)]\tLoss: 0.021006\n",
            "Train Epoch: 67 [6400/14860 (43%)]\tLoss: 0.017277\n",
            "Train Epoch: 67 [6528/14860 (44%)]\tLoss: 0.015030\n",
            "Train Epoch: 67 [6656/14860 (44%)]\tLoss: 0.019211\n",
            "Train Epoch: 67 [6784/14860 (45%)]\tLoss: 0.019851\n",
            "Train Epoch: 67 [6912/14860 (46%)]\tLoss: 0.018226\n",
            "Train Epoch: 67 [7040/14860 (47%)]\tLoss: 0.011012\n",
            "Train Epoch: 67 [7168/14860 (48%)]\tLoss: 0.023404\n",
            "Train Epoch: 67 [7296/14860 (49%)]\tLoss: 0.014196\n",
            "Train Epoch: 67 [7424/14860 (50%)]\tLoss: 0.022095\n",
            "Train Epoch: 67 [7552/14860 (50%)]\tLoss: 0.026286\n",
            "Train Epoch: 67 [7680/14860 (51%)]\tLoss: 0.013239\n",
            "Train Epoch: 67 [7808/14860 (52%)]\tLoss: 0.019032\n",
            "Train Epoch: 67 [7936/14860 (53%)]\tLoss: 0.024527\n",
            "Train Epoch: 67 [8064/14860 (54%)]\tLoss: 0.020021\n",
            "Train Epoch: 67 [8192/14860 (55%)]\tLoss: 0.019763\n",
            "Train Epoch: 67 [8320/14860 (56%)]\tLoss: 0.016436\n",
            "Train Epoch: 67 [8448/14860 (56%)]\tLoss: 0.023099\n",
            "Train Epoch: 67 [8576/14860 (57%)]\tLoss: 0.016142\n",
            "Train Epoch: 67 [8704/14860 (58%)]\tLoss: 0.018059\n",
            "Train Epoch: 67 [8832/14860 (59%)]\tLoss: 0.017947\n",
            "Train Epoch: 67 [8960/14860 (60%)]\tLoss: 0.023717\n",
            "Train Epoch: 67 [9088/14860 (61%)]\tLoss: 0.023126\n",
            "Train Epoch: 67 [9216/14860 (62%)]\tLoss: 0.013903\n",
            "Train Epoch: 67 [9344/14860 (62%)]\tLoss: 0.027015\n",
            "Train Epoch: 67 [9472/14860 (63%)]\tLoss: 0.017234\n",
            "Train Epoch: 67 [9600/14860 (64%)]\tLoss: 0.019253\n",
            "Train Epoch: 67 [9728/14860 (65%)]\tLoss: 0.018751\n",
            "Train Epoch: 67 [9856/14860 (66%)]\tLoss: 0.023511\n",
            "Train Epoch: 67 [9984/14860 (67%)]\tLoss: 0.026724\n",
            "Train Epoch: 67 [10112/14860 (68%)]\tLoss: 0.016610\n",
            "Train Epoch: 67 [10240/14860 (68%)]\tLoss: 0.018760\n",
            "Train Epoch: 67 [10368/14860 (69%)]\tLoss: 0.021390\n",
            "Train Epoch: 67 [10496/14860 (70%)]\tLoss: 0.016201\n",
            "Train Epoch: 67 [10624/14860 (71%)]\tLoss: 0.020387\n",
            "Train Epoch: 67 [10752/14860 (72%)]\tLoss: 0.022762\n",
            "Train Epoch: 67 [10880/14860 (73%)]\tLoss: 0.026014\n",
            "Train Epoch: 67 [11008/14860 (74%)]\tLoss: 0.015466\n",
            "Train Epoch: 67 [11136/14860 (74%)]\tLoss: 0.018101\n",
            "Train Epoch: 67 [11264/14860 (75%)]\tLoss: 0.017890\n",
            "Train Epoch: 67 [11392/14860 (76%)]\tLoss: 0.016135\n",
            "Train Epoch: 67 [11520/14860 (77%)]\tLoss: 0.010495\n",
            "Train Epoch: 67 [11648/14860 (78%)]\tLoss: 0.017019\n",
            "Train Epoch: 67 [11776/14860 (79%)]\tLoss: 0.017678\n",
            "Train Epoch: 67 [11904/14860 (79%)]\tLoss: 0.021329\n",
            "Train Epoch: 67 [12032/14860 (80%)]\tLoss: 0.020945\n",
            "Train Epoch: 67 [12160/14860 (81%)]\tLoss: 0.019925\n",
            "Train Epoch: 67 [12288/14860 (82%)]\tLoss: 0.020966\n",
            "Train Epoch: 67 [12416/14860 (83%)]\tLoss: 0.017394\n",
            "Train Epoch: 67 [12544/14860 (84%)]\tLoss: 0.023678\n",
            "Train Epoch: 67 [12672/14860 (85%)]\tLoss: 0.020388\n",
            "Train Epoch: 67 [12800/14860 (85%)]\tLoss: 0.019476\n",
            "Train Epoch: 67 [12928/14860 (86%)]\tLoss: 0.018689\n",
            "Train Epoch: 67 [13056/14860 (87%)]\tLoss: 0.023727\n",
            "Train Epoch: 67 [13184/14860 (88%)]\tLoss: 0.015931\n",
            "Train Epoch: 67 [13312/14860 (89%)]\tLoss: 0.021558\n",
            "Train Epoch: 67 [13440/14860 (90%)]\tLoss: 0.016177\n",
            "Train Epoch: 67 [13568/14860 (91%)]\tLoss: 0.026817\n",
            "Train Epoch: 67 [13696/14860 (91%)]\tLoss: 0.015468\n",
            "Train Epoch: 67 [13824/14860 (92%)]\tLoss: 0.019358\n",
            "Train Epoch: 67 [13952/14860 (93%)]\tLoss: 0.022399\n",
            "Train Epoch: 67 [14080/14860 (94%)]\tLoss: 0.019011\n",
            "Train Epoch: 67 [14208/14860 (95%)]\tLoss: 0.019094\n",
            "Train Epoch: 67 [14336/14860 (96%)]\tLoss: 0.029478\n",
            "Train Epoch: 67 [14464/14860 (97%)]\tLoss: 0.016608\n",
            "Train Epoch: 67 [14592/14860 (97%)]\tLoss: 0.015181\n",
            "Train Epoch: 67 [14720/14860 (98%)]\tLoss: 0.019642\n",
            "Train Epoch: 67 [1392/14860 (99%)]\tLoss: 0.021400\n",
            "epoch 67 training loss: 0.019358525331267435\n",
            "epoch 67 validation loss: 0.02043661121594704\n",
            "Train Epoch: 68 [0/14860 (0%)]\tLoss: 0.020516\n",
            "Train Epoch: 68 [128/14860 (1%)]\tLoss: 0.020607\n",
            "Train Epoch: 68 [256/14860 (2%)]\tLoss: 0.023219\n",
            "Train Epoch: 68 [384/14860 (3%)]\tLoss: 0.020203\n",
            "Train Epoch: 68 [512/14860 (3%)]\tLoss: 0.021859\n",
            "Train Epoch: 68 [640/14860 (4%)]\tLoss: 0.015800\n",
            "Train Epoch: 68 [768/14860 (5%)]\tLoss: 0.015797\n",
            "Train Epoch: 68 [896/14860 (6%)]\tLoss: 0.019004\n",
            "Train Epoch: 68 [1024/14860 (7%)]\tLoss: 0.021155\n",
            "Train Epoch: 68 [1152/14860 (8%)]\tLoss: 0.021265\n",
            "Train Epoch: 68 [1280/14860 (9%)]\tLoss: 0.022164\n",
            "Train Epoch: 68 [1408/14860 (9%)]\tLoss: 0.023423\n",
            "Train Epoch: 68 [1536/14860 (10%)]\tLoss: 0.014915\n",
            "Train Epoch: 68 [1664/14860 (11%)]\tLoss: 0.018724\n",
            "Train Epoch: 68 [1792/14860 (12%)]\tLoss: 0.015031\n",
            "Train Epoch: 68 [1920/14860 (13%)]\tLoss: 0.022097\n",
            "Train Epoch: 68 [2048/14860 (14%)]\tLoss: 0.019973\n",
            "Train Epoch: 68 [2176/14860 (15%)]\tLoss: 0.015118\n",
            "Train Epoch: 68 [2304/14860 (15%)]\tLoss: 0.022149\n",
            "Train Epoch: 68 [2432/14860 (16%)]\tLoss: 0.021046\n",
            "Train Epoch: 68 [2560/14860 (17%)]\tLoss: 0.017510\n",
            "Train Epoch: 68 [2688/14860 (18%)]\tLoss: 0.018028\n",
            "Train Epoch: 68 [2816/14860 (19%)]\tLoss: 0.025403\n",
            "Train Epoch: 68 [2944/14860 (20%)]\tLoss: 0.016239\n",
            "Train Epoch: 68 [3072/14860 (21%)]\tLoss: 0.022075\n",
            "Train Epoch: 68 [3200/14860 (21%)]\tLoss: 0.023016\n",
            "Train Epoch: 68 [3328/14860 (22%)]\tLoss: 0.024340\n",
            "Train Epoch: 68 [3456/14860 (23%)]\tLoss: 0.014150\n",
            "Train Epoch: 68 [3584/14860 (24%)]\tLoss: 0.017848\n",
            "Train Epoch: 68 [3712/14860 (25%)]\tLoss: 0.027560\n",
            "Train Epoch: 68 [3840/14860 (26%)]\tLoss: 0.017208\n",
            "Train Epoch: 68 [3968/14860 (26%)]\tLoss: 0.026261\n",
            "Train Epoch: 68 [4096/14860 (27%)]\tLoss: 0.019182\n",
            "Train Epoch: 68 [4224/14860 (28%)]\tLoss: 0.017822\n",
            "Train Epoch: 68 [4352/14860 (29%)]\tLoss: 0.020946\n",
            "Train Epoch: 68 [4480/14860 (30%)]\tLoss: 0.017103\n",
            "Train Epoch: 68 [4608/14860 (31%)]\tLoss: 0.029198\n",
            "Train Epoch: 68 [4736/14860 (32%)]\tLoss: 0.021820\n",
            "Train Epoch: 68 [4864/14860 (32%)]\tLoss: 0.015355\n",
            "Train Epoch: 68 [4992/14860 (33%)]\tLoss: 0.021438\n",
            "Train Epoch: 68 [5120/14860 (34%)]\tLoss: 0.022911\n",
            "Train Epoch: 68 [5248/14860 (35%)]\tLoss: 0.019562\n",
            "Train Epoch: 68 [5376/14860 (36%)]\tLoss: 0.016716\n",
            "Train Epoch: 68 [5504/14860 (37%)]\tLoss: 0.017584\n",
            "Train Epoch: 68 [5632/14860 (38%)]\tLoss: 0.016796\n",
            "Train Epoch: 68 [5760/14860 (38%)]\tLoss: 0.019839\n",
            "Train Epoch: 68 [5888/14860 (39%)]\tLoss: 0.016549\n",
            "Train Epoch: 68 [6016/14860 (40%)]\tLoss: 0.019215\n",
            "Train Epoch: 68 [6144/14860 (41%)]\tLoss: 0.028223\n",
            "Train Epoch: 68 [6272/14860 (42%)]\tLoss: 0.019229\n",
            "Train Epoch: 68 [6400/14860 (43%)]\tLoss: 0.023760\n",
            "Train Epoch: 68 [6528/14860 (44%)]\tLoss: 0.016299\n",
            "Train Epoch: 68 [6656/14860 (44%)]\tLoss: 0.017228\n",
            "Train Epoch: 68 [6784/14860 (45%)]\tLoss: 0.022512\n",
            "Train Epoch: 68 [6912/14860 (46%)]\tLoss: 0.014662\n",
            "Train Epoch: 68 [7040/14860 (47%)]\tLoss: 0.020836\n",
            "Train Epoch: 68 [7168/14860 (48%)]\tLoss: 0.022068\n",
            "Train Epoch: 68 [7296/14860 (49%)]\tLoss: 0.021097\n",
            "Train Epoch: 68 [7424/14860 (50%)]\tLoss: 0.017351\n",
            "Train Epoch: 68 [7552/14860 (50%)]\tLoss: 0.024029\n",
            "Train Epoch: 68 [7680/14860 (51%)]\tLoss: 0.019711\n",
            "Train Epoch: 68 [7808/14860 (52%)]\tLoss: 0.018487\n",
            "Train Epoch: 68 [7936/14860 (53%)]\tLoss: 0.012486\n",
            "Train Epoch: 68 [8064/14860 (54%)]\tLoss: 0.018234\n",
            "Train Epoch: 68 [8192/14860 (55%)]\tLoss: 0.014202\n",
            "Train Epoch: 68 [8320/14860 (56%)]\tLoss: 0.015150\n",
            "Train Epoch: 68 [8448/14860 (56%)]\tLoss: 0.014817\n",
            "Train Epoch: 68 [8576/14860 (57%)]\tLoss: 0.024422\n",
            "Train Epoch: 68 [8704/14860 (58%)]\tLoss: 0.020194\n",
            "Train Epoch: 68 [8832/14860 (59%)]\tLoss: 0.014749\n",
            "Train Epoch: 68 [8960/14860 (60%)]\tLoss: 0.020332\n",
            "Train Epoch: 68 [9088/14860 (61%)]\tLoss: 0.016996\n",
            "Train Epoch: 68 [9216/14860 (62%)]\tLoss: 0.024008\n",
            "Train Epoch: 68 [9344/14860 (62%)]\tLoss: 0.018673\n",
            "Train Epoch: 68 [9472/14860 (63%)]\tLoss: 0.016790\n",
            "Train Epoch: 68 [9600/14860 (64%)]\tLoss: 0.027657\n",
            "Train Epoch: 68 [9728/14860 (65%)]\tLoss: 0.019147\n",
            "Train Epoch: 68 [9856/14860 (66%)]\tLoss: 0.020037\n",
            "Train Epoch: 68 [9984/14860 (67%)]\tLoss: 0.022277\n",
            "Train Epoch: 68 [10112/14860 (68%)]\tLoss: 0.017919\n",
            "Train Epoch: 68 [10240/14860 (68%)]\tLoss: 0.018973\n",
            "Train Epoch: 68 [10368/14860 (69%)]\tLoss: 0.014834\n",
            "Train Epoch: 68 [10496/14860 (70%)]\tLoss: 0.024170\n",
            "Train Epoch: 68 [10624/14860 (71%)]\tLoss: 0.020251\n",
            "Train Epoch: 68 [10752/14860 (72%)]\tLoss: 0.013391\n",
            "Train Epoch: 68 [10880/14860 (73%)]\tLoss: 0.017679\n",
            "Train Epoch: 68 [11008/14860 (74%)]\tLoss: 0.020079\n",
            "Train Epoch: 68 [11136/14860 (74%)]\tLoss: 0.022651\n",
            "Train Epoch: 68 [11264/14860 (75%)]\tLoss: 0.018682\n",
            "Train Epoch: 68 [11392/14860 (76%)]\tLoss: 0.020991\n",
            "Train Epoch: 68 [11520/14860 (77%)]\tLoss: 0.022801\n",
            "Train Epoch: 68 [11648/14860 (78%)]\tLoss: 0.014551\n",
            "Train Epoch: 68 [11776/14860 (79%)]\tLoss: 0.021014\n",
            "Train Epoch: 68 [11904/14860 (79%)]\tLoss: 0.017444\n",
            "Train Epoch: 68 [12032/14860 (80%)]\tLoss: 0.020459\n",
            "Train Epoch: 68 [12160/14860 (81%)]\tLoss: 0.016804\n",
            "Train Epoch: 68 [12288/14860 (82%)]\tLoss: 0.023003\n",
            "Train Epoch: 68 [12416/14860 (83%)]\tLoss: 0.015852\n",
            "Train Epoch: 68 [12544/14860 (84%)]\tLoss: 0.016261\n",
            "Train Epoch: 68 [12672/14860 (85%)]\tLoss: 0.021529\n",
            "Train Epoch: 68 [12800/14860 (85%)]\tLoss: 0.034587\n",
            "Train Epoch: 68 [12928/14860 (86%)]\tLoss: 0.021006\n",
            "Train Epoch: 68 [13056/14860 (87%)]\tLoss: 0.020060\n",
            "Train Epoch: 68 [13184/14860 (88%)]\tLoss: 0.023095\n",
            "Train Epoch: 68 [13312/14860 (89%)]\tLoss: 0.015886\n",
            "Train Epoch: 68 [13440/14860 (90%)]\tLoss: 0.012448\n",
            "Train Epoch: 68 [13568/14860 (91%)]\tLoss: 0.020615\n",
            "Train Epoch: 68 [13696/14860 (91%)]\tLoss: 0.016196\n",
            "Train Epoch: 68 [13824/14860 (92%)]\tLoss: 0.020592\n",
            "Train Epoch: 68 [13952/14860 (93%)]\tLoss: 0.018651\n",
            "Train Epoch: 68 [14080/14860 (94%)]\tLoss: 0.028068\n",
            "Train Epoch: 68 [14208/14860 (95%)]\tLoss: 0.031467\n",
            "Train Epoch: 68 [14336/14860 (96%)]\tLoss: 0.018609\n",
            "Train Epoch: 68 [14464/14860 (97%)]\tLoss: 0.022783\n",
            "Train Epoch: 68 [14592/14860 (97%)]\tLoss: 0.019312\n",
            "Train Epoch: 68 [14720/14860 (98%)]\tLoss: 0.020806\n",
            "Train Epoch: 68 [1392/14860 (99%)]\tLoss: 0.023567\n",
            "epoch 68 training loss: 0.019901574708712406\n",
            "epoch 68 validation loss: 0.022463475387841103\n",
            "Train Epoch: 69 [0/14860 (0%)]\tLoss: 0.024146\n",
            "Train Epoch: 69 [128/14860 (1%)]\tLoss: 0.023413\n",
            "Train Epoch: 69 [256/14860 (2%)]\tLoss: 0.015767\n",
            "Train Epoch: 69 [384/14860 (3%)]\tLoss: 0.012645\n",
            "Train Epoch: 69 [512/14860 (3%)]\tLoss: 0.014165\n",
            "Train Epoch: 69 [640/14860 (4%)]\tLoss: 0.019593\n",
            "Train Epoch: 69 [768/14860 (5%)]\tLoss: 0.015190\n",
            "Train Epoch: 69 [896/14860 (6%)]\tLoss: 0.014489\n",
            "Train Epoch: 69 [1024/14860 (7%)]\tLoss: 0.024269\n",
            "Train Epoch: 69 [1152/14860 (8%)]\tLoss: 0.023269\n",
            "Train Epoch: 69 [1280/14860 (9%)]\tLoss: 0.021867\n",
            "Train Epoch: 69 [1408/14860 (9%)]\tLoss: 0.019972\n",
            "Train Epoch: 69 [1536/14860 (10%)]\tLoss: 0.022627\n",
            "Train Epoch: 69 [1664/14860 (11%)]\tLoss: 0.018570\n",
            "Train Epoch: 69 [1792/14860 (12%)]\tLoss: 0.026215\n",
            "Train Epoch: 69 [1920/14860 (13%)]\tLoss: 0.017257\n",
            "Train Epoch: 69 [2048/14860 (14%)]\tLoss: 0.020806\n",
            "Train Epoch: 69 [2176/14860 (15%)]\tLoss: 0.015257\n",
            "Train Epoch: 69 [2304/14860 (15%)]\tLoss: 0.019609\n",
            "Train Epoch: 69 [2432/14860 (16%)]\tLoss: 0.016283\n",
            "Train Epoch: 69 [2560/14860 (17%)]\tLoss: 0.021742\n",
            "Train Epoch: 69 [2688/14860 (18%)]\tLoss: 0.023858\n",
            "Train Epoch: 69 [2816/14860 (19%)]\tLoss: 0.022662\n",
            "Train Epoch: 69 [2944/14860 (20%)]\tLoss: 0.021507\n",
            "Train Epoch: 69 [3072/14860 (21%)]\tLoss: 0.019335\n",
            "Train Epoch: 69 [3200/14860 (21%)]\tLoss: 0.014504\n",
            "Train Epoch: 69 [3328/14860 (22%)]\tLoss: 0.015463\n",
            "Train Epoch: 69 [3456/14860 (23%)]\tLoss: 0.017846\n",
            "Train Epoch: 69 [3584/14860 (24%)]\tLoss: 0.020489\n",
            "Train Epoch: 69 [3712/14860 (25%)]\tLoss: 0.019299\n",
            "Train Epoch: 69 [3840/14860 (26%)]\tLoss: 0.020196\n",
            "Train Epoch: 69 [3968/14860 (26%)]\tLoss: 0.014364\n",
            "Train Epoch: 69 [4096/14860 (27%)]\tLoss: 0.014812\n",
            "Train Epoch: 69 [4224/14860 (28%)]\tLoss: 0.022058\n",
            "Train Epoch: 69 [4352/14860 (29%)]\tLoss: 0.020149\n",
            "Train Epoch: 69 [4480/14860 (30%)]\tLoss: 0.015262\n",
            "Train Epoch: 69 [4608/14860 (31%)]\tLoss: 0.022100\n",
            "Train Epoch: 69 [4736/14860 (32%)]\tLoss: 0.025165\n",
            "Train Epoch: 69 [4864/14860 (32%)]\tLoss: 0.019604\n",
            "Train Epoch: 69 [4992/14860 (33%)]\tLoss: 0.024306\n",
            "Train Epoch: 69 [5120/14860 (34%)]\tLoss: 0.010336\n",
            "Train Epoch: 69 [5248/14860 (35%)]\tLoss: 0.021490\n",
            "Train Epoch: 69 [5376/14860 (36%)]\tLoss: 0.013428\n",
            "Train Epoch: 69 [5504/14860 (37%)]\tLoss: 0.019456\n",
            "Train Epoch: 69 [5632/14860 (38%)]\tLoss: 0.018214\n",
            "Train Epoch: 69 [5760/14860 (38%)]\tLoss: 0.017373\n",
            "Train Epoch: 69 [5888/14860 (39%)]\tLoss: 0.015137\n",
            "Train Epoch: 69 [6016/14860 (40%)]\tLoss: 0.014539\n",
            "Train Epoch: 69 [6144/14860 (41%)]\tLoss: 0.016097\n",
            "Train Epoch: 69 [6272/14860 (42%)]\tLoss: 0.016192\n",
            "Train Epoch: 69 [6400/14860 (43%)]\tLoss: 0.019061\n",
            "Train Epoch: 69 [6528/14860 (44%)]\tLoss: 0.019017\n",
            "Train Epoch: 69 [6656/14860 (44%)]\tLoss: 0.015732\n",
            "Train Epoch: 69 [6784/14860 (45%)]\tLoss: 0.015828\n",
            "Train Epoch: 69 [6912/14860 (46%)]\tLoss: 0.017264\n",
            "Train Epoch: 69 [7040/14860 (47%)]\tLoss: 0.025032\n",
            "Train Epoch: 69 [7168/14860 (48%)]\tLoss: 0.027120\n",
            "Train Epoch: 69 [7296/14860 (49%)]\tLoss: 0.020891\n",
            "Train Epoch: 69 [7424/14860 (50%)]\tLoss: 0.020011\n",
            "Train Epoch: 69 [7552/14860 (50%)]\tLoss: 0.022354\n",
            "Train Epoch: 69 [7680/14860 (51%)]\tLoss: 0.025682\n",
            "Train Epoch: 69 [7808/14860 (52%)]\tLoss: 0.023355\n",
            "Train Epoch: 69 [7936/14860 (53%)]\tLoss: 0.029784\n",
            "Train Epoch: 69 [8064/14860 (54%)]\tLoss: 0.011967\n",
            "Train Epoch: 69 [8192/14860 (55%)]\tLoss: 0.028384\n",
            "Train Epoch: 69 [8320/14860 (56%)]\tLoss: 0.035052\n",
            "Train Epoch: 69 [8448/14860 (56%)]\tLoss: 0.015160\n",
            "Train Epoch: 69 [8576/14860 (57%)]\tLoss: 0.037864\n",
            "Train Epoch: 69 [8704/14860 (58%)]\tLoss: 0.022475\n",
            "Train Epoch: 69 [8832/14860 (59%)]\tLoss: 0.023434\n",
            "Train Epoch: 69 [8960/14860 (60%)]\tLoss: 0.026792\n",
            "Train Epoch: 69 [9088/14860 (61%)]\tLoss: 0.019553\n",
            "Train Epoch: 69 [9216/14860 (62%)]\tLoss: 0.023918\n",
            "Train Epoch: 69 [9344/14860 (62%)]\tLoss: 0.015482\n",
            "Train Epoch: 69 [9472/14860 (63%)]\tLoss: 0.024747\n",
            "Train Epoch: 69 [9600/14860 (64%)]\tLoss: 0.022382\n",
            "Train Epoch: 69 [9728/14860 (65%)]\tLoss: 0.024010\n",
            "Train Epoch: 69 [9856/14860 (66%)]\tLoss: 0.013943\n",
            "Train Epoch: 69 [9984/14860 (67%)]\tLoss: 0.029892\n",
            "Train Epoch: 69 [10112/14860 (68%)]\tLoss: 0.021631\n",
            "Train Epoch: 69 [10240/14860 (68%)]\tLoss: 0.016227\n",
            "Train Epoch: 69 [10368/14860 (69%)]\tLoss: 0.021714\n",
            "Train Epoch: 69 [10496/14860 (70%)]\tLoss: 0.031195\n",
            "Train Epoch: 69 [10624/14860 (71%)]\tLoss: 0.024088\n",
            "Train Epoch: 69 [10752/14860 (72%)]\tLoss: 0.015616\n",
            "Train Epoch: 69 [10880/14860 (73%)]\tLoss: 0.018936\n",
            "Train Epoch: 69 [11008/14860 (74%)]\tLoss: 0.023508\n",
            "Train Epoch: 69 [11136/14860 (74%)]\tLoss: 0.016109\n",
            "Train Epoch: 69 [11264/14860 (75%)]\tLoss: 0.020653\n",
            "Train Epoch: 69 [11392/14860 (76%)]\tLoss: 0.018760\n",
            "Train Epoch: 69 [11520/14860 (77%)]\tLoss: 0.022324\n",
            "Train Epoch: 69 [11648/14860 (78%)]\tLoss: 0.021631\n",
            "Train Epoch: 69 [11776/14860 (79%)]\tLoss: 0.023324\n",
            "Train Epoch: 69 [11904/14860 (79%)]\tLoss: 0.019007\n",
            "Train Epoch: 69 [12032/14860 (80%)]\tLoss: 0.018143\n",
            "Train Epoch: 69 [12160/14860 (81%)]\tLoss: 0.020791\n",
            "Train Epoch: 69 [12288/14860 (82%)]\tLoss: 0.018526\n",
            "Train Epoch: 69 [12416/14860 (83%)]\tLoss: 0.017292\n",
            "Train Epoch: 69 [12544/14860 (84%)]\tLoss: 0.020152\n",
            "Train Epoch: 69 [12672/14860 (85%)]\tLoss: 0.029866\n",
            "Train Epoch: 69 [12800/14860 (85%)]\tLoss: 0.024378\n",
            "Train Epoch: 69 [12928/14860 (86%)]\tLoss: 0.014412\n",
            "Train Epoch: 69 [13056/14860 (87%)]\tLoss: 0.022411\n",
            "Train Epoch: 69 [13184/14860 (88%)]\tLoss: 0.020329\n",
            "Train Epoch: 69 [13312/14860 (89%)]\tLoss: 0.028926\n",
            "Train Epoch: 69 [13440/14860 (90%)]\tLoss: 0.025310\n",
            "Train Epoch: 69 [13568/14860 (91%)]\tLoss: 0.019136\n",
            "Train Epoch: 69 [13696/14860 (91%)]\tLoss: 0.014630\n",
            "Train Epoch: 69 [13824/14860 (92%)]\tLoss: 0.026464\n",
            "Train Epoch: 69 [13952/14860 (93%)]\tLoss: 0.015062\n",
            "Train Epoch: 69 [14080/14860 (94%)]\tLoss: 0.012939\n",
            "Train Epoch: 69 [14208/14860 (95%)]\tLoss: 0.020190\n",
            "Train Epoch: 69 [14336/14860 (96%)]\tLoss: 0.013388\n",
            "Train Epoch: 69 [14464/14860 (97%)]\tLoss: 0.016470\n",
            "Train Epoch: 69 [14592/14860 (97%)]\tLoss: 0.016433\n",
            "Train Epoch: 69 [14720/14860 (98%)]\tLoss: 0.017505\n",
            "Train Epoch: 69 [1392/14860 (99%)]\tLoss: 0.014249\n",
            "epoch 69 training loss: 0.020173549071018003\n",
            "epoch 69 validation loss: 0.020536430089872052\n",
            "Train Epoch: 70 [0/14860 (0%)]\tLoss: 0.019575\n",
            "Train Epoch: 70 [128/14860 (1%)]\tLoss: 0.014257\n",
            "Train Epoch: 70 [256/14860 (2%)]\tLoss: 0.021536\n",
            "Train Epoch: 70 [384/14860 (3%)]\tLoss: 0.030006\n",
            "Train Epoch: 70 [512/14860 (3%)]\tLoss: 0.021270\n",
            "Train Epoch: 70 [640/14860 (4%)]\tLoss: 0.017759\n",
            "Train Epoch: 70 [768/14860 (5%)]\tLoss: 0.014267\n",
            "Train Epoch: 70 [896/14860 (6%)]\tLoss: 0.017528\n",
            "Train Epoch: 70 [1024/14860 (7%)]\tLoss: 0.020167\n",
            "Train Epoch: 70 [1152/14860 (8%)]\tLoss: 0.024001\n",
            "Train Epoch: 70 [1280/14860 (9%)]\tLoss: 0.017081\n",
            "Train Epoch: 70 [1408/14860 (9%)]\tLoss: 0.017544\n",
            "Train Epoch: 70 [1536/14860 (10%)]\tLoss: 0.017792\n",
            "Train Epoch: 70 [1664/14860 (11%)]\tLoss: 0.017322\n",
            "Train Epoch: 70 [1792/14860 (12%)]\tLoss: 0.012784\n",
            "Train Epoch: 70 [1920/14860 (13%)]\tLoss: 0.027515\n",
            "Train Epoch: 70 [2048/14860 (14%)]\tLoss: 0.017486\n",
            "Train Epoch: 70 [2176/14860 (15%)]\tLoss: 0.018844\n",
            "Train Epoch: 70 [2304/14860 (15%)]\tLoss: 0.018211\n",
            "Train Epoch: 70 [2432/14860 (16%)]\tLoss: 0.026968\n",
            "Train Epoch: 70 [2560/14860 (17%)]\tLoss: 0.019249\n",
            "Train Epoch: 70 [2688/14860 (18%)]\tLoss: 0.014003\n",
            "Train Epoch: 70 [2816/14860 (19%)]\tLoss: 0.019975\n",
            "Train Epoch: 70 [2944/14860 (20%)]\tLoss: 0.017066\n",
            "Train Epoch: 70 [3072/14860 (21%)]\tLoss: 0.018479\n",
            "Train Epoch: 70 [3200/14860 (21%)]\tLoss: 0.018833\n",
            "Train Epoch: 70 [3328/14860 (22%)]\tLoss: 0.028205\n",
            "Train Epoch: 70 [3456/14860 (23%)]\tLoss: 0.019962\n",
            "Train Epoch: 70 [3584/14860 (24%)]\tLoss: 0.025403\n",
            "Train Epoch: 70 [3712/14860 (25%)]\tLoss: 0.016702\n",
            "Train Epoch: 70 [3840/14860 (26%)]\tLoss: 0.018303\n",
            "Train Epoch: 70 [3968/14860 (26%)]\tLoss: 0.026104\n",
            "Train Epoch: 70 [4096/14860 (27%)]\tLoss: 0.019875\n",
            "Train Epoch: 70 [4224/14860 (28%)]\tLoss: 0.013118\n",
            "Train Epoch: 70 [4352/14860 (29%)]\tLoss: 0.015049\n",
            "Train Epoch: 70 [4480/14860 (30%)]\tLoss: 0.020482\n",
            "Train Epoch: 70 [4608/14860 (31%)]\tLoss: 0.021216\n",
            "Train Epoch: 70 [4736/14860 (32%)]\tLoss: 0.018142\n",
            "Train Epoch: 70 [4864/14860 (32%)]\tLoss: 0.016010\n",
            "Train Epoch: 70 [4992/14860 (33%)]\tLoss: 0.024231\n",
            "Train Epoch: 70 [5120/14860 (34%)]\tLoss: 0.012902\n",
            "Train Epoch: 70 [5248/14860 (35%)]\tLoss: 0.024899\n",
            "Train Epoch: 70 [5376/14860 (36%)]\tLoss: 0.017059\n",
            "Train Epoch: 70 [5504/14860 (37%)]\tLoss: 0.020620\n",
            "Train Epoch: 70 [5632/14860 (38%)]\tLoss: 0.014716\n",
            "Train Epoch: 70 [5760/14860 (38%)]\tLoss: 0.017044\n",
            "Train Epoch: 70 [5888/14860 (39%)]\tLoss: 0.019426\n",
            "Train Epoch: 70 [6016/14860 (40%)]\tLoss: 0.025551\n",
            "Train Epoch: 70 [6144/14860 (41%)]\tLoss: 0.021212\n",
            "Train Epoch: 70 [6272/14860 (42%)]\tLoss: 0.014896\n",
            "Train Epoch: 70 [6400/14860 (43%)]\tLoss: 0.024785\n",
            "Train Epoch: 70 [6528/14860 (44%)]\tLoss: 0.017264\n",
            "Train Epoch: 70 [6656/14860 (44%)]\tLoss: 0.024613\n",
            "Train Epoch: 70 [6784/14860 (45%)]\tLoss: 0.016115\n",
            "Train Epoch: 70 [6912/14860 (46%)]\tLoss: 0.020274\n",
            "Train Epoch: 70 [7040/14860 (47%)]\tLoss: 0.019794\n",
            "Train Epoch: 70 [7168/14860 (48%)]\tLoss: 0.021466\n",
            "Train Epoch: 70 [7296/14860 (49%)]\tLoss: 0.013108\n",
            "Train Epoch: 70 [7424/14860 (50%)]\tLoss: 0.019699\n",
            "Train Epoch: 70 [7552/14860 (50%)]\tLoss: 0.019756\n",
            "Train Epoch: 70 [7680/14860 (51%)]\tLoss: 0.023950\n",
            "Train Epoch: 70 [7808/14860 (52%)]\tLoss: 0.020370\n",
            "Train Epoch: 70 [7936/14860 (53%)]\tLoss: 0.017553\n",
            "Train Epoch: 70 [8064/14860 (54%)]\tLoss: 0.016039\n",
            "Train Epoch: 70 [8192/14860 (55%)]\tLoss: 0.016936\n",
            "Train Epoch: 70 [8320/14860 (56%)]\tLoss: 0.013190\n",
            "Train Epoch: 70 [8448/14860 (56%)]\tLoss: 0.024496\n",
            "Train Epoch: 70 [8576/14860 (57%)]\tLoss: 0.016249\n",
            "Train Epoch: 70 [8704/14860 (58%)]\tLoss: 0.018393\n",
            "Train Epoch: 70 [8832/14860 (59%)]\tLoss: 0.020229\n",
            "Train Epoch: 70 [8960/14860 (60%)]\tLoss: 0.016222\n",
            "Train Epoch: 70 [9088/14860 (61%)]\tLoss: 0.013193\n",
            "Train Epoch: 70 [9216/14860 (62%)]\tLoss: 0.014398\n",
            "Train Epoch: 70 [9344/14860 (62%)]\tLoss: 0.032389\n",
            "Train Epoch: 70 [9472/14860 (63%)]\tLoss: 0.026051\n",
            "Train Epoch: 70 [9600/14860 (64%)]\tLoss: 0.017930\n",
            "Train Epoch: 70 [9728/14860 (65%)]\tLoss: 0.020973\n",
            "Train Epoch: 70 [9856/14860 (66%)]\tLoss: 0.021340\n",
            "Train Epoch: 70 [9984/14860 (67%)]\tLoss: 0.016942\n",
            "Train Epoch: 70 [10112/14860 (68%)]\tLoss: 0.022580\n",
            "Train Epoch: 70 [10240/14860 (68%)]\tLoss: 0.025094\n",
            "Train Epoch: 70 [10368/14860 (69%)]\tLoss: 0.021501\n",
            "Train Epoch: 70 [10496/14860 (70%)]\tLoss: 0.020868\n",
            "Train Epoch: 70 [10624/14860 (71%)]\tLoss: 0.014507\n",
            "Train Epoch: 70 [10752/14860 (72%)]\tLoss: 0.025202\n",
            "Train Epoch: 70 [10880/14860 (73%)]\tLoss: 0.018853\n",
            "Train Epoch: 70 [11008/14860 (74%)]\tLoss: 0.020622\n",
            "Train Epoch: 70 [11136/14860 (74%)]\tLoss: 0.016411\n",
            "Train Epoch: 70 [11264/14860 (75%)]\tLoss: 0.022225\n",
            "Train Epoch: 70 [11392/14860 (76%)]\tLoss: 0.016636\n",
            "Train Epoch: 70 [11520/14860 (77%)]\tLoss: 0.018838\n",
            "Train Epoch: 70 [11648/14860 (78%)]\tLoss: 0.017170\n",
            "Train Epoch: 70 [11776/14860 (79%)]\tLoss: 0.022179\n",
            "Train Epoch: 70 [11904/14860 (79%)]\tLoss: 0.017654\n",
            "Train Epoch: 70 [12032/14860 (80%)]\tLoss: 0.019187\n",
            "Train Epoch: 70 [12160/14860 (81%)]\tLoss: 0.015252\n",
            "Train Epoch: 70 [12288/14860 (82%)]\tLoss: 0.020246\n",
            "Train Epoch: 70 [12416/14860 (83%)]\tLoss: 0.021660\n",
            "Train Epoch: 70 [12544/14860 (84%)]\tLoss: 0.018164\n",
            "Train Epoch: 70 [12672/14860 (85%)]\tLoss: 0.017567\n",
            "Train Epoch: 70 [12800/14860 (85%)]\tLoss: 0.017649\n",
            "Train Epoch: 70 [12928/14860 (86%)]\tLoss: 0.022399\n",
            "Train Epoch: 70 [13056/14860 (87%)]\tLoss: 0.032388\n",
            "Train Epoch: 70 [13184/14860 (88%)]\tLoss: 0.022733\n",
            "Train Epoch: 70 [13312/14860 (89%)]\tLoss: 0.018623\n",
            "Train Epoch: 70 [13440/14860 (90%)]\tLoss: 0.017844\n",
            "Train Epoch: 70 [13568/14860 (91%)]\tLoss: 0.017357\n",
            "Train Epoch: 70 [13696/14860 (91%)]\tLoss: 0.020790\n",
            "Train Epoch: 70 [13824/14860 (92%)]\tLoss: 0.017401\n",
            "Train Epoch: 70 [13952/14860 (93%)]\tLoss: 0.020663\n",
            "Train Epoch: 70 [14080/14860 (94%)]\tLoss: 0.017750\n",
            "Train Epoch: 70 [14208/14860 (95%)]\tLoss: 0.019801\n",
            "Train Epoch: 70 [14336/14860 (96%)]\tLoss: 0.019727\n",
            "Train Epoch: 70 [14464/14860 (97%)]\tLoss: 0.018192\n",
            "Train Epoch: 70 [14592/14860 (97%)]\tLoss: 0.021957\n",
            "Train Epoch: 70 [14720/14860 (98%)]\tLoss: 0.016253\n",
            "Train Epoch: 70 [1392/14860 (99%)]\tLoss: 0.009678\n",
            "epoch 70 training loss: 0.019469937070822105\n",
            "epoch 70 validation loss: 0.020231886651845013\n",
            "Train Epoch: 71 [0/14860 (0%)]\tLoss: 0.015620\n",
            "Train Epoch: 71 [128/14860 (1%)]\tLoss: 0.032132\n",
            "Train Epoch: 71 [256/14860 (2%)]\tLoss: 0.017965\n",
            "Train Epoch: 71 [384/14860 (3%)]\tLoss: 0.025491\n",
            "Train Epoch: 71 [512/14860 (3%)]\tLoss: 0.020945\n",
            "Train Epoch: 71 [640/14860 (4%)]\tLoss: 0.018531\n",
            "Train Epoch: 71 [768/14860 (5%)]\tLoss: 0.012769\n",
            "Train Epoch: 71 [896/14860 (6%)]\tLoss: 0.020740\n",
            "Train Epoch: 71 [1024/14860 (7%)]\tLoss: 0.013743\n",
            "Train Epoch: 71 [1152/14860 (8%)]\tLoss: 0.018224\n",
            "Train Epoch: 71 [1280/14860 (9%)]\tLoss: 0.022650\n",
            "Train Epoch: 71 [1408/14860 (9%)]\tLoss: 0.018713\n",
            "Train Epoch: 71 [1536/14860 (10%)]\tLoss: 0.019632\n",
            "Train Epoch: 71 [1664/14860 (11%)]\tLoss: 0.022492\n",
            "Train Epoch: 71 [1792/14860 (12%)]\tLoss: 0.013777\n",
            "Train Epoch: 71 [1920/14860 (13%)]\tLoss: 0.015710\n",
            "Train Epoch: 71 [2048/14860 (14%)]\tLoss: 0.018188\n",
            "Train Epoch: 71 [2176/14860 (15%)]\tLoss: 0.016501\n",
            "Train Epoch: 71 [2304/14860 (15%)]\tLoss: 0.019358\n",
            "Train Epoch: 71 [2432/14860 (16%)]\tLoss: 0.017389\n",
            "Train Epoch: 71 [2560/14860 (17%)]\tLoss: 0.017330\n",
            "Train Epoch: 71 [2688/14860 (18%)]\tLoss: 0.021527\n",
            "Train Epoch: 71 [2816/14860 (19%)]\tLoss: 0.013761\n",
            "Train Epoch: 71 [2944/14860 (20%)]\tLoss: 0.015050\n",
            "Train Epoch: 71 [3072/14860 (21%)]\tLoss: 0.031412\n",
            "Train Epoch: 71 [3200/14860 (21%)]\tLoss: 0.018520\n",
            "Train Epoch: 71 [3328/14860 (22%)]\tLoss: 0.016692\n",
            "Train Epoch: 71 [3456/14860 (23%)]\tLoss: 0.020466\n",
            "Train Epoch: 71 [3584/14860 (24%)]\tLoss: 0.018486\n",
            "Train Epoch: 71 [3712/14860 (25%)]\tLoss: 0.022109\n",
            "Train Epoch: 71 [3840/14860 (26%)]\tLoss: 0.014637\n",
            "Train Epoch: 71 [3968/14860 (26%)]\tLoss: 0.024358\n",
            "Train Epoch: 71 [4096/14860 (27%)]\tLoss: 0.018736\n",
            "Train Epoch: 71 [4224/14860 (28%)]\tLoss: 0.022150\n",
            "Train Epoch: 71 [4352/14860 (29%)]\tLoss: 0.019375\n",
            "Train Epoch: 71 [4480/14860 (30%)]\tLoss: 0.022648\n",
            "Train Epoch: 71 [4608/14860 (31%)]\tLoss: 0.014761\n",
            "Train Epoch: 71 [4736/14860 (32%)]\tLoss: 0.023664\n",
            "Train Epoch: 71 [4864/14860 (32%)]\tLoss: 0.016101\n",
            "Train Epoch: 71 [4992/14860 (33%)]\tLoss: 0.017169\n",
            "Train Epoch: 71 [5120/14860 (34%)]\tLoss: 0.026948\n",
            "Train Epoch: 71 [5248/14860 (35%)]\tLoss: 0.018377\n",
            "Train Epoch: 71 [5376/14860 (36%)]\tLoss: 0.018991\n",
            "Train Epoch: 71 [5504/14860 (37%)]\tLoss: 0.018750\n",
            "Train Epoch: 71 [5632/14860 (38%)]\tLoss: 0.014153\n",
            "Train Epoch: 71 [5760/14860 (38%)]\tLoss: 0.027152\n",
            "Train Epoch: 71 [5888/14860 (39%)]\tLoss: 0.018504\n",
            "Train Epoch: 71 [6016/14860 (40%)]\tLoss: 0.025886\n",
            "Train Epoch: 71 [6144/14860 (41%)]\tLoss: 0.019341\n",
            "Train Epoch: 71 [6272/14860 (42%)]\tLoss: 0.013302\n",
            "Train Epoch: 71 [6400/14860 (43%)]\tLoss: 0.019158\n",
            "Train Epoch: 71 [6528/14860 (44%)]\tLoss: 0.016932\n",
            "Train Epoch: 71 [6656/14860 (44%)]\tLoss: 0.017146\n",
            "Train Epoch: 71 [6784/14860 (45%)]\tLoss: 0.018509\n",
            "Train Epoch: 71 [6912/14860 (46%)]\tLoss: 0.019091\n",
            "Train Epoch: 71 [7040/14860 (47%)]\tLoss: 0.020288\n",
            "Train Epoch: 71 [7168/14860 (48%)]\tLoss: 0.017211\n",
            "Train Epoch: 71 [7296/14860 (49%)]\tLoss: 0.020018\n",
            "Train Epoch: 71 [7424/14860 (50%)]\tLoss: 0.022056\n",
            "Train Epoch: 71 [7552/14860 (50%)]\tLoss: 0.023142\n",
            "Train Epoch: 71 [7680/14860 (51%)]\tLoss: 0.022357\n",
            "Train Epoch: 71 [7808/14860 (52%)]\tLoss: 0.015860\n",
            "Train Epoch: 71 [7936/14860 (53%)]\tLoss: 0.012005\n",
            "Train Epoch: 71 [8064/14860 (54%)]\tLoss: 0.021284\n",
            "Train Epoch: 71 [8192/14860 (55%)]\tLoss: 0.016250\n",
            "Train Epoch: 71 [8320/14860 (56%)]\tLoss: 0.014076\n",
            "Train Epoch: 71 [8448/14860 (56%)]\tLoss: 0.018578\n",
            "Train Epoch: 71 [8576/14860 (57%)]\tLoss: 0.021516\n",
            "Train Epoch: 71 [8704/14860 (58%)]\tLoss: 0.017422\n",
            "Train Epoch: 71 [8832/14860 (59%)]\tLoss: 0.023756\n",
            "Train Epoch: 71 [8960/14860 (60%)]\tLoss: 0.019186\n",
            "Train Epoch: 71 [9088/14860 (61%)]\tLoss: 0.020231\n",
            "Train Epoch: 71 [9216/14860 (62%)]\tLoss: 0.020309\n",
            "Train Epoch: 71 [9344/14860 (62%)]\tLoss: 0.022059\n",
            "Train Epoch: 71 [9472/14860 (63%)]\tLoss: 0.024560\n",
            "Train Epoch: 71 [9600/14860 (64%)]\tLoss: 0.020306\n",
            "Train Epoch: 71 [9728/14860 (65%)]\tLoss: 0.021848\n",
            "Train Epoch: 71 [9856/14860 (66%)]\tLoss: 0.014157\n",
            "Train Epoch: 71 [9984/14860 (67%)]\tLoss: 0.032689\n",
            "Train Epoch: 71 [10112/14860 (68%)]\tLoss: 0.015420\n",
            "Train Epoch: 71 [10240/14860 (68%)]\tLoss: 0.025439\n",
            "Train Epoch: 71 [10368/14860 (69%)]\tLoss: 0.028421\n",
            "Train Epoch: 71 [10496/14860 (70%)]\tLoss: 0.021291\n",
            "Train Epoch: 71 [10624/14860 (71%)]\tLoss: 0.018091\n",
            "Train Epoch: 71 [10752/14860 (72%)]\tLoss: 0.018697\n",
            "Train Epoch: 71 [10880/14860 (73%)]\tLoss: 0.023831\n",
            "Train Epoch: 71 [11008/14860 (74%)]\tLoss: 0.014344\n",
            "Train Epoch: 71 [11136/14860 (74%)]\tLoss: 0.014742\n",
            "Train Epoch: 71 [11264/14860 (75%)]\tLoss: 0.016465\n",
            "Train Epoch: 71 [11392/14860 (76%)]\tLoss: 0.021082\n",
            "Train Epoch: 71 [11520/14860 (77%)]\tLoss: 0.015826\n",
            "Train Epoch: 71 [11648/14860 (78%)]\tLoss: 0.022093\n",
            "Train Epoch: 71 [11776/14860 (79%)]\tLoss: 0.021613\n",
            "Train Epoch: 71 [11904/14860 (79%)]\tLoss: 0.020891\n",
            "Train Epoch: 71 [12032/14860 (80%)]\tLoss: 0.016085\n",
            "Train Epoch: 71 [12160/14860 (81%)]\tLoss: 0.023879\n",
            "Train Epoch: 71 [12288/14860 (82%)]\tLoss: 0.011828\n",
            "Train Epoch: 71 [12416/14860 (83%)]\tLoss: 0.016855\n",
            "Train Epoch: 71 [12544/14860 (84%)]\tLoss: 0.020906\n",
            "Train Epoch: 71 [12672/14860 (85%)]\tLoss: 0.020978\n",
            "Train Epoch: 71 [12800/14860 (85%)]\tLoss: 0.015746\n",
            "Train Epoch: 71 [12928/14860 (86%)]\tLoss: 0.017013\n",
            "Train Epoch: 71 [13056/14860 (87%)]\tLoss: 0.017026\n",
            "Train Epoch: 71 [13184/14860 (88%)]\tLoss: 0.021575\n",
            "Train Epoch: 71 [13312/14860 (89%)]\tLoss: 0.017776\n",
            "Train Epoch: 71 [13440/14860 (90%)]\tLoss: 0.018800\n",
            "Train Epoch: 71 [13568/14860 (91%)]\tLoss: 0.024123\n",
            "Train Epoch: 71 [13696/14860 (91%)]\tLoss: 0.028704\n",
            "Train Epoch: 71 [13824/14860 (92%)]\tLoss: 0.019371\n",
            "Train Epoch: 71 [13952/14860 (93%)]\tLoss: 0.018917\n",
            "Train Epoch: 71 [14080/14860 (94%)]\tLoss: 0.022089\n",
            "Train Epoch: 71 [14208/14860 (95%)]\tLoss: 0.013997\n",
            "Train Epoch: 71 [14336/14860 (96%)]\tLoss: 0.015435\n",
            "Train Epoch: 71 [14464/14860 (97%)]\tLoss: 0.022719\n",
            "Train Epoch: 71 [14592/14860 (97%)]\tLoss: 0.016124\n",
            "Train Epoch: 71 [14720/14860 (98%)]\tLoss: 0.017402\n",
            "Train Epoch: 71 [1392/14860 (99%)]\tLoss: 0.012271\n",
            "epoch 71 training loss: 0.01940847222462424\n",
            "epoch 71 validation loss: 0.021666029319347538\n",
            "Train Epoch: 72 [0/14860 (0%)]\tLoss: 0.031688\n",
            "Train Epoch: 72 [128/14860 (1%)]\tLoss: 0.019512\n",
            "Train Epoch: 72 [256/14860 (2%)]\tLoss: 0.024839\n",
            "Train Epoch: 72 [384/14860 (3%)]\tLoss: 0.018159\n",
            "Train Epoch: 72 [512/14860 (3%)]\tLoss: 0.027681\n",
            "Train Epoch: 72 [640/14860 (4%)]\tLoss: 0.018964\n",
            "Train Epoch: 72 [768/14860 (5%)]\tLoss: 0.022175\n",
            "Train Epoch: 72 [896/14860 (6%)]\tLoss: 0.023780\n",
            "Train Epoch: 72 [1024/14860 (7%)]\tLoss: 0.022919\n",
            "Train Epoch: 72 [1152/14860 (8%)]\tLoss: 0.022516\n",
            "Train Epoch: 72 [1280/14860 (9%)]\tLoss: 0.021311\n",
            "Train Epoch: 72 [1408/14860 (9%)]\tLoss: 0.019580\n",
            "Train Epoch: 72 [1536/14860 (10%)]\tLoss: 0.018895\n",
            "Train Epoch: 72 [1664/14860 (11%)]\tLoss: 0.028329\n",
            "Train Epoch: 72 [1792/14860 (12%)]\tLoss: 0.017472\n",
            "Train Epoch: 72 [1920/14860 (13%)]\tLoss: 0.022312\n",
            "Train Epoch: 72 [2048/14860 (14%)]\tLoss: 0.019679\n",
            "Train Epoch: 72 [2176/14860 (15%)]\tLoss: 0.015761\n",
            "Train Epoch: 72 [2304/14860 (15%)]\tLoss: 0.016385\n",
            "Train Epoch: 72 [2432/14860 (16%)]\tLoss: 0.012953\n",
            "Train Epoch: 72 [2560/14860 (17%)]\tLoss: 0.014767\n",
            "Train Epoch: 72 [2688/14860 (18%)]\tLoss: 0.014504\n",
            "Train Epoch: 72 [2816/14860 (19%)]\tLoss: 0.024026\n",
            "Train Epoch: 72 [2944/14860 (20%)]\tLoss: 0.015766\n",
            "Train Epoch: 72 [3072/14860 (21%)]\tLoss: 0.023158\n",
            "Train Epoch: 72 [3200/14860 (21%)]\tLoss: 0.021031\n",
            "Train Epoch: 72 [3328/14860 (22%)]\tLoss: 0.018940\n",
            "Train Epoch: 72 [3456/14860 (23%)]\tLoss: 0.018497\n",
            "Train Epoch: 72 [3584/14860 (24%)]\tLoss: 0.015346\n",
            "Train Epoch: 72 [3712/14860 (25%)]\tLoss: 0.015759\n",
            "Train Epoch: 72 [3840/14860 (26%)]\tLoss: 0.021404\n",
            "Train Epoch: 72 [3968/14860 (26%)]\tLoss: 0.022757\n",
            "Train Epoch: 72 [4096/14860 (27%)]\tLoss: 0.021690\n",
            "Train Epoch: 72 [4224/14860 (28%)]\tLoss: 0.021513\n",
            "Train Epoch: 72 [4352/14860 (29%)]\tLoss: 0.016676\n",
            "Train Epoch: 72 [4480/14860 (30%)]\tLoss: 0.019665\n",
            "Train Epoch: 72 [4608/14860 (31%)]\tLoss: 0.019221\n",
            "Train Epoch: 72 [4736/14860 (32%)]\tLoss: 0.013935\n",
            "Train Epoch: 72 [4864/14860 (32%)]\tLoss: 0.020285\n",
            "Train Epoch: 72 [4992/14860 (33%)]\tLoss: 0.021870\n",
            "Train Epoch: 72 [5120/14860 (34%)]\tLoss: 0.020285\n",
            "Train Epoch: 72 [5248/14860 (35%)]\tLoss: 0.019372\n",
            "Train Epoch: 72 [5376/14860 (36%)]\tLoss: 0.013170\n",
            "Train Epoch: 72 [5504/14860 (37%)]\tLoss: 0.021479\n",
            "Train Epoch: 72 [5632/14860 (38%)]\tLoss: 0.017899\n",
            "Train Epoch: 72 [5760/14860 (38%)]\tLoss: 0.018414\n",
            "Train Epoch: 72 [5888/14860 (39%)]\tLoss: 0.017218\n",
            "Train Epoch: 72 [6016/14860 (40%)]\tLoss: 0.014868\n",
            "Train Epoch: 72 [6144/14860 (41%)]\tLoss: 0.016791\n",
            "Train Epoch: 72 [6272/14860 (42%)]\tLoss: 0.023192\n",
            "Train Epoch: 72 [6400/14860 (43%)]\tLoss: 0.022020\n",
            "Train Epoch: 72 [6528/14860 (44%)]\tLoss: 0.024965\n",
            "Train Epoch: 72 [6656/14860 (44%)]\tLoss: 0.025748\n",
            "Train Epoch: 72 [6784/14860 (45%)]\tLoss: 0.017935\n",
            "Train Epoch: 72 [6912/14860 (46%)]\tLoss: 0.024829\n",
            "Train Epoch: 72 [7040/14860 (47%)]\tLoss: 0.020082\n",
            "Train Epoch: 72 [7168/14860 (48%)]\tLoss: 0.018337\n",
            "Train Epoch: 72 [7296/14860 (49%)]\tLoss: 0.020651\n",
            "Train Epoch: 72 [7424/14860 (50%)]\tLoss: 0.022641\n",
            "Train Epoch: 72 [7552/14860 (50%)]\tLoss: 0.022346\n",
            "Train Epoch: 72 [7680/14860 (51%)]\tLoss: 0.018535\n",
            "Train Epoch: 72 [7808/14860 (52%)]\tLoss: 0.026348\n",
            "Train Epoch: 72 [7936/14860 (53%)]\tLoss: 0.021160\n",
            "Train Epoch: 72 [8064/14860 (54%)]\tLoss: 0.022168\n",
            "Train Epoch: 72 [8192/14860 (55%)]\tLoss: 0.027566\n",
            "Train Epoch: 72 [8320/14860 (56%)]\tLoss: 0.013268\n",
            "Train Epoch: 72 [8448/14860 (56%)]\tLoss: 0.018611\n",
            "Train Epoch: 72 [8576/14860 (57%)]\tLoss: 0.016153\n",
            "Train Epoch: 72 [8704/14860 (58%)]\tLoss: 0.014030\n",
            "Train Epoch: 72 [8832/14860 (59%)]\tLoss: 0.020159\n",
            "Train Epoch: 72 [8960/14860 (60%)]\tLoss: 0.022335\n",
            "Train Epoch: 72 [9088/14860 (61%)]\tLoss: 0.019788\n",
            "Train Epoch: 72 [9216/14860 (62%)]\tLoss: 0.017071\n",
            "Train Epoch: 72 [9344/14860 (62%)]\tLoss: 0.030984\n",
            "Train Epoch: 72 [9472/14860 (63%)]\tLoss: 0.015716\n",
            "Train Epoch: 72 [9600/14860 (64%)]\tLoss: 0.026020\n",
            "Train Epoch: 72 [9728/14860 (65%)]\tLoss: 0.017772\n",
            "Train Epoch: 72 [9856/14860 (66%)]\tLoss: 0.011146\n",
            "Train Epoch: 72 [9984/14860 (67%)]\tLoss: 0.021438\n",
            "Train Epoch: 72 [10112/14860 (68%)]\tLoss: 0.017188\n",
            "Train Epoch: 72 [10240/14860 (68%)]\tLoss: 0.014992\n",
            "Train Epoch: 72 [10368/14860 (69%)]\tLoss: 0.017720\n",
            "Train Epoch: 72 [10496/14860 (70%)]\tLoss: 0.016064\n",
            "Train Epoch: 72 [10624/14860 (71%)]\tLoss: 0.024076\n",
            "Train Epoch: 72 [10752/14860 (72%)]\tLoss: 0.013658\n",
            "Train Epoch: 72 [10880/14860 (73%)]\tLoss: 0.012707\n",
            "Train Epoch: 72 [11008/14860 (74%)]\tLoss: 0.030468\n",
            "Train Epoch: 72 [11136/14860 (74%)]\tLoss: 0.015025\n",
            "Train Epoch: 72 [11264/14860 (75%)]\tLoss: 0.015399\n",
            "Train Epoch: 72 [11392/14860 (76%)]\tLoss: 0.016018\n",
            "Train Epoch: 72 [11520/14860 (77%)]\tLoss: 0.016313\n",
            "Train Epoch: 72 [11648/14860 (78%)]\tLoss: 0.017803\n",
            "Train Epoch: 72 [11776/14860 (79%)]\tLoss: 0.016824\n",
            "Train Epoch: 72 [11904/14860 (79%)]\tLoss: 0.015823\n",
            "Train Epoch: 72 [12032/14860 (80%)]\tLoss: 0.017950\n",
            "Train Epoch: 72 [12160/14860 (81%)]\tLoss: 0.026634\n",
            "Train Epoch: 72 [12288/14860 (82%)]\tLoss: 0.016612\n",
            "Train Epoch: 72 [12416/14860 (83%)]\tLoss: 0.022449\n",
            "Train Epoch: 72 [12544/14860 (84%)]\tLoss: 0.016955\n",
            "Train Epoch: 72 [12672/14860 (85%)]\tLoss: 0.013142\n",
            "Train Epoch: 72 [12800/14860 (85%)]\tLoss: 0.030822\n",
            "Train Epoch: 72 [12928/14860 (86%)]\tLoss: 0.012718\n",
            "Train Epoch: 72 [13056/14860 (87%)]\tLoss: 0.026590\n",
            "Train Epoch: 72 [13184/14860 (88%)]\tLoss: 0.024814\n",
            "Train Epoch: 72 [13312/14860 (89%)]\tLoss: 0.023154\n",
            "Train Epoch: 72 [13440/14860 (90%)]\tLoss: 0.013242\n",
            "Train Epoch: 72 [13568/14860 (91%)]\tLoss: 0.012687\n",
            "Train Epoch: 72 [13696/14860 (91%)]\tLoss: 0.018807\n",
            "Train Epoch: 72 [13824/14860 (92%)]\tLoss: 0.020406\n",
            "Train Epoch: 72 [13952/14860 (93%)]\tLoss: 0.021226\n",
            "Train Epoch: 72 [14080/14860 (94%)]\tLoss: 0.021535\n",
            "Train Epoch: 72 [14208/14860 (95%)]\tLoss: 0.016820\n",
            "Train Epoch: 72 [14336/14860 (96%)]\tLoss: 0.021405\n",
            "Train Epoch: 72 [14464/14860 (97%)]\tLoss: 0.019454\n",
            "Train Epoch: 72 [14592/14860 (97%)]\tLoss: 0.019671\n",
            "Train Epoch: 72 [14720/14860 (98%)]\tLoss: 0.019948\n",
            "Train Epoch: 72 [1392/14860 (99%)]\tLoss: 0.016893\n",
            "epoch 72 training loss: 0.019677314915272415\n",
            "epoch 72 validation loss: 0.02208807566552705\n",
            "Train Epoch: 73 [0/14860 (0%)]\tLoss: 0.018253\n",
            "Train Epoch: 73 [128/14860 (1%)]\tLoss: 0.021175\n",
            "Train Epoch: 73 [256/14860 (2%)]\tLoss: 0.015760\n",
            "Train Epoch: 73 [384/14860 (3%)]\tLoss: 0.024324\n",
            "Train Epoch: 73 [512/14860 (3%)]\tLoss: 0.018773\n",
            "Train Epoch: 73 [640/14860 (4%)]\tLoss: 0.015297\n",
            "Train Epoch: 73 [768/14860 (5%)]\tLoss: 0.016564\n",
            "Train Epoch: 73 [896/14860 (6%)]\tLoss: 0.017882\n",
            "Train Epoch: 73 [1024/14860 (7%)]\tLoss: 0.013754\n",
            "Train Epoch: 73 [1152/14860 (8%)]\tLoss: 0.026776\n",
            "Train Epoch: 73 [1280/14860 (9%)]\tLoss: 0.019157\n",
            "Train Epoch: 73 [1408/14860 (9%)]\tLoss: 0.025034\n",
            "Train Epoch: 73 [1536/14860 (10%)]\tLoss: 0.020685\n",
            "Train Epoch: 73 [1664/14860 (11%)]\tLoss: 0.025937\n",
            "Train Epoch: 73 [1792/14860 (12%)]\tLoss: 0.014558\n",
            "Train Epoch: 73 [1920/14860 (13%)]\tLoss: 0.020178\n",
            "Train Epoch: 73 [2048/14860 (14%)]\tLoss: 0.026818\n",
            "Train Epoch: 73 [2176/14860 (15%)]\tLoss: 0.016347\n",
            "Train Epoch: 73 [2304/14860 (15%)]\tLoss: 0.020528\n",
            "Train Epoch: 73 [2432/14860 (16%)]\tLoss: 0.013369\n",
            "Train Epoch: 73 [2560/14860 (17%)]\tLoss: 0.018673\n",
            "Train Epoch: 73 [2688/14860 (18%)]\tLoss: 0.015640\n",
            "Train Epoch: 73 [2816/14860 (19%)]\tLoss: 0.016251\n",
            "Train Epoch: 73 [2944/14860 (20%)]\tLoss: 0.014902\n",
            "Train Epoch: 73 [3072/14860 (21%)]\tLoss: 0.022070\n",
            "Train Epoch: 73 [3200/14860 (21%)]\tLoss: 0.017528\n",
            "Train Epoch: 73 [3328/14860 (22%)]\tLoss: 0.020059\n",
            "Train Epoch: 73 [3456/14860 (23%)]\tLoss: 0.021866\n",
            "Train Epoch: 73 [3584/14860 (24%)]\tLoss: 0.023851\n",
            "Train Epoch: 73 [3712/14860 (25%)]\tLoss: 0.027239\n",
            "Train Epoch: 73 [3840/14860 (26%)]\tLoss: 0.027931\n",
            "Train Epoch: 73 [3968/14860 (26%)]\tLoss: 0.021393\n",
            "Train Epoch: 73 [4096/14860 (27%)]\tLoss: 0.017087\n",
            "Train Epoch: 73 [4224/14860 (28%)]\tLoss: 0.013483\n",
            "Train Epoch: 73 [4352/14860 (29%)]\tLoss: 0.022604\n",
            "Train Epoch: 73 [4480/14860 (30%)]\tLoss: 0.020116\n",
            "Train Epoch: 73 [4608/14860 (31%)]\tLoss: 0.016172\n",
            "Train Epoch: 73 [4736/14860 (32%)]\tLoss: 0.014130\n",
            "Train Epoch: 73 [4864/14860 (32%)]\tLoss: 0.024845\n",
            "Train Epoch: 73 [4992/14860 (33%)]\tLoss: 0.014387\n",
            "Train Epoch: 73 [5120/14860 (34%)]\tLoss: 0.013657\n",
            "Train Epoch: 73 [5248/14860 (35%)]\tLoss: 0.019722\n",
            "Train Epoch: 73 [5376/14860 (36%)]\tLoss: 0.018549\n",
            "Train Epoch: 73 [5504/14860 (37%)]\tLoss: 0.016812\n",
            "Train Epoch: 73 [5632/14860 (38%)]\tLoss: 0.016394\n",
            "Train Epoch: 73 [5760/14860 (38%)]\tLoss: 0.024345\n",
            "Train Epoch: 73 [5888/14860 (39%)]\tLoss: 0.018665\n",
            "Train Epoch: 73 [6016/14860 (40%)]\tLoss: 0.018139\n",
            "Train Epoch: 73 [6144/14860 (41%)]\tLoss: 0.014931\n",
            "Train Epoch: 73 [6272/14860 (42%)]\tLoss: 0.015499\n",
            "Train Epoch: 73 [6400/14860 (43%)]\tLoss: 0.023592\n",
            "Train Epoch: 73 [6528/14860 (44%)]\tLoss: 0.020949\n",
            "Train Epoch: 73 [6656/14860 (44%)]\tLoss: 0.018796\n",
            "Train Epoch: 73 [6784/14860 (45%)]\tLoss: 0.015890\n",
            "Train Epoch: 73 [6912/14860 (46%)]\tLoss: 0.020196\n",
            "Train Epoch: 73 [7040/14860 (47%)]\tLoss: 0.015965\n",
            "Train Epoch: 73 [7168/14860 (48%)]\tLoss: 0.020077\n",
            "Train Epoch: 73 [7296/14860 (49%)]\tLoss: 0.017336\n",
            "Train Epoch: 73 [7424/14860 (50%)]\tLoss: 0.013481\n",
            "Train Epoch: 73 [7552/14860 (50%)]\tLoss: 0.021985\n",
            "Train Epoch: 73 [7680/14860 (51%)]\tLoss: 0.018986\n",
            "Train Epoch: 73 [7808/14860 (52%)]\tLoss: 0.023364\n",
            "Train Epoch: 73 [7936/14860 (53%)]\tLoss: 0.026112\n",
            "Train Epoch: 73 [8064/14860 (54%)]\tLoss: 0.023031\n",
            "Train Epoch: 73 [8192/14860 (55%)]\tLoss: 0.012369\n",
            "Train Epoch: 73 [8320/14860 (56%)]\tLoss: 0.035298\n",
            "Train Epoch: 73 [8448/14860 (56%)]\tLoss: 0.018196\n",
            "Train Epoch: 73 [8576/14860 (57%)]\tLoss: 0.016864\n",
            "Train Epoch: 73 [8704/14860 (58%)]\tLoss: 0.019161\n",
            "Train Epoch: 73 [8832/14860 (59%)]\tLoss: 0.018780\n",
            "Train Epoch: 73 [8960/14860 (60%)]\tLoss: 0.015843\n",
            "Train Epoch: 73 [9088/14860 (61%)]\tLoss: 0.025552\n",
            "Train Epoch: 73 [9216/14860 (62%)]\tLoss: 0.025112\n",
            "Train Epoch: 73 [9344/14860 (62%)]\tLoss: 0.013074\n",
            "Train Epoch: 73 [9472/14860 (63%)]\tLoss: 0.018506\n",
            "Train Epoch: 73 [9600/14860 (64%)]\tLoss: 0.019190\n",
            "Train Epoch: 73 [9728/14860 (65%)]\tLoss: 0.018727\n",
            "Train Epoch: 73 [9856/14860 (66%)]\tLoss: 0.025912\n",
            "Train Epoch: 73 [9984/14860 (67%)]\tLoss: 0.014004\n",
            "Train Epoch: 73 [10112/14860 (68%)]\tLoss: 0.020996\n",
            "Train Epoch: 73 [10240/14860 (68%)]\tLoss: 0.022611\n",
            "Train Epoch: 73 [10368/14860 (69%)]\tLoss: 0.018827\n",
            "Train Epoch: 73 [10496/14860 (70%)]\tLoss: 0.018155\n",
            "Train Epoch: 73 [10624/14860 (71%)]\tLoss: 0.019037\n",
            "Train Epoch: 73 [10752/14860 (72%)]\tLoss: 0.018442\n",
            "Train Epoch: 73 [10880/14860 (73%)]\tLoss: 0.022532\n",
            "Train Epoch: 73 [11008/14860 (74%)]\tLoss: 0.014931\n",
            "Train Epoch: 73 [11136/14860 (74%)]\tLoss: 0.024129\n",
            "Train Epoch: 73 [11264/14860 (75%)]\tLoss: 0.021590\n",
            "Train Epoch: 73 [11392/14860 (76%)]\tLoss: 0.023491\n",
            "Train Epoch: 73 [11520/14860 (77%)]\tLoss: 0.019460\n",
            "Train Epoch: 73 [11648/14860 (78%)]\tLoss: 0.019402\n",
            "Train Epoch: 73 [11776/14860 (79%)]\tLoss: 0.019772\n",
            "Train Epoch: 73 [11904/14860 (79%)]\tLoss: 0.023892\n",
            "Train Epoch: 73 [12032/14860 (80%)]\tLoss: 0.017430\n",
            "Train Epoch: 73 [12160/14860 (81%)]\tLoss: 0.019548\n",
            "Train Epoch: 73 [12288/14860 (82%)]\tLoss: 0.028728\n",
            "Train Epoch: 73 [12416/14860 (83%)]\tLoss: 0.014202\n",
            "Train Epoch: 73 [12544/14860 (84%)]\tLoss: 0.018124\n",
            "Train Epoch: 73 [12672/14860 (85%)]\tLoss: 0.016684\n",
            "Train Epoch: 73 [12800/14860 (85%)]\tLoss: 0.027947\n",
            "Train Epoch: 73 [12928/14860 (86%)]\tLoss: 0.018905\n",
            "Train Epoch: 73 [13056/14860 (87%)]\tLoss: 0.023211\n",
            "Train Epoch: 73 [13184/14860 (88%)]\tLoss: 0.015505\n",
            "Train Epoch: 73 [13312/14860 (89%)]\tLoss: 0.015621\n",
            "Train Epoch: 73 [13440/14860 (90%)]\tLoss: 0.025148\n",
            "Train Epoch: 73 [13568/14860 (91%)]\tLoss: 0.014410\n",
            "Train Epoch: 73 [13696/14860 (91%)]\tLoss: 0.018567\n",
            "Train Epoch: 73 [13824/14860 (92%)]\tLoss: 0.018045\n",
            "Train Epoch: 73 [13952/14860 (93%)]\tLoss: 0.021837\n",
            "Train Epoch: 73 [14080/14860 (94%)]\tLoss: 0.024250\n",
            "Train Epoch: 73 [14208/14860 (95%)]\tLoss: 0.013831\n",
            "Train Epoch: 73 [14336/14860 (96%)]\tLoss: 0.017378\n",
            "Train Epoch: 73 [14464/14860 (97%)]\tLoss: 0.014534\n",
            "Train Epoch: 73 [14592/14860 (97%)]\tLoss: 0.016847\n",
            "Train Epoch: 73 [14720/14860 (98%)]\tLoss: 0.025468\n",
            "Train Epoch: 73 [1392/14860 (99%)]\tLoss: 0.031822\n",
            "epoch 73 training loss: 0.019656116373709634\n",
            "epoch 73 validation loss: 0.04186815153311298\n",
            "Train Epoch: 74 [0/14860 (0%)]\tLoss: 0.049278\n",
            "Train Epoch: 74 [128/14860 (1%)]\tLoss: 0.024186\n",
            "Train Epoch: 74 [256/14860 (2%)]\tLoss: 0.023204\n",
            "Train Epoch: 74 [384/14860 (3%)]\tLoss: 0.026909\n",
            "Train Epoch: 74 [512/14860 (3%)]\tLoss: 0.020417\n",
            "Train Epoch: 74 [640/14860 (4%)]\tLoss: 0.016295\n",
            "Train Epoch: 74 [768/14860 (5%)]\tLoss: 0.024885\n",
            "Train Epoch: 74 [896/14860 (6%)]\tLoss: 0.013348\n",
            "Train Epoch: 74 [1024/14860 (7%)]\tLoss: 0.014858\n",
            "Train Epoch: 74 [1152/14860 (8%)]\tLoss: 0.032473\n",
            "Train Epoch: 74 [1280/14860 (9%)]\tLoss: 0.016142\n",
            "Train Epoch: 74 [1408/14860 (9%)]\tLoss: 0.012953\n",
            "Train Epoch: 74 [1536/14860 (10%)]\tLoss: 0.021711\n",
            "Train Epoch: 74 [1664/14860 (11%)]\tLoss: 0.018646\n",
            "Train Epoch: 74 [1792/14860 (12%)]\tLoss: 0.017849\n",
            "Train Epoch: 74 [1920/14860 (13%)]\tLoss: 0.024646\n",
            "Train Epoch: 74 [2048/14860 (14%)]\tLoss: 0.018070\n",
            "Train Epoch: 74 [2176/14860 (15%)]\tLoss: 0.021772\n",
            "Train Epoch: 74 [2304/14860 (15%)]\tLoss: 0.017960\n",
            "Train Epoch: 74 [2432/14860 (16%)]\tLoss: 0.014921\n",
            "Train Epoch: 74 [2560/14860 (17%)]\tLoss: 0.016047\n",
            "Train Epoch: 74 [2688/14860 (18%)]\tLoss: 0.020515\n",
            "Train Epoch: 74 [2816/14860 (19%)]\tLoss: 0.018702\n",
            "Train Epoch: 74 [2944/14860 (20%)]\tLoss: 0.019126\n",
            "Train Epoch: 74 [3072/14860 (21%)]\tLoss: 0.020501\n",
            "Train Epoch: 74 [3200/14860 (21%)]\tLoss: 0.014572\n",
            "Train Epoch: 74 [3328/14860 (22%)]\tLoss: 0.024640\n",
            "Train Epoch: 74 [3456/14860 (23%)]\tLoss: 0.019560\n",
            "Train Epoch: 74 [3584/14860 (24%)]\tLoss: 0.020655\n",
            "Train Epoch: 74 [3712/14860 (25%)]\tLoss: 0.016031\n",
            "Train Epoch: 74 [3840/14860 (26%)]\tLoss: 0.022716\n",
            "Train Epoch: 74 [3968/14860 (26%)]\tLoss: 0.021157\n",
            "Train Epoch: 74 [4096/14860 (27%)]\tLoss: 0.023584\n",
            "Train Epoch: 74 [4224/14860 (28%)]\tLoss: 0.016296\n",
            "Train Epoch: 74 [4352/14860 (29%)]\tLoss: 0.020454\n",
            "Train Epoch: 74 [4480/14860 (30%)]\tLoss: 0.016864\n",
            "Train Epoch: 74 [4608/14860 (31%)]\tLoss: 0.019231\n",
            "Train Epoch: 74 [4736/14860 (32%)]\tLoss: 0.016010\n",
            "Train Epoch: 74 [4864/14860 (32%)]\tLoss: 0.018370\n",
            "Train Epoch: 74 [4992/14860 (33%)]\tLoss: 0.015329\n",
            "Train Epoch: 74 [5120/14860 (34%)]\tLoss: 0.016804\n",
            "Train Epoch: 74 [5248/14860 (35%)]\tLoss: 0.024286\n",
            "Train Epoch: 74 [5376/14860 (36%)]\tLoss: 0.016773\n",
            "Train Epoch: 74 [5504/14860 (37%)]\tLoss: 0.021768\n",
            "Train Epoch: 74 [5632/14860 (38%)]\tLoss: 0.020303\n",
            "Train Epoch: 74 [5760/14860 (38%)]\tLoss: 0.016866\n",
            "Train Epoch: 74 [5888/14860 (39%)]\tLoss: 0.017760\n",
            "Train Epoch: 74 [6016/14860 (40%)]\tLoss: 0.013357\n",
            "Train Epoch: 74 [6144/14860 (41%)]\tLoss: 0.019833\n",
            "Train Epoch: 74 [6272/14860 (42%)]\tLoss: 0.033975\n",
            "Train Epoch: 74 [6400/14860 (43%)]\tLoss: 0.023509\n",
            "Train Epoch: 74 [6528/14860 (44%)]\tLoss: 0.020551\n",
            "Train Epoch: 74 [6656/14860 (44%)]\tLoss: 0.026735\n",
            "Train Epoch: 74 [6784/14860 (45%)]\tLoss: 0.025995\n",
            "Train Epoch: 74 [6912/14860 (46%)]\tLoss: 0.016242\n",
            "Train Epoch: 74 [7040/14860 (47%)]\tLoss: 0.019199\n",
            "Train Epoch: 74 [7168/14860 (48%)]\tLoss: 0.025555\n",
            "Train Epoch: 74 [7296/14860 (49%)]\tLoss: 0.014642\n",
            "Train Epoch: 74 [7424/14860 (50%)]\tLoss: 0.014163\n",
            "Train Epoch: 74 [7552/14860 (50%)]\tLoss: 0.025126\n",
            "Train Epoch: 74 [7680/14860 (51%)]\tLoss: 0.028305\n",
            "Train Epoch: 74 [7808/14860 (52%)]\tLoss: 0.019062\n",
            "Train Epoch: 74 [7936/14860 (53%)]\tLoss: 0.022558\n",
            "Train Epoch: 74 [8064/14860 (54%)]\tLoss: 0.019676\n",
            "Train Epoch: 74 [8192/14860 (55%)]\tLoss: 0.031744\n",
            "Train Epoch: 74 [8320/14860 (56%)]\tLoss: 0.017419\n",
            "Train Epoch: 74 [8448/14860 (56%)]\tLoss: 0.011342\n",
            "Train Epoch: 74 [8576/14860 (57%)]\tLoss: 0.018623\n",
            "Train Epoch: 74 [8704/14860 (58%)]\tLoss: 0.021460\n",
            "Train Epoch: 74 [8832/14860 (59%)]\tLoss: 0.017944\n",
            "Train Epoch: 74 [8960/14860 (60%)]\tLoss: 0.025507\n",
            "Train Epoch: 74 [9088/14860 (61%)]\tLoss: 0.017564\n",
            "Train Epoch: 74 [9216/14860 (62%)]\tLoss: 0.013166\n",
            "Train Epoch: 74 [9344/14860 (62%)]\tLoss: 0.023619\n",
            "Train Epoch: 74 [9472/14860 (63%)]\tLoss: 0.019616\n",
            "Train Epoch: 74 [9600/14860 (64%)]\tLoss: 0.015796\n",
            "Train Epoch: 74 [9728/14860 (65%)]\tLoss: 0.013595\n",
            "Train Epoch: 74 [9856/14860 (66%)]\tLoss: 0.020385\n",
            "Train Epoch: 74 [9984/14860 (67%)]\tLoss: 0.013748\n",
            "Train Epoch: 74 [10112/14860 (68%)]\tLoss: 0.014168\n",
            "Train Epoch: 74 [10240/14860 (68%)]\tLoss: 0.020201\n",
            "Train Epoch: 74 [10368/14860 (69%)]\tLoss: 0.015091\n",
            "Train Epoch: 74 [10496/14860 (70%)]\tLoss: 0.017955\n",
            "Train Epoch: 74 [10624/14860 (71%)]\tLoss: 0.019351\n",
            "Train Epoch: 74 [10752/14860 (72%)]\tLoss: 0.019238\n",
            "Train Epoch: 74 [10880/14860 (73%)]\tLoss: 0.015859\n",
            "Train Epoch: 74 [11008/14860 (74%)]\tLoss: 0.011532\n",
            "Train Epoch: 74 [11136/14860 (74%)]\tLoss: 0.022663\n",
            "Train Epoch: 74 [11264/14860 (75%)]\tLoss: 0.018391\n",
            "Train Epoch: 74 [11392/14860 (76%)]\tLoss: 0.012322\n",
            "Train Epoch: 74 [11520/14860 (77%)]\tLoss: 0.017595\n",
            "Train Epoch: 74 [11648/14860 (78%)]\tLoss: 0.029433\n",
            "Train Epoch: 74 [11776/14860 (79%)]\tLoss: 0.016090\n",
            "Train Epoch: 74 [11904/14860 (79%)]\tLoss: 0.021659\n",
            "Train Epoch: 74 [12032/14860 (80%)]\tLoss: 0.013301\n",
            "Train Epoch: 74 [12160/14860 (81%)]\tLoss: 0.023780\n",
            "Train Epoch: 74 [12288/14860 (82%)]\tLoss: 0.019953\n",
            "Train Epoch: 74 [12416/14860 (83%)]\tLoss: 0.015870\n",
            "Train Epoch: 74 [12544/14860 (84%)]\tLoss: 0.021509\n",
            "Train Epoch: 74 [12672/14860 (85%)]\tLoss: 0.026462\n",
            "Train Epoch: 74 [12800/14860 (85%)]\tLoss: 0.020244\n",
            "Train Epoch: 74 [12928/14860 (86%)]\tLoss: 0.035317\n",
            "Train Epoch: 74 [13056/14860 (87%)]\tLoss: 0.034271\n",
            "Train Epoch: 74 [13184/14860 (88%)]\tLoss: 0.027308\n",
            "Train Epoch: 74 [13312/14860 (89%)]\tLoss: 0.015771\n",
            "Train Epoch: 74 [13440/14860 (90%)]\tLoss: 0.040074\n",
            "Train Epoch: 74 [13568/14860 (91%)]\tLoss: 0.031050\n",
            "Train Epoch: 74 [13696/14860 (91%)]\tLoss: 0.025126\n",
            "Train Epoch: 74 [13824/14860 (92%)]\tLoss: 0.028007\n",
            "Train Epoch: 74 [13952/14860 (93%)]\tLoss: 0.021413\n",
            "Train Epoch: 74 [14080/14860 (94%)]\tLoss: 0.021693\n",
            "Train Epoch: 74 [14208/14860 (95%)]\tLoss: 0.015361\n",
            "Train Epoch: 74 [14336/14860 (96%)]\tLoss: 0.023651\n",
            "Train Epoch: 74 [14464/14860 (97%)]\tLoss: 0.040226\n",
            "Train Epoch: 74 [14592/14860 (97%)]\tLoss: 0.019818\n",
            "Train Epoch: 74 [14720/14860 (98%)]\tLoss: 0.019613\n",
            "Train Epoch: 74 [1392/14860 (99%)]\tLoss: 0.019987\n",
            "epoch 74 training loss: 0.020741903692738622\n",
            "epoch 74 validation loss: 0.029228262837804837\n",
            "Train Epoch: 75 [0/14860 (0%)]\tLoss: 0.028386\n",
            "Train Epoch: 75 [128/14860 (1%)]\tLoss: 0.023431\n",
            "Train Epoch: 75 [256/14860 (2%)]\tLoss: 0.018080\n",
            "Train Epoch: 75 [384/14860 (3%)]\tLoss: 0.015337\n",
            "Train Epoch: 75 [512/14860 (3%)]\tLoss: 0.026392\n",
            "Train Epoch: 75 [640/14860 (4%)]\tLoss: 0.027092\n",
            "Train Epoch: 75 [768/14860 (5%)]\tLoss: 0.021301\n",
            "Train Epoch: 75 [896/14860 (6%)]\tLoss: 0.026496\n",
            "Train Epoch: 75 [1024/14860 (7%)]\tLoss: 0.025635\n",
            "Train Epoch: 75 [1152/14860 (8%)]\tLoss: 0.021500\n",
            "Train Epoch: 75 [1280/14860 (9%)]\tLoss: 0.025135\n",
            "Train Epoch: 75 [1408/14860 (9%)]\tLoss: 0.020780\n",
            "Train Epoch: 75 [1536/14860 (10%)]\tLoss: 0.018049\n",
            "Train Epoch: 75 [1664/14860 (11%)]\tLoss: 0.021162\n",
            "Train Epoch: 75 [1792/14860 (12%)]\tLoss: 0.015922\n",
            "Train Epoch: 75 [1920/14860 (13%)]\tLoss: 0.017876\n",
            "Train Epoch: 75 [2048/14860 (14%)]\tLoss: 0.018155\n",
            "Train Epoch: 75 [2176/14860 (15%)]\tLoss: 0.017505\n",
            "Train Epoch: 75 [2304/14860 (15%)]\tLoss: 0.022171\n",
            "Train Epoch: 75 [2432/14860 (16%)]\tLoss: 0.016463\n",
            "Train Epoch: 75 [2560/14860 (17%)]\tLoss: 0.018915\n",
            "Train Epoch: 75 [2688/14860 (18%)]\tLoss: 0.018100\n",
            "Train Epoch: 75 [2816/14860 (19%)]\tLoss: 0.018068\n",
            "Train Epoch: 75 [2944/14860 (20%)]\tLoss: 0.020086\n",
            "Train Epoch: 75 [3072/14860 (21%)]\tLoss: 0.025522\n",
            "Train Epoch: 75 [3200/14860 (21%)]\tLoss: 0.020598\n",
            "Train Epoch: 75 [3328/14860 (22%)]\tLoss: 0.018042\n",
            "Train Epoch: 75 [3456/14860 (23%)]\tLoss: 0.018656\n",
            "Train Epoch: 75 [3584/14860 (24%)]\tLoss: 0.014813\n",
            "Train Epoch: 75 [3712/14860 (25%)]\tLoss: 0.034575\n",
            "Train Epoch: 75 [3840/14860 (26%)]\tLoss: 0.021590\n",
            "Train Epoch: 75 [3968/14860 (26%)]\tLoss: 0.022327\n",
            "Train Epoch: 75 [4096/14860 (27%)]\tLoss: 0.016708\n",
            "Train Epoch: 75 [4224/14860 (28%)]\tLoss: 0.017461\n",
            "Train Epoch: 75 [4352/14860 (29%)]\tLoss: 0.013954\n",
            "Train Epoch: 75 [4480/14860 (30%)]\tLoss: 0.017811\n",
            "Train Epoch: 75 [4608/14860 (31%)]\tLoss: 0.019040\n",
            "Train Epoch: 75 [4736/14860 (32%)]\tLoss: 0.012109\n",
            "Train Epoch: 75 [4864/14860 (32%)]\tLoss: 0.028181\n",
            "Train Epoch: 75 [4992/14860 (33%)]\tLoss: 0.027253\n",
            "Train Epoch: 75 [5120/14860 (34%)]\tLoss: 0.013238\n",
            "Train Epoch: 75 [5248/14860 (35%)]\tLoss: 0.015297\n",
            "Train Epoch: 75 [5376/14860 (36%)]\tLoss: 0.017696\n",
            "Train Epoch: 75 [5504/14860 (37%)]\tLoss: 0.015233\n",
            "Train Epoch: 75 [5632/14860 (38%)]\tLoss: 0.015703\n",
            "Train Epoch: 75 [5760/14860 (38%)]\tLoss: 0.024426\n",
            "Train Epoch: 75 [5888/14860 (39%)]\tLoss: 0.023446\n",
            "Train Epoch: 75 [6016/14860 (40%)]\tLoss: 0.020353\n",
            "Train Epoch: 75 [6144/14860 (41%)]\tLoss: 0.011605\n",
            "Train Epoch: 75 [6272/14860 (42%)]\tLoss: 0.019463\n",
            "Train Epoch: 75 [6400/14860 (43%)]\tLoss: 0.019742\n",
            "Train Epoch: 75 [6528/14860 (44%)]\tLoss: 0.022851\n",
            "Train Epoch: 75 [6656/14860 (44%)]\tLoss: 0.019903\n",
            "Train Epoch: 75 [6784/14860 (45%)]\tLoss: 0.027311\n",
            "Train Epoch: 75 [6912/14860 (46%)]\tLoss: 0.016469\n",
            "Train Epoch: 75 [7040/14860 (47%)]\tLoss: 0.020333\n",
            "Train Epoch: 75 [7168/14860 (48%)]\tLoss: 0.018775\n",
            "Train Epoch: 75 [7296/14860 (49%)]\tLoss: 0.022152\n",
            "Train Epoch: 75 [7424/14860 (50%)]\tLoss: 0.017966\n",
            "Train Epoch: 75 [7552/14860 (50%)]\tLoss: 0.018343\n",
            "Train Epoch: 75 [7680/14860 (51%)]\tLoss: 0.017545\n",
            "Train Epoch: 75 [7808/14860 (52%)]\tLoss: 0.021523\n",
            "Train Epoch: 75 [7936/14860 (53%)]\tLoss: 0.018354\n",
            "Train Epoch: 75 [8064/14860 (54%)]\tLoss: 0.016947\n",
            "Train Epoch: 75 [8192/14860 (55%)]\tLoss: 0.018299\n",
            "Train Epoch: 75 [8320/14860 (56%)]\tLoss: 0.018776\n",
            "Train Epoch: 75 [8448/14860 (56%)]\tLoss: 0.019878\n",
            "Train Epoch: 75 [8576/14860 (57%)]\tLoss: 0.025344\n",
            "Train Epoch: 75 [8704/14860 (58%)]\tLoss: 0.020628\n",
            "Train Epoch: 75 [8832/14860 (59%)]\tLoss: 0.022142\n",
            "Train Epoch: 75 [8960/14860 (60%)]\tLoss: 0.022540\n",
            "Train Epoch: 75 [9088/14860 (61%)]\tLoss: 0.018519\n",
            "Train Epoch: 75 [9216/14860 (62%)]\tLoss: 0.026255\n",
            "Train Epoch: 75 [9344/14860 (62%)]\tLoss: 0.024513\n",
            "Train Epoch: 75 [9472/14860 (63%)]\tLoss: 0.023221\n",
            "Train Epoch: 75 [9600/14860 (64%)]\tLoss: 0.022050\n",
            "Train Epoch: 75 [9728/14860 (65%)]\tLoss: 0.019047\n",
            "Train Epoch: 75 [9856/14860 (66%)]\tLoss: 0.028182\n",
            "Train Epoch: 75 [9984/14860 (67%)]\tLoss: 0.010910\n",
            "Train Epoch: 75 [10112/14860 (68%)]\tLoss: 0.021726\n",
            "Train Epoch: 75 [10240/14860 (68%)]\tLoss: 0.022236\n",
            "Train Epoch: 75 [10368/14860 (69%)]\tLoss: 0.021781\n",
            "Train Epoch: 75 [10496/14860 (70%)]\tLoss: 0.020351\n",
            "Train Epoch: 75 [10624/14860 (71%)]\tLoss: 0.023033\n",
            "Train Epoch: 75 [10752/14860 (72%)]\tLoss: 0.018421\n",
            "Train Epoch: 75 [10880/14860 (73%)]\tLoss: 0.019159\n",
            "Train Epoch: 75 [11008/14860 (74%)]\tLoss: 0.018639\n",
            "Train Epoch: 75 [11136/14860 (74%)]\tLoss: 0.018303\n",
            "Train Epoch: 75 [11264/14860 (75%)]\tLoss: 0.016427\n",
            "Train Epoch: 75 [11392/14860 (76%)]\tLoss: 0.025020\n",
            "Train Epoch: 75 [11520/14860 (77%)]\tLoss: 0.015808\n",
            "Train Epoch: 75 [11648/14860 (78%)]\tLoss: 0.021642\n",
            "Train Epoch: 75 [11776/14860 (79%)]\tLoss: 0.023172\n",
            "Train Epoch: 75 [11904/14860 (79%)]\tLoss: 0.015595\n",
            "Train Epoch: 75 [12032/14860 (80%)]\tLoss: 0.022250\n",
            "Train Epoch: 75 [12160/14860 (81%)]\tLoss: 0.023233\n",
            "Train Epoch: 75 [12288/14860 (82%)]\tLoss: 0.017621\n",
            "Train Epoch: 75 [12416/14860 (83%)]\tLoss: 0.018214\n",
            "Train Epoch: 75 [12544/14860 (84%)]\tLoss: 0.010217\n",
            "Train Epoch: 75 [12672/14860 (85%)]\tLoss: 0.016682\n",
            "Train Epoch: 75 [12800/14860 (85%)]\tLoss: 0.011432\n",
            "Train Epoch: 75 [12928/14860 (86%)]\tLoss: 0.013719\n",
            "Train Epoch: 75 [13056/14860 (87%)]\tLoss: 0.019588\n",
            "Train Epoch: 75 [13184/14860 (88%)]\tLoss: 0.019248\n",
            "Train Epoch: 75 [13312/14860 (89%)]\tLoss: 0.017140\n",
            "Train Epoch: 75 [13440/14860 (90%)]\tLoss: 0.014336\n",
            "Train Epoch: 75 [13568/14860 (91%)]\tLoss: 0.011989\n",
            "Train Epoch: 75 [13696/14860 (91%)]\tLoss: 0.025432\n",
            "Train Epoch: 75 [13824/14860 (92%)]\tLoss: 0.016312\n",
            "Train Epoch: 75 [13952/14860 (93%)]\tLoss: 0.016994\n",
            "Train Epoch: 75 [14080/14860 (94%)]\tLoss: 0.020166\n",
            "Train Epoch: 75 [14208/14860 (95%)]\tLoss: 0.015132\n",
            "Train Epoch: 75 [14336/14860 (96%)]\tLoss: 0.017385\n",
            "Train Epoch: 75 [14464/14860 (97%)]\tLoss: 0.015736\n",
            "Train Epoch: 75 [14592/14860 (97%)]\tLoss: 0.022432\n",
            "Train Epoch: 75 [14720/14860 (98%)]\tLoss: 0.017547\n",
            "Train Epoch: 75 [1392/14860 (99%)]\tLoss: 0.019276\n",
            "epoch 75 training loss: 0.019735440611839294\n",
            "epoch 75 validation loss: 0.020456810263109554\n",
            "Train Epoch: 76 [0/14860 (0%)]\tLoss: 0.016998\n",
            "Train Epoch: 76 [128/14860 (1%)]\tLoss: 0.020386\n",
            "Train Epoch: 76 [256/14860 (2%)]\tLoss: 0.019822\n",
            "Train Epoch: 76 [384/14860 (3%)]\tLoss: 0.033037\n",
            "Train Epoch: 76 [512/14860 (3%)]\tLoss: 0.019575\n",
            "Train Epoch: 76 [640/14860 (4%)]\tLoss: 0.020891\n",
            "Train Epoch: 76 [768/14860 (5%)]\tLoss: 0.023466\n",
            "Train Epoch: 76 [896/14860 (6%)]\tLoss: 0.018660\n",
            "Train Epoch: 76 [1024/14860 (7%)]\tLoss: 0.021622\n",
            "Train Epoch: 76 [1152/14860 (8%)]\tLoss: 0.022141\n",
            "Train Epoch: 76 [1280/14860 (9%)]\tLoss: 0.017592\n",
            "Train Epoch: 76 [1408/14860 (9%)]\tLoss: 0.019447\n",
            "Train Epoch: 76 [1536/14860 (10%)]\tLoss: 0.018329\n",
            "Train Epoch: 76 [1664/14860 (11%)]\tLoss: 0.026358\n",
            "Train Epoch: 76 [1792/14860 (12%)]\tLoss: 0.023506\n",
            "Train Epoch: 76 [1920/14860 (13%)]\tLoss: 0.022744\n",
            "Train Epoch: 76 [2048/14860 (14%)]\tLoss: 0.023330\n",
            "Train Epoch: 76 [2176/14860 (15%)]\tLoss: 0.017086\n",
            "Train Epoch: 76 [2304/14860 (15%)]\tLoss: 0.029181\n",
            "Train Epoch: 76 [2432/14860 (16%)]\tLoss: 0.024382\n",
            "Train Epoch: 76 [2560/14860 (17%)]\tLoss: 0.022918\n",
            "Train Epoch: 76 [2688/14860 (18%)]\tLoss: 0.025798\n",
            "Train Epoch: 76 [2816/14860 (19%)]\tLoss: 0.017792\n",
            "Train Epoch: 76 [2944/14860 (20%)]\tLoss: 0.014824\n",
            "Train Epoch: 76 [3072/14860 (21%)]\tLoss: 0.033421\n",
            "Train Epoch: 76 [3200/14860 (21%)]\tLoss: 0.014912\n",
            "Train Epoch: 76 [3328/14860 (22%)]\tLoss: 0.021847\n",
            "Train Epoch: 76 [3456/14860 (23%)]\tLoss: 0.020808\n",
            "Train Epoch: 76 [3584/14860 (24%)]\tLoss: 0.012899\n",
            "Train Epoch: 76 [3712/14860 (25%)]\tLoss: 0.019719\n",
            "Train Epoch: 76 [3840/14860 (26%)]\tLoss: 0.018017\n",
            "Train Epoch: 76 [3968/14860 (26%)]\tLoss: 0.018567\n",
            "Train Epoch: 76 [4096/14860 (27%)]\tLoss: 0.017715\n",
            "Train Epoch: 76 [4224/14860 (28%)]\tLoss: 0.018878\n",
            "Train Epoch: 76 [4352/14860 (29%)]\tLoss: 0.020333\n",
            "Train Epoch: 76 [4480/14860 (30%)]\tLoss: 0.014243\n",
            "Train Epoch: 76 [4608/14860 (31%)]\tLoss: 0.014458\n",
            "Train Epoch: 76 [4736/14860 (32%)]\tLoss: 0.020956\n",
            "Train Epoch: 76 [4864/14860 (32%)]\tLoss: 0.021633\n",
            "Train Epoch: 76 [4992/14860 (33%)]\tLoss: 0.023006\n",
            "Train Epoch: 76 [5120/14860 (34%)]\tLoss: 0.020468\n",
            "Train Epoch: 76 [5248/14860 (35%)]\tLoss: 0.021667\n",
            "Train Epoch: 76 [5376/14860 (36%)]\tLoss: 0.023478\n",
            "Train Epoch: 76 [5504/14860 (37%)]\tLoss: 0.014838\n",
            "Train Epoch: 76 [5632/14860 (38%)]\tLoss: 0.018552\n",
            "Train Epoch: 76 [5760/14860 (38%)]\tLoss: 0.016413\n",
            "Train Epoch: 76 [5888/14860 (39%)]\tLoss: 0.017411\n",
            "Train Epoch: 76 [6016/14860 (40%)]\tLoss: 0.016712\n",
            "Train Epoch: 76 [6144/14860 (41%)]\tLoss: 0.017897\n",
            "Train Epoch: 76 [6272/14860 (42%)]\tLoss: 0.016199\n",
            "Train Epoch: 76 [6400/14860 (43%)]\tLoss: 0.019727\n",
            "Train Epoch: 76 [6528/14860 (44%)]\tLoss: 0.016560\n",
            "Train Epoch: 76 [6656/14860 (44%)]\tLoss: 0.014802\n",
            "Train Epoch: 76 [6784/14860 (45%)]\tLoss: 0.021853\n",
            "Train Epoch: 76 [6912/14860 (46%)]\tLoss: 0.024083\n",
            "Train Epoch: 76 [7040/14860 (47%)]\tLoss: 0.018788\n",
            "Train Epoch: 76 [7168/14860 (48%)]\tLoss: 0.017058\n",
            "Train Epoch: 76 [7296/14860 (49%)]\tLoss: 0.017808\n",
            "Train Epoch: 76 [7424/14860 (50%)]\tLoss: 0.022126\n",
            "Train Epoch: 76 [7552/14860 (50%)]\tLoss: 0.018533\n",
            "Train Epoch: 76 [7680/14860 (51%)]\tLoss: 0.015923\n",
            "Train Epoch: 76 [7808/14860 (52%)]\tLoss: 0.019089\n",
            "Train Epoch: 76 [7936/14860 (53%)]\tLoss: 0.019320\n",
            "Train Epoch: 76 [8064/14860 (54%)]\tLoss: 0.016918\n",
            "Train Epoch: 76 [8192/14860 (55%)]\tLoss: 0.019250\n",
            "Train Epoch: 76 [8320/14860 (56%)]\tLoss: 0.015448\n",
            "Train Epoch: 76 [8448/14860 (56%)]\tLoss: 0.016735\n",
            "Train Epoch: 76 [8576/14860 (57%)]\tLoss: 0.023031\n",
            "Train Epoch: 76 [8704/14860 (58%)]\tLoss: 0.019660\n",
            "Train Epoch: 76 [8832/14860 (59%)]\tLoss: 0.020218\n",
            "Train Epoch: 76 [8960/14860 (60%)]\tLoss: 0.017025\n",
            "Train Epoch: 76 [9088/14860 (61%)]\tLoss: 0.020126\n",
            "Train Epoch: 76 [9216/14860 (62%)]\tLoss: 0.016887\n",
            "Train Epoch: 76 [9344/14860 (62%)]\tLoss: 0.013452\n",
            "Train Epoch: 76 [9472/14860 (63%)]\tLoss: 0.019110\n",
            "Train Epoch: 76 [9600/14860 (64%)]\tLoss: 0.024628\n",
            "Train Epoch: 76 [9728/14860 (65%)]\tLoss: 0.017802\n",
            "Train Epoch: 76 [9856/14860 (66%)]\tLoss: 0.018605\n",
            "Train Epoch: 76 [9984/14860 (67%)]\tLoss: 0.021435\n",
            "Train Epoch: 76 [10112/14860 (68%)]\tLoss: 0.028086\n",
            "Train Epoch: 76 [10240/14860 (68%)]\tLoss: 0.025596\n",
            "Train Epoch: 76 [10368/14860 (69%)]\tLoss: 0.015073\n",
            "Train Epoch: 76 [10496/14860 (70%)]\tLoss: 0.036466\n",
            "Train Epoch: 76 [10624/14860 (71%)]\tLoss: 0.023022\n",
            "Train Epoch: 76 [10752/14860 (72%)]\tLoss: 0.020144\n",
            "Train Epoch: 76 [10880/14860 (73%)]\tLoss: 0.031597\n",
            "Train Epoch: 76 [11008/14860 (74%)]\tLoss: 0.017345\n",
            "Train Epoch: 76 [11136/14860 (74%)]\tLoss: 0.016888\n",
            "Train Epoch: 76 [11264/14860 (75%)]\tLoss: 0.029067\n",
            "Train Epoch: 76 [11392/14860 (76%)]\tLoss: 0.028921\n",
            "Train Epoch: 76 [11520/14860 (77%)]\tLoss: 0.011505\n",
            "Train Epoch: 76 [11648/14860 (78%)]\tLoss: 0.019364\n",
            "Train Epoch: 76 [11776/14860 (79%)]\tLoss: 0.023911\n",
            "Train Epoch: 76 [11904/14860 (79%)]\tLoss: 0.018761\n",
            "Train Epoch: 76 [12032/14860 (80%)]\tLoss: 0.020636\n",
            "Train Epoch: 76 [12160/14860 (81%)]\tLoss: 0.020382\n",
            "Train Epoch: 76 [12288/14860 (82%)]\tLoss: 0.021352\n",
            "Train Epoch: 76 [12416/14860 (83%)]\tLoss: 0.014221\n",
            "Train Epoch: 76 [12544/14860 (84%)]\tLoss: 0.021406\n",
            "Train Epoch: 76 [12672/14860 (85%)]\tLoss: 0.018114\n",
            "Train Epoch: 76 [12800/14860 (85%)]\tLoss: 0.026796\n",
            "Train Epoch: 76 [12928/14860 (86%)]\tLoss: 0.028132\n",
            "Train Epoch: 76 [13056/14860 (87%)]\tLoss: 0.018109\n",
            "Train Epoch: 76 [13184/14860 (88%)]\tLoss: 0.016781\n",
            "Train Epoch: 76 [13312/14860 (89%)]\tLoss: 0.027246\n",
            "Train Epoch: 76 [13440/14860 (90%)]\tLoss: 0.013125\n",
            "Train Epoch: 76 [13568/14860 (91%)]\tLoss: 0.014199\n",
            "Train Epoch: 76 [13696/14860 (91%)]\tLoss: 0.019424\n",
            "Train Epoch: 76 [13824/14860 (92%)]\tLoss: 0.021785\n",
            "Train Epoch: 76 [13952/14860 (93%)]\tLoss: 0.015018\n",
            "Train Epoch: 76 [14080/14860 (94%)]\tLoss: 0.011976\n",
            "Train Epoch: 76 [14208/14860 (95%)]\tLoss: 0.018140\n",
            "Train Epoch: 76 [14336/14860 (96%)]\tLoss: 0.019164\n",
            "Train Epoch: 76 [14464/14860 (97%)]\tLoss: 0.013420\n",
            "Train Epoch: 76 [14592/14860 (97%)]\tLoss: 0.017696\n",
            "Train Epoch: 76 [14720/14860 (98%)]\tLoss: 0.017437\n",
            "Train Epoch: 76 [1392/14860 (99%)]\tLoss: 0.006573\n",
            "epoch 76 training loss: 0.01989581412436743\n",
            "epoch 76 validation loss: 0.022846389913674416\n",
            "Train Epoch: 77 [0/14860 (0%)]\tLoss: 0.028684\n",
            "Train Epoch: 77 [128/14860 (1%)]\tLoss: 0.021597\n",
            "Train Epoch: 77 [256/14860 (2%)]\tLoss: 0.021005\n",
            "Train Epoch: 77 [384/14860 (3%)]\tLoss: 0.019845\n",
            "Train Epoch: 77 [512/14860 (3%)]\tLoss: 0.028366\n",
            "Train Epoch: 77 [640/14860 (4%)]\tLoss: 0.017912\n",
            "Train Epoch: 77 [768/14860 (5%)]\tLoss: 0.017531\n",
            "Train Epoch: 77 [896/14860 (6%)]\tLoss: 0.017199\n",
            "Train Epoch: 77 [1024/14860 (7%)]\tLoss: 0.024664\n",
            "Train Epoch: 77 [1152/14860 (8%)]\tLoss: 0.012046\n",
            "Train Epoch: 77 [1280/14860 (9%)]\tLoss: 0.014709\n",
            "Train Epoch: 77 [1408/14860 (9%)]\tLoss: 0.018604\n",
            "Train Epoch: 77 [1536/14860 (10%)]\tLoss: 0.014836\n",
            "Train Epoch: 77 [1664/14860 (11%)]\tLoss: 0.014579\n",
            "Train Epoch: 77 [1792/14860 (12%)]\tLoss: 0.021631\n",
            "Train Epoch: 77 [1920/14860 (13%)]\tLoss: 0.023853\n",
            "Train Epoch: 77 [2048/14860 (14%)]\tLoss: 0.025795\n",
            "Train Epoch: 77 [2176/14860 (15%)]\tLoss: 0.017728\n",
            "Train Epoch: 77 [2304/14860 (15%)]\tLoss: 0.019123\n",
            "Train Epoch: 77 [2432/14860 (16%)]\tLoss: 0.023854\n",
            "Train Epoch: 77 [2560/14860 (17%)]\tLoss: 0.024161\n",
            "Train Epoch: 77 [2688/14860 (18%)]\tLoss: 0.013382\n",
            "Train Epoch: 77 [2816/14860 (19%)]\tLoss: 0.013464\n",
            "Train Epoch: 77 [2944/14860 (20%)]\tLoss: 0.030042\n",
            "Train Epoch: 77 [3072/14860 (21%)]\tLoss: 0.020645\n",
            "Train Epoch: 77 [3200/14860 (21%)]\tLoss: 0.015257\n",
            "Train Epoch: 77 [3328/14860 (22%)]\tLoss: 0.023596\n",
            "Train Epoch: 77 [3456/14860 (23%)]\tLoss: 0.016074\n",
            "Train Epoch: 77 [3584/14860 (24%)]\tLoss: 0.022487\n",
            "Train Epoch: 77 [3712/14860 (25%)]\tLoss: 0.020209\n",
            "Train Epoch: 77 [3840/14860 (26%)]\tLoss: 0.026037\n",
            "Train Epoch: 77 [3968/14860 (26%)]\tLoss: 0.028159\n",
            "Train Epoch: 77 [4096/14860 (27%)]\tLoss: 0.018862\n",
            "Train Epoch: 77 [4224/14860 (28%)]\tLoss: 0.017770\n",
            "Train Epoch: 77 [4352/14860 (29%)]\tLoss: 0.023497\n",
            "Train Epoch: 77 [4480/14860 (30%)]\tLoss: 0.018531\n",
            "Train Epoch: 77 [4608/14860 (31%)]\tLoss: 0.014006\n",
            "Train Epoch: 77 [4736/14860 (32%)]\tLoss: 0.026412\n",
            "Train Epoch: 77 [4864/14860 (32%)]\tLoss: 0.015223\n",
            "Train Epoch: 77 [4992/14860 (33%)]\tLoss: 0.017467\n",
            "Train Epoch: 77 [5120/14860 (34%)]\tLoss: 0.021239\n",
            "Train Epoch: 77 [5248/14860 (35%)]\tLoss: 0.011386\n",
            "Train Epoch: 77 [5376/14860 (36%)]\tLoss: 0.012860\n",
            "Train Epoch: 77 [5504/14860 (37%)]\tLoss: 0.024211\n",
            "Train Epoch: 77 [5632/14860 (38%)]\tLoss: 0.012099\n",
            "Train Epoch: 77 [5760/14860 (38%)]\tLoss: 0.023344\n",
            "Train Epoch: 77 [5888/14860 (39%)]\tLoss: 0.020458\n",
            "Train Epoch: 77 [6016/14860 (40%)]\tLoss: 0.018201\n",
            "Train Epoch: 77 [6144/14860 (41%)]\tLoss: 0.015994\n",
            "Train Epoch: 77 [6272/14860 (42%)]\tLoss: 0.016617\n",
            "Train Epoch: 77 [6400/14860 (43%)]\tLoss: 0.015736\n",
            "Train Epoch: 77 [6528/14860 (44%)]\tLoss: 0.027857\n",
            "Train Epoch: 77 [6656/14860 (44%)]\tLoss: 0.015841\n",
            "Train Epoch: 77 [6784/14860 (45%)]\tLoss: 0.016235\n",
            "Train Epoch: 77 [6912/14860 (46%)]\tLoss: 0.018792\n",
            "Train Epoch: 77 [7040/14860 (47%)]\tLoss: 0.016698\n",
            "Train Epoch: 77 [7168/14860 (48%)]\tLoss: 0.022989\n",
            "Train Epoch: 77 [7296/14860 (49%)]\tLoss: 0.018210\n",
            "Train Epoch: 77 [7424/14860 (50%)]\tLoss: 0.017012\n",
            "Train Epoch: 77 [7552/14860 (50%)]\tLoss: 0.014301\n",
            "Train Epoch: 77 [7680/14860 (51%)]\tLoss: 0.015490\n",
            "Train Epoch: 77 [7808/14860 (52%)]\tLoss: 0.016576\n",
            "Train Epoch: 77 [7936/14860 (53%)]\tLoss: 0.016131\n",
            "Train Epoch: 77 [8064/14860 (54%)]\tLoss: 0.017019\n",
            "Train Epoch: 77 [8192/14860 (55%)]\tLoss: 0.021675\n",
            "Train Epoch: 77 [8320/14860 (56%)]\tLoss: 0.022690\n",
            "Train Epoch: 77 [8448/14860 (56%)]\tLoss: 0.017233\n",
            "Train Epoch: 77 [8576/14860 (57%)]\tLoss: 0.021396\n",
            "Train Epoch: 77 [8704/14860 (58%)]\tLoss: 0.011743\n",
            "Train Epoch: 77 [8832/14860 (59%)]\tLoss: 0.029482\n",
            "Train Epoch: 77 [8960/14860 (60%)]\tLoss: 0.019346\n",
            "Train Epoch: 77 [9088/14860 (61%)]\tLoss: 0.024471\n",
            "Train Epoch: 77 [9216/14860 (62%)]\tLoss: 0.024205\n",
            "Train Epoch: 77 [9344/14860 (62%)]\tLoss: 0.023843\n",
            "Train Epoch: 77 [9472/14860 (63%)]\tLoss: 0.017409\n",
            "Train Epoch: 77 [9600/14860 (64%)]\tLoss: 0.025481\n",
            "Train Epoch: 77 [9728/14860 (65%)]\tLoss: 0.021106\n",
            "Train Epoch: 77 [9856/14860 (66%)]\tLoss: 0.015945\n",
            "Train Epoch: 77 [9984/14860 (67%)]\tLoss: 0.021833\n",
            "Train Epoch: 77 [10112/14860 (68%)]\tLoss: 0.014619\n",
            "Train Epoch: 77 [10240/14860 (68%)]\tLoss: 0.016950\n",
            "Train Epoch: 77 [10368/14860 (69%)]\tLoss: 0.020966\n",
            "Train Epoch: 77 [10496/14860 (70%)]\tLoss: 0.014342\n",
            "Train Epoch: 77 [10624/14860 (71%)]\tLoss: 0.017781\n",
            "Train Epoch: 77 [10752/14860 (72%)]\tLoss: 0.027811\n",
            "Train Epoch: 77 [10880/14860 (73%)]\tLoss: 0.019095\n",
            "Train Epoch: 77 [11008/14860 (74%)]\tLoss: 0.019311\n",
            "Train Epoch: 77 [11136/14860 (74%)]\tLoss: 0.020689\n",
            "Train Epoch: 77 [11264/14860 (75%)]\tLoss: 0.020470\n",
            "Train Epoch: 77 [11392/14860 (76%)]\tLoss: 0.013497\n",
            "Train Epoch: 77 [11520/14860 (77%)]\tLoss: 0.016997\n",
            "Train Epoch: 77 [11648/14860 (78%)]\tLoss: 0.013705\n",
            "Train Epoch: 77 [11776/14860 (79%)]\tLoss: 0.021736\n",
            "Train Epoch: 77 [11904/14860 (79%)]\tLoss: 0.015844\n",
            "Train Epoch: 77 [12032/14860 (80%)]\tLoss: 0.020846\n",
            "Train Epoch: 77 [12160/14860 (81%)]\tLoss: 0.023371\n",
            "Train Epoch: 77 [12288/14860 (82%)]\tLoss: 0.019907\n",
            "Train Epoch: 77 [12416/14860 (83%)]\tLoss: 0.016415\n",
            "Train Epoch: 77 [12544/14860 (84%)]\tLoss: 0.015643\n",
            "Train Epoch: 77 [12672/14860 (85%)]\tLoss: 0.013662\n",
            "Train Epoch: 77 [12800/14860 (85%)]\tLoss: 0.016954\n",
            "Train Epoch: 77 [12928/14860 (86%)]\tLoss: 0.017777\n",
            "Train Epoch: 77 [13056/14860 (87%)]\tLoss: 0.016650\n",
            "Train Epoch: 77 [13184/14860 (88%)]\tLoss: 0.018917\n",
            "Train Epoch: 77 [13312/14860 (89%)]\tLoss: 0.017449\n",
            "Train Epoch: 77 [13440/14860 (90%)]\tLoss: 0.024721\n",
            "Train Epoch: 77 [13568/14860 (91%)]\tLoss: 0.017707\n",
            "Train Epoch: 77 [13696/14860 (91%)]\tLoss: 0.018647\n",
            "Train Epoch: 77 [13824/14860 (92%)]\tLoss: 0.023758\n",
            "Train Epoch: 77 [13952/14860 (93%)]\tLoss: 0.022868\n",
            "Train Epoch: 77 [14080/14860 (94%)]\tLoss: 0.016423\n",
            "Train Epoch: 77 [14208/14860 (95%)]\tLoss: 0.024168\n",
            "Train Epoch: 77 [14336/14860 (96%)]\tLoss: 0.022234\n",
            "Train Epoch: 77 [14464/14860 (97%)]\tLoss: 0.020612\n",
            "Train Epoch: 77 [14592/14860 (97%)]\tLoss: 0.018074\n",
            "Train Epoch: 77 [14720/14860 (98%)]\tLoss: 0.014307\n",
            "Train Epoch: 77 [1392/14860 (99%)]\tLoss: 0.009676\n",
            "epoch 77 training loss: 0.019287123655279476\n",
            "epoch 77 validation loss: 0.02109519946084473\n",
            "Train Epoch: 78 [0/14860 (0%)]\tLoss: 0.018421\n",
            "Train Epoch: 78 [128/14860 (1%)]\tLoss: 0.027650\n",
            "Train Epoch: 78 [256/14860 (2%)]\tLoss: 0.028103\n",
            "Train Epoch: 78 [384/14860 (3%)]\tLoss: 0.017452\n",
            "Train Epoch: 78 [512/14860 (3%)]\tLoss: 0.021989\n",
            "Train Epoch: 78 [640/14860 (4%)]\tLoss: 0.030031\n",
            "Train Epoch: 78 [768/14860 (5%)]\tLoss: 0.023591\n",
            "Train Epoch: 78 [896/14860 (6%)]\tLoss: 0.024144\n",
            "Train Epoch: 78 [1024/14860 (7%)]\tLoss: 0.022300\n",
            "Train Epoch: 78 [1152/14860 (8%)]\tLoss: 0.017601\n",
            "Train Epoch: 78 [1280/14860 (9%)]\tLoss: 0.019609\n",
            "Train Epoch: 78 [1408/14860 (9%)]\tLoss: 0.020108\n",
            "Train Epoch: 78 [1536/14860 (10%)]\tLoss: 0.016600\n",
            "Train Epoch: 78 [1664/14860 (11%)]\tLoss: 0.016599\n",
            "Train Epoch: 78 [1792/14860 (12%)]\tLoss: 0.018771\n",
            "Train Epoch: 78 [1920/14860 (13%)]\tLoss: 0.019578\n",
            "Train Epoch: 78 [2048/14860 (14%)]\tLoss: 0.021329\n",
            "Train Epoch: 78 [2176/14860 (15%)]\tLoss: 0.020006\n",
            "Train Epoch: 78 [2304/14860 (15%)]\tLoss: 0.019470\n",
            "Train Epoch: 78 [2432/14860 (16%)]\tLoss: 0.017476\n",
            "Train Epoch: 78 [2560/14860 (17%)]\tLoss: 0.015726\n",
            "Train Epoch: 78 [2688/14860 (18%)]\tLoss: 0.015604\n",
            "Train Epoch: 78 [2816/14860 (19%)]\tLoss: 0.016530\n",
            "Train Epoch: 78 [2944/14860 (20%)]\tLoss: 0.029206\n",
            "Train Epoch: 78 [3072/14860 (21%)]\tLoss: 0.018223\n",
            "Train Epoch: 78 [3200/14860 (21%)]\tLoss: 0.024636\n",
            "Train Epoch: 78 [3328/14860 (22%)]\tLoss: 0.017118\n",
            "Train Epoch: 78 [3456/14860 (23%)]\tLoss: 0.019251\n",
            "Train Epoch: 78 [3584/14860 (24%)]\tLoss: 0.021501\n",
            "Train Epoch: 78 [3712/14860 (25%)]\tLoss: 0.017409\n",
            "Train Epoch: 78 [3840/14860 (26%)]\tLoss: 0.017490\n",
            "Train Epoch: 78 [3968/14860 (26%)]\tLoss: 0.017321\n",
            "Train Epoch: 78 [4096/14860 (27%)]\tLoss: 0.017477\n",
            "Train Epoch: 78 [4224/14860 (28%)]\tLoss: 0.019208\n",
            "Train Epoch: 78 [4352/14860 (29%)]\tLoss: 0.023784\n",
            "Train Epoch: 78 [4480/14860 (30%)]\tLoss: 0.023397\n",
            "Train Epoch: 78 [4608/14860 (31%)]\tLoss: 0.018882\n",
            "Train Epoch: 78 [4736/14860 (32%)]\tLoss: 0.020067\n",
            "Train Epoch: 78 [4864/14860 (32%)]\tLoss: 0.018619\n",
            "Train Epoch: 78 [4992/14860 (33%)]\tLoss: 0.014718\n",
            "Train Epoch: 78 [5120/14860 (34%)]\tLoss: 0.017610\n",
            "Train Epoch: 78 [5248/14860 (35%)]\tLoss: 0.031502\n",
            "Train Epoch: 78 [5376/14860 (36%)]\tLoss: 0.024739\n",
            "Train Epoch: 78 [5504/14860 (37%)]\tLoss: 0.017548\n",
            "Train Epoch: 78 [5632/14860 (38%)]\tLoss: 0.016913\n",
            "Train Epoch: 78 [5760/14860 (38%)]\tLoss: 0.018429\n",
            "Train Epoch: 78 [5888/14860 (39%)]\tLoss: 0.025174\n",
            "Train Epoch: 78 [6016/14860 (40%)]\tLoss: 0.019555\n",
            "Train Epoch: 78 [6144/14860 (41%)]\tLoss: 0.015697\n",
            "Train Epoch: 78 [6272/14860 (42%)]\tLoss: 0.018757\n",
            "Train Epoch: 78 [6400/14860 (43%)]\tLoss: 0.014363\n",
            "Train Epoch: 78 [6528/14860 (44%)]\tLoss: 0.022645\n",
            "Train Epoch: 78 [6656/14860 (44%)]\tLoss: 0.018548\n",
            "Train Epoch: 78 [6784/14860 (45%)]\tLoss: 0.025860\n",
            "Train Epoch: 78 [6912/14860 (46%)]\tLoss: 0.020126\n",
            "Train Epoch: 78 [7040/14860 (47%)]\tLoss: 0.025712\n",
            "Train Epoch: 78 [7168/14860 (48%)]\tLoss: 0.021817\n",
            "Train Epoch: 78 [7296/14860 (49%)]\tLoss: 0.017206\n",
            "Train Epoch: 78 [7424/14860 (50%)]\tLoss: 0.018602\n",
            "Train Epoch: 78 [7552/14860 (50%)]\tLoss: 0.017383\n",
            "Train Epoch: 78 [7680/14860 (51%)]\tLoss: 0.019387\n",
            "Train Epoch: 78 [7808/14860 (52%)]\tLoss: 0.018298\n",
            "Train Epoch: 78 [7936/14860 (53%)]\tLoss: 0.018256\n",
            "Train Epoch: 78 [8064/14860 (54%)]\tLoss: 0.018960\n",
            "Train Epoch: 78 [8192/14860 (55%)]\tLoss: 0.014495\n",
            "Train Epoch: 78 [8320/14860 (56%)]\tLoss: 0.010302\n",
            "Train Epoch: 78 [8448/14860 (56%)]\tLoss: 0.020457\n",
            "Train Epoch: 78 [8576/14860 (57%)]\tLoss: 0.012304\n",
            "Train Epoch: 78 [8704/14860 (58%)]\tLoss: 0.016006\n",
            "Train Epoch: 78 [8832/14860 (59%)]\tLoss: 0.019958\n",
            "Train Epoch: 78 [8960/14860 (60%)]\tLoss: 0.014846\n",
            "Train Epoch: 78 [9088/14860 (61%)]\tLoss: 0.020411\n",
            "Train Epoch: 78 [9216/14860 (62%)]\tLoss: 0.019056\n",
            "Train Epoch: 78 [9344/14860 (62%)]\tLoss: 0.022138\n",
            "Train Epoch: 78 [9472/14860 (63%)]\tLoss: 0.020529\n",
            "Train Epoch: 78 [9600/14860 (64%)]\tLoss: 0.020428\n",
            "Train Epoch: 78 [9728/14860 (65%)]\tLoss: 0.019502\n",
            "Train Epoch: 78 [9856/14860 (66%)]\tLoss: 0.013686\n",
            "Train Epoch: 78 [9984/14860 (67%)]\tLoss: 0.010485\n",
            "Train Epoch: 78 [10112/14860 (68%)]\tLoss: 0.020667\n",
            "Train Epoch: 78 [10240/14860 (68%)]\tLoss: 0.023529\n",
            "Train Epoch: 78 [10368/14860 (69%)]\tLoss: 0.026879\n",
            "Train Epoch: 78 [10496/14860 (70%)]\tLoss: 0.018266\n",
            "Train Epoch: 78 [10624/14860 (71%)]\tLoss: 0.018660\n",
            "Train Epoch: 78 [10752/14860 (72%)]\tLoss: 0.024714\n",
            "Train Epoch: 78 [10880/14860 (73%)]\tLoss: 0.020281\n",
            "Train Epoch: 78 [11008/14860 (74%)]\tLoss: 0.025044\n",
            "Train Epoch: 78 [11136/14860 (74%)]\tLoss: 0.016398\n",
            "Train Epoch: 78 [11264/14860 (75%)]\tLoss: 0.017206\n",
            "Train Epoch: 78 [11392/14860 (76%)]\tLoss: 0.023838\n",
            "Train Epoch: 78 [11520/14860 (77%)]\tLoss: 0.018047\n",
            "Train Epoch: 78 [11648/14860 (78%)]\tLoss: 0.015958\n",
            "Train Epoch: 78 [11776/14860 (79%)]\tLoss: 0.018453\n",
            "Train Epoch: 78 [11904/14860 (79%)]\tLoss: 0.022879\n",
            "Train Epoch: 78 [12032/14860 (80%)]\tLoss: 0.011156\n",
            "Train Epoch: 78 [12160/14860 (81%)]\tLoss: 0.012675\n",
            "Train Epoch: 78 [12288/14860 (82%)]\tLoss: 0.023899\n",
            "Train Epoch: 78 [12416/14860 (83%)]\tLoss: 0.020374\n",
            "Train Epoch: 78 [12544/14860 (84%)]\tLoss: 0.026253\n",
            "Train Epoch: 78 [12672/14860 (85%)]\tLoss: 0.019552\n",
            "Train Epoch: 78 [12800/14860 (85%)]\tLoss: 0.027827\n",
            "Train Epoch: 78 [12928/14860 (86%)]\tLoss: 0.023202\n",
            "Train Epoch: 78 [13056/14860 (87%)]\tLoss: 0.021456\n",
            "Train Epoch: 78 [13184/14860 (88%)]\tLoss: 0.020325\n",
            "Train Epoch: 78 [13312/14860 (89%)]\tLoss: 0.018252\n",
            "Train Epoch: 78 [13440/14860 (90%)]\tLoss: 0.025420\n",
            "Train Epoch: 78 [13568/14860 (91%)]\tLoss: 0.017311\n",
            "Train Epoch: 78 [13696/14860 (91%)]\tLoss: 0.018855\n",
            "Train Epoch: 78 [13824/14860 (92%)]\tLoss: 0.016497\n",
            "Train Epoch: 78 [13952/14860 (93%)]\tLoss: 0.020657\n",
            "Train Epoch: 78 [14080/14860 (94%)]\tLoss: 0.018358\n",
            "Train Epoch: 78 [14208/14860 (95%)]\tLoss: 0.026734\n",
            "Train Epoch: 78 [14336/14860 (96%)]\tLoss: 0.020307\n",
            "Train Epoch: 78 [14464/14860 (97%)]\tLoss: 0.021322\n",
            "Train Epoch: 78 [14592/14860 (97%)]\tLoss: 0.018323\n",
            "Train Epoch: 78 [14720/14860 (98%)]\tLoss: 0.019330\n",
            "Train Epoch: 78 [1392/14860 (99%)]\tLoss: 0.013216\n",
            "epoch 78 training loss: 0.01980174543797715\n",
            "epoch 78 validation loss: 0.021782793952535486\n",
            "Train Epoch: 79 [0/14860 (0%)]\tLoss: 0.016646\n",
            "Train Epoch: 79 [128/14860 (1%)]\tLoss: 0.016666\n",
            "Train Epoch: 79 [256/14860 (2%)]\tLoss: 0.024705\n",
            "Train Epoch: 79 [384/14860 (3%)]\tLoss: 0.022188\n",
            "Train Epoch: 79 [512/14860 (3%)]\tLoss: 0.020772\n",
            "Train Epoch: 79 [640/14860 (4%)]\tLoss: 0.014962\n",
            "Train Epoch: 79 [768/14860 (5%)]\tLoss: 0.020186\n",
            "Train Epoch: 79 [896/14860 (6%)]\tLoss: 0.022506\n",
            "Train Epoch: 79 [1024/14860 (7%)]\tLoss: 0.031804\n",
            "Train Epoch: 79 [1152/14860 (8%)]\tLoss: 0.016488\n",
            "Train Epoch: 79 [1280/14860 (9%)]\tLoss: 0.025032\n",
            "Train Epoch: 79 [1408/14860 (9%)]\tLoss: 0.017211\n",
            "Train Epoch: 79 [1536/14860 (10%)]\tLoss: 0.014382\n",
            "Train Epoch: 79 [1664/14860 (11%)]\tLoss: 0.015597\n",
            "Train Epoch: 79 [1792/14860 (12%)]\tLoss: 0.017438\n",
            "Train Epoch: 79 [1920/14860 (13%)]\tLoss: 0.017738\n",
            "Train Epoch: 79 [2048/14860 (14%)]\tLoss: 0.018657\n",
            "Train Epoch: 79 [2176/14860 (15%)]\tLoss: 0.015744\n",
            "Train Epoch: 79 [2304/14860 (15%)]\tLoss: 0.021119\n",
            "Train Epoch: 79 [2432/14860 (16%)]\tLoss: 0.025294\n",
            "Train Epoch: 79 [2560/14860 (17%)]\tLoss: 0.019185\n",
            "Train Epoch: 79 [2688/14860 (18%)]\tLoss: 0.018308\n",
            "Train Epoch: 79 [2816/14860 (19%)]\tLoss: 0.014934\n",
            "Train Epoch: 79 [2944/14860 (20%)]\tLoss: 0.021144\n",
            "Train Epoch: 79 [3072/14860 (21%)]\tLoss: 0.016435\n",
            "Train Epoch: 79 [3200/14860 (21%)]\tLoss: 0.020106\n",
            "Train Epoch: 79 [3328/14860 (22%)]\tLoss: 0.023176\n",
            "Train Epoch: 79 [3456/14860 (23%)]\tLoss: 0.022335\n",
            "Train Epoch: 79 [3584/14860 (24%)]\tLoss: 0.014601\n",
            "Train Epoch: 79 [3712/14860 (25%)]\tLoss: 0.023409\n",
            "Train Epoch: 79 [3840/14860 (26%)]\tLoss: 0.020836\n",
            "Train Epoch: 79 [3968/14860 (26%)]\tLoss: 0.016559\n",
            "Train Epoch: 79 [4096/14860 (27%)]\tLoss: 0.020602\n",
            "Train Epoch: 79 [4224/14860 (28%)]\tLoss: 0.020446\n",
            "Train Epoch: 79 [4352/14860 (29%)]\tLoss: 0.015687\n",
            "Train Epoch: 79 [4480/14860 (30%)]\tLoss: 0.018106\n",
            "Train Epoch: 79 [4608/14860 (31%)]\tLoss: 0.016072\n",
            "Train Epoch: 79 [4736/14860 (32%)]\tLoss: 0.015027\n",
            "Train Epoch: 79 [4864/14860 (32%)]\tLoss: 0.014740\n",
            "Train Epoch: 79 [4992/14860 (33%)]\tLoss: 0.018872\n",
            "Train Epoch: 79 [5120/14860 (34%)]\tLoss: 0.023554\n",
            "Train Epoch: 79 [5248/14860 (35%)]\tLoss: 0.021938\n",
            "Train Epoch: 79 [5376/14860 (36%)]\tLoss: 0.015614\n",
            "Train Epoch: 79 [5504/14860 (37%)]\tLoss: 0.018462\n",
            "Train Epoch: 79 [5632/14860 (38%)]\tLoss: 0.016685\n",
            "Train Epoch: 79 [5760/14860 (38%)]\tLoss: 0.019993\n",
            "Train Epoch: 79 [5888/14860 (39%)]\tLoss: 0.020809\n",
            "Train Epoch: 79 [6016/14860 (40%)]\tLoss: 0.018214\n",
            "Train Epoch: 79 [6144/14860 (41%)]\tLoss: 0.025871\n",
            "Train Epoch: 79 [6272/14860 (42%)]\tLoss: 0.012054\n",
            "Train Epoch: 79 [6400/14860 (43%)]\tLoss: 0.017355\n",
            "Train Epoch: 79 [6528/14860 (44%)]\tLoss: 0.026956\n",
            "Train Epoch: 79 [6656/14860 (44%)]\tLoss: 0.027238\n",
            "Train Epoch: 79 [6784/14860 (45%)]\tLoss: 0.022944\n",
            "Train Epoch: 79 [6912/14860 (46%)]\tLoss: 0.024710\n",
            "Train Epoch: 79 [7040/14860 (47%)]\tLoss: 0.018815\n",
            "Train Epoch: 79 [7168/14860 (48%)]\tLoss: 0.012825\n",
            "Train Epoch: 79 [7296/14860 (49%)]\tLoss: 0.013323\n",
            "Train Epoch: 79 [7424/14860 (50%)]\tLoss: 0.016446\n",
            "Train Epoch: 79 [7552/14860 (50%)]\tLoss: 0.019304\n",
            "Train Epoch: 79 [7680/14860 (51%)]\tLoss: 0.017997\n",
            "Train Epoch: 79 [7808/14860 (52%)]\tLoss: 0.016556\n",
            "Train Epoch: 79 [7936/14860 (53%)]\tLoss: 0.020119\n",
            "Train Epoch: 79 [8064/14860 (54%)]\tLoss: 0.019548\n",
            "Train Epoch: 79 [8192/14860 (55%)]\tLoss: 0.013090\n",
            "Train Epoch: 79 [8320/14860 (56%)]\tLoss: 0.021233\n",
            "Train Epoch: 79 [8448/14860 (56%)]\tLoss: 0.020431\n",
            "Train Epoch: 79 [8576/14860 (57%)]\tLoss: 0.021429\n",
            "Train Epoch: 79 [8704/14860 (58%)]\tLoss: 0.017257\n",
            "Train Epoch: 79 [8832/14860 (59%)]\tLoss: 0.019770\n",
            "Train Epoch: 79 [8960/14860 (60%)]\tLoss: 0.022435\n",
            "Train Epoch: 79 [9088/14860 (61%)]\tLoss: 0.016005\n",
            "Train Epoch: 79 [9216/14860 (62%)]\tLoss: 0.016871\n",
            "Train Epoch: 79 [9344/14860 (62%)]\tLoss: 0.016505\n",
            "Train Epoch: 79 [9472/14860 (63%)]\tLoss: 0.015249\n",
            "Train Epoch: 79 [9600/14860 (64%)]\tLoss: 0.018103\n",
            "Train Epoch: 79 [9728/14860 (65%)]\tLoss: 0.023659\n",
            "Train Epoch: 79 [9856/14860 (66%)]\tLoss: 0.019678\n",
            "Train Epoch: 79 [9984/14860 (67%)]\tLoss: 0.018364\n",
            "Train Epoch: 79 [10112/14860 (68%)]\tLoss: 0.016807\n",
            "Train Epoch: 79 [10240/14860 (68%)]\tLoss: 0.019198\n",
            "Train Epoch: 79 [10368/14860 (69%)]\tLoss: 0.017884\n",
            "Train Epoch: 79 [10496/14860 (70%)]\tLoss: 0.018321\n",
            "Train Epoch: 79 [10624/14860 (71%)]\tLoss: 0.017995\n",
            "Train Epoch: 79 [10752/14860 (72%)]\tLoss: 0.022419\n",
            "Train Epoch: 79 [10880/14860 (73%)]\tLoss: 0.021451\n",
            "Train Epoch: 79 [11008/14860 (74%)]\tLoss: 0.015999\n",
            "Train Epoch: 79 [11136/14860 (74%)]\tLoss: 0.021190\n",
            "Train Epoch: 79 [11264/14860 (75%)]\tLoss: 0.020034\n",
            "Train Epoch: 79 [11392/14860 (76%)]\tLoss: 0.017305\n",
            "Train Epoch: 79 [11520/14860 (77%)]\tLoss: 0.013469\n",
            "Train Epoch: 79 [11648/14860 (78%)]\tLoss: 0.015188\n",
            "Train Epoch: 79 [11776/14860 (79%)]\tLoss: 0.014419\n",
            "Train Epoch: 79 [11904/14860 (79%)]\tLoss: 0.027529\n",
            "Train Epoch: 79 [12032/14860 (80%)]\tLoss: 0.022409\n",
            "Train Epoch: 79 [12160/14860 (81%)]\tLoss: 0.016304\n",
            "Train Epoch: 79 [12288/14860 (82%)]\tLoss: 0.017591\n",
            "Train Epoch: 79 [12416/14860 (83%)]\tLoss: 0.014151\n",
            "Train Epoch: 79 [12544/14860 (84%)]\tLoss: 0.022729\n",
            "Train Epoch: 79 [12672/14860 (85%)]\tLoss: 0.026103\n",
            "Train Epoch: 79 [12800/14860 (85%)]\tLoss: 0.016444\n",
            "Train Epoch: 79 [12928/14860 (86%)]\tLoss: 0.020377\n",
            "Train Epoch: 79 [13056/14860 (87%)]\tLoss: 0.027129\n",
            "Train Epoch: 79 [13184/14860 (88%)]\tLoss: 0.014809\n",
            "Train Epoch: 79 [13312/14860 (89%)]\tLoss: 0.018045\n",
            "Train Epoch: 79 [13440/14860 (90%)]\tLoss: 0.017785\n",
            "Train Epoch: 79 [13568/14860 (91%)]\tLoss: 0.016522\n",
            "Train Epoch: 79 [13696/14860 (91%)]\tLoss: 0.013904\n",
            "Train Epoch: 79 [13824/14860 (92%)]\tLoss: 0.016560\n",
            "Train Epoch: 79 [13952/14860 (93%)]\tLoss: 0.018797\n",
            "Train Epoch: 79 [14080/14860 (94%)]\tLoss: 0.020222\n",
            "Train Epoch: 79 [14208/14860 (95%)]\tLoss: 0.021218\n",
            "Train Epoch: 79 [14336/14860 (96%)]\tLoss: 0.025013\n",
            "Train Epoch: 79 [14464/14860 (97%)]\tLoss: 0.027681\n",
            "Train Epoch: 79 [14592/14860 (97%)]\tLoss: 0.016131\n",
            "Train Epoch: 79 [14720/14860 (98%)]\tLoss: 0.020741\n",
            "Train Epoch: 79 [1392/14860 (99%)]\tLoss: 0.013052\n",
            "epoch 79 training loss: 0.019111569724085495\n",
            "epoch 79 validation loss: 0.01985308022822364\n",
            "Train Epoch: 80 [0/14860 (0%)]\tLoss: 0.023860\n",
            "Train Epoch: 80 [128/14860 (1%)]\tLoss: 0.019762\n",
            "Train Epoch: 80 [256/14860 (2%)]\tLoss: 0.019765\n",
            "Train Epoch: 80 [384/14860 (3%)]\tLoss: 0.016738\n",
            "Train Epoch: 80 [512/14860 (3%)]\tLoss: 0.020475\n",
            "Train Epoch: 80 [640/14860 (4%)]\tLoss: 0.016629\n",
            "Train Epoch: 80 [768/14860 (5%)]\tLoss: 0.017504\n",
            "Train Epoch: 80 [896/14860 (6%)]\tLoss: 0.021847\n",
            "Train Epoch: 80 [1024/14860 (7%)]\tLoss: 0.015981\n",
            "Train Epoch: 80 [1152/14860 (8%)]\tLoss: 0.026040\n",
            "Train Epoch: 80 [1280/14860 (9%)]\tLoss: 0.022531\n",
            "Train Epoch: 80 [1408/14860 (9%)]\tLoss: 0.018905\n",
            "Train Epoch: 80 [1536/14860 (10%)]\tLoss: 0.013373\n",
            "Train Epoch: 80 [1664/14860 (11%)]\tLoss: 0.015816\n",
            "Train Epoch: 80 [1792/14860 (12%)]\tLoss: 0.017022\n",
            "Train Epoch: 80 [1920/14860 (13%)]\tLoss: 0.015706\n",
            "Train Epoch: 80 [2048/14860 (14%)]\tLoss: 0.018311\n",
            "Train Epoch: 80 [2176/14860 (15%)]\tLoss: 0.014622\n",
            "Train Epoch: 80 [2304/14860 (15%)]\tLoss: 0.015603\n",
            "Train Epoch: 80 [2432/14860 (16%)]\tLoss: 0.015617\n",
            "Train Epoch: 80 [2560/14860 (17%)]\tLoss: 0.016842\n",
            "Train Epoch: 80 [2688/14860 (18%)]\tLoss: 0.019042\n",
            "Train Epoch: 80 [2816/14860 (19%)]\tLoss: 0.019008\n",
            "Train Epoch: 80 [2944/14860 (20%)]\tLoss: 0.021766\n",
            "Train Epoch: 80 [3072/14860 (21%)]\tLoss: 0.024770\n",
            "Train Epoch: 80 [3200/14860 (21%)]\tLoss: 0.015675\n",
            "Train Epoch: 80 [3328/14860 (22%)]\tLoss: 0.031026\n",
            "Train Epoch: 80 [3456/14860 (23%)]\tLoss: 0.019117\n",
            "Train Epoch: 80 [3584/14860 (24%)]\tLoss: 0.021179\n",
            "Train Epoch: 80 [3712/14860 (25%)]\tLoss: 0.022587\n",
            "Train Epoch: 80 [3840/14860 (26%)]\tLoss: 0.014951\n",
            "Train Epoch: 80 [3968/14860 (26%)]\tLoss: 0.016339\n",
            "Train Epoch: 80 [4096/14860 (27%)]\tLoss: 0.015425\n",
            "Train Epoch: 80 [4224/14860 (28%)]\tLoss: 0.015497\n",
            "Train Epoch: 80 [4352/14860 (29%)]\tLoss: 0.018024\n",
            "Train Epoch: 80 [4480/14860 (30%)]\tLoss: 0.019916\n",
            "Train Epoch: 80 [4608/14860 (31%)]\tLoss: 0.018404\n",
            "Train Epoch: 80 [4736/14860 (32%)]\tLoss: 0.021919\n",
            "Train Epoch: 80 [4864/14860 (32%)]\tLoss: 0.021391\n",
            "Train Epoch: 80 [4992/14860 (33%)]\tLoss: 0.016742\n",
            "Train Epoch: 80 [5120/14860 (34%)]\tLoss: 0.016773\n",
            "Train Epoch: 80 [5248/14860 (35%)]\tLoss: 0.024080\n",
            "Train Epoch: 80 [5376/14860 (36%)]\tLoss: 0.019122\n",
            "Train Epoch: 80 [5504/14860 (37%)]\tLoss: 0.025837\n",
            "Train Epoch: 80 [5632/14860 (38%)]\tLoss: 0.019732\n",
            "Train Epoch: 80 [5760/14860 (38%)]\tLoss: 0.014162\n",
            "Train Epoch: 80 [5888/14860 (39%)]\tLoss: 0.022111\n",
            "Train Epoch: 80 [6016/14860 (40%)]\tLoss: 0.015298\n",
            "Train Epoch: 80 [6144/14860 (41%)]\tLoss: 0.022855\n",
            "Train Epoch: 80 [6272/14860 (42%)]\tLoss: 0.019866\n",
            "Train Epoch: 80 [6400/14860 (43%)]\tLoss: 0.020006\n",
            "Train Epoch: 80 [6528/14860 (44%)]\tLoss: 0.011449\n",
            "Train Epoch: 80 [6656/14860 (44%)]\tLoss: 0.025406\n",
            "Train Epoch: 80 [6784/14860 (45%)]\tLoss: 0.023804\n",
            "Train Epoch: 80 [6912/14860 (46%)]\tLoss: 0.024706\n",
            "Train Epoch: 80 [7040/14860 (47%)]\tLoss: 0.022375\n",
            "Train Epoch: 80 [7168/14860 (48%)]\tLoss: 0.014616\n",
            "Train Epoch: 80 [7296/14860 (49%)]\tLoss: 0.025190\n",
            "Train Epoch: 80 [7424/14860 (50%)]\tLoss: 0.016822\n",
            "Train Epoch: 80 [7552/14860 (50%)]\tLoss: 0.018267\n",
            "Train Epoch: 80 [7680/14860 (51%)]\tLoss: 0.016495\n",
            "Train Epoch: 80 [7808/14860 (52%)]\tLoss: 0.017470\n",
            "Train Epoch: 80 [7936/14860 (53%)]\tLoss: 0.019877\n",
            "Train Epoch: 80 [8064/14860 (54%)]\tLoss: 0.022822\n",
            "Train Epoch: 80 [8192/14860 (55%)]\tLoss: 0.024675\n",
            "Train Epoch: 80 [8320/14860 (56%)]\tLoss: 0.016804\n",
            "Train Epoch: 80 [8448/14860 (56%)]\tLoss: 0.013444\n",
            "Train Epoch: 80 [8576/14860 (57%)]\tLoss: 0.019004\n",
            "Train Epoch: 80 [8704/14860 (58%)]\tLoss: 0.021723\n",
            "Train Epoch: 80 [8832/14860 (59%)]\tLoss: 0.016717\n",
            "Train Epoch: 80 [8960/14860 (60%)]\tLoss: 0.017126\n",
            "Train Epoch: 80 [9088/14860 (61%)]\tLoss: 0.017964\n",
            "Train Epoch: 80 [9216/14860 (62%)]\tLoss: 0.014162\n",
            "Train Epoch: 80 [9344/14860 (62%)]\tLoss: 0.016255\n",
            "Train Epoch: 80 [9472/14860 (63%)]\tLoss: 0.014442\n",
            "Train Epoch: 80 [9600/14860 (64%)]\tLoss: 0.023443\n",
            "Train Epoch: 80 [9728/14860 (65%)]\tLoss: 0.018238\n",
            "Train Epoch: 80 [9856/14860 (66%)]\tLoss: 0.020542\n",
            "Train Epoch: 80 [9984/14860 (67%)]\tLoss: 0.017929\n",
            "Train Epoch: 80 [10112/14860 (68%)]\tLoss: 0.020162\n",
            "Train Epoch: 80 [10240/14860 (68%)]\tLoss: 0.016071\n",
            "Train Epoch: 80 [10368/14860 (69%)]\tLoss: 0.012650\n",
            "Train Epoch: 80 [10496/14860 (70%)]\tLoss: 0.019278\n",
            "Train Epoch: 80 [10624/14860 (71%)]\tLoss: 0.012461\n",
            "Train Epoch: 80 [10752/14860 (72%)]\tLoss: 0.018779\n",
            "Train Epoch: 80 [10880/14860 (73%)]\tLoss: 0.026274\n",
            "Train Epoch: 80 [11008/14860 (74%)]\tLoss: 0.019365\n",
            "Train Epoch: 80 [11136/14860 (74%)]\tLoss: 0.021247\n",
            "Train Epoch: 80 [11264/14860 (75%)]\tLoss: 0.020842\n",
            "Train Epoch: 80 [11392/14860 (76%)]\tLoss: 0.017174\n",
            "Train Epoch: 80 [11520/14860 (77%)]\tLoss: 0.022195\n",
            "Train Epoch: 80 [11648/14860 (78%)]\tLoss: 0.017215\n",
            "Train Epoch: 80 [11776/14860 (79%)]\tLoss: 0.028353\n",
            "Train Epoch: 80 [11904/14860 (79%)]\tLoss: 0.015916\n",
            "Train Epoch: 80 [12032/14860 (80%)]\tLoss: 0.015737\n",
            "Train Epoch: 80 [12160/14860 (81%)]\tLoss: 0.021850\n",
            "Train Epoch: 80 [12288/14860 (82%)]\tLoss: 0.022137\n",
            "Train Epoch: 80 [12416/14860 (83%)]\tLoss: 0.018442\n",
            "Train Epoch: 80 [12544/14860 (84%)]\tLoss: 0.015948\n",
            "Train Epoch: 80 [12672/14860 (85%)]\tLoss: 0.016843\n",
            "Train Epoch: 80 [12800/14860 (85%)]\tLoss: 0.021218\n",
            "Train Epoch: 80 [12928/14860 (86%)]\tLoss: 0.015282\n",
            "Train Epoch: 80 [13056/14860 (87%)]\tLoss: 0.014696\n",
            "Train Epoch: 80 [13184/14860 (88%)]\tLoss: 0.020887\n",
            "Train Epoch: 80 [13312/14860 (89%)]\tLoss: 0.023258\n",
            "Train Epoch: 80 [13440/14860 (90%)]\tLoss: 0.021386\n",
            "Train Epoch: 80 [13568/14860 (91%)]\tLoss: 0.021895\n",
            "Train Epoch: 80 [13696/14860 (91%)]\tLoss: 0.023858\n",
            "Train Epoch: 80 [13824/14860 (92%)]\tLoss: 0.020308\n",
            "Train Epoch: 80 [13952/14860 (93%)]\tLoss: 0.016105\n",
            "Train Epoch: 80 [14080/14860 (94%)]\tLoss: 0.014293\n",
            "Train Epoch: 80 [14208/14860 (95%)]\tLoss: 0.019057\n",
            "Train Epoch: 80 [14336/14860 (96%)]\tLoss: 0.014576\n",
            "Train Epoch: 80 [14464/14860 (97%)]\tLoss: 0.020901\n",
            "Train Epoch: 80 [14592/14860 (97%)]\tLoss: 0.015815\n",
            "Train Epoch: 80 [14720/14860 (98%)]\tLoss: 0.022795\n",
            "Train Epoch: 80 [1392/14860 (99%)]\tLoss: 0.054671\n",
            "epoch 80 training loss: 0.019378393315351926\n",
            "epoch 80 validation loss: 0.02749447860094306\n",
            "Train Epoch: 81 [0/14860 (0%)]\tLoss: 0.024301\n",
            "Train Epoch: 81 [128/14860 (1%)]\tLoss: 0.023218\n",
            "Train Epoch: 81 [256/14860 (2%)]\tLoss: 0.021224\n",
            "Train Epoch: 81 [384/14860 (3%)]\tLoss: 0.020822\n",
            "Train Epoch: 81 [512/14860 (3%)]\tLoss: 0.018641\n",
            "Train Epoch: 81 [640/14860 (4%)]\tLoss: 0.021329\n",
            "Train Epoch: 81 [768/14860 (5%)]\tLoss: 0.025027\n",
            "Train Epoch: 81 [896/14860 (6%)]\tLoss: 0.015898\n",
            "Train Epoch: 81 [1024/14860 (7%)]\tLoss: 0.016055\n",
            "Train Epoch: 81 [1152/14860 (8%)]\tLoss: 0.028904\n",
            "Train Epoch: 81 [1280/14860 (9%)]\tLoss: 0.018674\n",
            "Train Epoch: 81 [1408/14860 (9%)]\tLoss: 0.014232\n",
            "Train Epoch: 81 [1536/14860 (10%)]\tLoss: 0.021330\n",
            "Train Epoch: 81 [1664/14860 (11%)]\tLoss: 0.016049\n",
            "Train Epoch: 81 [1792/14860 (12%)]\tLoss: 0.015662\n",
            "Train Epoch: 81 [1920/14860 (13%)]\tLoss: 0.026044\n",
            "Train Epoch: 81 [2048/14860 (14%)]\tLoss: 0.019327\n",
            "Train Epoch: 81 [2176/14860 (15%)]\tLoss: 0.018352\n",
            "Train Epoch: 81 [2304/14860 (15%)]\tLoss: 0.015542\n",
            "Train Epoch: 81 [2432/14860 (16%)]\tLoss: 0.016424\n",
            "Train Epoch: 81 [2560/14860 (17%)]\tLoss: 0.015613\n",
            "Train Epoch: 81 [2688/14860 (18%)]\tLoss: 0.013540\n",
            "Train Epoch: 81 [2816/14860 (19%)]\tLoss: 0.013975\n",
            "Train Epoch: 81 [2944/14860 (20%)]\tLoss: 0.016885\n",
            "Train Epoch: 81 [3072/14860 (21%)]\tLoss: 0.013611\n",
            "Train Epoch: 81 [3200/14860 (21%)]\tLoss: 0.015454\n",
            "Train Epoch: 81 [3328/14860 (22%)]\tLoss: 0.019353\n",
            "Train Epoch: 81 [3456/14860 (23%)]\tLoss: 0.019433\n",
            "Train Epoch: 81 [3584/14860 (24%)]\tLoss: 0.017667\n",
            "Train Epoch: 81 [3712/14860 (25%)]\tLoss: 0.023699\n",
            "Train Epoch: 81 [3840/14860 (26%)]\tLoss: 0.013747\n",
            "Train Epoch: 81 [3968/14860 (26%)]\tLoss: 0.016568\n",
            "Train Epoch: 81 [4096/14860 (27%)]\tLoss: 0.021868\n",
            "Train Epoch: 81 [4224/14860 (28%)]\tLoss: 0.018593\n",
            "Train Epoch: 81 [4352/14860 (29%)]\tLoss: 0.020594\n",
            "Train Epoch: 81 [4480/14860 (30%)]\tLoss: 0.020447\n",
            "Train Epoch: 81 [4608/14860 (31%)]\tLoss: 0.028027\n",
            "Train Epoch: 81 [4736/14860 (32%)]\tLoss: 0.018165\n",
            "Train Epoch: 81 [4864/14860 (32%)]\tLoss: 0.029664\n",
            "Train Epoch: 81 [4992/14860 (33%)]\tLoss: 0.020458\n",
            "Train Epoch: 81 [5120/14860 (34%)]\tLoss: 0.021149\n",
            "Train Epoch: 81 [5248/14860 (35%)]\tLoss: 0.015965\n",
            "Train Epoch: 81 [5376/14860 (36%)]\tLoss: 0.020068\n",
            "Train Epoch: 81 [5504/14860 (37%)]\tLoss: 0.019377\n",
            "Train Epoch: 81 [5632/14860 (38%)]\tLoss: 0.025417\n",
            "Train Epoch: 81 [5760/14860 (38%)]\tLoss: 0.021100\n",
            "Train Epoch: 81 [5888/14860 (39%)]\tLoss: 0.016198\n",
            "Train Epoch: 81 [6016/14860 (40%)]\tLoss: 0.029390\n",
            "Train Epoch: 81 [6144/14860 (41%)]\tLoss: 0.018019\n",
            "Train Epoch: 81 [6272/14860 (42%)]\tLoss: 0.023591\n",
            "Train Epoch: 81 [6400/14860 (43%)]\tLoss: 0.019847\n",
            "Train Epoch: 81 [6528/14860 (44%)]\tLoss: 0.015698\n",
            "Train Epoch: 81 [6656/14860 (44%)]\tLoss: 0.019793\n",
            "Train Epoch: 81 [6784/14860 (45%)]\tLoss: 0.019912\n",
            "Train Epoch: 81 [6912/14860 (46%)]\tLoss: 0.014430\n",
            "Train Epoch: 81 [7040/14860 (47%)]\tLoss: 0.025570\n",
            "Train Epoch: 81 [7168/14860 (48%)]\tLoss: 0.023191\n",
            "Train Epoch: 81 [7296/14860 (49%)]\tLoss: 0.019875\n",
            "Train Epoch: 81 [7424/14860 (50%)]\tLoss: 0.016574\n",
            "Train Epoch: 81 [7552/14860 (50%)]\tLoss: 0.026572\n",
            "Train Epoch: 81 [7680/14860 (51%)]\tLoss: 0.031591\n",
            "Train Epoch: 81 [7808/14860 (52%)]\tLoss: 0.011630\n",
            "Train Epoch: 81 [7936/14860 (53%)]\tLoss: 0.021729\n",
            "Train Epoch: 81 [8064/14860 (54%)]\tLoss: 0.015641\n",
            "Train Epoch: 81 [8192/14860 (55%)]\tLoss: 0.016256\n",
            "Train Epoch: 81 [8320/14860 (56%)]\tLoss: 0.015717\n",
            "Train Epoch: 81 [8448/14860 (56%)]\tLoss: 0.022001\n",
            "Train Epoch: 81 [8576/14860 (57%)]\tLoss: 0.023980\n",
            "Train Epoch: 81 [8704/14860 (58%)]\tLoss: 0.014620\n",
            "Train Epoch: 81 [8832/14860 (59%)]\tLoss: 0.019925\n",
            "Train Epoch: 81 [8960/14860 (60%)]\tLoss: 0.015964\n",
            "Train Epoch: 81 [9088/14860 (61%)]\tLoss: 0.024014\n",
            "Train Epoch: 81 [9216/14860 (62%)]\tLoss: 0.015908\n",
            "Train Epoch: 81 [9344/14860 (62%)]\tLoss: 0.023475\n",
            "Train Epoch: 81 [9472/14860 (63%)]\tLoss: 0.018476\n",
            "Train Epoch: 81 [9600/14860 (64%)]\tLoss: 0.018240\n",
            "Train Epoch: 81 [9728/14860 (65%)]\tLoss: 0.020067\n",
            "Train Epoch: 81 [9856/14860 (66%)]\tLoss: 0.024413\n",
            "Train Epoch: 81 [9984/14860 (67%)]\tLoss: 0.021644\n",
            "Train Epoch: 81 [10112/14860 (68%)]\tLoss: 0.016476\n",
            "Train Epoch: 81 [10240/14860 (68%)]\tLoss: 0.020217\n",
            "Train Epoch: 81 [10368/14860 (69%)]\tLoss: 0.018279\n",
            "Train Epoch: 81 [10496/14860 (70%)]\tLoss: 0.021798\n",
            "Train Epoch: 81 [10624/14860 (71%)]\tLoss: 0.017853\n",
            "Train Epoch: 81 [10752/14860 (72%)]\tLoss: 0.015642\n",
            "Train Epoch: 81 [10880/14860 (73%)]\tLoss: 0.023117\n",
            "Train Epoch: 81 [11008/14860 (74%)]\tLoss: 0.014891\n",
            "Train Epoch: 81 [11136/14860 (74%)]\tLoss: 0.017037\n",
            "Train Epoch: 81 [11264/14860 (75%)]\tLoss: 0.026680\n",
            "Train Epoch: 81 [11392/14860 (76%)]\tLoss: 0.013868\n",
            "Train Epoch: 81 [11520/14860 (77%)]\tLoss: 0.018908\n",
            "Train Epoch: 81 [11648/14860 (78%)]\tLoss: 0.020268\n",
            "Train Epoch: 81 [11776/14860 (79%)]\tLoss: 0.019322\n",
            "Train Epoch: 81 [11904/14860 (79%)]\tLoss: 0.017206\n",
            "Train Epoch: 81 [12032/14860 (80%)]\tLoss: 0.017937\n",
            "Train Epoch: 81 [12160/14860 (81%)]\tLoss: 0.016982\n",
            "Train Epoch: 81 [12288/14860 (82%)]\tLoss: 0.024506\n",
            "Train Epoch: 81 [12416/14860 (83%)]\tLoss: 0.015162\n",
            "Train Epoch: 81 [12544/14860 (84%)]\tLoss: 0.016086\n",
            "Train Epoch: 81 [12672/14860 (85%)]\tLoss: 0.013341\n",
            "Train Epoch: 81 [12800/14860 (85%)]\tLoss: 0.017741\n",
            "Train Epoch: 81 [12928/14860 (86%)]\tLoss: 0.018394\n",
            "Train Epoch: 81 [13056/14860 (87%)]\tLoss: 0.023427\n",
            "Train Epoch: 81 [13184/14860 (88%)]\tLoss: 0.023861\n",
            "Train Epoch: 81 [13312/14860 (89%)]\tLoss: 0.021079\n",
            "Train Epoch: 81 [13440/14860 (90%)]\tLoss: 0.016052\n",
            "Train Epoch: 81 [13568/14860 (91%)]\tLoss: 0.016101\n",
            "Train Epoch: 81 [13696/14860 (91%)]\tLoss: 0.024335\n",
            "Train Epoch: 81 [13824/14860 (92%)]\tLoss: 0.014240\n",
            "Train Epoch: 81 [13952/14860 (93%)]\tLoss: 0.022104\n",
            "Train Epoch: 81 [14080/14860 (94%)]\tLoss: 0.018766\n",
            "Train Epoch: 81 [14208/14860 (95%)]\tLoss: 0.018103\n",
            "Train Epoch: 81 [14336/14860 (96%)]\tLoss: 0.018425\n",
            "Train Epoch: 81 [14464/14860 (97%)]\tLoss: 0.019684\n",
            "Train Epoch: 81 [14592/14860 (97%)]\tLoss: 0.025388\n",
            "Train Epoch: 81 [14720/14860 (98%)]\tLoss: 0.015591\n",
            "Train Epoch: 81 [1392/14860 (99%)]\tLoss: 0.006562\n",
            "epoch 81 training loss: 0.019374966060217373\n",
            "epoch 81 validation loss: 0.020071462770928482\n",
            "Train Epoch: 82 [0/14860 (0%)]\tLoss: 0.020573\n",
            "Train Epoch: 82 [128/14860 (1%)]\tLoss: 0.019781\n",
            "Train Epoch: 82 [256/14860 (2%)]\tLoss: 0.020854\n",
            "Train Epoch: 82 [384/14860 (3%)]\tLoss: 0.018217\n",
            "Train Epoch: 82 [512/14860 (3%)]\tLoss: 0.027431\n",
            "Train Epoch: 82 [640/14860 (4%)]\tLoss: 0.016491\n",
            "Train Epoch: 82 [768/14860 (5%)]\tLoss: 0.019381\n",
            "Train Epoch: 82 [896/14860 (6%)]\tLoss: 0.021724\n",
            "Train Epoch: 82 [1024/14860 (7%)]\tLoss: 0.019136\n",
            "Train Epoch: 82 [1152/14860 (8%)]\tLoss: 0.014662\n",
            "Train Epoch: 82 [1280/14860 (9%)]\tLoss: 0.019007\n",
            "Train Epoch: 82 [1408/14860 (9%)]\tLoss: 0.022265\n",
            "Train Epoch: 82 [1536/14860 (10%)]\tLoss: 0.022967\n",
            "Train Epoch: 82 [1664/14860 (11%)]\tLoss: 0.020219\n",
            "Train Epoch: 82 [1792/14860 (12%)]\tLoss: 0.019616\n",
            "Train Epoch: 82 [1920/14860 (13%)]\tLoss: 0.019042\n",
            "Train Epoch: 82 [2048/14860 (14%)]\tLoss: 0.018748\n",
            "Train Epoch: 82 [2176/14860 (15%)]\tLoss: 0.016284\n",
            "Train Epoch: 82 [2304/14860 (15%)]\tLoss: 0.020241\n",
            "Train Epoch: 82 [2432/14860 (16%)]\tLoss: 0.018880\n",
            "Train Epoch: 82 [2560/14860 (17%)]\tLoss: 0.024261\n",
            "Train Epoch: 82 [2688/14860 (18%)]\tLoss: 0.020788\n",
            "Train Epoch: 82 [2816/14860 (19%)]\tLoss: 0.021333\n",
            "Train Epoch: 82 [2944/14860 (20%)]\tLoss: 0.023619\n",
            "Train Epoch: 82 [3072/14860 (21%)]\tLoss: 0.013884\n",
            "Train Epoch: 82 [3200/14860 (21%)]\tLoss: 0.020308\n",
            "Train Epoch: 82 [3328/14860 (22%)]\tLoss: 0.019935\n",
            "Train Epoch: 82 [3456/14860 (23%)]\tLoss: 0.017693\n",
            "Train Epoch: 82 [3584/14860 (24%)]\tLoss: 0.033130\n",
            "Train Epoch: 82 [3712/14860 (25%)]\tLoss: 0.024647\n",
            "Train Epoch: 82 [3840/14860 (26%)]\tLoss: 0.020471\n",
            "Train Epoch: 82 [3968/14860 (26%)]\tLoss: 0.011450\n",
            "Train Epoch: 82 [4096/14860 (27%)]\tLoss: 0.018883\n",
            "Train Epoch: 82 [4224/14860 (28%)]\tLoss: 0.016225\n",
            "Train Epoch: 82 [4352/14860 (29%)]\tLoss: 0.025018\n",
            "Train Epoch: 82 [4480/14860 (30%)]\tLoss: 0.016678\n",
            "Train Epoch: 82 [4608/14860 (31%)]\tLoss: 0.021076\n",
            "Train Epoch: 82 [4736/14860 (32%)]\tLoss: 0.017606\n",
            "Train Epoch: 82 [4864/14860 (32%)]\tLoss: 0.017277\n",
            "Train Epoch: 82 [4992/14860 (33%)]\tLoss: 0.019242\n",
            "Train Epoch: 82 [5120/14860 (34%)]\tLoss: 0.014610\n",
            "Train Epoch: 82 [5248/14860 (35%)]\tLoss: 0.015507\n",
            "Train Epoch: 82 [5376/14860 (36%)]\tLoss: 0.012294\n",
            "Train Epoch: 82 [5504/14860 (37%)]\tLoss: 0.013441\n",
            "Train Epoch: 82 [5632/14860 (38%)]\tLoss: 0.021062\n",
            "Train Epoch: 82 [5760/14860 (38%)]\tLoss: 0.020519\n",
            "Train Epoch: 82 [5888/14860 (39%)]\tLoss: 0.022206\n",
            "Train Epoch: 82 [6016/14860 (40%)]\tLoss: 0.021009\n",
            "Train Epoch: 82 [6144/14860 (41%)]\tLoss: 0.013498\n",
            "Train Epoch: 82 [6272/14860 (42%)]\tLoss: 0.017904\n",
            "Train Epoch: 82 [6400/14860 (43%)]\tLoss: 0.017601\n",
            "Train Epoch: 82 [6528/14860 (44%)]\tLoss: 0.020484\n",
            "Train Epoch: 82 [6656/14860 (44%)]\tLoss: 0.019957\n",
            "Train Epoch: 82 [6784/14860 (45%)]\tLoss: 0.023918\n",
            "Train Epoch: 82 [6912/14860 (46%)]\tLoss: 0.022943\n",
            "Train Epoch: 82 [7040/14860 (47%)]\tLoss: 0.019073\n",
            "Train Epoch: 82 [7168/14860 (48%)]\tLoss: 0.027834\n",
            "Train Epoch: 82 [7296/14860 (49%)]\tLoss: 0.020159\n",
            "Train Epoch: 82 [7424/14860 (50%)]\tLoss: 0.019507\n",
            "Train Epoch: 82 [7552/14860 (50%)]\tLoss: 0.019958\n",
            "Train Epoch: 82 [7680/14860 (51%)]\tLoss: 0.023621\n",
            "Train Epoch: 82 [7808/14860 (52%)]\tLoss: 0.023656\n",
            "Train Epoch: 82 [7936/14860 (53%)]\tLoss: 0.022126\n",
            "Train Epoch: 82 [8064/14860 (54%)]\tLoss: 0.027245\n",
            "Train Epoch: 82 [8192/14860 (55%)]\tLoss: 0.020965\n",
            "Train Epoch: 82 [8320/14860 (56%)]\tLoss: 0.028398\n",
            "Train Epoch: 82 [8448/14860 (56%)]\tLoss: 0.024819\n",
            "Train Epoch: 82 [8576/14860 (57%)]\tLoss: 0.015712\n",
            "Train Epoch: 82 [8704/14860 (58%)]\tLoss: 0.019261\n",
            "Train Epoch: 82 [8832/14860 (59%)]\tLoss: 0.022241\n",
            "Train Epoch: 82 [8960/14860 (60%)]\tLoss: 0.016525\n",
            "Train Epoch: 82 [9088/14860 (61%)]\tLoss: 0.016488\n",
            "Train Epoch: 82 [9216/14860 (62%)]\tLoss: 0.038645\n",
            "Train Epoch: 82 [9344/14860 (62%)]\tLoss: 0.017190\n",
            "Train Epoch: 82 [9472/14860 (63%)]\tLoss: 0.021224\n",
            "Train Epoch: 82 [9600/14860 (64%)]\tLoss: 0.022113\n",
            "Train Epoch: 82 [9728/14860 (65%)]\tLoss: 0.018653\n",
            "Train Epoch: 82 [9856/14860 (66%)]\tLoss: 0.026343\n",
            "Train Epoch: 82 [9984/14860 (67%)]\tLoss: 0.024513\n",
            "Train Epoch: 82 [10112/14860 (68%)]\tLoss: 0.014841\n",
            "Train Epoch: 82 [10240/14860 (68%)]\tLoss: 0.013908\n",
            "Train Epoch: 82 [10368/14860 (69%)]\tLoss: 0.025546\n",
            "Train Epoch: 82 [10496/14860 (70%)]\tLoss: 0.020481\n",
            "Train Epoch: 82 [10624/14860 (71%)]\tLoss: 0.020220\n",
            "Train Epoch: 82 [10752/14860 (72%)]\tLoss: 0.016547\n",
            "Train Epoch: 82 [10880/14860 (73%)]\tLoss: 0.019213\n",
            "Train Epoch: 82 [11008/14860 (74%)]\tLoss: 0.017742\n",
            "Train Epoch: 82 [11136/14860 (74%)]\tLoss: 0.016412\n",
            "Train Epoch: 82 [11264/14860 (75%)]\tLoss: 0.019011\n",
            "Train Epoch: 82 [11392/14860 (76%)]\tLoss: 0.016853\n",
            "Train Epoch: 82 [11520/14860 (77%)]\tLoss: 0.010438\n",
            "Train Epoch: 82 [11648/14860 (78%)]\tLoss: 0.018401\n",
            "Train Epoch: 82 [11776/14860 (79%)]\tLoss: 0.014072\n",
            "Train Epoch: 82 [11904/14860 (79%)]\tLoss: 0.012647\n",
            "Train Epoch: 82 [12032/14860 (80%)]\tLoss: 0.013092\n",
            "Train Epoch: 82 [12160/14860 (81%)]\tLoss: 0.018322\n",
            "Train Epoch: 82 [12288/14860 (82%)]\tLoss: 0.021141\n",
            "Train Epoch: 82 [12416/14860 (83%)]\tLoss: 0.012492\n",
            "Train Epoch: 82 [12544/14860 (84%)]\tLoss: 0.018433\n",
            "Train Epoch: 82 [12672/14860 (85%)]\tLoss: 0.019468\n",
            "Train Epoch: 82 [12800/14860 (85%)]\tLoss: 0.015875\n",
            "Train Epoch: 82 [12928/14860 (86%)]\tLoss: 0.013400\n",
            "Train Epoch: 82 [13056/14860 (87%)]\tLoss: 0.024102\n",
            "Train Epoch: 82 [13184/14860 (88%)]\tLoss: 0.017480\n",
            "Train Epoch: 82 [13312/14860 (89%)]\tLoss: 0.031500\n",
            "Train Epoch: 82 [13440/14860 (90%)]\tLoss: 0.018166\n",
            "Train Epoch: 82 [13568/14860 (91%)]\tLoss: 0.021071\n",
            "Train Epoch: 82 [13696/14860 (91%)]\tLoss: 0.019845\n",
            "Train Epoch: 82 [13824/14860 (92%)]\tLoss: 0.017433\n",
            "Train Epoch: 82 [13952/14860 (93%)]\tLoss: 0.017145\n",
            "Train Epoch: 82 [14080/14860 (94%)]\tLoss: 0.022942\n",
            "Train Epoch: 82 [14208/14860 (95%)]\tLoss: 0.016915\n",
            "Train Epoch: 82 [14336/14860 (96%)]\tLoss: 0.020307\n",
            "Train Epoch: 82 [14464/14860 (97%)]\tLoss: 0.018163\n",
            "Train Epoch: 82 [14592/14860 (97%)]\tLoss: 0.014438\n",
            "Train Epoch: 82 [14720/14860 (98%)]\tLoss: 0.019593\n",
            "Train Epoch: 82 [1392/14860 (99%)]\tLoss: 0.031103\n",
            "epoch 82 training loss: 0.019752338488833007\n",
            "epoch 82 validation loss: 0.019985678986833403\n",
            "Train Epoch: 83 [0/14860 (0%)]\tLoss: 0.021085\n",
            "Train Epoch: 83 [128/14860 (1%)]\tLoss: 0.010659\n",
            "Train Epoch: 83 [256/14860 (2%)]\tLoss: 0.012238\n",
            "Train Epoch: 83 [384/14860 (3%)]\tLoss: 0.023333\n",
            "Train Epoch: 83 [512/14860 (3%)]\tLoss: 0.016969\n",
            "Train Epoch: 83 [640/14860 (4%)]\tLoss: 0.017190\n",
            "Train Epoch: 83 [768/14860 (5%)]\tLoss: 0.021116\n",
            "Train Epoch: 83 [896/14860 (6%)]\tLoss: 0.025036\n",
            "Train Epoch: 83 [1024/14860 (7%)]\tLoss: 0.022400\n",
            "Train Epoch: 83 [1152/14860 (8%)]\tLoss: 0.022473\n",
            "Train Epoch: 83 [1280/14860 (9%)]\tLoss: 0.016781\n",
            "Train Epoch: 83 [1408/14860 (9%)]\tLoss: 0.024707\n",
            "Train Epoch: 83 [1536/14860 (10%)]\tLoss: 0.016131\n",
            "Train Epoch: 83 [1664/14860 (11%)]\tLoss: 0.013773\n",
            "Train Epoch: 83 [1792/14860 (12%)]\tLoss: 0.011616\n",
            "Train Epoch: 83 [1920/14860 (13%)]\tLoss: 0.020551\n",
            "Train Epoch: 83 [2048/14860 (14%)]\tLoss: 0.019717\n",
            "Train Epoch: 83 [2176/14860 (15%)]\tLoss: 0.019077\n",
            "Train Epoch: 83 [2304/14860 (15%)]\tLoss: 0.018361\n",
            "Train Epoch: 83 [2432/14860 (16%)]\tLoss: 0.017628\n",
            "Train Epoch: 83 [2560/14860 (17%)]\tLoss: 0.021926\n",
            "Train Epoch: 83 [2688/14860 (18%)]\tLoss: 0.024058\n",
            "Train Epoch: 83 [2816/14860 (19%)]\tLoss: 0.015426\n",
            "Train Epoch: 83 [2944/14860 (20%)]\tLoss: 0.018779\n",
            "Train Epoch: 83 [3072/14860 (21%)]\tLoss: 0.017715\n",
            "Train Epoch: 83 [3200/14860 (21%)]\tLoss: 0.020524\n",
            "Train Epoch: 83 [3328/14860 (22%)]\tLoss: 0.014176\n",
            "Train Epoch: 83 [3456/14860 (23%)]\tLoss: 0.015910\n",
            "Train Epoch: 83 [3584/14860 (24%)]\tLoss: 0.020068\n",
            "Train Epoch: 83 [3712/14860 (25%)]\tLoss: 0.018846\n",
            "Train Epoch: 83 [3840/14860 (26%)]\tLoss: 0.016597\n",
            "Train Epoch: 83 [3968/14860 (26%)]\tLoss: 0.015020\n",
            "Train Epoch: 83 [4096/14860 (27%)]\tLoss: 0.018984\n",
            "Train Epoch: 83 [4224/14860 (28%)]\tLoss: 0.015112\n",
            "Train Epoch: 83 [4352/14860 (29%)]\tLoss: 0.017122\n",
            "Train Epoch: 83 [4480/14860 (30%)]\tLoss: 0.017073\n",
            "Train Epoch: 83 [4608/14860 (31%)]\tLoss: 0.024561\n",
            "Train Epoch: 83 [4736/14860 (32%)]\tLoss: 0.020347\n",
            "Train Epoch: 83 [4864/14860 (32%)]\tLoss: 0.020189\n",
            "Train Epoch: 83 [4992/14860 (33%)]\tLoss: 0.014688\n",
            "Train Epoch: 83 [5120/14860 (34%)]\tLoss: 0.016132\n",
            "Train Epoch: 83 [5248/14860 (35%)]\tLoss: 0.020499\n",
            "Train Epoch: 83 [5376/14860 (36%)]\tLoss: 0.018008\n",
            "Train Epoch: 83 [5504/14860 (37%)]\tLoss: 0.019821\n",
            "Train Epoch: 83 [5632/14860 (38%)]\tLoss: 0.017240\n",
            "Train Epoch: 83 [5760/14860 (38%)]\tLoss: 0.017044\n",
            "Train Epoch: 83 [5888/14860 (39%)]\tLoss: 0.017569\n",
            "Train Epoch: 83 [6016/14860 (40%)]\tLoss: 0.018975\n",
            "Train Epoch: 83 [6144/14860 (41%)]\tLoss: 0.018791\n",
            "Train Epoch: 83 [6272/14860 (42%)]\tLoss: 0.013500\n",
            "Train Epoch: 83 [6400/14860 (43%)]\tLoss: 0.024644\n",
            "Train Epoch: 83 [6528/14860 (44%)]\tLoss: 0.024154\n",
            "Train Epoch: 83 [6656/14860 (44%)]\tLoss: 0.022077\n",
            "Train Epoch: 83 [6784/14860 (45%)]\tLoss: 0.019815\n",
            "Train Epoch: 83 [6912/14860 (46%)]\tLoss: 0.022126\n",
            "Train Epoch: 83 [7040/14860 (47%)]\tLoss: 0.027250\n",
            "Train Epoch: 83 [7168/14860 (48%)]\tLoss: 0.014059\n",
            "Train Epoch: 83 [7296/14860 (49%)]\tLoss: 0.026512\n",
            "Train Epoch: 83 [7424/14860 (50%)]\tLoss: 0.017141\n",
            "Train Epoch: 83 [7552/14860 (50%)]\tLoss: 0.015900\n",
            "Train Epoch: 83 [7680/14860 (51%)]\tLoss: 0.020592\n",
            "Train Epoch: 83 [7808/14860 (52%)]\tLoss: 0.023620\n",
            "Train Epoch: 83 [7936/14860 (53%)]\tLoss: 0.018939\n",
            "Train Epoch: 83 [8064/14860 (54%)]\tLoss: 0.015048\n",
            "Train Epoch: 83 [8192/14860 (55%)]\tLoss: 0.019523\n",
            "Train Epoch: 83 [8320/14860 (56%)]\tLoss: 0.015536\n",
            "Train Epoch: 83 [8448/14860 (56%)]\tLoss: 0.017887\n",
            "Train Epoch: 83 [8576/14860 (57%)]\tLoss: 0.018553\n",
            "Train Epoch: 83 [8704/14860 (58%)]\tLoss: 0.015967\n",
            "Train Epoch: 83 [8832/14860 (59%)]\tLoss: 0.018803\n",
            "Train Epoch: 83 [8960/14860 (60%)]\tLoss: 0.022139\n",
            "Train Epoch: 83 [9088/14860 (61%)]\tLoss: 0.013868\n",
            "Train Epoch: 83 [9216/14860 (62%)]\tLoss: 0.016338\n",
            "Train Epoch: 83 [9344/14860 (62%)]\tLoss: 0.017192\n",
            "Train Epoch: 83 [9472/14860 (63%)]\tLoss: 0.022821\n",
            "Train Epoch: 83 [9600/14860 (64%)]\tLoss: 0.021198\n",
            "Train Epoch: 83 [9728/14860 (65%)]\tLoss: 0.025305\n",
            "Train Epoch: 83 [9856/14860 (66%)]\tLoss: 0.019119\n",
            "Train Epoch: 83 [9984/14860 (67%)]\tLoss: 0.023409\n",
            "Train Epoch: 83 [10112/14860 (68%)]\tLoss: 0.028479\n",
            "Train Epoch: 83 [10240/14860 (68%)]\tLoss: 0.032734\n",
            "Train Epoch: 83 [10368/14860 (69%)]\tLoss: 0.015361\n",
            "Train Epoch: 83 [10496/14860 (70%)]\tLoss: 0.017330\n",
            "Train Epoch: 83 [10624/14860 (71%)]\tLoss: 0.020827\n",
            "Train Epoch: 83 [10752/14860 (72%)]\tLoss: 0.021032\n",
            "Train Epoch: 83 [10880/14860 (73%)]\tLoss: 0.020330\n",
            "Train Epoch: 83 [11008/14860 (74%)]\tLoss: 0.014589\n",
            "Train Epoch: 83 [11136/14860 (74%)]\tLoss: 0.024467\n",
            "Train Epoch: 83 [11264/14860 (75%)]\tLoss: 0.022073\n",
            "Train Epoch: 83 [11392/14860 (76%)]\tLoss: 0.012794\n",
            "Train Epoch: 83 [11520/14860 (77%)]\tLoss: 0.021757\n",
            "Train Epoch: 83 [11648/14860 (78%)]\tLoss: 0.022220\n",
            "Train Epoch: 83 [11776/14860 (79%)]\tLoss: 0.027538\n",
            "Train Epoch: 83 [11904/14860 (79%)]\tLoss: 0.020673\n",
            "Train Epoch: 83 [12032/14860 (80%)]\tLoss: 0.017866\n",
            "Train Epoch: 83 [12160/14860 (81%)]\tLoss: 0.021440\n",
            "Train Epoch: 83 [12288/14860 (82%)]\tLoss: 0.019370\n",
            "Train Epoch: 83 [12416/14860 (83%)]\tLoss: 0.018199\n",
            "Train Epoch: 83 [12544/14860 (84%)]\tLoss: 0.020072\n",
            "Train Epoch: 83 [12672/14860 (85%)]\tLoss: 0.028303\n",
            "Train Epoch: 83 [12800/14860 (85%)]\tLoss: 0.023829\n",
            "Train Epoch: 83 [12928/14860 (86%)]\tLoss: 0.020435\n",
            "Train Epoch: 83 [13056/14860 (87%)]\tLoss: 0.022070\n",
            "Train Epoch: 83 [13184/14860 (88%)]\tLoss: 0.022920\n",
            "Train Epoch: 83 [13312/14860 (89%)]\tLoss: 0.019037\n",
            "Train Epoch: 83 [13440/14860 (90%)]\tLoss: 0.024386\n",
            "Train Epoch: 83 [13568/14860 (91%)]\tLoss: 0.017968\n",
            "Train Epoch: 83 [13696/14860 (91%)]\tLoss: 0.020471\n",
            "Train Epoch: 83 [13824/14860 (92%)]\tLoss: 0.019600\n",
            "Train Epoch: 83 [13952/14860 (93%)]\tLoss: 0.023507\n",
            "Train Epoch: 83 [14080/14860 (94%)]\tLoss: 0.021275\n",
            "Train Epoch: 83 [14208/14860 (95%)]\tLoss: 0.020133\n",
            "Train Epoch: 83 [14336/14860 (96%)]\tLoss: 0.022145\n",
            "Train Epoch: 83 [14464/14860 (97%)]\tLoss: 0.020912\n",
            "Train Epoch: 83 [14592/14860 (97%)]\tLoss: 0.017457\n",
            "Train Epoch: 83 [14720/14860 (98%)]\tLoss: 0.027037\n",
            "Train Epoch: 83 [1392/14860 (99%)]\tLoss: 0.040270\n",
            "epoch 83 training loss: 0.019880225093891986\n",
            "epoch 83 validation loss: 0.024709160478005397\n",
            "Train Epoch: 84 [0/14860 (0%)]\tLoss: 0.023856\n",
            "Train Epoch: 84 [128/14860 (1%)]\tLoss: 0.024948\n",
            "Train Epoch: 84 [256/14860 (2%)]\tLoss: 0.018362\n",
            "Train Epoch: 84 [384/14860 (3%)]\tLoss: 0.015312\n",
            "Train Epoch: 84 [512/14860 (3%)]\tLoss: 0.015720\n",
            "Train Epoch: 84 [640/14860 (4%)]\tLoss: 0.027916\n",
            "Train Epoch: 84 [768/14860 (5%)]\tLoss: 0.022965\n",
            "Train Epoch: 84 [896/14860 (6%)]\tLoss: 0.017158\n",
            "Train Epoch: 84 [1024/14860 (7%)]\tLoss: 0.021566\n",
            "Train Epoch: 84 [1152/14860 (8%)]\tLoss: 0.021256\n",
            "Train Epoch: 84 [1280/14860 (9%)]\tLoss: 0.013083\n",
            "Train Epoch: 84 [1408/14860 (9%)]\tLoss: 0.019771\n",
            "Train Epoch: 84 [1536/14860 (10%)]\tLoss: 0.021934\n",
            "Train Epoch: 84 [1664/14860 (11%)]\tLoss: 0.029371\n",
            "Train Epoch: 84 [1792/14860 (12%)]\tLoss: 0.019966\n",
            "Train Epoch: 84 [1920/14860 (13%)]\tLoss: 0.022550\n",
            "Train Epoch: 84 [2048/14860 (14%)]\tLoss: 0.021119\n",
            "Train Epoch: 84 [2176/14860 (15%)]\tLoss: 0.017439\n",
            "Train Epoch: 84 [2304/14860 (15%)]\tLoss: 0.017417\n",
            "Train Epoch: 84 [2432/14860 (16%)]\tLoss: 0.021263\n",
            "Train Epoch: 84 [2560/14860 (17%)]\tLoss: 0.023352\n",
            "Train Epoch: 84 [2688/14860 (18%)]\tLoss: 0.022377\n",
            "Train Epoch: 84 [2816/14860 (19%)]\tLoss: 0.016895\n",
            "Train Epoch: 84 [2944/14860 (20%)]\tLoss: 0.024916\n",
            "Train Epoch: 84 [3072/14860 (21%)]\tLoss: 0.020933\n",
            "Train Epoch: 84 [3200/14860 (21%)]\tLoss: 0.019036\n",
            "Train Epoch: 84 [3328/14860 (22%)]\tLoss: 0.014180\n",
            "Train Epoch: 84 [3456/14860 (23%)]\tLoss: 0.016831\n",
            "Train Epoch: 84 [3584/14860 (24%)]\tLoss: 0.019275\n",
            "Train Epoch: 84 [3712/14860 (25%)]\tLoss: 0.020556\n",
            "Train Epoch: 84 [3840/14860 (26%)]\tLoss: 0.022683\n",
            "Train Epoch: 84 [3968/14860 (26%)]\tLoss: 0.021732\n",
            "Train Epoch: 84 [4096/14860 (27%)]\tLoss: 0.024152\n",
            "Train Epoch: 84 [4224/14860 (28%)]\tLoss: 0.018139\n",
            "Train Epoch: 84 [4352/14860 (29%)]\tLoss: 0.019417\n",
            "Train Epoch: 84 [4480/14860 (30%)]\tLoss: 0.022454\n",
            "Train Epoch: 84 [4608/14860 (31%)]\tLoss: 0.015083\n",
            "Train Epoch: 84 [4736/14860 (32%)]\tLoss: 0.020549\n",
            "Train Epoch: 84 [4864/14860 (32%)]\tLoss: 0.019741\n",
            "Train Epoch: 84 [4992/14860 (33%)]\tLoss: 0.029038\n",
            "Train Epoch: 84 [5120/14860 (34%)]\tLoss: 0.016877\n",
            "Train Epoch: 84 [5248/14860 (35%)]\tLoss: 0.018507\n",
            "Train Epoch: 84 [5376/14860 (36%)]\tLoss: 0.019074\n",
            "Train Epoch: 84 [5504/14860 (37%)]\tLoss: 0.024390\n",
            "Train Epoch: 84 [5632/14860 (38%)]\tLoss: 0.020225\n",
            "Train Epoch: 84 [5760/14860 (38%)]\tLoss: 0.028136\n",
            "Train Epoch: 84 [5888/14860 (39%)]\tLoss: 0.028077\n",
            "Train Epoch: 84 [6016/14860 (40%)]\tLoss: 0.022091\n",
            "Train Epoch: 84 [6144/14860 (41%)]\tLoss: 0.019961\n",
            "Train Epoch: 84 [6272/14860 (42%)]\tLoss: 0.030956\n",
            "Train Epoch: 84 [6400/14860 (43%)]\tLoss: 0.037868\n",
            "Train Epoch: 84 [6528/14860 (44%)]\tLoss: 0.016516\n",
            "Train Epoch: 84 [6656/14860 (44%)]\tLoss: 0.017130\n",
            "Train Epoch: 84 [6784/14860 (45%)]\tLoss: 0.020747\n",
            "Train Epoch: 84 [6912/14860 (46%)]\tLoss: 0.020870\n",
            "Train Epoch: 84 [7040/14860 (47%)]\tLoss: 0.017924\n",
            "Train Epoch: 84 [7168/14860 (48%)]\tLoss: 0.021872\n",
            "Train Epoch: 84 [7296/14860 (49%)]\tLoss: 0.026596\n",
            "Train Epoch: 84 [7424/14860 (50%)]\tLoss: 0.017184\n",
            "Train Epoch: 84 [7552/14860 (50%)]\tLoss: 0.020621\n",
            "Train Epoch: 84 [7680/14860 (51%)]\tLoss: 0.025599\n",
            "Train Epoch: 84 [7808/14860 (52%)]\tLoss: 0.022160\n",
            "Train Epoch: 84 [7936/14860 (53%)]\tLoss: 0.016358\n",
            "Train Epoch: 84 [8064/14860 (54%)]\tLoss: 0.021813\n",
            "Train Epoch: 84 [8192/14860 (55%)]\tLoss: 0.018893\n",
            "Train Epoch: 84 [8320/14860 (56%)]\tLoss: 0.018475\n",
            "Train Epoch: 84 [8448/14860 (56%)]\tLoss: 0.020978\n",
            "Train Epoch: 84 [8576/14860 (57%)]\tLoss: 0.026465\n",
            "Train Epoch: 84 [8704/14860 (58%)]\tLoss: 0.018854\n",
            "Train Epoch: 84 [8832/14860 (59%)]\tLoss: 0.025702\n",
            "Train Epoch: 84 [8960/14860 (60%)]\tLoss: 0.021826\n",
            "Train Epoch: 84 [9088/14860 (61%)]\tLoss: 0.011157\n",
            "Train Epoch: 84 [9216/14860 (62%)]\tLoss: 0.020795\n",
            "Train Epoch: 84 [9344/14860 (62%)]\tLoss: 0.031990\n",
            "Train Epoch: 84 [9472/14860 (63%)]\tLoss: 0.018855\n",
            "Train Epoch: 84 [9600/14860 (64%)]\tLoss: 0.018116\n",
            "Train Epoch: 84 [9728/14860 (65%)]\tLoss: 0.022254\n",
            "Train Epoch: 84 [9856/14860 (66%)]\tLoss: 0.025687\n",
            "Train Epoch: 84 [9984/14860 (67%)]\tLoss: 0.029049\n",
            "Train Epoch: 84 [10112/14860 (68%)]\tLoss: 0.014621\n",
            "Train Epoch: 84 [10240/14860 (68%)]\tLoss: 0.029992\n",
            "Train Epoch: 84 [10368/14860 (69%)]\tLoss: 0.028654\n",
            "Train Epoch: 84 [10496/14860 (70%)]\tLoss: 0.023876\n",
            "Train Epoch: 84 [10624/14860 (71%)]\tLoss: 0.020174\n",
            "Train Epoch: 84 [10752/14860 (72%)]\tLoss: 0.024315\n",
            "Train Epoch: 84 [10880/14860 (73%)]\tLoss: 0.032167\n",
            "Train Epoch: 84 [11008/14860 (74%)]\tLoss: 0.024109\n",
            "Train Epoch: 84 [11136/14860 (74%)]\tLoss: 0.024680\n",
            "Train Epoch: 84 [11264/14860 (75%)]\tLoss: 0.020905\n",
            "Train Epoch: 84 [11392/14860 (76%)]\tLoss: 0.023856\n",
            "Train Epoch: 84 [11520/14860 (77%)]\tLoss: 0.018791\n",
            "Train Epoch: 84 [11648/14860 (78%)]\tLoss: 0.022144\n",
            "Train Epoch: 84 [11776/14860 (79%)]\tLoss: 0.021279\n",
            "Train Epoch: 84 [11904/14860 (79%)]\tLoss: 0.021908\n",
            "Train Epoch: 84 [12032/14860 (80%)]\tLoss: 0.024036\n",
            "Train Epoch: 84 [12160/14860 (81%)]\tLoss: 0.015504\n",
            "Train Epoch: 84 [12288/14860 (82%)]\tLoss: 0.016473\n",
            "Train Epoch: 84 [12416/14860 (83%)]\tLoss: 0.021707\n",
            "Train Epoch: 84 [12544/14860 (84%)]\tLoss: 0.025607\n",
            "Train Epoch: 84 [12672/14860 (85%)]\tLoss: 0.029652\n",
            "Train Epoch: 84 [12800/14860 (85%)]\tLoss: 0.022416\n",
            "Train Epoch: 84 [12928/14860 (86%)]\tLoss: 0.023297\n",
            "Train Epoch: 84 [13056/14860 (87%)]\tLoss: 0.021535\n",
            "Train Epoch: 84 [13184/14860 (88%)]\tLoss: 0.018305\n",
            "Train Epoch: 84 [13312/14860 (89%)]\tLoss: 0.013694\n",
            "Train Epoch: 84 [13440/14860 (90%)]\tLoss: 0.017262\n",
            "Train Epoch: 84 [13568/14860 (91%)]\tLoss: 0.015387\n",
            "Train Epoch: 84 [13696/14860 (91%)]\tLoss: 0.018814\n",
            "Train Epoch: 84 [13824/14860 (92%)]\tLoss: 0.023617\n",
            "Train Epoch: 84 [13952/14860 (93%)]\tLoss: 0.012622\n",
            "Train Epoch: 84 [14080/14860 (94%)]\tLoss: 0.018696\n",
            "Train Epoch: 84 [14208/14860 (95%)]\tLoss: 0.020920\n",
            "Train Epoch: 84 [14336/14860 (96%)]\tLoss: 0.021794\n",
            "Train Epoch: 84 [14464/14860 (97%)]\tLoss: 0.016763\n",
            "Train Epoch: 84 [14592/14860 (97%)]\tLoss: 0.016994\n",
            "Train Epoch: 84 [14720/14860 (98%)]\tLoss: 0.024864\n",
            "Train Epoch: 84 [1392/14860 (99%)]\tLoss: 0.006533\n",
            "epoch 84 training loss: 0.021221546607458185\n",
            "epoch 84 validation loss: 0.02029129292716703\n",
            "Train Epoch: 85 [0/14860 (0%)]\tLoss: 0.011674\n",
            "Train Epoch: 85 [128/14860 (1%)]\tLoss: 0.010999\n",
            "Train Epoch: 85 [256/14860 (2%)]\tLoss: 0.015725\n",
            "Train Epoch: 85 [384/14860 (3%)]\tLoss: 0.020140\n",
            "Train Epoch: 85 [512/14860 (3%)]\tLoss: 0.018461\n",
            "Train Epoch: 85 [640/14860 (4%)]\tLoss: 0.018821\n",
            "Train Epoch: 85 [768/14860 (5%)]\tLoss: 0.018214\n",
            "Train Epoch: 85 [896/14860 (6%)]\tLoss: 0.030159\n",
            "Train Epoch: 85 [1024/14860 (7%)]\tLoss: 0.015532\n",
            "Train Epoch: 85 [1152/14860 (8%)]\tLoss: 0.027590\n",
            "Train Epoch: 85 [1280/14860 (9%)]\tLoss: 0.015659\n",
            "Train Epoch: 85 [1408/14860 (9%)]\tLoss: 0.017399\n",
            "Train Epoch: 85 [1536/14860 (10%)]\tLoss: 0.022259\n",
            "Train Epoch: 85 [1664/14860 (11%)]\tLoss: 0.020770\n",
            "Train Epoch: 85 [1792/14860 (12%)]\tLoss: 0.016263\n",
            "Train Epoch: 85 [1920/14860 (13%)]\tLoss: 0.017249\n",
            "Train Epoch: 85 [2048/14860 (14%)]\tLoss: 0.017376\n",
            "Train Epoch: 85 [2176/14860 (15%)]\tLoss: 0.021676\n",
            "Train Epoch: 85 [2304/14860 (15%)]\tLoss: 0.015329\n",
            "Train Epoch: 85 [2432/14860 (16%)]\tLoss: 0.015156\n",
            "Train Epoch: 85 [2560/14860 (17%)]\tLoss: 0.018214\n",
            "Train Epoch: 85 [2688/14860 (18%)]\tLoss: 0.016917\n",
            "Train Epoch: 85 [2816/14860 (19%)]\tLoss: 0.019193\n",
            "Train Epoch: 85 [2944/14860 (20%)]\tLoss: 0.015522\n",
            "Train Epoch: 85 [3072/14860 (21%)]\tLoss: 0.020615\n",
            "Train Epoch: 85 [3200/14860 (21%)]\tLoss: 0.013501\n",
            "Train Epoch: 85 [3328/14860 (22%)]\tLoss: 0.016550\n",
            "Train Epoch: 85 [3456/14860 (23%)]\tLoss: 0.020743\n",
            "Train Epoch: 85 [3584/14860 (24%)]\tLoss: 0.016299\n",
            "Train Epoch: 85 [3712/14860 (25%)]\tLoss: 0.020698\n",
            "Train Epoch: 85 [3840/14860 (26%)]\tLoss: 0.020018\n",
            "Train Epoch: 85 [3968/14860 (26%)]\tLoss: 0.018249\n",
            "Train Epoch: 85 [4096/14860 (27%)]\tLoss: 0.024352\n",
            "Train Epoch: 85 [4224/14860 (28%)]\tLoss: 0.014447\n",
            "Train Epoch: 85 [4352/14860 (29%)]\tLoss: 0.030405\n",
            "Train Epoch: 85 [4480/14860 (30%)]\tLoss: 0.018994\n",
            "Train Epoch: 85 [4608/14860 (31%)]\tLoss: 0.018383\n",
            "Train Epoch: 85 [4736/14860 (32%)]\tLoss: 0.018048\n",
            "Train Epoch: 85 [4864/14860 (32%)]\tLoss: 0.027664\n",
            "Train Epoch: 85 [4992/14860 (33%)]\tLoss: 0.022041\n",
            "Train Epoch: 85 [5120/14860 (34%)]\tLoss: 0.016551\n",
            "Train Epoch: 85 [5248/14860 (35%)]\tLoss: 0.020481\n",
            "Train Epoch: 85 [5376/14860 (36%)]\tLoss: 0.018646\n",
            "Train Epoch: 85 [5504/14860 (37%)]\tLoss: 0.011924\n",
            "Train Epoch: 85 [5632/14860 (38%)]\tLoss: 0.020701\n",
            "Train Epoch: 85 [5760/14860 (38%)]\tLoss: 0.020739\n",
            "Train Epoch: 85 [5888/14860 (39%)]\tLoss: 0.020243\n",
            "Train Epoch: 85 [6016/14860 (40%)]\tLoss: 0.021226\n",
            "Train Epoch: 85 [6144/14860 (41%)]\tLoss: 0.023317\n",
            "Train Epoch: 85 [6272/14860 (42%)]\tLoss: 0.020124\n",
            "Train Epoch: 85 [6400/14860 (43%)]\tLoss: 0.026183\n",
            "Train Epoch: 85 [6528/14860 (44%)]\tLoss: 0.019759\n",
            "Train Epoch: 85 [6656/14860 (44%)]\tLoss: 0.016489\n",
            "Train Epoch: 85 [6784/14860 (45%)]\tLoss: 0.013778\n",
            "Train Epoch: 85 [6912/14860 (46%)]\tLoss: 0.020542\n",
            "Train Epoch: 85 [7040/14860 (47%)]\tLoss: 0.018919\n",
            "Train Epoch: 85 [7168/14860 (48%)]\tLoss: 0.019604\n",
            "Train Epoch: 85 [7296/14860 (49%)]\tLoss: 0.018182\n",
            "Train Epoch: 85 [7424/14860 (50%)]\tLoss: 0.016915\n",
            "Train Epoch: 85 [7552/14860 (50%)]\tLoss: 0.020428\n",
            "Train Epoch: 85 [7680/14860 (51%)]\tLoss: 0.015129\n",
            "Train Epoch: 85 [7808/14860 (52%)]\tLoss: 0.017265\n",
            "Train Epoch: 85 [7936/14860 (53%)]\tLoss: 0.014715\n",
            "Train Epoch: 85 [8064/14860 (54%)]\tLoss: 0.021274\n",
            "Train Epoch: 85 [8192/14860 (55%)]\tLoss: 0.021895\n",
            "Train Epoch: 85 [8320/14860 (56%)]\tLoss: 0.015208\n",
            "Train Epoch: 85 [8448/14860 (56%)]\tLoss: 0.016394\n",
            "Train Epoch: 85 [8576/14860 (57%)]\tLoss: 0.024121\n",
            "Train Epoch: 85 [8704/14860 (58%)]\tLoss: 0.021264\n",
            "Train Epoch: 85 [8832/14860 (59%)]\tLoss: 0.013057\n",
            "Train Epoch: 85 [8960/14860 (60%)]\tLoss: 0.021343\n",
            "Train Epoch: 85 [9088/14860 (61%)]\tLoss: 0.028177\n",
            "Train Epoch: 85 [9216/14860 (62%)]\tLoss: 0.017135\n",
            "Train Epoch: 85 [9344/14860 (62%)]\tLoss: 0.021184\n",
            "Train Epoch: 85 [9472/14860 (63%)]\tLoss: 0.022158\n",
            "Train Epoch: 85 [9600/14860 (64%)]\tLoss: 0.023920\n",
            "Train Epoch: 85 [9728/14860 (65%)]\tLoss: 0.024221\n",
            "Train Epoch: 85 [9856/14860 (66%)]\tLoss: 0.016968\n",
            "Train Epoch: 85 [9984/14860 (67%)]\tLoss: 0.017387\n",
            "Train Epoch: 85 [10112/14860 (68%)]\tLoss: 0.014779\n",
            "Train Epoch: 85 [10240/14860 (68%)]\tLoss: 0.021914\n",
            "Train Epoch: 85 [10368/14860 (69%)]\tLoss: 0.024964\n",
            "Train Epoch: 85 [10496/14860 (70%)]\tLoss: 0.019271\n",
            "Train Epoch: 85 [10624/14860 (71%)]\tLoss: 0.022429\n",
            "Train Epoch: 85 [10752/14860 (72%)]\tLoss: 0.013499\n",
            "Train Epoch: 85 [10880/14860 (73%)]\tLoss: 0.013749\n",
            "Train Epoch: 85 [11008/14860 (74%)]\tLoss: 0.016060\n",
            "Train Epoch: 85 [11136/14860 (74%)]\tLoss: 0.012874\n",
            "Train Epoch: 85 [11264/14860 (75%)]\tLoss: 0.017880\n",
            "Train Epoch: 85 [11392/14860 (76%)]\tLoss: 0.021800\n",
            "Train Epoch: 85 [11520/14860 (77%)]\tLoss: 0.015844\n",
            "Train Epoch: 85 [11648/14860 (78%)]\tLoss: 0.017801\n",
            "Train Epoch: 85 [11776/14860 (79%)]\tLoss: 0.015028\n",
            "Train Epoch: 85 [11904/14860 (79%)]\tLoss: 0.023024\n",
            "Train Epoch: 85 [12032/14860 (80%)]\tLoss: 0.033487\n",
            "Train Epoch: 85 [12160/14860 (81%)]\tLoss: 0.021368\n",
            "Train Epoch: 85 [12288/14860 (82%)]\tLoss: 0.019904\n",
            "Train Epoch: 85 [12416/14860 (83%)]\tLoss: 0.027212\n",
            "Train Epoch: 85 [12544/14860 (84%)]\tLoss: 0.018894\n",
            "Train Epoch: 85 [12672/14860 (85%)]\tLoss: 0.015251\n",
            "Train Epoch: 85 [12800/14860 (85%)]\tLoss: 0.019332\n",
            "Train Epoch: 85 [12928/14860 (86%)]\tLoss: 0.023042\n",
            "Train Epoch: 85 [13056/14860 (87%)]\tLoss: 0.019962\n",
            "Train Epoch: 85 [13184/14860 (88%)]\tLoss: 0.019264\n",
            "Train Epoch: 85 [13312/14860 (89%)]\tLoss: 0.016296\n",
            "Train Epoch: 85 [13440/14860 (90%)]\tLoss: 0.018542\n",
            "Train Epoch: 85 [13568/14860 (91%)]\tLoss: 0.014540\n",
            "Train Epoch: 85 [13696/14860 (91%)]\tLoss: 0.014739\n",
            "Train Epoch: 85 [13824/14860 (92%)]\tLoss: 0.018826\n",
            "Train Epoch: 85 [13952/14860 (93%)]\tLoss: 0.021328\n",
            "Train Epoch: 85 [14080/14860 (94%)]\tLoss: 0.017758\n",
            "Train Epoch: 85 [14208/14860 (95%)]\tLoss: 0.024840\n",
            "Train Epoch: 85 [14336/14860 (96%)]\tLoss: 0.028374\n",
            "Train Epoch: 85 [14464/14860 (97%)]\tLoss: 0.017467\n",
            "Train Epoch: 85 [14592/14860 (97%)]\tLoss: 0.020180\n",
            "Train Epoch: 85 [14720/14860 (98%)]\tLoss: 0.018730\n",
            "Train Epoch: 85 [1392/14860 (99%)]\tLoss: 0.024307\n",
            "epoch 85 training loss: 0.019311330726959258\n",
            "epoch 85 validation loss: 0.022109361162485856\n",
            "Train Epoch: 86 [0/14860 (0%)]\tLoss: 0.024956\n",
            "Train Epoch: 86 [128/14860 (1%)]\tLoss: 0.016425\n",
            "Train Epoch: 86 [256/14860 (2%)]\tLoss: 0.018864\n",
            "Train Epoch: 86 [384/14860 (3%)]\tLoss: 0.020658\n",
            "Train Epoch: 86 [512/14860 (3%)]\tLoss: 0.022016\n",
            "Train Epoch: 86 [640/14860 (4%)]\tLoss: 0.016876\n",
            "Train Epoch: 86 [768/14860 (5%)]\tLoss: 0.026742\n",
            "Train Epoch: 86 [896/14860 (6%)]\tLoss: 0.021186\n",
            "Train Epoch: 86 [1024/14860 (7%)]\tLoss: 0.025803\n",
            "Train Epoch: 86 [1152/14860 (8%)]\tLoss: 0.024924\n",
            "Train Epoch: 86 [1280/14860 (9%)]\tLoss: 0.017164\n",
            "Train Epoch: 86 [1408/14860 (9%)]\tLoss: 0.019589\n",
            "Train Epoch: 86 [1536/14860 (10%)]\tLoss: 0.020366\n",
            "Train Epoch: 86 [1664/14860 (11%)]\tLoss: 0.018047\n",
            "Train Epoch: 86 [1792/14860 (12%)]\tLoss: 0.017433\n",
            "Train Epoch: 86 [1920/14860 (13%)]\tLoss: 0.017000\n",
            "Train Epoch: 86 [2048/14860 (14%)]\tLoss: 0.015946\n",
            "Train Epoch: 86 [2176/14860 (15%)]\tLoss: 0.020332\n",
            "Train Epoch: 86 [2304/14860 (15%)]\tLoss: 0.013446\n",
            "Train Epoch: 86 [2432/14860 (16%)]\tLoss: 0.022107\n",
            "Train Epoch: 86 [2560/14860 (17%)]\tLoss: 0.020361\n",
            "Train Epoch: 86 [2688/14860 (18%)]\tLoss: 0.014235\n",
            "Train Epoch: 86 [2816/14860 (19%)]\tLoss: 0.015522\n",
            "Train Epoch: 86 [2944/14860 (20%)]\tLoss: 0.018208\n",
            "Train Epoch: 86 [3072/14860 (21%)]\tLoss: 0.020398\n",
            "Train Epoch: 86 [3200/14860 (21%)]\tLoss: 0.016883\n",
            "Train Epoch: 86 [3328/14860 (22%)]\tLoss: 0.016325\n",
            "Train Epoch: 86 [3456/14860 (23%)]\tLoss: 0.021162\n",
            "Train Epoch: 86 [3584/14860 (24%)]\tLoss: 0.021864\n",
            "Train Epoch: 86 [3712/14860 (25%)]\tLoss: 0.013574\n",
            "Train Epoch: 86 [3840/14860 (26%)]\tLoss: 0.017688\n",
            "Train Epoch: 86 [3968/14860 (26%)]\tLoss: 0.025441\n",
            "Train Epoch: 86 [4096/14860 (27%)]\tLoss: 0.016098\n",
            "Train Epoch: 86 [4224/14860 (28%)]\tLoss: 0.018108\n",
            "Train Epoch: 86 [4352/14860 (29%)]\tLoss: 0.015653\n",
            "Train Epoch: 86 [4480/14860 (30%)]\tLoss: 0.018964\n",
            "Train Epoch: 86 [4608/14860 (31%)]\tLoss: 0.017480\n",
            "Train Epoch: 86 [4736/14860 (32%)]\tLoss: 0.012177\n",
            "Train Epoch: 86 [4864/14860 (32%)]\tLoss: 0.020404\n",
            "Train Epoch: 86 [4992/14860 (33%)]\tLoss: 0.019834\n",
            "Train Epoch: 86 [5120/14860 (34%)]\tLoss: 0.026723\n",
            "Train Epoch: 86 [5248/14860 (35%)]\tLoss: 0.017193\n",
            "Train Epoch: 86 [5376/14860 (36%)]\tLoss: 0.018984\n",
            "Train Epoch: 86 [5504/14860 (37%)]\tLoss: 0.018187\n",
            "Train Epoch: 86 [5632/14860 (38%)]\tLoss: 0.018978\n",
            "Train Epoch: 86 [5760/14860 (38%)]\tLoss: 0.019343\n",
            "Train Epoch: 86 [5888/14860 (39%)]\tLoss: 0.029030\n",
            "Train Epoch: 86 [6016/14860 (40%)]\tLoss: 0.018916\n",
            "Train Epoch: 86 [6144/14860 (41%)]\tLoss: 0.016357\n",
            "Train Epoch: 86 [6272/14860 (42%)]\tLoss: 0.015361\n",
            "Train Epoch: 86 [6400/14860 (43%)]\tLoss: 0.018660\n",
            "Train Epoch: 86 [6528/14860 (44%)]\tLoss: 0.017304\n",
            "Train Epoch: 86 [6656/14860 (44%)]\tLoss: 0.014973\n",
            "Train Epoch: 86 [6784/14860 (45%)]\tLoss: 0.018067\n",
            "Train Epoch: 86 [6912/14860 (46%)]\tLoss: 0.026165\n",
            "Train Epoch: 86 [7040/14860 (47%)]\tLoss: 0.020865\n",
            "Train Epoch: 86 [7168/14860 (48%)]\tLoss: 0.016098\n",
            "Train Epoch: 86 [7296/14860 (49%)]\tLoss: 0.016103\n",
            "Train Epoch: 86 [7424/14860 (50%)]\tLoss: 0.020353\n",
            "Train Epoch: 86 [7552/14860 (50%)]\tLoss: 0.017330\n",
            "Train Epoch: 86 [7680/14860 (51%)]\tLoss: 0.015010\n",
            "Train Epoch: 86 [7808/14860 (52%)]\tLoss: 0.020541\n",
            "Train Epoch: 86 [7936/14860 (53%)]\tLoss: 0.014866\n",
            "Train Epoch: 86 [8064/14860 (54%)]\tLoss: 0.011877\n",
            "Train Epoch: 86 [8192/14860 (55%)]\tLoss: 0.013126\n",
            "Train Epoch: 86 [8320/14860 (56%)]\tLoss: 0.021241\n",
            "Train Epoch: 86 [8448/14860 (56%)]\tLoss: 0.018300\n",
            "Train Epoch: 86 [8576/14860 (57%)]\tLoss: 0.018224\n",
            "Train Epoch: 86 [8704/14860 (58%)]\tLoss: 0.025278\n",
            "Train Epoch: 86 [8832/14860 (59%)]\tLoss: 0.015767\n",
            "Train Epoch: 86 [8960/14860 (60%)]\tLoss: 0.025386\n",
            "Train Epoch: 86 [9088/14860 (61%)]\tLoss: 0.017688\n",
            "Train Epoch: 86 [9216/14860 (62%)]\tLoss: 0.018139\n",
            "Train Epoch: 86 [9344/14860 (62%)]\tLoss: 0.016527\n",
            "Train Epoch: 86 [9472/14860 (63%)]\tLoss: 0.021517\n",
            "Train Epoch: 86 [9600/14860 (64%)]\tLoss: 0.020000\n",
            "Train Epoch: 86 [9728/14860 (65%)]\tLoss: 0.017546\n",
            "Train Epoch: 86 [9856/14860 (66%)]\tLoss: 0.020767\n",
            "Train Epoch: 86 [9984/14860 (67%)]\tLoss: 0.019024\n",
            "Train Epoch: 86 [10112/14860 (68%)]\tLoss: 0.024467\n",
            "Train Epoch: 86 [10240/14860 (68%)]\tLoss: 0.020425\n",
            "Train Epoch: 86 [10368/14860 (69%)]\tLoss: 0.025279\n",
            "Train Epoch: 86 [10496/14860 (70%)]\tLoss: 0.017514\n",
            "Train Epoch: 86 [10624/14860 (71%)]\tLoss: 0.023585\n",
            "Train Epoch: 86 [10752/14860 (72%)]\tLoss: 0.018863\n",
            "Train Epoch: 86 [10880/14860 (73%)]\tLoss: 0.015389\n",
            "Train Epoch: 86 [11008/14860 (74%)]\tLoss: 0.016418\n",
            "Train Epoch: 86 [11136/14860 (74%)]\tLoss: 0.013977\n",
            "Train Epoch: 86 [11264/14860 (75%)]\tLoss: 0.023528\n",
            "Train Epoch: 86 [11392/14860 (76%)]\tLoss: 0.022208\n",
            "Train Epoch: 86 [11520/14860 (77%)]\tLoss: 0.022118\n",
            "Train Epoch: 86 [11648/14860 (78%)]\tLoss: 0.024498\n",
            "Train Epoch: 86 [11776/14860 (79%)]\tLoss: 0.022963\n",
            "Train Epoch: 86 [11904/14860 (79%)]\tLoss: 0.019204\n",
            "Train Epoch: 86 [12032/14860 (80%)]\tLoss: 0.026305\n",
            "Train Epoch: 86 [12160/14860 (81%)]\tLoss: 0.012395\n",
            "Train Epoch: 86 [12288/14860 (82%)]\tLoss: 0.020308\n",
            "Train Epoch: 86 [12416/14860 (83%)]\tLoss: 0.028663\n",
            "Train Epoch: 86 [12544/14860 (84%)]\tLoss: 0.017519\n",
            "Train Epoch: 86 [12672/14860 (85%)]\tLoss: 0.022627\n",
            "Train Epoch: 86 [12800/14860 (85%)]\tLoss: 0.023115\n",
            "Train Epoch: 86 [12928/14860 (86%)]\tLoss: 0.020570\n",
            "Train Epoch: 86 [13056/14860 (87%)]\tLoss: 0.018868\n",
            "Train Epoch: 86 [13184/14860 (88%)]\tLoss: 0.025351\n",
            "Train Epoch: 86 [13312/14860 (89%)]\tLoss: 0.016097\n",
            "Train Epoch: 86 [13440/14860 (90%)]\tLoss: 0.020090\n",
            "Train Epoch: 86 [13568/14860 (91%)]\tLoss: 0.025826\n",
            "Train Epoch: 86 [13696/14860 (91%)]\tLoss: 0.015394\n",
            "Train Epoch: 86 [13824/14860 (92%)]\tLoss: 0.016732\n",
            "Train Epoch: 86 [13952/14860 (93%)]\tLoss: 0.019290\n",
            "Train Epoch: 86 [14080/14860 (94%)]\tLoss: 0.017671\n",
            "Train Epoch: 86 [14208/14860 (95%)]\tLoss: 0.011855\n",
            "Train Epoch: 86 [14336/14860 (96%)]\tLoss: 0.025337\n",
            "Train Epoch: 86 [14464/14860 (97%)]\tLoss: 0.016438\n",
            "Train Epoch: 86 [14592/14860 (97%)]\tLoss: 0.015137\n",
            "Train Epoch: 86 [14720/14860 (98%)]\tLoss: 0.019315\n",
            "Train Epoch: 86 [1392/14860 (99%)]\tLoss: 0.014466\n",
            "epoch 86 training loss: 0.01928102175713095\n",
            "epoch 86 validation loss: 0.02494741712874997\n",
            "Train Epoch: 87 [0/14860 (0%)]\tLoss: 0.022310\n",
            "Train Epoch: 87 [128/14860 (1%)]\tLoss: 0.027290\n",
            "Train Epoch: 87 [256/14860 (2%)]\tLoss: 0.016420\n",
            "Train Epoch: 87 [384/14860 (3%)]\tLoss: 0.023033\n",
            "Train Epoch: 87 [512/14860 (3%)]\tLoss: 0.034640\n",
            "Train Epoch: 87 [640/14860 (4%)]\tLoss: 0.022164\n",
            "Train Epoch: 87 [768/14860 (5%)]\tLoss: 0.019791\n",
            "Train Epoch: 87 [896/14860 (6%)]\tLoss: 0.022700\n",
            "Train Epoch: 87 [1024/14860 (7%)]\tLoss: 0.023100\n",
            "Train Epoch: 87 [1152/14860 (8%)]\tLoss: 0.024026\n",
            "Train Epoch: 87 [1280/14860 (9%)]\tLoss: 0.028372\n",
            "Train Epoch: 87 [1408/14860 (9%)]\tLoss: 0.024265\n",
            "Train Epoch: 87 [1536/14860 (10%)]\tLoss: 0.017352\n",
            "Train Epoch: 87 [1664/14860 (11%)]\tLoss: 0.019697\n",
            "Train Epoch: 87 [1792/14860 (12%)]\tLoss: 0.028332\n",
            "Train Epoch: 87 [1920/14860 (13%)]\tLoss: 0.034326\n",
            "Train Epoch: 87 [2048/14860 (14%)]\tLoss: 0.024395\n",
            "Train Epoch: 87 [2176/14860 (15%)]\tLoss: 0.019798\n",
            "Train Epoch: 87 [2304/14860 (15%)]\tLoss: 0.022890\n",
            "Train Epoch: 87 [2432/14860 (16%)]\tLoss: 0.022260\n",
            "Train Epoch: 87 [2560/14860 (17%)]\tLoss: 0.014748\n",
            "Train Epoch: 87 [2688/14860 (18%)]\tLoss: 0.019239\n",
            "Train Epoch: 87 [2816/14860 (19%)]\tLoss: 0.027738\n",
            "Train Epoch: 87 [2944/14860 (20%)]\tLoss: 0.021694\n",
            "Train Epoch: 87 [3072/14860 (21%)]\tLoss: 0.026820\n",
            "Train Epoch: 87 [3200/14860 (21%)]\tLoss: 0.021781\n",
            "Train Epoch: 87 [3328/14860 (22%)]\tLoss: 0.030202\n",
            "Train Epoch: 87 [3456/14860 (23%)]\tLoss: 0.026172\n",
            "Train Epoch: 87 [3584/14860 (24%)]\tLoss: 0.018276\n",
            "Train Epoch: 87 [3712/14860 (25%)]\tLoss: 0.028333\n",
            "Train Epoch: 87 [3840/14860 (26%)]\tLoss: 0.020487\n",
            "Train Epoch: 87 [3968/14860 (26%)]\tLoss: 0.024646\n",
            "Train Epoch: 87 [4096/14860 (27%)]\tLoss: 0.018074\n",
            "Train Epoch: 87 [4224/14860 (28%)]\tLoss: 0.014748\n",
            "Train Epoch: 87 [4352/14860 (29%)]\tLoss: 0.023829\n",
            "Train Epoch: 87 [4480/14860 (30%)]\tLoss: 0.024263\n",
            "Train Epoch: 87 [4608/14860 (31%)]\tLoss: 0.018401\n",
            "Train Epoch: 87 [4736/14860 (32%)]\tLoss: 0.016509\n",
            "Train Epoch: 87 [4864/14860 (32%)]\tLoss: 0.025816\n",
            "Train Epoch: 87 [4992/14860 (33%)]\tLoss: 0.015764\n",
            "Train Epoch: 87 [5120/14860 (34%)]\tLoss: 0.023485\n",
            "Train Epoch: 87 [5248/14860 (35%)]\tLoss: 0.016905\n",
            "Train Epoch: 87 [5376/14860 (36%)]\tLoss: 0.020265\n",
            "Train Epoch: 87 [5504/14860 (37%)]\tLoss: 0.014659\n",
            "Train Epoch: 87 [5632/14860 (38%)]\tLoss: 0.022859\n",
            "Train Epoch: 87 [5760/14860 (38%)]\tLoss: 0.017518\n",
            "Train Epoch: 87 [5888/14860 (39%)]\tLoss: 0.019116\n",
            "Train Epoch: 87 [6016/14860 (40%)]\tLoss: 0.020243\n",
            "Train Epoch: 87 [6144/14860 (41%)]\tLoss: 0.017328\n",
            "Train Epoch: 87 [6272/14860 (42%)]\tLoss: 0.022236\n",
            "Train Epoch: 87 [6400/14860 (43%)]\tLoss: 0.025442\n",
            "Train Epoch: 87 [6528/14860 (44%)]\tLoss: 0.017749\n",
            "Train Epoch: 87 [6656/14860 (44%)]\tLoss: 0.015875\n",
            "Train Epoch: 87 [6784/14860 (45%)]\tLoss: 0.015781\n",
            "Train Epoch: 87 [6912/14860 (46%)]\tLoss: 0.017172\n",
            "Train Epoch: 87 [7040/14860 (47%)]\tLoss: 0.024316\n",
            "Train Epoch: 87 [7168/14860 (48%)]\tLoss: 0.016811\n",
            "Train Epoch: 87 [7296/14860 (49%)]\tLoss: 0.013078\n",
            "Train Epoch: 87 [7424/14860 (50%)]\tLoss: 0.013319\n",
            "Train Epoch: 87 [7552/14860 (50%)]\tLoss: 0.015835\n",
            "Train Epoch: 87 [7680/14860 (51%)]\tLoss: 0.017198\n",
            "Train Epoch: 87 [7808/14860 (52%)]\tLoss: 0.018652\n",
            "Train Epoch: 87 [7936/14860 (53%)]\tLoss: 0.019841\n",
            "Train Epoch: 87 [8064/14860 (54%)]\tLoss: 0.023915\n",
            "Train Epoch: 87 [8192/14860 (55%)]\tLoss: 0.011977\n",
            "Train Epoch: 87 [8320/14860 (56%)]\tLoss: 0.021160\n",
            "Train Epoch: 87 [8448/14860 (56%)]\tLoss: 0.019283\n",
            "Train Epoch: 87 [8576/14860 (57%)]\tLoss: 0.024657\n",
            "Train Epoch: 87 [8704/14860 (58%)]\tLoss: 0.023055\n",
            "Train Epoch: 87 [8832/14860 (59%)]\tLoss: 0.020741\n",
            "Train Epoch: 87 [8960/14860 (60%)]\tLoss: 0.022037\n",
            "Train Epoch: 87 [9088/14860 (61%)]\tLoss: 0.022669\n",
            "Train Epoch: 87 [9216/14860 (62%)]\tLoss: 0.016564\n",
            "Train Epoch: 87 [9344/14860 (62%)]\tLoss: 0.021451\n",
            "Train Epoch: 87 [9472/14860 (63%)]\tLoss: 0.020255\n",
            "Train Epoch: 87 [9600/14860 (64%)]\tLoss: 0.022685\n",
            "Train Epoch: 87 [9728/14860 (65%)]\tLoss: 0.022173\n",
            "Train Epoch: 87 [9856/14860 (66%)]\tLoss: 0.025009\n",
            "Train Epoch: 87 [9984/14860 (67%)]\tLoss: 0.018942\n",
            "Train Epoch: 87 [10112/14860 (68%)]\tLoss: 0.016772\n",
            "Train Epoch: 87 [10240/14860 (68%)]\tLoss: 0.018628\n",
            "Train Epoch: 87 [10368/14860 (69%)]\tLoss: 0.022135\n",
            "Train Epoch: 87 [10496/14860 (70%)]\tLoss: 0.019225\n",
            "Train Epoch: 87 [10624/14860 (71%)]\tLoss: 0.018480\n",
            "Train Epoch: 87 [10752/14860 (72%)]\tLoss: 0.016401\n",
            "Train Epoch: 87 [10880/14860 (73%)]\tLoss: 0.018505\n",
            "Train Epoch: 87 [11008/14860 (74%)]\tLoss: 0.015828\n",
            "Train Epoch: 87 [11136/14860 (74%)]\tLoss: 0.015175\n",
            "Train Epoch: 87 [11264/14860 (75%)]\tLoss: 0.020203\n",
            "Train Epoch: 87 [11392/14860 (76%)]\tLoss: 0.020195\n",
            "Train Epoch: 87 [11520/14860 (77%)]\tLoss: 0.017579\n",
            "Train Epoch: 87 [11648/14860 (78%)]\tLoss: 0.020599\n",
            "Train Epoch: 87 [11776/14860 (79%)]\tLoss: 0.012919\n",
            "Train Epoch: 87 [11904/14860 (79%)]\tLoss: 0.014838\n",
            "Train Epoch: 87 [12032/14860 (80%)]\tLoss: 0.022844\n",
            "Train Epoch: 87 [12160/14860 (81%)]\tLoss: 0.012910\n",
            "Train Epoch: 87 [12288/14860 (82%)]\tLoss: 0.012998\n",
            "Train Epoch: 87 [12416/14860 (83%)]\tLoss: 0.016426\n",
            "Train Epoch: 87 [12544/14860 (84%)]\tLoss: 0.030637\n",
            "Train Epoch: 87 [12672/14860 (85%)]\tLoss: 0.020849\n",
            "Train Epoch: 87 [12800/14860 (85%)]\tLoss: 0.021263\n",
            "Train Epoch: 87 [12928/14860 (86%)]\tLoss: 0.022998\n",
            "Train Epoch: 87 [13056/14860 (87%)]\tLoss: 0.009221\n",
            "Train Epoch: 87 [13184/14860 (88%)]\tLoss: 0.019612\n",
            "Train Epoch: 87 [13312/14860 (89%)]\tLoss: 0.018283\n",
            "Train Epoch: 87 [13440/14860 (90%)]\tLoss: 0.016990\n",
            "Train Epoch: 87 [13568/14860 (91%)]\tLoss: 0.017569\n",
            "Train Epoch: 87 [13696/14860 (91%)]\tLoss: 0.016687\n",
            "Train Epoch: 87 [13824/14860 (92%)]\tLoss: 0.024124\n",
            "Train Epoch: 87 [13952/14860 (93%)]\tLoss: 0.019428\n",
            "Train Epoch: 87 [14080/14860 (94%)]\tLoss: 0.013031\n",
            "Train Epoch: 87 [14208/14860 (95%)]\tLoss: 0.035310\n",
            "Train Epoch: 87 [14336/14860 (96%)]\tLoss: 0.020100\n",
            "Train Epoch: 87 [14464/14860 (97%)]\tLoss: 0.018001\n",
            "Train Epoch: 87 [14592/14860 (97%)]\tLoss: 0.021674\n",
            "Train Epoch: 87 [14720/14860 (98%)]\tLoss: 0.018405\n",
            "Train Epoch: 87 [1392/14860 (99%)]\tLoss: 0.009127\n",
            "epoch 87 training loss: 0.020366877635829467\n",
            "epoch 87 validation loss: 0.028838019971408797\n",
            "Train Epoch: 88 [0/14860 (0%)]\tLoss: 0.026850\n",
            "Train Epoch: 88 [128/14860 (1%)]\tLoss: 0.045315\n",
            "Train Epoch: 88 [256/14860 (2%)]\tLoss: 0.031010\n",
            "Train Epoch: 88 [384/14860 (3%)]\tLoss: 0.014180\n",
            "Train Epoch: 88 [512/14860 (3%)]\tLoss: 0.025058\n",
            "Train Epoch: 88 [640/14860 (4%)]\tLoss: 0.030183\n",
            "Train Epoch: 88 [768/14860 (5%)]\tLoss: 0.022133\n",
            "Train Epoch: 88 [896/14860 (6%)]\tLoss: 0.021042\n",
            "Train Epoch: 88 [1024/14860 (7%)]\tLoss: 0.023163\n",
            "Train Epoch: 88 [1152/14860 (8%)]\tLoss: 0.033827\n",
            "Train Epoch: 88 [1280/14860 (9%)]\tLoss: 0.033086\n",
            "Train Epoch: 88 [1408/14860 (9%)]\tLoss: 0.024724\n",
            "Train Epoch: 88 [1536/14860 (10%)]\tLoss: 0.022002\n",
            "Train Epoch: 88 [1664/14860 (11%)]\tLoss: 0.025521\n",
            "Train Epoch: 88 [1792/14860 (12%)]\tLoss: 0.024600\n",
            "Train Epoch: 88 [1920/14860 (13%)]\tLoss: 0.020835\n",
            "Train Epoch: 88 [2048/14860 (14%)]\tLoss: 0.017114\n",
            "Train Epoch: 88 [2176/14860 (15%)]\tLoss: 0.018666\n",
            "Train Epoch: 88 [2304/14860 (15%)]\tLoss: 0.018479\n",
            "Train Epoch: 88 [2432/14860 (16%)]\tLoss: 0.023271\n",
            "Train Epoch: 88 [2560/14860 (17%)]\tLoss: 0.026828\n",
            "Train Epoch: 88 [2688/14860 (18%)]\tLoss: 0.015902\n",
            "Train Epoch: 88 [2816/14860 (19%)]\tLoss: 0.022958\n",
            "Train Epoch: 88 [2944/14860 (20%)]\tLoss: 0.024928\n",
            "Train Epoch: 88 [3072/14860 (21%)]\tLoss: 0.027110\n",
            "Train Epoch: 88 [3200/14860 (21%)]\tLoss: 0.025231\n",
            "Train Epoch: 88 [3328/14860 (22%)]\tLoss: 0.015806\n",
            "Train Epoch: 88 [3456/14860 (23%)]\tLoss: 0.013392\n",
            "Train Epoch: 88 [3584/14860 (24%)]\tLoss: 0.019874\n",
            "Train Epoch: 88 [3712/14860 (25%)]\tLoss: 0.015368\n",
            "Train Epoch: 88 [3840/14860 (26%)]\tLoss: 0.021478\n",
            "Train Epoch: 88 [3968/14860 (26%)]\tLoss: 0.020505\n",
            "Train Epoch: 88 [4096/14860 (27%)]\tLoss: 0.021006\n",
            "Train Epoch: 88 [4224/14860 (28%)]\tLoss: 0.020840\n",
            "Train Epoch: 88 [4352/14860 (29%)]\tLoss: 0.013391\n",
            "Train Epoch: 88 [4480/14860 (30%)]\tLoss: 0.019875\n",
            "Train Epoch: 88 [4608/14860 (31%)]\tLoss: 0.028556\n",
            "Train Epoch: 88 [4736/14860 (32%)]\tLoss: 0.021585\n",
            "Train Epoch: 88 [4864/14860 (32%)]\tLoss: 0.024150\n",
            "Train Epoch: 88 [4992/14860 (33%)]\tLoss: 0.021633\n",
            "Train Epoch: 88 [5120/14860 (34%)]\tLoss: 0.021720\n",
            "Train Epoch: 88 [5248/14860 (35%)]\tLoss: 0.016551\n",
            "Train Epoch: 88 [5376/14860 (36%)]\tLoss: 0.018828\n",
            "Train Epoch: 88 [5504/14860 (37%)]\tLoss: 0.029575\n",
            "Train Epoch: 88 [5632/14860 (38%)]\tLoss: 0.018812\n",
            "Train Epoch: 88 [5760/14860 (38%)]\tLoss: 0.018081\n",
            "Train Epoch: 88 [5888/14860 (39%)]\tLoss: 0.017016\n",
            "Train Epoch: 88 [6016/14860 (40%)]\tLoss: 0.018186\n",
            "Train Epoch: 88 [6144/14860 (41%)]\tLoss: 0.020026\n",
            "Train Epoch: 88 [6272/14860 (42%)]\tLoss: 0.017641\n",
            "Train Epoch: 88 [6400/14860 (43%)]\tLoss: 0.024405\n",
            "Train Epoch: 88 [6528/14860 (44%)]\tLoss: 0.017282\n",
            "Train Epoch: 88 [6656/14860 (44%)]\tLoss: 0.015783\n",
            "Train Epoch: 88 [6784/14860 (45%)]\tLoss: 0.017031\n",
            "Train Epoch: 88 [6912/14860 (46%)]\tLoss: 0.016791\n",
            "Train Epoch: 88 [7040/14860 (47%)]\tLoss: 0.017649\n",
            "Train Epoch: 88 [7168/14860 (48%)]\tLoss: 0.019968\n",
            "Train Epoch: 88 [7296/14860 (49%)]\tLoss: 0.018181\n",
            "Train Epoch: 88 [7424/14860 (50%)]\tLoss: 0.025190\n",
            "Train Epoch: 88 [7552/14860 (50%)]\tLoss: 0.017285\n",
            "Train Epoch: 88 [7680/14860 (51%)]\tLoss: 0.023678\n",
            "Train Epoch: 88 [7808/14860 (52%)]\tLoss: 0.015232\n",
            "Train Epoch: 88 [7936/14860 (53%)]\tLoss: 0.010137\n",
            "Train Epoch: 88 [8064/14860 (54%)]\tLoss: 0.025753\n",
            "Train Epoch: 88 [8192/14860 (55%)]\tLoss: 0.020783\n",
            "Train Epoch: 88 [8320/14860 (56%)]\tLoss: 0.018221\n",
            "Train Epoch: 88 [8448/14860 (56%)]\tLoss: 0.022328\n",
            "Train Epoch: 88 [8576/14860 (57%)]\tLoss: 0.022735\n",
            "Train Epoch: 88 [8704/14860 (58%)]\tLoss: 0.017941\n",
            "Train Epoch: 88 [8832/14860 (59%)]\tLoss: 0.016520\n",
            "Train Epoch: 88 [8960/14860 (60%)]\tLoss: 0.022298\n",
            "Train Epoch: 88 [9088/14860 (61%)]\tLoss: 0.020339\n",
            "Train Epoch: 88 [9216/14860 (62%)]\tLoss: 0.013727\n",
            "Train Epoch: 88 [9344/14860 (62%)]\tLoss: 0.021624\n",
            "Train Epoch: 88 [9472/14860 (63%)]\tLoss: 0.016065\n",
            "Train Epoch: 88 [9600/14860 (64%)]\tLoss: 0.017501\n",
            "Train Epoch: 88 [9728/14860 (65%)]\tLoss: 0.018243\n",
            "Train Epoch: 88 [9856/14860 (66%)]\tLoss: 0.017594\n",
            "Train Epoch: 88 [9984/14860 (67%)]\tLoss: 0.018750\n",
            "Train Epoch: 88 [10112/14860 (68%)]\tLoss: 0.024335\n",
            "Train Epoch: 88 [10240/14860 (68%)]\tLoss: 0.012996\n",
            "Train Epoch: 88 [10368/14860 (69%)]\tLoss: 0.016099\n",
            "Train Epoch: 88 [10496/14860 (70%)]\tLoss: 0.022331\n",
            "Train Epoch: 88 [10624/14860 (71%)]\tLoss: 0.022667\n",
            "Train Epoch: 88 [10752/14860 (72%)]\tLoss: 0.018766\n",
            "Train Epoch: 88 [10880/14860 (73%)]\tLoss: 0.010731\n",
            "Train Epoch: 88 [11008/14860 (74%)]\tLoss: 0.019759\n",
            "Train Epoch: 88 [11136/14860 (74%)]\tLoss: 0.022193\n",
            "Train Epoch: 88 [11264/14860 (75%)]\tLoss: 0.018051\n",
            "Train Epoch: 88 [11392/14860 (76%)]\tLoss: 0.020246\n",
            "Train Epoch: 88 [11520/14860 (77%)]\tLoss: 0.013988\n",
            "Train Epoch: 88 [11648/14860 (78%)]\tLoss: 0.014814\n",
            "Train Epoch: 88 [11776/14860 (79%)]\tLoss: 0.018010\n",
            "Train Epoch: 88 [11904/14860 (79%)]\tLoss: 0.019691\n",
            "Train Epoch: 88 [12032/14860 (80%)]\tLoss: 0.019143\n",
            "Train Epoch: 88 [12160/14860 (81%)]\tLoss: 0.017782\n",
            "Train Epoch: 88 [12288/14860 (82%)]\tLoss: 0.021476\n",
            "Train Epoch: 88 [12416/14860 (83%)]\tLoss: 0.034585\n",
            "Train Epoch: 88 [12544/14860 (84%)]\tLoss: 0.019733\n",
            "Train Epoch: 88 [12672/14860 (85%)]\tLoss: 0.022215\n",
            "Train Epoch: 88 [12800/14860 (85%)]\tLoss: 0.024130\n",
            "Train Epoch: 88 [12928/14860 (86%)]\tLoss: 0.012480\n",
            "Train Epoch: 88 [13056/14860 (87%)]\tLoss: 0.014725\n",
            "Train Epoch: 88 [13184/14860 (88%)]\tLoss: 0.017373\n",
            "Train Epoch: 88 [13312/14860 (89%)]\tLoss: 0.013523\n",
            "Train Epoch: 88 [13440/14860 (90%)]\tLoss: 0.014912\n",
            "Train Epoch: 88 [13568/14860 (91%)]\tLoss: 0.016084\n",
            "Train Epoch: 88 [13696/14860 (91%)]\tLoss: 0.027170\n",
            "Train Epoch: 88 [13824/14860 (92%)]\tLoss: 0.021547\n",
            "Train Epoch: 88 [13952/14860 (93%)]\tLoss: 0.027757\n",
            "Train Epoch: 88 [14080/14860 (94%)]\tLoss: 0.016560\n",
            "Train Epoch: 88 [14208/14860 (95%)]\tLoss: 0.013135\n",
            "Train Epoch: 88 [14336/14860 (96%)]\tLoss: 0.026480\n",
            "Train Epoch: 88 [14464/14860 (97%)]\tLoss: 0.022029\n",
            "Train Epoch: 88 [14592/14860 (97%)]\tLoss: 0.024258\n",
            "Train Epoch: 88 [14720/14860 (98%)]\tLoss: 0.018802\n",
            "Train Epoch: 88 [1392/14860 (99%)]\tLoss: 0.034860\n",
            "epoch 88 training loss: 0.02070410058507298\n",
            "epoch 88 validation loss: 0.03219393090532132\n",
            "Train Epoch: 89 [0/14860 (0%)]\tLoss: 0.027179\n",
            "Train Epoch: 89 [128/14860 (1%)]\tLoss: 0.036835\n",
            "Train Epoch: 89 [256/14860 (2%)]\tLoss: 0.013314\n",
            "Train Epoch: 89 [384/14860 (3%)]\tLoss: 0.017801\n",
            "Train Epoch: 89 [512/14860 (3%)]\tLoss: 0.027184\n",
            "Train Epoch: 89 [640/14860 (4%)]\tLoss: 0.024917\n",
            "Train Epoch: 89 [768/14860 (5%)]\tLoss: 0.032187\n",
            "Train Epoch: 89 [896/14860 (6%)]\tLoss: 0.016909\n",
            "Train Epoch: 89 [1024/14860 (7%)]\tLoss: 0.024418\n",
            "Train Epoch: 89 [1152/14860 (8%)]\tLoss: 0.022545\n",
            "Train Epoch: 89 [1280/14860 (9%)]\tLoss: 0.020763\n",
            "Train Epoch: 89 [1408/14860 (9%)]\tLoss: 0.023703\n",
            "Train Epoch: 89 [1536/14860 (10%)]\tLoss: 0.026439\n",
            "Train Epoch: 89 [1664/14860 (11%)]\tLoss: 0.020473\n",
            "Train Epoch: 89 [1792/14860 (12%)]\tLoss: 0.025696\n",
            "Train Epoch: 89 [1920/14860 (13%)]\tLoss: 0.015231\n",
            "Train Epoch: 89 [2048/14860 (14%)]\tLoss: 0.025109\n",
            "Train Epoch: 89 [2176/14860 (15%)]\tLoss: 0.025626\n",
            "Train Epoch: 89 [2304/14860 (15%)]\tLoss: 0.015683\n",
            "Train Epoch: 89 [2432/14860 (16%)]\tLoss: 0.017134\n",
            "Train Epoch: 89 [2560/14860 (17%)]\tLoss: 0.022569\n",
            "Train Epoch: 89 [2688/14860 (18%)]\tLoss: 0.018347\n",
            "Train Epoch: 89 [2816/14860 (19%)]\tLoss: 0.018855\n",
            "Train Epoch: 89 [2944/14860 (20%)]\tLoss: 0.028460\n",
            "Train Epoch: 89 [3072/14860 (21%)]\tLoss: 0.019965\n",
            "Train Epoch: 89 [3200/14860 (21%)]\tLoss: 0.013187\n",
            "Train Epoch: 89 [3328/14860 (22%)]\tLoss: 0.020381\n",
            "Train Epoch: 89 [3456/14860 (23%)]\tLoss: 0.020547\n",
            "Train Epoch: 89 [3584/14860 (24%)]\tLoss: 0.020226\n",
            "Train Epoch: 89 [3712/14860 (25%)]\tLoss: 0.013747\n",
            "Train Epoch: 89 [3840/14860 (26%)]\tLoss: 0.020872\n",
            "Train Epoch: 89 [3968/14860 (26%)]\tLoss: 0.014917\n",
            "Train Epoch: 89 [4096/14860 (27%)]\tLoss: 0.021154\n",
            "Train Epoch: 89 [4224/14860 (28%)]\tLoss: 0.025276\n",
            "Train Epoch: 89 [4352/14860 (29%)]\tLoss: 0.017820\n",
            "Train Epoch: 89 [4480/14860 (30%)]\tLoss: 0.025910\n",
            "Train Epoch: 89 [4608/14860 (31%)]\tLoss: 0.017788\n",
            "Train Epoch: 89 [4736/14860 (32%)]\tLoss: 0.020300\n",
            "Train Epoch: 89 [4864/14860 (32%)]\tLoss: 0.011919\n",
            "Train Epoch: 89 [4992/14860 (33%)]\tLoss: 0.014026\n",
            "Train Epoch: 89 [5120/14860 (34%)]\tLoss: 0.018664\n",
            "Train Epoch: 89 [5248/14860 (35%)]\tLoss: 0.019288\n",
            "Train Epoch: 89 [5376/14860 (36%)]\tLoss: 0.014809\n",
            "Train Epoch: 89 [5504/14860 (37%)]\tLoss: 0.017868\n",
            "Train Epoch: 89 [5632/14860 (38%)]\tLoss: 0.017364\n",
            "Train Epoch: 89 [5760/14860 (38%)]\tLoss: 0.020282\n",
            "Train Epoch: 89 [5888/14860 (39%)]\tLoss: 0.018073\n",
            "Train Epoch: 89 [6016/14860 (40%)]\tLoss: 0.023584\n",
            "Train Epoch: 89 [6144/14860 (41%)]\tLoss: 0.022730\n",
            "Train Epoch: 89 [6272/14860 (42%)]\tLoss: 0.016113\n",
            "Train Epoch: 89 [6400/14860 (43%)]\tLoss: 0.018667\n",
            "Train Epoch: 89 [6528/14860 (44%)]\tLoss: 0.022654\n",
            "Train Epoch: 89 [6656/14860 (44%)]\tLoss: 0.038637\n",
            "Train Epoch: 89 [6784/14860 (45%)]\tLoss: 0.016871\n",
            "Train Epoch: 89 [6912/14860 (46%)]\tLoss: 0.024601\n",
            "Train Epoch: 89 [7040/14860 (47%)]\tLoss: 0.017953\n",
            "Train Epoch: 89 [7168/14860 (48%)]\tLoss: 0.014857\n",
            "Train Epoch: 89 [7296/14860 (49%)]\tLoss: 0.018280\n",
            "Train Epoch: 89 [7424/14860 (50%)]\tLoss: 0.029362\n",
            "Train Epoch: 89 [7552/14860 (50%)]\tLoss: 0.016741\n",
            "Train Epoch: 89 [7680/14860 (51%)]\tLoss: 0.016185\n",
            "Train Epoch: 89 [7808/14860 (52%)]\tLoss: 0.019016\n",
            "Train Epoch: 89 [7936/14860 (53%)]\tLoss: 0.020415\n",
            "Train Epoch: 89 [8064/14860 (54%)]\tLoss: 0.019075\n",
            "Train Epoch: 89 [8192/14860 (55%)]\tLoss: 0.019942\n",
            "Train Epoch: 89 [8320/14860 (56%)]\tLoss: 0.022454\n",
            "Train Epoch: 89 [8448/14860 (56%)]\tLoss: 0.021865\n",
            "Train Epoch: 89 [8576/14860 (57%)]\tLoss: 0.017788\n",
            "Train Epoch: 89 [8704/14860 (58%)]\tLoss: 0.028755\n",
            "Train Epoch: 89 [8832/14860 (59%)]\tLoss: 0.020001\n",
            "Train Epoch: 89 [8960/14860 (60%)]\tLoss: 0.017486\n",
            "Train Epoch: 89 [9088/14860 (61%)]\tLoss: 0.017482\n",
            "Train Epoch: 89 [9216/14860 (62%)]\tLoss: 0.016917\n",
            "Train Epoch: 89 [9344/14860 (62%)]\tLoss: 0.027794\n",
            "Train Epoch: 89 [9472/14860 (63%)]\tLoss: 0.020273\n",
            "Train Epoch: 89 [9600/14860 (64%)]\tLoss: 0.020379\n",
            "Train Epoch: 89 [9728/14860 (65%)]\tLoss: 0.017354\n",
            "Train Epoch: 89 [9856/14860 (66%)]\tLoss: 0.022559\n",
            "Train Epoch: 89 [9984/14860 (67%)]\tLoss: 0.018177\n",
            "Train Epoch: 89 [10112/14860 (68%)]\tLoss: 0.013553\n",
            "Train Epoch: 89 [10240/14860 (68%)]\tLoss: 0.031384\n",
            "Train Epoch: 89 [10368/14860 (69%)]\tLoss: 0.019535\n",
            "Train Epoch: 89 [10496/14860 (70%)]\tLoss: 0.017395\n",
            "Train Epoch: 89 [10624/14860 (71%)]\tLoss: 0.017661\n",
            "Train Epoch: 89 [10752/14860 (72%)]\tLoss: 0.016310\n",
            "Train Epoch: 89 [10880/14860 (73%)]\tLoss: 0.015368\n",
            "Train Epoch: 89 [11008/14860 (74%)]\tLoss: 0.027133\n",
            "Train Epoch: 89 [11136/14860 (74%)]\tLoss: 0.028042\n",
            "Train Epoch: 89 [11264/14860 (75%)]\tLoss: 0.013437\n",
            "Train Epoch: 89 [11392/14860 (76%)]\tLoss: 0.016696\n",
            "Train Epoch: 89 [11520/14860 (77%)]\tLoss: 0.019478\n",
            "Train Epoch: 89 [11648/14860 (78%)]\tLoss: 0.017264\n",
            "Train Epoch: 89 [11776/14860 (79%)]\tLoss: 0.013917\n",
            "Train Epoch: 89 [11904/14860 (79%)]\tLoss: 0.022755\n",
            "Train Epoch: 89 [12032/14860 (80%)]\tLoss: 0.024523\n",
            "Train Epoch: 89 [12160/14860 (81%)]\tLoss: 0.019357\n",
            "Train Epoch: 89 [12288/14860 (82%)]\tLoss: 0.023676\n",
            "Train Epoch: 89 [12416/14860 (83%)]\tLoss: 0.022263\n",
            "Train Epoch: 89 [12544/14860 (84%)]\tLoss: 0.020399\n",
            "Train Epoch: 89 [12672/14860 (85%)]\tLoss: 0.023556\n",
            "Train Epoch: 89 [12800/14860 (85%)]\tLoss: 0.010004\n",
            "Train Epoch: 89 [12928/14860 (86%)]\tLoss: 0.025301\n",
            "Train Epoch: 89 [13056/14860 (87%)]\tLoss: 0.019726\n",
            "Train Epoch: 89 [13184/14860 (88%)]\tLoss: 0.023731\n",
            "Train Epoch: 89 [13312/14860 (89%)]\tLoss: 0.020182\n",
            "Train Epoch: 89 [13440/14860 (90%)]\tLoss: 0.025572\n",
            "Train Epoch: 89 [13568/14860 (91%)]\tLoss: 0.014893\n",
            "Train Epoch: 89 [13696/14860 (91%)]\tLoss: 0.023036\n",
            "Train Epoch: 89 [13824/14860 (92%)]\tLoss: 0.018288\n",
            "Train Epoch: 89 [13952/14860 (93%)]\tLoss: 0.024475\n",
            "Train Epoch: 89 [14080/14860 (94%)]\tLoss: 0.017299\n",
            "Train Epoch: 89 [14208/14860 (95%)]\tLoss: 0.015636\n",
            "Train Epoch: 89 [14336/14860 (96%)]\tLoss: 0.017313\n",
            "Train Epoch: 89 [14464/14860 (97%)]\tLoss: 0.021432\n",
            "Train Epoch: 89 [14592/14860 (97%)]\tLoss: 0.016483\n",
            "Train Epoch: 89 [14720/14860 (98%)]\tLoss: 0.017733\n",
            "Train Epoch: 89 [1392/14860 (99%)]\tLoss: 0.011250\n",
            "epoch 89 training loss: 0.020365655796331726\n",
            "epoch 89 validation loss: 0.020402258735592083\n",
            "Train Epoch: 90 [0/14860 (0%)]\tLoss: 0.016776\n",
            "Train Epoch: 90 [128/14860 (1%)]\tLoss: 0.016805\n",
            "Train Epoch: 90 [256/14860 (2%)]\tLoss: 0.018968\n",
            "Train Epoch: 90 [384/14860 (3%)]\tLoss: 0.018519\n",
            "Train Epoch: 90 [512/14860 (3%)]\tLoss: 0.021151\n",
            "Train Epoch: 90 [640/14860 (4%)]\tLoss: 0.018113\n",
            "Train Epoch: 90 [768/14860 (5%)]\tLoss: 0.018898\n",
            "Train Epoch: 90 [896/14860 (6%)]\tLoss: 0.017198\n",
            "Train Epoch: 90 [1024/14860 (7%)]\tLoss: 0.020421\n",
            "Train Epoch: 90 [1152/14860 (8%)]\tLoss: 0.011214\n",
            "Train Epoch: 90 [1280/14860 (9%)]\tLoss: 0.014941\n",
            "Train Epoch: 90 [1408/14860 (9%)]\tLoss: 0.017743\n",
            "Train Epoch: 90 [1536/14860 (10%)]\tLoss: 0.019009\n",
            "Train Epoch: 90 [1664/14860 (11%)]\tLoss: 0.017839\n",
            "Train Epoch: 90 [1792/14860 (12%)]\tLoss: 0.019109\n",
            "Train Epoch: 90 [1920/14860 (13%)]\tLoss: 0.021021\n",
            "Train Epoch: 90 [2048/14860 (14%)]\tLoss: 0.016047\n",
            "Train Epoch: 90 [2176/14860 (15%)]\tLoss: 0.018549\n",
            "Train Epoch: 90 [2304/14860 (15%)]\tLoss: 0.011886\n",
            "Train Epoch: 90 [2432/14860 (16%)]\tLoss: 0.016084\n",
            "Train Epoch: 90 [2560/14860 (17%)]\tLoss: 0.015646\n",
            "Train Epoch: 90 [2688/14860 (18%)]\tLoss: 0.020344\n",
            "Train Epoch: 90 [2816/14860 (19%)]\tLoss: 0.017396\n",
            "Train Epoch: 90 [2944/14860 (20%)]\tLoss: 0.025534\n",
            "Train Epoch: 90 [3072/14860 (21%)]\tLoss: 0.018476\n",
            "Train Epoch: 90 [3200/14860 (21%)]\tLoss: 0.035674\n",
            "Train Epoch: 90 [3328/14860 (22%)]\tLoss: 0.017744\n",
            "Train Epoch: 90 [3456/14860 (23%)]\tLoss: 0.020888\n",
            "Train Epoch: 90 [3584/14860 (24%)]\tLoss: 0.026935\n",
            "Train Epoch: 90 [3712/14860 (25%)]\tLoss: 0.020165\n",
            "Train Epoch: 90 [3840/14860 (26%)]\tLoss: 0.026720\n",
            "Train Epoch: 90 [3968/14860 (26%)]\tLoss: 0.020998\n",
            "Train Epoch: 90 [4096/14860 (27%)]\tLoss: 0.023841\n",
            "Train Epoch: 90 [4224/14860 (28%)]\tLoss: 0.019993\n",
            "Train Epoch: 90 [4352/14860 (29%)]\tLoss: 0.018526\n",
            "Train Epoch: 90 [4480/14860 (30%)]\tLoss: 0.017849\n",
            "Train Epoch: 90 [4608/14860 (31%)]\tLoss: 0.022668\n",
            "Train Epoch: 90 [4736/14860 (32%)]\tLoss: 0.012698\n",
            "Train Epoch: 90 [4864/14860 (32%)]\tLoss: 0.018221\n",
            "Train Epoch: 90 [4992/14860 (33%)]\tLoss: 0.017194\n",
            "Train Epoch: 90 [5120/14860 (34%)]\tLoss: 0.018724\n",
            "Train Epoch: 90 [5248/14860 (35%)]\tLoss: 0.018948\n",
            "Train Epoch: 90 [5376/14860 (36%)]\tLoss: 0.029235\n",
            "Train Epoch: 90 [5504/14860 (37%)]\tLoss: 0.012615\n",
            "Train Epoch: 90 [5632/14860 (38%)]\tLoss: 0.020560\n",
            "Train Epoch: 90 [5760/14860 (38%)]\tLoss: 0.020059\n",
            "Train Epoch: 90 [5888/14860 (39%)]\tLoss: 0.019272\n",
            "Train Epoch: 90 [6016/14860 (40%)]\tLoss: 0.022700\n",
            "Train Epoch: 90 [6144/14860 (41%)]\tLoss: 0.019704\n",
            "Train Epoch: 90 [6272/14860 (42%)]\tLoss: 0.021049\n",
            "Train Epoch: 90 [6400/14860 (43%)]\tLoss: 0.012981\n",
            "Train Epoch: 90 [6528/14860 (44%)]\tLoss: 0.019483\n",
            "Train Epoch: 90 [6656/14860 (44%)]\tLoss: 0.014352\n",
            "Train Epoch: 90 [6784/14860 (45%)]\tLoss: 0.024261\n",
            "Train Epoch: 90 [6912/14860 (46%)]\tLoss: 0.025322\n",
            "Train Epoch: 90 [7040/14860 (47%)]\tLoss: 0.019388\n",
            "Train Epoch: 90 [7168/14860 (48%)]\tLoss: 0.023477\n",
            "Train Epoch: 90 [7296/14860 (49%)]\tLoss: 0.018187\n",
            "Train Epoch: 90 [7424/14860 (50%)]\tLoss: 0.021673\n",
            "Train Epoch: 90 [7552/14860 (50%)]\tLoss: 0.018068\n",
            "Train Epoch: 90 [7680/14860 (51%)]\tLoss: 0.019337\n",
            "Train Epoch: 90 [7808/14860 (52%)]\tLoss: 0.024664\n",
            "Train Epoch: 90 [7936/14860 (53%)]\tLoss: 0.019955\n",
            "Train Epoch: 90 [8064/14860 (54%)]\tLoss: 0.020041\n",
            "Train Epoch: 90 [8192/14860 (55%)]\tLoss: 0.018766\n",
            "Train Epoch: 90 [8320/14860 (56%)]\tLoss: 0.020894\n",
            "Train Epoch: 90 [8448/14860 (56%)]\tLoss: 0.018457\n",
            "Train Epoch: 90 [8576/14860 (57%)]\tLoss: 0.024346\n",
            "Train Epoch: 90 [8704/14860 (58%)]\tLoss: 0.015640\n",
            "Train Epoch: 90 [8832/14860 (59%)]\tLoss: 0.025253\n",
            "Train Epoch: 90 [8960/14860 (60%)]\tLoss: 0.019325\n",
            "Train Epoch: 90 [9088/14860 (61%)]\tLoss: 0.025641\n",
            "Train Epoch: 90 [9216/14860 (62%)]\tLoss: 0.028686\n",
            "Train Epoch: 90 [9344/14860 (62%)]\tLoss: 0.018779\n",
            "Train Epoch: 90 [9472/14860 (63%)]\tLoss: 0.018481\n",
            "Train Epoch: 90 [9600/14860 (64%)]\tLoss: 0.020343\n",
            "Train Epoch: 90 [9728/14860 (65%)]\tLoss: 0.017924\n",
            "Train Epoch: 90 [9856/14860 (66%)]\tLoss: 0.016788\n",
            "Train Epoch: 90 [9984/14860 (67%)]\tLoss: 0.014800\n",
            "Train Epoch: 90 [10112/14860 (68%)]\tLoss: 0.024187\n",
            "Train Epoch: 90 [10240/14860 (68%)]\tLoss: 0.021191\n",
            "Train Epoch: 90 [10368/14860 (69%)]\tLoss: 0.019358\n",
            "Train Epoch: 90 [10496/14860 (70%)]\tLoss: 0.021073\n",
            "Train Epoch: 90 [10624/14860 (71%)]\tLoss: 0.021512\n",
            "Train Epoch: 90 [10752/14860 (72%)]\tLoss: 0.023391\n",
            "Train Epoch: 90 [10880/14860 (73%)]\tLoss: 0.016841\n",
            "Train Epoch: 90 [11008/14860 (74%)]\tLoss: 0.021140\n",
            "Train Epoch: 90 [11136/14860 (74%)]\tLoss: 0.013534\n",
            "Train Epoch: 90 [11264/14860 (75%)]\tLoss: 0.016265\n",
            "Train Epoch: 90 [11392/14860 (76%)]\tLoss: 0.013390\n",
            "Train Epoch: 90 [11520/14860 (77%)]\tLoss: 0.014303\n",
            "Train Epoch: 90 [11648/14860 (78%)]\tLoss: 0.017340\n",
            "Train Epoch: 90 [11776/14860 (79%)]\tLoss: 0.018866\n",
            "Train Epoch: 90 [11904/14860 (79%)]\tLoss: 0.023576\n",
            "Train Epoch: 90 [12032/14860 (80%)]\tLoss: 0.014506\n",
            "Train Epoch: 90 [12160/14860 (81%)]\tLoss: 0.017442\n",
            "Train Epoch: 90 [12288/14860 (82%)]\tLoss: 0.020964\n",
            "Train Epoch: 90 [12416/14860 (83%)]\tLoss: 0.019855\n",
            "Train Epoch: 90 [12544/14860 (84%)]\tLoss: 0.012394\n",
            "Train Epoch: 90 [12672/14860 (85%)]\tLoss: 0.014119\n",
            "Train Epoch: 90 [12800/14860 (85%)]\tLoss: 0.018051\n",
            "Train Epoch: 90 [12928/14860 (86%)]\tLoss: 0.021928\n",
            "Train Epoch: 90 [13056/14860 (87%)]\tLoss: 0.015287\n",
            "Train Epoch: 90 [13184/14860 (88%)]\tLoss: 0.024549\n",
            "Train Epoch: 90 [13312/14860 (89%)]\tLoss: 0.019725\n",
            "Train Epoch: 90 [13440/14860 (90%)]\tLoss: 0.016887\n",
            "Train Epoch: 90 [13568/14860 (91%)]\tLoss: 0.013374\n",
            "Train Epoch: 90 [13696/14860 (91%)]\tLoss: 0.026712\n",
            "Train Epoch: 90 [13824/14860 (92%)]\tLoss: 0.017958\n",
            "Train Epoch: 90 [13952/14860 (93%)]\tLoss: 0.022378\n",
            "Train Epoch: 90 [14080/14860 (94%)]\tLoss: 0.021021\n",
            "Train Epoch: 90 [14208/14860 (95%)]\tLoss: 0.023522\n",
            "Train Epoch: 90 [14336/14860 (96%)]\tLoss: 0.016158\n",
            "Train Epoch: 90 [14464/14860 (97%)]\tLoss: 0.016428\n",
            "Train Epoch: 90 [14592/14860 (97%)]\tLoss: 0.022471\n",
            "Train Epoch: 90 [14720/14860 (98%)]\tLoss: 0.023481\n",
            "Train Epoch: 90 [1392/14860 (99%)]\tLoss: 0.006771\n",
            "epoch 90 training loss: 0.019383996701202333\n",
            "epoch 90 validation loss: 0.020017190504882296\n",
            "Train Epoch: 91 [0/14860 (0%)]\tLoss: 0.018319\n",
            "Train Epoch: 91 [128/14860 (1%)]\tLoss: 0.016565\n",
            "Train Epoch: 91 [256/14860 (2%)]\tLoss: 0.017395\n",
            "Train Epoch: 91 [384/14860 (3%)]\tLoss: 0.014984\n",
            "Train Epoch: 91 [512/14860 (3%)]\tLoss: 0.019750\n",
            "Train Epoch: 91 [640/14860 (4%)]\tLoss: 0.017527\n",
            "Train Epoch: 91 [768/14860 (5%)]\tLoss: 0.018511\n",
            "Train Epoch: 91 [896/14860 (6%)]\tLoss: 0.019975\n",
            "Train Epoch: 91 [1024/14860 (7%)]\tLoss: 0.019421\n",
            "Train Epoch: 91 [1152/14860 (8%)]\tLoss: 0.014771\n",
            "Train Epoch: 91 [1280/14860 (9%)]\tLoss: 0.023020\n",
            "Train Epoch: 91 [1408/14860 (9%)]\tLoss: 0.023524\n",
            "Train Epoch: 91 [1536/14860 (10%)]\tLoss: 0.021898\n",
            "Train Epoch: 91 [1664/14860 (11%)]\tLoss: 0.022604\n",
            "Train Epoch: 91 [1792/14860 (12%)]\tLoss: 0.020924\n",
            "Train Epoch: 91 [1920/14860 (13%)]\tLoss: 0.020732\n",
            "Train Epoch: 91 [2048/14860 (14%)]\tLoss: 0.019891\n",
            "Train Epoch: 91 [2176/14860 (15%)]\tLoss: 0.016596\n",
            "Train Epoch: 91 [2304/14860 (15%)]\tLoss: 0.023988\n",
            "Train Epoch: 91 [2432/14860 (16%)]\tLoss: 0.020187\n",
            "Train Epoch: 91 [2560/14860 (17%)]\tLoss: 0.020218\n",
            "Train Epoch: 91 [2688/14860 (18%)]\tLoss: 0.021901\n",
            "Train Epoch: 91 [2816/14860 (19%)]\tLoss: 0.022485\n",
            "Train Epoch: 91 [2944/14860 (20%)]\tLoss: 0.021963\n",
            "Train Epoch: 91 [3072/14860 (21%)]\tLoss: 0.015647\n",
            "Train Epoch: 91 [3200/14860 (21%)]\tLoss: 0.020753\n",
            "Train Epoch: 91 [3328/14860 (22%)]\tLoss: 0.017173\n",
            "Train Epoch: 91 [3456/14860 (23%)]\tLoss: 0.015894\n",
            "Train Epoch: 91 [3584/14860 (24%)]\tLoss: 0.016220\n",
            "Train Epoch: 91 [3712/14860 (25%)]\tLoss: 0.027079\n",
            "Train Epoch: 91 [3840/14860 (26%)]\tLoss: 0.021351\n",
            "Train Epoch: 91 [3968/14860 (26%)]\tLoss: 0.024886\n",
            "Train Epoch: 91 [4096/14860 (27%)]\tLoss: 0.023869\n",
            "Train Epoch: 91 [4224/14860 (28%)]\tLoss: 0.030740\n",
            "Train Epoch: 91 [4352/14860 (29%)]\tLoss: 0.015648\n",
            "Train Epoch: 91 [4480/14860 (30%)]\tLoss: 0.021688\n",
            "Train Epoch: 91 [4608/14860 (31%)]\tLoss: 0.013182\n",
            "Train Epoch: 91 [4736/14860 (32%)]\tLoss: 0.016156\n",
            "Train Epoch: 91 [4864/14860 (32%)]\tLoss: 0.015252\n",
            "Train Epoch: 91 [4992/14860 (33%)]\tLoss: 0.019563\n",
            "Train Epoch: 91 [5120/14860 (34%)]\tLoss: 0.019719\n",
            "Train Epoch: 91 [5248/14860 (35%)]\tLoss: 0.022591\n",
            "Train Epoch: 91 [5376/14860 (36%)]\tLoss: 0.014448\n",
            "Train Epoch: 91 [5504/14860 (37%)]\tLoss: 0.021818\n",
            "Train Epoch: 91 [5632/14860 (38%)]\tLoss: 0.021427\n",
            "Train Epoch: 91 [5760/14860 (38%)]\tLoss: 0.016908\n",
            "Train Epoch: 91 [5888/14860 (39%)]\tLoss: 0.020775\n",
            "Train Epoch: 91 [6016/14860 (40%)]\tLoss: 0.021844\n",
            "Train Epoch: 91 [6144/14860 (41%)]\tLoss: 0.018318\n",
            "Train Epoch: 91 [6272/14860 (42%)]\tLoss: 0.014455\n",
            "Train Epoch: 91 [6400/14860 (43%)]\tLoss: 0.018756\n",
            "Train Epoch: 91 [6528/14860 (44%)]\tLoss: 0.017831\n",
            "Train Epoch: 91 [6656/14860 (44%)]\tLoss: 0.020405\n",
            "Train Epoch: 91 [6784/14860 (45%)]\tLoss: 0.013848\n",
            "Train Epoch: 91 [6912/14860 (46%)]\tLoss: 0.016154\n",
            "Train Epoch: 91 [7040/14860 (47%)]\tLoss: 0.019852\n",
            "Train Epoch: 91 [7168/14860 (48%)]\tLoss: 0.016407\n",
            "Train Epoch: 91 [7296/14860 (49%)]\tLoss: 0.016263\n",
            "Train Epoch: 91 [7424/14860 (50%)]\tLoss: 0.017620\n",
            "Train Epoch: 91 [7552/14860 (50%)]\tLoss: 0.019351\n",
            "Train Epoch: 91 [7680/14860 (51%)]\tLoss: 0.016424\n",
            "Train Epoch: 91 [7808/14860 (52%)]\tLoss: 0.017327\n",
            "Train Epoch: 91 [7936/14860 (53%)]\tLoss: 0.023305\n",
            "Train Epoch: 91 [8064/14860 (54%)]\tLoss: 0.013985\n",
            "Train Epoch: 91 [8192/14860 (55%)]\tLoss: 0.022218\n",
            "Train Epoch: 91 [8320/14860 (56%)]\tLoss: 0.020931\n",
            "Train Epoch: 91 [8448/14860 (56%)]\tLoss: 0.025555\n",
            "Train Epoch: 91 [8576/14860 (57%)]\tLoss: 0.020141\n",
            "Train Epoch: 91 [8704/14860 (58%)]\tLoss: 0.019279\n",
            "Train Epoch: 91 [8832/14860 (59%)]\tLoss: 0.024879\n",
            "Train Epoch: 91 [8960/14860 (60%)]\tLoss: 0.019123\n",
            "Train Epoch: 91 [9088/14860 (61%)]\tLoss: 0.022852\n",
            "Train Epoch: 91 [9216/14860 (62%)]\tLoss: 0.017962\n",
            "Train Epoch: 91 [9344/14860 (62%)]\tLoss: 0.016645\n",
            "Train Epoch: 91 [9472/14860 (63%)]\tLoss: 0.013336\n",
            "Train Epoch: 91 [9600/14860 (64%)]\tLoss: 0.017072\n",
            "Train Epoch: 91 [9728/14860 (65%)]\tLoss: 0.018195\n",
            "Train Epoch: 91 [9856/14860 (66%)]\tLoss: 0.024527\n",
            "Train Epoch: 91 [9984/14860 (67%)]\tLoss: 0.018153\n",
            "Train Epoch: 91 [10112/14860 (68%)]\tLoss: 0.016252\n",
            "Train Epoch: 91 [10240/14860 (68%)]\tLoss: 0.019196\n",
            "Train Epoch: 91 [10368/14860 (69%)]\tLoss: 0.024787\n",
            "Train Epoch: 91 [10496/14860 (70%)]\tLoss: 0.016799\n",
            "Train Epoch: 91 [10624/14860 (71%)]\tLoss: 0.021668\n",
            "Train Epoch: 91 [10752/14860 (72%)]\tLoss: 0.017369\n",
            "Train Epoch: 91 [10880/14860 (73%)]\tLoss: 0.014961\n",
            "Train Epoch: 91 [11008/14860 (74%)]\tLoss: 0.019221\n",
            "Train Epoch: 91 [11136/14860 (74%)]\tLoss: 0.012560\n",
            "Train Epoch: 91 [11264/14860 (75%)]\tLoss: 0.016928\n",
            "Train Epoch: 91 [11392/14860 (76%)]\tLoss: 0.019187\n",
            "Train Epoch: 91 [11520/14860 (77%)]\tLoss: 0.020652\n",
            "Train Epoch: 91 [11648/14860 (78%)]\tLoss: 0.016399\n",
            "Train Epoch: 91 [11776/14860 (79%)]\tLoss: 0.021832\n",
            "Train Epoch: 91 [11904/14860 (79%)]\tLoss: 0.012229\n",
            "Train Epoch: 91 [12032/14860 (80%)]\tLoss: 0.022478\n",
            "Train Epoch: 91 [12160/14860 (81%)]\tLoss: 0.011666\n",
            "Train Epoch: 91 [12288/14860 (82%)]\tLoss: 0.021423\n",
            "Train Epoch: 91 [12416/14860 (83%)]\tLoss: 0.020270\n",
            "Train Epoch: 91 [12544/14860 (84%)]\tLoss: 0.015792\n",
            "Train Epoch: 91 [12672/14860 (85%)]\tLoss: 0.017712\n",
            "Train Epoch: 91 [12800/14860 (85%)]\tLoss: 0.017220\n",
            "Train Epoch: 91 [12928/14860 (86%)]\tLoss: 0.023603\n",
            "Train Epoch: 91 [13056/14860 (87%)]\tLoss: 0.016560\n",
            "Train Epoch: 91 [13184/14860 (88%)]\tLoss: 0.030579\n",
            "Train Epoch: 91 [13312/14860 (89%)]\tLoss: 0.019157\n",
            "Train Epoch: 91 [13440/14860 (90%)]\tLoss: 0.019015\n",
            "Train Epoch: 91 [13568/14860 (91%)]\tLoss: 0.021450\n",
            "Train Epoch: 91 [13696/14860 (91%)]\tLoss: 0.012787\n",
            "Train Epoch: 91 [13824/14860 (92%)]\tLoss: 0.023471\n",
            "Train Epoch: 91 [13952/14860 (93%)]\tLoss: 0.018473\n",
            "Train Epoch: 91 [14080/14860 (94%)]\tLoss: 0.020861\n",
            "Train Epoch: 91 [14208/14860 (95%)]\tLoss: 0.016395\n",
            "Train Epoch: 91 [14336/14860 (96%)]\tLoss: 0.021812\n",
            "Train Epoch: 91 [14464/14860 (97%)]\tLoss: 0.017373\n",
            "Train Epoch: 91 [14592/14860 (97%)]\tLoss: 0.012244\n",
            "Train Epoch: 91 [14720/14860 (98%)]\tLoss: 0.017109\n",
            "Train Epoch: 91 [1392/14860 (99%)]\tLoss: 0.035854\n",
            "epoch 91 training loss: 0.019284515800830137\n",
            "epoch 91 validation loss: 0.022215580391826122\n",
            "Train Epoch: 92 [0/14860 (0%)]\tLoss: 0.019779\n",
            "Train Epoch: 92 [128/14860 (1%)]\tLoss: 0.016946\n",
            "Train Epoch: 92 [256/14860 (2%)]\tLoss: 0.019751\n",
            "Train Epoch: 92 [384/14860 (3%)]\tLoss: 0.016867\n",
            "Train Epoch: 92 [512/14860 (3%)]\tLoss: 0.012845\n",
            "Train Epoch: 92 [640/14860 (4%)]\tLoss: 0.019077\n",
            "Train Epoch: 92 [768/14860 (5%)]\tLoss: 0.021304\n",
            "Train Epoch: 92 [896/14860 (6%)]\tLoss: 0.026113\n",
            "Train Epoch: 92 [1024/14860 (7%)]\tLoss: 0.023037\n",
            "Train Epoch: 92 [1152/14860 (8%)]\tLoss: 0.022472\n",
            "Train Epoch: 92 [1280/14860 (9%)]\tLoss: 0.020255\n",
            "Train Epoch: 92 [1408/14860 (9%)]\tLoss: 0.013081\n",
            "Train Epoch: 92 [1536/14860 (10%)]\tLoss: 0.018741\n",
            "Train Epoch: 92 [1664/14860 (11%)]\tLoss: 0.017979\n",
            "Train Epoch: 92 [1792/14860 (12%)]\tLoss: 0.021466\n",
            "Train Epoch: 92 [1920/14860 (13%)]\tLoss: 0.019604\n",
            "Train Epoch: 92 [2048/14860 (14%)]\tLoss: 0.019565\n",
            "Train Epoch: 92 [2176/14860 (15%)]\tLoss: 0.020203\n",
            "Train Epoch: 92 [2304/14860 (15%)]\tLoss: 0.016820\n",
            "Train Epoch: 92 [2432/14860 (16%)]\tLoss: 0.014929\n",
            "Train Epoch: 92 [2560/14860 (17%)]\tLoss: 0.020463\n",
            "Train Epoch: 92 [2688/14860 (18%)]\tLoss: 0.021493\n",
            "Train Epoch: 92 [2816/14860 (19%)]\tLoss: 0.023518\n",
            "Train Epoch: 92 [2944/14860 (20%)]\tLoss: 0.014206\n",
            "Train Epoch: 92 [3072/14860 (21%)]\tLoss: 0.023563\n",
            "Train Epoch: 92 [3200/14860 (21%)]\tLoss: 0.020708\n",
            "Train Epoch: 92 [3328/14860 (22%)]\tLoss: 0.021435\n",
            "Train Epoch: 92 [3456/14860 (23%)]\tLoss: 0.015585\n",
            "Train Epoch: 92 [3584/14860 (24%)]\tLoss: 0.021720\n",
            "Train Epoch: 92 [3712/14860 (25%)]\tLoss: 0.029581\n",
            "Train Epoch: 92 [3840/14860 (26%)]\tLoss: 0.019479\n",
            "Train Epoch: 92 [3968/14860 (26%)]\tLoss: 0.027011\n",
            "Train Epoch: 92 [4096/14860 (27%)]\tLoss: 0.017259\n",
            "Train Epoch: 92 [4224/14860 (28%)]\tLoss: 0.018290\n",
            "Train Epoch: 92 [4352/14860 (29%)]\tLoss: 0.021091\n",
            "Train Epoch: 92 [4480/14860 (30%)]\tLoss: 0.027430\n",
            "Train Epoch: 92 [4608/14860 (31%)]\tLoss: 0.020927\n",
            "Train Epoch: 92 [4736/14860 (32%)]\tLoss: 0.018136\n",
            "Train Epoch: 92 [4864/14860 (32%)]\tLoss: 0.025538\n",
            "Train Epoch: 92 [4992/14860 (33%)]\tLoss: 0.019538\n",
            "Train Epoch: 92 [5120/14860 (34%)]\tLoss: 0.014610\n",
            "Train Epoch: 92 [5248/14860 (35%)]\tLoss: 0.023067\n",
            "Train Epoch: 92 [5376/14860 (36%)]\tLoss: 0.016931\n",
            "Train Epoch: 92 [5504/14860 (37%)]\tLoss: 0.019724\n",
            "Train Epoch: 92 [5632/14860 (38%)]\tLoss: 0.017912\n",
            "Train Epoch: 92 [5760/14860 (38%)]\tLoss: 0.019065\n",
            "Train Epoch: 92 [5888/14860 (39%)]\tLoss: 0.017750\n",
            "Train Epoch: 92 [6016/14860 (40%)]\tLoss: 0.021619\n",
            "Train Epoch: 92 [6144/14860 (41%)]\tLoss: 0.017042\n",
            "Train Epoch: 92 [6272/14860 (42%)]\tLoss: 0.016828\n",
            "Train Epoch: 92 [6400/14860 (43%)]\tLoss: 0.023498\n",
            "Train Epoch: 92 [6528/14860 (44%)]\tLoss: 0.013485\n",
            "Train Epoch: 92 [6656/14860 (44%)]\tLoss: 0.012473\n",
            "Train Epoch: 92 [6784/14860 (45%)]\tLoss: 0.027709\n",
            "Train Epoch: 92 [6912/14860 (46%)]\tLoss: 0.012442\n",
            "Train Epoch: 92 [7040/14860 (47%)]\tLoss: 0.014288\n",
            "Train Epoch: 92 [7168/14860 (48%)]\tLoss: 0.020484\n",
            "Train Epoch: 92 [7296/14860 (49%)]\tLoss: 0.014448\n",
            "Train Epoch: 92 [7424/14860 (50%)]\tLoss: 0.015281\n",
            "Train Epoch: 92 [7552/14860 (50%)]\tLoss: 0.017094\n",
            "Train Epoch: 92 [7680/14860 (51%)]\tLoss: 0.014758\n",
            "Train Epoch: 92 [7808/14860 (52%)]\tLoss: 0.019163\n",
            "Train Epoch: 92 [7936/14860 (53%)]\tLoss: 0.014706\n",
            "Train Epoch: 92 [8064/14860 (54%)]\tLoss: 0.021786\n",
            "Train Epoch: 92 [8192/14860 (55%)]\tLoss: 0.024667\n",
            "Train Epoch: 92 [8320/14860 (56%)]\tLoss: 0.023148\n",
            "Train Epoch: 92 [8448/14860 (56%)]\tLoss: 0.016784\n",
            "Train Epoch: 92 [8576/14860 (57%)]\tLoss: 0.016806\n",
            "Train Epoch: 92 [8704/14860 (58%)]\tLoss: 0.016966\n",
            "Train Epoch: 92 [8832/14860 (59%)]\tLoss: 0.018568\n",
            "Train Epoch: 92 [8960/14860 (60%)]\tLoss: 0.015587\n",
            "Train Epoch: 92 [9088/14860 (61%)]\tLoss: 0.015905\n",
            "Train Epoch: 92 [9216/14860 (62%)]\tLoss: 0.023295\n",
            "Train Epoch: 92 [9344/14860 (62%)]\tLoss: 0.018370\n",
            "Train Epoch: 92 [9472/14860 (63%)]\tLoss: 0.012980\n",
            "Train Epoch: 92 [9600/14860 (64%)]\tLoss: 0.034567\n",
            "Train Epoch: 92 [9728/14860 (65%)]\tLoss: 0.026043\n",
            "Train Epoch: 92 [9856/14860 (66%)]\tLoss: 0.020010\n",
            "Train Epoch: 92 [9984/14860 (67%)]\tLoss: 0.022449\n",
            "Train Epoch: 92 [10112/14860 (68%)]\tLoss: 0.022714\n",
            "Train Epoch: 92 [10240/14860 (68%)]\tLoss: 0.019561\n",
            "Train Epoch: 92 [10368/14860 (69%)]\tLoss: 0.014831\n",
            "Train Epoch: 92 [10496/14860 (70%)]\tLoss: 0.020245\n",
            "Train Epoch: 92 [10624/14860 (71%)]\tLoss: 0.012178\n",
            "Train Epoch: 92 [10752/14860 (72%)]\tLoss: 0.013229\n",
            "Train Epoch: 92 [10880/14860 (73%)]\tLoss: 0.019176\n",
            "Train Epoch: 92 [11008/14860 (74%)]\tLoss: 0.021495\n",
            "Train Epoch: 92 [11136/14860 (74%)]\tLoss: 0.024929\n",
            "Train Epoch: 92 [11264/14860 (75%)]\tLoss: 0.011235\n",
            "Train Epoch: 92 [11392/14860 (76%)]\tLoss: 0.022507\n",
            "Train Epoch: 92 [11520/14860 (77%)]\tLoss: 0.034594\n",
            "Train Epoch: 92 [11648/14860 (78%)]\tLoss: 0.018265\n",
            "Train Epoch: 92 [11776/14860 (79%)]\tLoss: 0.022138\n",
            "Train Epoch: 92 [11904/14860 (79%)]\tLoss: 0.028142\n",
            "Train Epoch: 92 [12032/14860 (80%)]\tLoss: 0.020122\n",
            "Train Epoch: 92 [12160/14860 (81%)]\tLoss: 0.019723\n",
            "Train Epoch: 92 [12288/14860 (82%)]\tLoss: 0.035517\n",
            "Train Epoch: 92 [12416/14860 (83%)]\tLoss: 0.017092\n",
            "Train Epoch: 92 [12544/14860 (84%)]\tLoss: 0.019367\n",
            "Train Epoch: 92 [12672/14860 (85%)]\tLoss: 0.017739\n",
            "Train Epoch: 92 [12800/14860 (85%)]\tLoss: 0.016142\n",
            "Train Epoch: 92 [12928/14860 (86%)]\tLoss: 0.013121\n",
            "Train Epoch: 92 [13056/14860 (87%)]\tLoss: 0.022779\n",
            "Train Epoch: 92 [13184/14860 (88%)]\tLoss: 0.020329\n",
            "Train Epoch: 92 [13312/14860 (89%)]\tLoss: 0.013729\n",
            "Train Epoch: 92 [13440/14860 (90%)]\tLoss: 0.017524\n",
            "Train Epoch: 92 [13568/14860 (91%)]\tLoss: 0.021531\n",
            "Train Epoch: 92 [13696/14860 (91%)]\tLoss: 0.015509\n",
            "Train Epoch: 92 [13824/14860 (92%)]\tLoss: 0.023177\n",
            "Train Epoch: 92 [13952/14860 (93%)]\tLoss: 0.020027\n",
            "Train Epoch: 92 [14080/14860 (94%)]\tLoss: 0.017893\n",
            "Train Epoch: 92 [14208/14860 (95%)]\tLoss: 0.020978\n",
            "Train Epoch: 92 [14336/14860 (96%)]\tLoss: 0.021101\n",
            "Train Epoch: 92 [14464/14860 (97%)]\tLoss: 0.019668\n",
            "Train Epoch: 92 [14592/14860 (97%)]\tLoss: 0.015971\n",
            "Train Epoch: 92 [14720/14860 (98%)]\tLoss: 0.022345\n",
            "Train Epoch: 92 [1392/14860 (99%)]\tLoss: 0.009185\n",
            "epoch 92 training loss: 0.01953777474247747\n",
            "epoch 92 validation loss: 0.02017437791131599\n",
            "Train Epoch: 93 [0/14860 (0%)]\tLoss: 0.015027\n",
            "Train Epoch: 93 [128/14860 (1%)]\tLoss: 0.015642\n",
            "Train Epoch: 93 [256/14860 (2%)]\tLoss: 0.020844\n",
            "Train Epoch: 93 [384/14860 (3%)]\tLoss: 0.019076\n",
            "Train Epoch: 93 [512/14860 (3%)]\tLoss: 0.016995\n",
            "Train Epoch: 93 [640/14860 (4%)]\tLoss: 0.013533\n",
            "Train Epoch: 93 [768/14860 (5%)]\tLoss: 0.015396\n",
            "Train Epoch: 93 [896/14860 (6%)]\tLoss: 0.020814\n",
            "Train Epoch: 93 [1024/14860 (7%)]\tLoss: 0.017700\n",
            "Train Epoch: 93 [1152/14860 (8%)]\tLoss: 0.016941\n",
            "Train Epoch: 93 [1280/14860 (9%)]\tLoss: 0.023175\n",
            "Train Epoch: 93 [1408/14860 (9%)]\tLoss: 0.022984\n",
            "Train Epoch: 93 [1536/14860 (10%)]\tLoss: 0.013773\n",
            "Train Epoch: 93 [1664/14860 (11%)]\tLoss: 0.025774\n",
            "Train Epoch: 93 [1792/14860 (12%)]\tLoss: 0.013636\n",
            "Train Epoch: 93 [1920/14860 (13%)]\tLoss: 0.018293\n",
            "Train Epoch: 93 [2048/14860 (14%)]\tLoss: 0.017512\n",
            "Train Epoch: 93 [2176/14860 (15%)]\tLoss: 0.021050\n",
            "Train Epoch: 93 [2304/14860 (15%)]\tLoss: 0.019482\n",
            "Train Epoch: 93 [2432/14860 (16%)]\tLoss: 0.018976\n",
            "Train Epoch: 93 [2560/14860 (17%)]\tLoss: 0.016367\n",
            "Train Epoch: 93 [2688/14860 (18%)]\tLoss: 0.020675\n",
            "Train Epoch: 93 [2816/14860 (19%)]\tLoss: 0.020131\n",
            "Train Epoch: 93 [2944/14860 (20%)]\tLoss: 0.014271\n",
            "Train Epoch: 93 [3072/14860 (21%)]\tLoss: 0.015199\n",
            "Train Epoch: 93 [3200/14860 (21%)]\tLoss: 0.018520\n",
            "Train Epoch: 93 [3328/14860 (22%)]\tLoss: 0.026699\n",
            "Train Epoch: 93 [3456/14860 (23%)]\tLoss: 0.030563\n",
            "Train Epoch: 93 [3584/14860 (24%)]\tLoss: 0.023928\n",
            "Train Epoch: 93 [3712/14860 (25%)]\tLoss: 0.022485\n",
            "Train Epoch: 93 [3840/14860 (26%)]\tLoss: 0.021577\n",
            "Train Epoch: 93 [3968/14860 (26%)]\tLoss: 0.021922\n",
            "Train Epoch: 93 [4096/14860 (27%)]\tLoss: 0.018344\n",
            "Train Epoch: 93 [4224/14860 (28%)]\tLoss: 0.019256\n",
            "Train Epoch: 93 [4352/14860 (29%)]\tLoss: 0.020288\n",
            "Train Epoch: 93 [4480/14860 (30%)]\tLoss: 0.030502\n",
            "Train Epoch: 93 [4608/14860 (31%)]\tLoss: 0.022287\n",
            "Train Epoch: 93 [4736/14860 (32%)]\tLoss: 0.018958\n",
            "Train Epoch: 93 [4864/14860 (32%)]\tLoss: 0.016789\n",
            "Train Epoch: 93 [4992/14860 (33%)]\tLoss: 0.015238\n",
            "Train Epoch: 93 [5120/14860 (34%)]\tLoss: 0.021209\n",
            "Train Epoch: 93 [5248/14860 (35%)]\tLoss: 0.021931\n",
            "Train Epoch: 93 [5376/14860 (36%)]\tLoss: 0.022516\n",
            "Train Epoch: 93 [5504/14860 (37%)]\tLoss: 0.024982\n",
            "Train Epoch: 93 [5632/14860 (38%)]\tLoss: 0.017265\n",
            "Train Epoch: 93 [5760/14860 (38%)]\tLoss: 0.014052\n",
            "Train Epoch: 93 [5888/14860 (39%)]\tLoss: 0.019614\n",
            "Train Epoch: 93 [6016/14860 (40%)]\tLoss: 0.024689\n",
            "Train Epoch: 93 [6144/14860 (41%)]\tLoss: 0.016292\n",
            "Train Epoch: 93 [6272/14860 (42%)]\tLoss: 0.016581\n",
            "Train Epoch: 93 [6400/14860 (43%)]\tLoss: 0.021943\n",
            "Train Epoch: 93 [6528/14860 (44%)]\tLoss: 0.018071\n",
            "Train Epoch: 93 [6656/14860 (44%)]\tLoss: 0.036435\n",
            "Train Epoch: 93 [6784/14860 (45%)]\tLoss: 0.017267\n",
            "Train Epoch: 93 [6912/14860 (46%)]\tLoss: 0.021219\n",
            "Train Epoch: 93 [7040/14860 (47%)]\tLoss: 0.014257\n",
            "Train Epoch: 93 [7168/14860 (48%)]\tLoss: 0.017089\n",
            "Train Epoch: 93 [7296/14860 (49%)]\tLoss: 0.024268\n",
            "Train Epoch: 93 [7424/14860 (50%)]\tLoss: 0.034239\n",
            "Train Epoch: 93 [7552/14860 (50%)]\tLoss: 0.015190\n",
            "Train Epoch: 93 [7680/14860 (51%)]\tLoss: 0.020144\n",
            "Train Epoch: 93 [7808/14860 (52%)]\tLoss: 0.030244\n",
            "Train Epoch: 93 [7936/14860 (53%)]\tLoss: 0.024282\n",
            "Train Epoch: 93 [8064/14860 (54%)]\tLoss: 0.017986\n",
            "Train Epoch: 93 [8192/14860 (55%)]\tLoss: 0.028675\n",
            "Train Epoch: 93 [8320/14860 (56%)]\tLoss: 0.012943\n",
            "Train Epoch: 93 [8448/14860 (56%)]\tLoss: 0.021285\n",
            "Train Epoch: 93 [8576/14860 (57%)]\tLoss: 0.017146\n",
            "Train Epoch: 93 [8704/14860 (58%)]\tLoss: 0.023562\n",
            "Train Epoch: 93 [8832/14860 (59%)]\tLoss: 0.020196\n",
            "Train Epoch: 93 [8960/14860 (60%)]\tLoss: 0.016399\n",
            "Train Epoch: 93 [9088/14860 (61%)]\tLoss: 0.026805\n",
            "Train Epoch: 93 [9216/14860 (62%)]\tLoss: 0.017874\n",
            "Train Epoch: 93 [9344/14860 (62%)]\tLoss: 0.016648\n",
            "Train Epoch: 93 [9472/14860 (63%)]\tLoss: 0.022253\n",
            "Train Epoch: 93 [9600/14860 (64%)]\tLoss: 0.018432\n",
            "Train Epoch: 93 [9728/14860 (65%)]\tLoss: 0.020178\n",
            "Train Epoch: 93 [9856/14860 (66%)]\tLoss: 0.016798\n",
            "Train Epoch: 93 [9984/14860 (67%)]\tLoss: 0.018737\n",
            "Train Epoch: 93 [10112/14860 (68%)]\tLoss: 0.014650\n",
            "Train Epoch: 93 [10240/14860 (68%)]\tLoss: 0.019082\n",
            "Train Epoch: 93 [10368/14860 (69%)]\tLoss: 0.026054\n",
            "Train Epoch: 93 [10496/14860 (70%)]\tLoss: 0.021722\n",
            "Train Epoch: 93 [10624/14860 (71%)]\tLoss: 0.024625\n",
            "Train Epoch: 93 [10752/14860 (72%)]\tLoss: 0.027431\n",
            "Train Epoch: 93 [10880/14860 (73%)]\tLoss: 0.020724\n",
            "Train Epoch: 93 [11008/14860 (74%)]\tLoss: 0.020663\n",
            "Train Epoch: 93 [11136/14860 (74%)]\tLoss: 0.021999\n",
            "Train Epoch: 93 [11264/14860 (75%)]\tLoss: 0.016288\n",
            "Train Epoch: 93 [11392/14860 (76%)]\tLoss: 0.013169\n",
            "Train Epoch: 93 [11520/14860 (77%)]\tLoss: 0.016972\n",
            "Train Epoch: 93 [11648/14860 (78%)]\tLoss: 0.019563\n",
            "Train Epoch: 93 [11776/14860 (79%)]\tLoss: 0.020280\n",
            "Train Epoch: 93 [11904/14860 (79%)]\tLoss: 0.013744\n",
            "Train Epoch: 93 [12032/14860 (80%)]\tLoss: 0.023831\n",
            "Train Epoch: 93 [12160/14860 (81%)]\tLoss: 0.022450\n",
            "Train Epoch: 93 [12288/14860 (82%)]\tLoss: 0.011245\n",
            "Train Epoch: 93 [12416/14860 (83%)]\tLoss: 0.025880\n",
            "Train Epoch: 93 [12544/14860 (84%)]\tLoss: 0.020398\n",
            "Train Epoch: 93 [12672/14860 (85%)]\tLoss: 0.019249\n",
            "Train Epoch: 93 [12800/14860 (85%)]\tLoss: 0.022908\n",
            "Train Epoch: 93 [12928/14860 (86%)]\tLoss: 0.016128\n",
            "Train Epoch: 93 [13056/14860 (87%)]\tLoss: 0.016754\n",
            "Train Epoch: 93 [13184/14860 (88%)]\tLoss: 0.019967\n",
            "Train Epoch: 93 [13312/14860 (89%)]\tLoss: 0.017735\n",
            "Train Epoch: 93 [13440/14860 (90%)]\tLoss: 0.018784\n",
            "Train Epoch: 93 [13568/14860 (91%)]\tLoss: 0.011814\n",
            "Train Epoch: 93 [13696/14860 (91%)]\tLoss: 0.020693\n",
            "Train Epoch: 93 [13824/14860 (92%)]\tLoss: 0.014282\n",
            "Train Epoch: 93 [13952/14860 (93%)]\tLoss: 0.018369\n",
            "Train Epoch: 93 [14080/14860 (94%)]\tLoss: 0.016959\n",
            "Train Epoch: 93 [14208/14860 (95%)]\tLoss: 0.012110\n",
            "Train Epoch: 93 [14336/14860 (96%)]\tLoss: 0.016063\n",
            "Train Epoch: 93 [14464/14860 (97%)]\tLoss: 0.020048\n",
            "Train Epoch: 93 [14592/14860 (97%)]\tLoss: 0.016074\n",
            "Train Epoch: 93 [14720/14860 (98%)]\tLoss: 0.019868\n",
            "Train Epoch: 93 [1392/14860 (99%)]\tLoss: 0.027626\n",
            "epoch 93 training loss: 0.019799280044041637\n",
            "epoch 93 validation loss: 0.022569152258210264\n",
            "Train Epoch: 94 [0/14860 (0%)]\tLoss: 0.019512\n",
            "Train Epoch: 94 [128/14860 (1%)]\tLoss: 0.020359\n",
            "Train Epoch: 94 [256/14860 (2%)]\tLoss: 0.021237\n",
            "Train Epoch: 94 [384/14860 (3%)]\tLoss: 0.019161\n",
            "Train Epoch: 94 [512/14860 (3%)]\tLoss: 0.018431\n",
            "Train Epoch: 94 [640/14860 (4%)]\tLoss: 0.018028\n",
            "Train Epoch: 94 [768/14860 (5%)]\tLoss: 0.018516\n",
            "Train Epoch: 94 [896/14860 (6%)]\tLoss: 0.021422\n",
            "Train Epoch: 94 [1024/14860 (7%)]\tLoss: 0.020844\n",
            "Train Epoch: 94 [1152/14860 (8%)]\tLoss: 0.025181\n",
            "Train Epoch: 94 [1280/14860 (9%)]\tLoss: 0.021027\n",
            "Train Epoch: 94 [1408/14860 (9%)]\tLoss: 0.017775\n",
            "Train Epoch: 94 [1536/14860 (10%)]\tLoss: 0.023677\n",
            "Train Epoch: 94 [1664/14860 (11%)]\tLoss: 0.024847\n",
            "Train Epoch: 94 [1792/14860 (12%)]\tLoss: 0.014749\n",
            "Train Epoch: 94 [1920/14860 (13%)]\tLoss: 0.017394\n",
            "Train Epoch: 94 [2048/14860 (14%)]\tLoss: 0.026591\n",
            "Train Epoch: 94 [2176/14860 (15%)]\tLoss: 0.018483\n",
            "Train Epoch: 94 [2304/14860 (15%)]\tLoss: 0.021006\n",
            "Train Epoch: 94 [2432/14860 (16%)]\tLoss: 0.018296\n",
            "Train Epoch: 94 [2560/14860 (17%)]\tLoss: 0.015608\n",
            "Train Epoch: 94 [2688/14860 (18%)]\tLoss: 0.021112\n",
            "Train Epoch: 94 [2816/14860 (19%)]\tLoss: 0.023317\n",
            "Train Epoch: 94 [2944/14860 (20%)]\tLoss: 0.018937\n",
            "Train Epoch: 94 [3072/14860 (21%)]\tLoss: 0.020324\n",
            "Train Epoch: 94 [3200/14860 (21%)]\tLoss: 0.024873\n",
            "Train Epoch: 94 [3328/14860 (22%)]\tLoss: 0.015686\n",
            "Train Epoch: 94 [3456/14860 (23%)]\tLoss: 0.018171\n",
            "Train Epoch: 94 [3584/14860 (24%)]\tLoss: 0.024531\n",
            "Train Epoch: 94 [3712/14860 (25%)]\tLoss: 0.013664\n",
            "Train Epoch: 94 [3840/14860 (26%)]\tLoss: 0.019123\n",
            "Train Epoch: 94 [3968/14860 (26%)]\tLoss: 0.021445\n",
            "Train Epoch: 94 [4096/14860 (27%)]\tLoss: 0.016855\n",
            "Train Epoch: 94 [4224/14860 (28%)]\tLoss: 0.020847\n",
            "Train Epoch: 94 [4352/14860 (29%)]\tLoss: 0.013694\n",
            "Train Epoch: 94 [4480/14860 (30%)]\tLoss: 0.016976\n",
            "Train Epoch: 94 [4608/14860 (31%)]\tLoss: 0.019636\n",
            "Train Epoch: 94 [4736/14860 (32%)]\tLoss: 0.021829\n",
            "Train Epoch: 94 [4864/14860 (32%)]\tLoss: 0.024041\n",
            "Train Epoch: 94 [4992/14860 (33%)]\tLoss: 0.024418\n",
            "Train Epoch: 94 [5120/14860 (34%)]\tLoss: 0.029453\n",
            "Train Epoch: 94 [5248/14860 (35%)]\tLoss: 0.019267\n",
            "Train Epoch: 94 [5376/14860 (36%)]\tLoss: 0.026143\n",
            "Train Epoch: 94 [5504/14860 (37%)]\tLoss: 0.012438\n",
            "Train Epoch: 94 [5632/14860 (38%)]\tLoss: 0.020448\n",
            "Train Epoch: 94 [5760/14860 (38%)]\tLoss: 0.013605\n",
            "Train Epoch: 94 [5888/14860 (39%)]\tLoss: 0.017960\n",
            "Train Epoch: 94 [6016/14860 (40%)]\tLoss: 0.019704\n",
            "Train Epoch: 94 [6144/14860 (41%)]\tLoss: 0.014663\n",
            "Train Epoch: 94 [6272/14860 (42%)]\tLoss: 0.029376\n",
            "Train Epoch: 94 [6400/14860 (43%)]\tLoss: 0.017270\n",
            "Train Epoch: 94 [6528/14860 (44%)]\tLoss: 0.025363\n",
            "Train Epoch: 94 [6656/14860 (44%)]\tLoss: 0.024395\n",
            "Train Epoch: 94 [6784/14860 (45%)]\tLoss: 0.016117\n",
            "Train Epoch: 94 [6912/14860 (46%)]\tLoss: 0.018977\n",
            "Train Epoch: 94 [7040/14860 (47%)]\tLoss: 0.022545\n",
            "Train Epoch: 94 [7168/14860 (48%)]\tLoss: 0.017439\n",
            "Train Epoch: 94 [7296/14860 (49%)]\tLoss: 0.018884\n",
            "Train Epoch: 94 [7424/14860 (50%)]\tLoss: 0.017665\n",
            "Train Epoch: 94 [7552/14860 (50%)]\tLoss: 0.016506\n",
            "Train Epoch: 94 [7680/14860 (51%)]\tLoss: 0.021285\n",
            "Train Epoch: 94 [7808/14860 (52%)]\tLoss: 0.019189\n",
            "Train Epoch: 94 [7936/14860 (53%)]\tLoss: 0.021465\n",
            "Train Epoch: 94 [8064/14860 (54%)]\tLoss: 0.014099\n",
            "Train Epoch: 94 [8192/14860 (55%)]\tLoss: 0.022495\n",
            "Train Epoch: 94 [8320/14860 (56%)]\tLoss: 0.018096\n",
            "Train Epoch: 94 [8448/14860 (56%)]\tLoss: 0.022127\n",
            "Train Epoch: 94 [8576/14860 (57%)]\tLoss: 0.019810\n",
            "Train Epoch: 94 [8704/14860 (58%)]\tLoss: 0.021810\n",
            "Train Epoch: 94 [8832/14860 (59%)]\tLoss: 0.018715\n",
            "Train Epoch: 94 [8960/14860 (60%)]\tLoss: 0.022961\n",
            "Train Epoch: 94 [9088/14860 (61%)]\tLoss: 0.018674\n",
            "Train Epoch: 94 [9216/14860 (62%)]\tLoss: 0.021184\n",
            "Train Epoch: 94 [9344/14860 (62%)]\tLoss: 0.029604\n",
            "Train Epoch: 94 [9472/14860 (63%)]\tLoss: 0.019789\n",
            "Train Epoch: 94 [9600/14860 (64%)]\tLoss: 0.018811\n",
            "Train Epoch: 94 [9728/14860 (65%)]\tLoss: 0.013860\n",
            "Train Epoch: 94 [9856/14860 (66%)]\tLoss: 0.017429\n",
            "Train Epoch: 94 [9984/14860 (67%)]\tLoss: 0.014837\n",
            "Train Epoch: 94 [10112/14860 (68%)]\tLoss: 0.021734\n",
            "Train Epoch: 94 [10240/14860 (68%)]\tLoss: 0.024567\n",
            "Train Epoch: 94 [10368/14860 (69%)]\tLoss: 0.026155\n",
            "Train Epoch: 94 [10496/14860 (70%)]\tLoss: 0.016371\n",
            "Train Epoch: 94 [10624/14860 (71%)]\tLoss: 0.016344\n",
            "Train Epoch: 94 [10752/14860 (72%)]\tLoss: 0.019371\n",
            "Train Epoch: 94 [10880/14860 (73%)]\tLoss: 0.018966\n",
            "Train Epoch: 94 [11008/14860 (74%)]\tLoss: 0.013506\n",
            "Train Epoch: 94 [11136/14860 (74%)]\tLoss: 0.018927\n",
            "Train Epoch: 94 [11264/14860 (75%)]\tLoss: 0.017257\n",
            "Train Epoch: 94 [11392/14860 (76%)]\tLoss: 0.021524\n",
            "Train Epoch: 94 [11520/14860 (77%)]\tLoss: 0.015844\n",
            "Train Epoch: 94 [11648/14860 (78%)]\tLoss: 0.023104\n",
            "Train Epoch: 94 [11776/14860 (79%)]\tLoss: 0.017747\n",
            "Train Epoch: 94 [11904/14860 (79%)]\tLoss: 0.023048\n",
            "Train Epoch: 94 [12032/14860 (80%)]\tLoss: 0.019680\n",
            "Train Epoch: 94 [12160/14860 (81%)]\tLoss: 0.018047\n",
            "Train Epoch: 94 [12288/14860 (82%)]\tLoss: 0.023399\n",
            "Train Epoch: 94 [12416/14860 (83%)]\tLoss: 0.017411\n",
            "Train Epoch: 94 [12544/14860 (84%)]\tLoss: 0.015212\n",
            "Train Epoch: 94 [12672/14860 (85%)]\tLoss: 0.017341\n",
            "Train Epoch: 94 [12800/14860 (85%)]\tLoss: 0.021263\n",
            "Train Epoch: 94 [12928/14860 (86%)]\tLoss: 0.022500\n",
            "Train Epoch: 94 [13056/14860 (87%)]\tLoss: 0.017815\n",
            "Train Epoch: 94 [13184/14860 (88%)]\tLoss: 0.018549\n",
            "Train Epoch: 94 [13312/14860 (89%)]\tLoss: 0.023177\n",
            "Train Epoch: 94 [13440/14860 (90%)]\tLoss: 0.015512\n",
            "Train Epoch: 94 [13568/14860 (91%)]\tLoss: 0.017782\n",
            "Train Epoch: 94 [13696/14860 (91%)]\tLoss: 0.017719\n",
            "Train Epoch: 94 [13824/14860 (92%)]\tLoss: 0.017891\n",
            "Train Epoch: 94 [13952/14860 (93%)]\tLoss: 0.020666\n",
            "Train Epoch: 94 [14080/14860 (94%)]\tLoss: 0.021751\n",
            "Train Epoch: 94 [14208/14860 (95%)]\tLoss: 0.022234\n",
            "Train Epoch: 94 [14336/14860 (96%)]\tLoss: 0.020556\n",
            "Train Epoch: 94 [14464/14860 (97%)]\tLoss: 0.015801\n",
            "Train Epoch: 94 [14592/14860 (97%)]\tLoss: 0.017668\n",
            "Train Epoch: 94 [14720/14860 (98%)]\tLoss: 0.025043\n",
            "Train Epoch: 94 [1392/14860 (99%)]\tLoss: 0.011360\n",
            "epoch 94 training loss: 0.019734396670873348\n",
            "epoch 94 validation loss: 0.020335350501335274\n",
            "Train Epoch: 95 [0/14860 (0%)]\tLoss: 0.021776\n",
            "Train Epoch: 95 [128/14860 (1%)]\tLoss: 0.020142\n",
            "Train Epoch: 95 [256/14860 (2%)]\tLoss: 0.023302\n",
            "Train Epoch: 95 [384/14860 (3%)]\tLoss: 0.014979\n",
            "Train Epoch: 95 [512/14860 (3%)]\tLoss: 0.016795\n",
            "Train Epoch: 95 [640/14860 (4%)]\tLoss: 0.023246\n",
            "Train Epoch: 95 [768/14860 (5%)]\tLoss: 0.012810\n",
            "Train Epoch: 95 [896/14860 (6%)]\tLoss: 0.015983\n",
            "Train Epoch: 95 [1024/14860 (7%)]\tLoss: 0.018961\n",
            "Train Epoch: 95 [1152/14860 (8%)]\tLoss: 0.027158\n",
            "Train Epoch: 95 [1280/14860 (9%)]\tLoss: 0.017862\n",
            "Train Epoch: 95 [1408/14860 (9%)]\tLoss: 0.021491\n",
            "Train Epoch: 95 [1536/14860 (10%)]\tLoss: 0.019246\n",
            "Train Epoch: 95 [1664/14860 (11%)]\tLoss: 0.017749\n",
            "Train Epoch: 95 [1792/14860 (12%)]\tLoss: 0.018234\n",
            "Train Epoch: 95 [1920/14860 (13%)]\tLoss: 0.015778\n",
            "Train Epoch: 95 [2048/14860 (14%)]\tLoss: 0.019206\n",
            "Train Epoch: 95 [2176/14860 (15%)]\tLoss: 0.022841\n",
            "Train Epoch: 95 [2304/14860 (15%)]\tLoss: 0.016585\n",
            "Train Epoch: 95 [2432/14860 (16%)]\tLoss: 0.014107\n",
            "Train Epoch: 95 [2560/14860 (17%)]\tLoss: 0.022979\n",
            "Train Epoch: 95 [2688/14860 (18%)]\tLoss: 0.025906\n",
            "Train Epoch: 95 [2816/14860 (19%)]\tLoss: 0.022191\n",
            "Train Epoch: 95 [2944/14860 (20%)]\tLoss: 0.022566\n",
            "Train Epoch: 95 [3072/14860 (21%)]\tLoss: 0.014953\n",
            "Train Epoch: 95 [3200/14860 (21%)]\tLoss: 0.021170\n",
            "Train Epoch: 95 [3328/14860 (22%)]\tLoss: 0.019591\n",
            "Train Epoch: 95 [3456/14860 (23%)]\tLoss: 0.019180\n",
            "Train Epoch: 95 [3584/14860 (24%)]\tLoss: 0.022259\n",
            "Train Epoch: 95 [3712/14860 (25%)]\tLoss: 0.016912\n",
            "Train Epoch: 95 [3840/14860 (26%)]\tLoss: 0.022703\n",
            "Train Epoch: 95 [3968/14860 (26%)]\tLoss: 0.019841\n",
            "Train Epoch: 95 [4096/14860 (27%)]\tLoss: 0.014213\n",
            "Train Epoch: 95 [4224/14860 (28%)]\tLoss: 0.014489\n",
            "Train Epoch: 95 [4352/14860 (29%)]\tLoss: 0.018808\n",
            "Train Epoch: 95 [4480/14860 (30%)]\tLoss: 0.020327\n",
            "Train Epoch: 95 [4608/14860 (31%)]\tLoss: 0.019574\n",
            "Train Epoch: 95 [4736/14860 (32%)]\tLoss: 0.020267\n",
            "Train Epoch: 95 [4864/14860 (32%)]\tLoss: 0.019135\n",
            "Train Epoch: 95 [4992/14860 (33%)]\tLoss: 0.017268\n",
            "Train Epoch: 95 [5120/14860 (34%)]\tLoss: 0.027796\n",
            "Train Epoch: 95 [5248/14860 (35%)]\tLoss: 0.013723\n",
            "Train Epoch: 95 [5376/14860 (36%)]\tLoss: 0.019291\n",
            "Train Epoch: 95 [5504/14860 (37%)]\tLoss: 0.016932\n",
            "Train Epoch: 95 [5632/14860 (38%)]\tLoss: 0.019672\n",
            "Train Epoch: 95 [5760/14860 (38%)]\tLoss: 0.016251\n",
            "Train Epoch: 95 [5888/14860 (39%)]\tLoss: 0.014357\n",
            "Train Epoch: 95 [6016/14860 (40%)]\tLoss: 0.013597\n",
            "Train Epoch: 95 [6144/14860 (41%)]\tLoss: 0.018783\n",
            "Train Epoch: 95 [6272/14860 (42%)]\tLoss: 0.021330\n",
            "Train Epoch: 95 [6400/14860 (43%)]\tLoss: 0.019073\n",
            "Train Epoch: 95 [6528/14860 (44%)]\tLoss: 0.012944\n",
            "Train Epoch: 95 [6656/14860 (44%)]\tLoss: 0.036978\n",
            "Train Epoch: 95 [6784/14860 (45%)]\tLoss: 0.015810\n",
            "Train Epoch: 95 [6912/14860 (46%)]\tLoss: 0.024795\n",
            "Train Epoch: 95 [7040/14860 (47%)]\tLoss: 0.018380\n",
            "Train Epoch: 95 [7168/14860 (48%)]\tLoss: 0.024697\n",
            "Train Epoch: 95 [7296/14860 (49%)]\tLoss: 0.024768\n",
            "Train Epoch: 95 [7424/14860 (50%)]\tLoss: 0.017529\n",
            "Train Epoch: 95 [7552/14860 (50%)]\tLoss: 0.018229\n",
            "Train Epoch: 95 [7680/14860 (51%)]\tLoss: 0.017427\n",
            "Train Epoch: 95 [7808/14860 (52%)]\tLoss: 0.017414\n",
            "Train Epoch: 95 [7936/14860 (53%)]\tLoss: 0.025754\n",
            "Train Epoch: 95 [8064/14860 (54%)]\tLoss: 0.024527\n",
            "Train Epoch: 95 [8192/14860 (55%)]\tLoss: 0.018776\n",
            "Train Epoch: 95 [8320/14860 (56%)]\tLoss: 0.020846\n",
            "Train Epoch: 95 [8448/14860 (56%)]\tLoss: 0.018340\n",
            "Train Epoch: 95 [8576/14860 (57%)]\tLoss: 0.022063\n",
            "Train Epoch: 95 [8704/14860 (58%)]\tLoss: 0.016577\n",
            "Train Epoch: 95 [8832/14860 (59%)]\tLoss: 0.024950\n",
            "Train Epoch: 95 [8960/14860 (60%)]\tLoss: 0.018683\n",
            "Train Epoch: 95 [9088/14860 (61%)]\tLoss: 0.030477\n",
            "Train Epoch: 95 [9216/14860 (62%)]\tLoss: 0.016132\n",
            "Train Epoch: 95 [9344/14860 (62%)]\tLoss: 0.021043\n",
            "Train Epoch: 95 [9472/14860 (63%)]\tLoss: 0.019187\n",
            "Train Epoch: 95 [9600/14860 (64%)]\tLoss: 0.015873\n",
            "Train Epoch: 95 [9728/14860 (65%)]\tLoss: 0.014090\n",
            "Train Epoch: 95 [9856/14860 (66%)]\tLoss: 0.018734\n",
            "Train Epoch: 95 [9984/14860 (67%)]\tLoss: 0.015744\n",
            "Train Epoch: 95 [10112/14860 (68%)]\tLoss: 0.018380\n",
            "Train Epoch: 95 [10240/14860 (68%)]\tLoss: 0.018796\n",
            "Train Epoch: 95 [10368/14860 (69%)]\tLoss: 0.020105\n",
            "Train Epoch: 95 [10496/14860 (70%)]\tLoss: 0.023855\n",
            "Train Epoch: 95 [10624/14860 (71%)]\tLoss: 0.019457\n",
            "Train Epoch: 95 [10752/14860 (72%)]\tLoss: 0.021297\n",
            "Train Epoch: 95 [10880/14860 (73%)]\tLoss: 0.022244\n",
            "Train Epoch: 95 [11008/14860 (74%)]\tLoss: 0.013688\n",
            "Train Epoch: 95 [11136/14860 (74%)]\tLoss: 0.019376\n",
            "Train Epoch: 95 [11264/14860 (75%)]\tLoss: 0.023825\n",
            "Train Epoch: 95 [11392/14860 (76%)]\tLoss: 0.021112\n",
            "Train Epoch: 95 [11520/14860 (77%)]\tLoss: 0.019404\n",
            "Train Epoch: 95 [11648/14860 (78%)]\tLoss: 0.021955\n",
            "Train Epoch: 95 [11776/14860 (79%)]\tLoss: 0.017743\n",
            "Train Epoch: 95 [11904/14860 (79%)]\tLoss: 0.021440\n",
            "Train Epoch: 95 [12032/14860 (80%)]\tLoss: 0.015641\n",
            "Train Epoch: 95 [12160/14860 (81%)]\tLoss: 0.015199\n",
            "Train Epoch: 95 [12288/14860 (82%)]\tLoss: 0.020576\n",
            "Train Epoch: 95 [12416/14860 (83%)]\tLoss: 0.025569\n",
            "Train Epoch: 95 [12544/14860 (84%)]\tLoss: 0.027877\n",
            "Train Epoch: 95 [12672/14860 (85%)]\tLoss: 0.022456\n",
            "Train Epoch: 95 [12800/14860 (85%)]\tLoss: 0.018696\n",
            "Train Epoch: 95 [12928/14860 (86%)]\tLoss: 0.017652\n",
            "Train Epoch: 95 [13056/14860 (87%)]\tLoss: 0.016736\n",
            "Train Epoch: 95 [13184/14860 (88%)]\tLoss: 0.014220\n",
            "Train Epoch: 95 [13312/14860 (89%)]\tLoss: 0.017125\n",
            "Train Epoch: 95 [13440/14860 (90%)]\tLoss: 0.015503\n",
            "Train Epoch: 95 [13568/14860 (91%)]\tLoss: 0.019945\n",
            "Train Epoch: 95 [13696/14860 (91%)]\tLoss: 0.017298\n",
            "Train Epoch: 95 [13824/14860 (92%)]\tLoss: 0.017524\n",
            "Train Epoch: 95 [13952/14860 (93%)]\tLoss: 0.017533\n",
            "Train Epoch: 95 [14080/14860 (94%)]\tLoss: 0.020001\n",
            "Train Epoch: 95 [14208/14860 (95%)]\tLoss: 0.014739\n",
            "Train Epoch: 95 [14336/14860 (96%)]\tLoss: 0.020045\n",
            "Train Epoch: 95 [14464/14860 (97%)]\tLoss: 0.018742\n",
            "Train Epoch: 95 [14592/14860 (97%)]\tLoss: 0.022301\n",
            "Train Epoch: 95 [14720/14860 (98%)]\tLoss: 0.022859\n",
            "Train Epoch: 95 [1392/14860 (99%)]\tLoss: 0.018136\n",
            "epoch 95 training loss: 0.019514575377743468\n",
            "epoch 95 validation loss: 0.02584312614459391\n",
            "Train Epoch: 96 [0/14860 (0%)]\tLoss: 0.022316\n",
            "Train Epoch: 96 [128/14860 (1%)]\tLoss: 0.022873\n",
            "Train Epoch: 96 [256/14860 (2%)]\tLoss: 0.021159\n",
            "Train Epoch: 96 [384/14860 (3%)]\tLoss: 0.021565\n",
            "Train Epoch: 96 [512/14860 (3%)]\tLoss: 0.023046\n",
            "Train Epoch: 96 [640/14860 (4%)]\tLoss: 0.016111\n",
            "Train Epoch: 96 [768/14860 (5%)]\tLoss: 0.020032\n",
            "Train Epoch: 96 [896/14860 (6%)]\tLoss: 0.020435\n",
            "Train Epoch: 96 [1024/14860 (7%)]\tLoss: 0.022258\n",
            "Train Epoch: 96 [1152/14860 (8%)]\tLoss: 0.028554\n",
            "Train Epoch: 96 [1280/14860 (9%)]\tLoss: 0.016448\n",
            "Train Epoch: 96 [1408/14860 (9%)]\tLoss: 0.018028\n",
            "Train Epoch: 96 [1536/14860 (10%)]\tLoss: 0.024046\n",
            "Train Epoch: 96 [1664/14860 (11%)]\tLoss: 0.021208\n",
            "Train Epoch: 96 [1792/14860 (12%)]\tLoss: 0.013551\n",
            "Train Epoch: 96 [1920/14860 (13%)]\tLoss: 0.018439\n",
            "Train Epoch: 96 [2048/14860 (14%)]\tLoss: 0.020033\n",
            "Train Epoch: 96 [2176/14860 (15%)]\tLoss: 0.014464\n",
            "Train Epoch: 96 [2304/14860 (15%)]\tLoss: 0.009552\n",
            "Train Epoch: 96 [2432/14860 (16%)]\tLoss: 0.015045\n",
            "Train Epoch: 96 [2560/14860 (17%)]\tLoss: 0.015203\n",
            "Train Epoch: 96 [2688/14860 (18%)]\tLoss: 0.018539\n",
            "Train Epoch: 96 [2816/14860 (19%)]\tLoss: 0.016340\n",
            "Train Epoch: 96 [2944/14860 (20%)]\tLoss: 0.016867\n",
            "Train Epoch: 96 [3072/14860 (21%)]\tLoss: 0.024551\n",
            "Train Epoch: 96 [3200/14860 (21%)]\tLoss: 0.018757\n",
            "Train Epoch: 96 [3328/14860 (22%)]\tLoss: 0.020028\n",
            "Train Epoch: 96 [3456/14860 (23%)]\tLoss: 0.016418\n",
            "Train Epoch: 96 [3584/14860 (24%)]\tLoss: 0.018267\n",
            "Train Epoch: 96 [3712/14860 (25%)]\tLoss: 0.016185\n",
            "Train Epoch: 96 [3840/14860 (26%)]\tLoss: 0.014501\n",
            "Train Epoch: 96 [3968/14860 (26%)]\tLoss: 0.016005\n",
            "Train Epoch: 96 [4096/14860 (27%)]\tLoss: 0.014965\n",
            "Train Epoch: 96 [4224/14860 (28%)]\tLoss: 0.018299\n",
            "Train Epoch: 96 [4352/14860 (29%)]\tLoss: 0.016470\n",
            "Train Epoch: 96 [4480/14860 (30%)]\tLoss: 0.018605\n",
            "Train Epoch: 96 [4608/14860 (31%)]\tLoss: 0.014858\n",
            "Train Epoch: 96 [4736/14860 (32%)]\tLoss: 0.015578\n",
            "Train Epoch: 96 [4864/14860 (32%)]\tLoss: 0.022179\n",
            "Train Epoch: 96 [4992/14860 (33%)]\tLoss: 0.019943\n",
            "Train Epoch: 96 [5120/14860 (34%)]\tLoss: 0.021597\n",
            "Train Epoch: 96 [5248/14860 (35%)]\tLoss: 0.024032\n",
            "Train Epoch: 96 [5376/14860 (36%)]\tLoss: 0.020183\n",
            "Train Epoch: 96 [5504/14860 (37%)]\tLoss: 0.015287\n",
            "Train Epoch: 96 [5632/14860 (38%)]\tLoss: 0.013522\n",
            "Train Epoch: 96 [5760/14860 (38%)]\tLoss: 0.014053\n",
            "Train Epoch: 96 [5888/14860 (39%)]\tLoss: 0.022056\n",
            "Train Epoch: 96 [6016/14860 (40%)]\tLoss: 0.021436\n",
            "Train Epoch: 96 [6144/14860 (41%)]\tLoss: 0.019212\n",
            "Train Epoch: 96 [6272/14860 (42%)]\tLoss: 0.016122\n",
            "Train Epoch: 96 [6400/14860 (43%)]\tLoss: 0.022237\n",
            "Train Epoch: 96 [6528/14860 (44%)]\tLoss: 0.019788\n",
            "Train Epoch: 96 [6656/14860 (44%)]\tLoss: 0.020667\n",
            "Train Epoch: 96 [6784/14860 (45%)]\tLoss: 0.019070\n",
            "Train Epoch: 96 [6912/14860 (46%)]\tLoss: 0.020249\n",
            "Train Epoch: 96 [7040/14860 (47%)]\tLoss: 0.015944\n",
            "Train Epoch: 96 [7168/14860 (48%)]\tLoss: 0.025821\n",
            "Train Epoch: 96 [7296/14860 (49%)]\tLoss: 0.019537\n",
            "Train Epoch: 96 [7424/14860 (50%)]\tLoss: 0.016577\n",
            "Train Epoch: 96 [7552/14860 (50%)]\tLoss: 0.017010\n",
            "Train Epoch: 96 [7680/14860 (51%)]\tLoss: 0.013662\n",
            "Train Epoch: 96 [7808/14860 (52%)]\tLoss: 0.022695\n",
            "Train Epoch: 96 [7936/14860 (53%)]\tLoss: 0.022576\n",
            "Train Epoch: 96 [8064/14860 (54%)]\tLoss: 0.019907\n",
            "Train Epoch: 96 [8192/14860 (55%)]\tLoss: 0.018066\n",
            "Train Epoch: 96 [8320/14860 (56%)]\tLoss: 0.021610\n",
            "Train Epoch: 96 [8448/14860 (56%)]\tLoss: 0.015101\n",
            "Train Epoch: 96 [8576/14860 (57%)]\tLoss: 0.017735\n",
            "Train Epoch: 96 [8704/14860 (58%)]\tLoss: 0.020437\n",
            "Train Epoch: 96 [8832/14860 (59%)]\tLoss: 0.024245\n",
            "Train Epoch: 96 [8960/14860 (60%)]\tLoss: 0.010401\n",
            "Train Epoch: 96 [9088/14860 (61%)]\tLoss: 0.025018\n",
            "Train Epoch: 96 [9216/14860 (62%)]\tLoss: 0.022899\n",
            "Train Epoch: 96 [9344/14860 (62%)]\tLoss: 0.013968\n",
            "Train Epoch: 96 [9472/14860 (63%)]\tLoss: 0.020707\n",
            "Train Epoch: 96 [9600/14860 (64%)]\tLoss: 0.022074\n",
            "Train Epoch: 96 [9728/14860 (65%)]\tLoss: 0.020332\n",
            "Train Epoch: 96 [9856/14860 (66%)]\tLoss: 0.019980\n",
            "Train Epoch: 96 [9984/14860 (67%)]\tLoss: 0.020403\n",
            "Train Epoch: 96 [10112/14860 (68%)]\tLoss: 0.020173\n",
            "Train Epoch: 96 [10240/14860 (68%)]\tLoss: 0.023908\n",
            "Train Epoch: 96 [10368/14860 (69%)]\tLoss: 0.021166\n",
            "Train Epoch: 96 [10496/14860 (70%)]\tLoss: 0.020423\n",
            "Train Epoch: 96 [10624/14860 (71%)]\tLoss: 0.015079\n",
            "Train Epoch: 96 [10752/14860 (72%)]\tLoss: 0.030930\n",
            "Train Epoch: 96 [10880/14860 (73%)]\tLoss: 0.020924\n",
            "Train Epoch: 96 [11008/14860 (74%)]\tLoss: 0.017982\n",
            "Train Epoch: 96 [11136/14860 (74%)]\tLoss: 0.020563\n",
            "Train Epoch: 96 [11264/14860 (75%)]\tLoss: 0.024919\n",
            "Train Epoch: 96 [11392/14860 (76%)]\tLoss: 0.025382\n",
            "Train Epoch: 96 [11520/14860 (77%)]\tLoss: 0.015889\n",
            "Train Epoch: 96 [11648/14860 (78%)]\tLoss: 0.017017\n",
            "Train Epoch: 96 [11776/14860 (79%)]\tLoss: 0.019107\n",
            "Train Epoch: 96 [11904/14860 (79%)]\tLoss: 0.020314\n",
            "Train Epoch: 96 [12032/14860 (80%)]\tLoss: 0.018018\n",
            "Train Epoch: 96 [12160/14860 (81%)]\tLoss: 0.016732\n",
            "Train Epoch: 96 [12288/14860 (82%)]\tLoss: 0.019787\n",
            "Train Epoch: 96 [12416/14860 (83%)]\tLoss: 0.024469\n",
            "Train Epoch: 96 [12544/14860 (84%)]\tLoss: 0.018056\n",
            "Train Epoch: 96 [12672/14860 (85%)]\tLoss: 0.020750\n",
            "Train Epoch: 96 [12800/14860 (85%)]\tLoss: 0.027023\n",
            "Train Epoch: 96 [12928/14860 (86%)]\tLoss: 0.018837\n",
            "Train Epoch: 96 [13056/14860 (87%)]\tLoss: 0.016362\n",
            "Train Epoch: 96 [13184/14860 (88%)]\tLoss: 0.024433\n",
            "Train Epoch: 96 [13312/14860 (89%)]\tLoss: 0.017720\n",
            "Train Epoch: 96 [13440/14860 (90%)]\tLoss: 0.012647\n",
            "Train Epoch: 96 [13568/14860 (91%)]\tLoss: 0.020169\n",
            "Train Epoch: 96 [13696/14860 (91%)]\tLoss: 0.011703\n",
            "Train Epoch: 96 [13824/14860 (92%)]\tLoss: 0.034622\n",
            "Train Epoch: 96 [13952/14860 (93%)]\tLoss: 0.015017\n",
            "Train Epoch: 96 [14080/14860 (94%)]\tLoss: 0.020436\n",
            "Train Epoch: 96 [14208/14860 (95%)]\tLoss: 0.021258\n",
            "Train Epoch: 96 [14336/14860 (96%)]\tLoss: 0.019801\n",
            "Train Epoch: 96 [14464/14860 (97%)]\tLoss: 0.019202\n",
            "Train Epoch: 96 [14592/14860 (97%)]\tLoss: 0.015338\n",
            "Train Epoch: 96 [14720/14860 (98%)]\tLoss: 0.018342\n",
            "Train Epoch: 96 [1392/14860 (99%)]\tLoss: 0.009216\n",
            "epoch 96 training loss: 0.01924487850509393\n",
            "epoch 96 validation loss: 0.024345196765502487\n",
            "Train Epoch: 97 [0/14860 (0%)]\tLoss: 0.021316\n",
            "Train Epoch: 97 [128/14860 (1%)]\tLoss: 0.035604\n",
            "Train Epoch: 97 [256/14860 (2%)]\tLoss: 0.016580\n",
            "Train Epoch: 97 [384/14860 (3%)]\tLoss: 0.020509\n",
            "Train Epoch: 97 [512/14860 (3%)]\tLoss: 0.013951\n",
            "Train Epoch: 97 [640/14860 (4%)]\tLoss: 0.021631\n",
            "Train Epoch: 97 [768/14860 (5%)]\tLoss: 0.023197\n",
            "Train Epoch: 97 [896/14860 (6%)]\tLoss: 0.022687\n",
            "Train Epoch: 97 [1024/14860 (7%)]\tLoss: 0.018944\n",
            "Train Epoch: 97 [1152/14860 (8%)]\tLoss: 0.016706\n",
            "Train Epoch: 97 [1280/14860 (9%)]\tLoss: 0.018073\n",
            "Train Epoch: 97 [1408/14860 (9%)]\tLoss: 0.020293\n",
            "Train Epoch: 97 [1536/14860 (10%)]\tLoss: 0.017158\n",
            "Train Epoch: 97 [1664/14860 (11%)]\tLoss: 0.018601\n",
            "Train Epoch: 97 [1792/14860 (12%)]\tLoss: 0.023168\n",
            "Train Epoch: 97 [1920/14860 (13%)]\tLoss: 0.024991\n",
            "Train Epoch: 97 [2048/14860 (14%)]\tLoss: 0.019225\n",
            "Train Epoch: 97 [2176/14860 (15%)]\tLoss: 0.018094\n",
            "Train Epoch: 97 [2304/14860 (15%)]\tLoss: 0.021970\n",
            "Train Epoch: 97 [2432/14860 (16%)]\tLoss: 0.022109\n",
            "Train Epoch: 97 [2560/14860 (17%)]\tLoss: 0.024447\n",
            "Train Epoch: 97 [2688/14860 (18%)]\tLoss: 0.013934\n",
            "Train Epoch: 97 [2816/14860 (19%)]\tLoss: 0.022350\n",
            "Train Epoch: 97 [2944/14860 (20%)]\tLoss: 0.021909\n",
            "Train Epoch: 97 [3072/14860 (21%)]\tLoss: 0.014580\n",
            "Train Epoch: 97 [3200/14860 (21%)]\tLoss: 0.017780\n",
            "Train Epoch: 97 [3328/14860 (22%)]\tLoss: 0.013060\n",
            "Train Epoch: 97 [3456/14860 (23%)]\tLoss: 0.024275\n",
            "Train Epoch: 97 [3584/14860 (24%)]\tLoss: 0.026338\n",
            "Train Epoch: 97 [3712/14860 (25%)]\tLoss: 0.018785\n",
            "Train Epoch: 97 [3840/14860 (26%)]\tLoss: 0.020153\n",
            "Train Epoch: 97 [3968/14860 (26%)]\tLoss: 0.016969\n",
            "Train Epoch: 97 [4096/14860 (27%)]\tLoss: 0.020693\n",
            "Train Epoch: 97 [4224/14860 (28%)]\tLoss: 0.016354\n",
            "Train Epoch: 97 [4352/14860 (29%)]\tLoss: 0.016539\n",
            "Train Epoch: 97 [4480/14860 (30%)]\tLoss: 0.020216\n",
            "Train Epoch: 97 [4608/14860 (31%)]\tLoss: 0.020075\n",
            "Train Epoch: 97 [4736/14860 (32%)]\tLoss: 0.016845\n",
            "Train Epoch: 97 [4864/14860 (32%)]\tLoss: 0.017681\n",
            "Train Epoch: 97 [4992/14860 (33%)]\tLoss: 0.021407\n",
            "Train Epoch: 97 [5120/14860 (34%)]\tLoss: 0.020634\n",
            "Train Epoch: 97 [5248/14860 (35%)]\tLoss: 0.017696\n",
            "Train Epoch: 97 [5376/14860 (36%)]\tLoss: 0.021805\n",
            "Train Epoch: 97 [5504/14860 (37%)]\tLoss: 0.017724\n",
            "Train Epoch: 97 [5632/14860 (38%)]\tLoss: 0.018267\n",
            "Train Epoch: 97 [5760/14860 (38%)]\tLoss: 0.018636\n",
            "Train Epoch: 97 [5888/14860 (39%)]\tLoss: 0.018317\n",
            "Train Epoch: 97 [6016/14860 (40%)]\tLoss: 0.015723\n",
            "Train Epoch: 97 [6144/14860 (41%)]\tLoss: 0.016452\n",
            "Train Epoch: 97 [6272/14860 (42%)]\tLoss: 0.017223\n",
            "Train Epoch: 97 [6400/14860 (43%)]\tLoss: 0.016251\n",
            "Train Epoch: 97 [6528/14860 (44%)]\tLoss: 0.023759\n",
            "Train Epoch: 97 [6656/14860 (44%)]\tLoss: 0.020373\n",
            "Train Epoch: 97 [6784/14860 (45%)]\tLoss: 0.020146\n",
            "Train Epoch: 97 [6912/14860 (46%)]\tLoss: 0.016032\n",
            "Train Epoch: 97 [7040/14860 (47%)]\tLoss: 0.012690\n",
            "Train Epoch: 97 [7168/14860 (48%)]\tLoss: 0.016781\n",
            "Train Epoch: 97 [7296/14860 (49%)]\tLoss: 0.021353\n",
            "Train Epoch: 97 [7424/14860 (50%)]\tLoss: 0.018504\n",
            "Train Epoch: 97 [7552/14860 (50%)]\tLoss: 0.019114\n",
            "Train Epoch: 97 [7680/14860 (51%)]\tLoss: 0.024480\n",
            "Train Epoch: 97 [7808/14860 (52%)]\tLoss: 0.022825\n",
            "Train Epoch: 97 [7936/14860 (53%)]\tLoss: 0.020764\n",
            "Train Epoch: 97 [8064/14860 (54%)]\tLoss: 0.019805\n",
            "Train Epoch: 97 [8192/14860 (55%)]\tLoss: 0.022650\n",
            "Train Epoch: 97 [8320/14860 (56%)]\tLoss: 0.022087\n",
            "Train Epoch: 97 [8448/14860 (56%)]\tLoss: 0.020169\n",
            "Train Epoch: 97 [8576/14860 (57%)]\tLoss: 0.020231\n",
            "Train Epoch: 97 [8704/14860 (58%)]\tLoss: 0.024812\n",
            "Train Epoch: 97 [8832/14860 (59%)]\tLoss: 0.017060\n",
            "Train Epoch: 97 [8960/14860 (60%)]\tLoss: 0.018319\n",
            "Train Epoch: 97 [9088/14860 (61%)]\tLoss: 0.018588\n",
            "Train Epoch: 97 [9216/14860 (62%)]\tLoss: 0.010721\n",
            "Train Epoch: 97 [9344/14860 (62%)]\tLoss: 0.015817\n",
            "Train Epoch: 97 [9472/14860 (63%)]\tLoss: 0.020773\n",
            "Train Epoch: 97 [9600/14860 (64%)]\tLoss: 0.025626\n",
            "Train Epoch: 97 [9728/14860 (65%)]\tLoss: 0.015809\n",
            "Train Epoch: 97 [9856/14860 (66%)]\tLoss: 0.019983\n",
            "Train Epoch: 97 [9984/14860 (67%)]\tLoss: 0.020544\n",
            "Train Epoch: 97 [10112/14860 (68%)]\tLoss: 0.014755\n",
            "Train Epoch: 97 [10240/14860 (68%)]\tLoss: 0.019299\n",
            "Train Epoch: 97 [10368/14860 (69%)]\tLoss: 0.020204\n",
            "Train Epoch: 97 [10496/14860 (70%)]\tLoss: 0.017868\n",
            "Train Epoch: 97 [10624/14860 (71%)]\tLoss: 0.018128\n",
            "Train Epoch: 97 [10752/14860 (72%)]\tLoss: 0.018385\n",
            "Train Epoch: 97 [10880/14860 (73%)]\tLoss: 0.018631\n",
            "Train Epoch: 97 [11008/14860 (74%)]\tLoss: 0.017921\n",
            "Train Epoch: 97 [11136/14860 (74%)]\tLoss: 0.021821\n",
            "Train Epoch: 97 [11264/14860 (75%)]\tLoss: 0.023868\n",
            "Train Epoch: 97 [11392/14860 (76%)]\tLoss: 0.027400\n",
            "Train Epoch: 97 [11520/14860 (77%)]\tLoss: 0.015737\n",
            "Train Epoch: 97 [11648/14860 (78%)]\tLoss: 0.012726\n",
            "Train Epoch: 97 [11776/14860 (79%)]\tLoss: 0.019593\n",
            "Train Epoch: 97 [11904/14860 (79%)]\tLoss: 0.028578\n",
            "Train Epoch: 97 [12032/14860 (80%)]\tLoss: 0.020705\n",
            "Train Epoch: 97 [12160/14860 (81%)]\tLoss: 0.017102\n",
            "Train Epoch: 97 [12288/14860 (82%)]\tLoss: 0.023786\n",
            "Train Epoch: 97 [12416/14860 (83%)]\tLoss: 0.016297\n",
            "Train Epoch: 97 [12544/14860 (84%)]\tLoss: 0.012862\n",
            "Train Epoch: 97 [12672/14860 (85%)]\tLoss: 0.019357\n",
            "Train Epoch: 97 [12800/14860 (85%)]\tLoss: 0.021586\n",
            "Train Epoch: 97 [12928/14860 (86%)]\tLoss: 0.019805\n",
            "Train Epoch: 97 [13056/14860 (87%)]\tLoss: 0.016395\n",
            "Train Epoch: 97 [13184/14860 (88%)]\tLoss: 0.022941\n",
            "Train Epoch: 97 [13312/14860 (89%)]\tLoss: 0.017471\n",
            "Train Epoch: 97 [13440/14860 (90%)]\tLoss: 0.021769\n",
            "Train Epoch: 97 [13568/14860 (91%)]\tLoss: 0.023982\n",
            "Train Epoch: 97 [13696/14860 (91%)]\tLoss: 0.015586\n",
            "Train Epoch: 97 [13824/14860 (92%)]\tLoss: 0.020717\n",
            "Train Epoch: 97 [13952/14860 (93%)]\tLoss: 0.015271\n",
            "Train Epoch: 97 [14080/14860 (94%)]\tLoss: 0.014337\n",
            "Train Epoch: 97 [14208/14860 (95%)]\tLoss: 0.019297\n",
            "Train Epoch: 97 [14336/14860 (96%)]\tLoss: 0.017693\n",
            "Train Epoch: 97 [14464/14860 (97%)]\tLoss: 0.019775\n",
            "Train Epoch: 97 [14592/14860 (97%)]\tLoss: 0.012233\n",
            "Train Epoch: 97 [14720/14860 (98%)]\tLoss: 0.017993\n",
            "Train Epoch: 97 [1392/14860 (99%)]\tLoss: 0.029576\n",
            "epoch 97 training loss: 0.01948032410353677\n",
            "epoch 97 validation loss: 0.02270522966223248\n",
            "Train Epoch: 98 [0/14860 (0%)]\tLoss: 0.026131\n",
            "Train Epoch: 98 [128/14860 (1%)]\tLoss: 0.026336\n",
            "Train Epoch: 98 [256/14860 (2%)]\tLoss: 0.024990\n",
            "Train Epoch: 98 [384/14860 (3%)]\tLoss: 0.018993\n",
            "Train Epoch: 98 [512/14860 (3%)]\tLoss: 0.021628\n",
            "Train Epoch: 98 [640/14860 (4%)]\tLoss: 0.019826\n",
            "Train Epoch: 98 [768/14860 (5%)]\tLoss: 0.020565\n",
            "Train Epoch: 98 [896/14860 (6%)]\tLoss: 0.018638\n",
            "Train Epoch: 98 [1024/14860 (7%)]\tLoss: 0.018267\n",
            "Train Epoch: 98 [1152/14860 (8%)]\tLoss: 0.022060\n",
            "Train Epoch: 98 [1280/14860 (9%)]\tLoss: 0.023063\n",
            "Train Epoch: 98 [1408/14860 (9%)]\tLoss: 0.023216\n",
            "Train Epoch: 98 [1536/14860 (10%)]\tLoss: 0.020626\n",
            "Train Epoch: 98 [1664/14860 (11%)]\tLoss: 0.022558\n",
            "Train Epoch: 98 [1792/14860 (12%)]\tLoss: 0.014911\n",
            "Train Epoch: 98 [1920/14860 (13%)]\tLoss: 0.025183\n",
            "Train Epoch: 98 [2048/14860 (14%)]\tLoss: 0.029163\n",
            "Train Epoch: 98 [2176/14860 (15%)]\tLoss: 0.016617\n",
            "Train Epoch: 98 [2304/14860 (15%)]\tLoss: 0.027935\n",
            "Train Epoch: 98 [2432/14860 (16%)]\tLoss: 0.020075\n",
            "Train Epoch: 98 [2560/14860 (17%)]\tLoss: 0.014904\n",
            "Train Epoch: 98 [2688/14860 (18%)]\tLoss: 0.021191\n",
            "Train Epoch: 98 [2816/14860 (19%)]\tLoss: 0.020606\n",
            "Train Epoch: 98 [2944/14860 (20%)]\tLoss: 0.016411\n",
            "Train Epoch: 98 [3072/14860 (21%)]\tLoss: 0.014278\n",
            "Train Epoch: 98 [3200/14860 (21%)]\tLoss: 0.015700\n",
            "Train Epoch: 98 [3328/14860 (22%)]\tLoss: 0.012635\n",
            "Train Epoch: 98 [3456/14860 (23%)]\tLoss: 0.020085\n",
            "Train Epoch: 98 [3584/14860 (24%)]\tLoss: 0.013281\n",
            "Train Epoch: 98 [3712/14860 (25%)]\tLoss: 0.019471\n",
            "Train Epoch: 98 [3840/14860 (26%)]\tLoss: 0.017265\n",
            "Train Epoch: 98 [3968/14860 (26%)]\tLoss: 0.023067\n",
            "Train Epoch: 98 [4096/14860 (27%)]\tLoss: 0.019241\n",
            "Train Epoch: 98 [4224/14860 (28%)]\tLoss: 0.017690\n",
            "Train Epoch: 98 [4352/14860 (29%)]\tLoss: 0.017476\n",
            "Train Epoch: 98 [4480/14860 (30%)]\tLoss: 0.019004\n",
            "Train Epoch: 98 [4608/14860 (31%)]\tLoss: 0.021510\n",
            "Train Epoch: 98 [4736/14860 (32%)]\tLoss: 0.027213\n",
            "Train Epoch: 98 [4864/14860 (32%)]\tLoss: 0.017671\n",
            "Train Epoch: 98 [4992/14860 (33%)]\tLoss: 0.022395\n",
            "Train Epoch: 98 [5120/14860 (34%)]\tLoss: 0.024435\n",
            "Train Epoch: 98 [5248/14860 (35%)]\tLoss: 0.019116\n",
            "Train Epoch: 98 [5376/14860 (36%)]\tLoss: 0.022101\n",
            "Train Epoch: 98 [5504/14860 (37%)]\tLoss: 0.020749\n",
            "Train Epoch: 98 [5632/14860 (38%)]\tLoss: 0.012821\n",
            "Train Epoch: 98 [5760/14860 (38%)]\tLoss: 0.019507\n",
            "Train Epoch: 98 [5888/14860 (39%)]\tLoss: 0.013928\n",
            "Train Epoch: 98 [6016/14860 (40%)]\tLoss: 0.013416\n",
            "Train Epoch: 98 [6144/14860 (41%)]\tLoss: 0.021533\n",
            "Train Epoch: 98 [6272/14860 (42%)]\tLoss: 0.012679\n",
            "Train Epoch: 98 [6400/14860 (43%)]\tLoss: 0.023885\n",
            "Train Epoch: 98 [6528/14860 (44%)]\tLoss: 0.019400\n",
            "Train Epoch: 98 [6656/14860 (44%)]\tLoss: 0.023396\n",
            "Train Epoch: 98 [6784/14860 (45%)]\tLoss: 0.018880\n",
            "Train Epoch: 98 [6912/14860 (46%)]\tLoss: 0.020859\n",
            "Train Epoch: 98 [7040/14860 (47%)]\tLoss: 0.022465\n",
            "Train Epoch: 98 [7168/14860 (48%)]\tLoss: 0.023213\n",
            "Train Epoch: 98 [7296/14860 (49%)]\tLoss: 0.022975\n",
            "Train Epoch: 98 [7424/14860 (50%)]\tLoss: 0.021780\n",
            "Train Epoch: 98 [7552/14860 (50%)]\tLoss: 0.020697\n",
            "Train Epoch: 98 [7680/14860 (51%)]\tLoss: 0.018315\n",
            "Train Epoch: 98 [7808/14860 (52%)]\tLoss: 0.025261\n",
            "Train Epoch: 98 [7936/14860 (53%)]\tLoss: 0.018761\n",
            "Train Epoch: 98 [8064/14860 (54%)]\tLoss: 0.023662\n",
            "Train Epoch: 98 [8192/14860 (55%)]\tLoss: 0.018508\n",
            "Train Epoch: 98 [8320/14860 (56%)]\tLoss: 0.023584\n",
            "Train Epoch: 98 [8448/14860 (56%)]\tLoss: 0.024446\n",
            "Train Epoch: 98 [8576/14860 (57%)]\tLoss: 0.019169\n",
            "Train Epoch: 98 [8704/14860 (58%)]\tLoss: 0.011969\n",
            "Train Epoch: 98 [8832/14860 (59%)]\tLoss: 0.024025\n",
            "Train Epoch: 98 [8960/14860 (60%)]\tLoss: 0.036855\n",
            "Train Epoch: 98 [9088/14860 (61%)]\tLoss: 0.016763\n",
            "Train Epoch: 98 [9216/14860 (62%)]\tLoss: 0.020647\n",
            "Train Epoch: 98 [9344/14860 (62%)]\tLoss: 0.017622\n",
            "Train Epoch: 98 [9472/14860 (63%)]\tLoss: 0.020595\n",
            "Train Epoch: 98 [9600/14860 (64%)]\tLoss: 0.014186\n",
            "Train Epoch: 98 [9728/14860 (65%)]\tLoss: 0.017501\n",
            "Train Epoch: 98 [9856/14860 (66%)]\tLoss: 0.024127\n",
            "Train Epoch: 98 [9984/14860 (67%)]\tLoss: 0.023758\n",
            "Train Epoch: 98 [10112/14860 (68%)]\tLoss: 0.020027\n",
            "Train Epoch: 98 [10240/14860 (68%)]\tLoss: 0.016475\n",
            "Train Epoch: 98 [10368/14860 (69%)]\tLoss: 0.020111\n",
            "Train Epoch: 98 [10496/14860 (70%)]\tLoss: 0.016352\n",
            "Train Epoch: 98 [10624/14860 (71%)]\tLoss: 0.015289\n",
            "Train Epoch: 98 [10752/14860 (72%)]\tLoss: 0.016574\n",
            "Train Epoch: 98 [10880/14860 (73%)]\tLoss: 0.012736\n",
            "Train Epoch: 98 [11008/14860 (74%)]\tLoss: 0.018305\n",
            "Train Epoch: 98 [11136/14860 (74%)]\tLoss: 0.017319\n",
            "Train Epoch: 98 [11264/14860 (75%)]\tLoss: 0.022512\n",
            "Train Epoch: 98 [11392/14860 (76%)]\tLoss: 0.022909\n",
            "Train Epoch: 98 [11520/14860 (77%)]\tLoss: 0.014204\n",
            "Train Epoch: 98 [11648/14860 (78%)]\tLoss: 0.018575\n",
            "Train Epoch: 98 [11776/14860 (79%)]\tLoss: 0.020631\n",
            "Train Epoch: 98 [11904/14860 (79%)]\tLoss: 0.016243\n",
            "Train Epoch: 98 [12032/14860 (80%)]\tLoss: 0.018901\n",
            "Train Epoch: 98 [12160/14860 (81%)]\tLoss: 0.022231\n",
            "Train Epoch: 98 [12288/14860 (82%)]\tLoss: 0.017737\n",
            "Train Epoch: 98 [12416/14860 (83%)]\tLoss: 0.020200\n",
            "Train Epoch: 98 [12544/14860 (84%)]\tLoss: 0.025700\n",
            "Train Epoch: 98 [12672/14860 (85%)]\tLoss: 0.017222\n",
            "Train Epoch: 98 [12800/14860 (85%)]\tLoss: 0.019575\n",
            "Train Epoch: 98 [12928/14860 (86%)]\tLoss: 0.020623\n",
            "Train Epoch: 98 [13056/14860 (87%)]\tLoss: 0.016680\n",
            "Train Epoch: 98 [13184/14860 (88%)]\tLoss: 0.024772\n",
            "Train Epoch: 98 [13312/14860 (89%)]\tLoss: 0.016755\n",
            "Train Epoch: 98 [13440/14860 (90%)]\tLoss: 0.013491\n",
            "Train Epoch: 98 [13568/14860 (91%)]\tLoss: 0.016162\n",
            "Train Epoch: 98 [13696/14860 (91%)]\tLoss: 0.021028\n",
            "Train Epoch: 98 [13824/14860 (92%)]\tLoss: 0.017264\n",
            "Train Epoch: 98 [13952/14860 (93%)]\tLoss: 0.017030\n",
            "Train Epoch: 98 [14080/14860 (94%)]\tLoss: 0.018647\n",
            "Train Epoch: 98 [14208/14860 (95%)]\tLoss: 0.016444\n",
            "Train Epoch: 98 [14336/14860 (96%)]\tLoss: 0.026560\n",
            "Train Epoch: 98 [14464/14860 (97%)]\tLoss: 0.020264\n",
            "Train Epoch: 98 [14592/14860 (97%)]\tLoss: 0.016494\n",
            "Train Epoch: 98 [14720/14860 (98%)]\tLoss: 0.017241\n",
            "Train Epoch: 98 [1392/14860 (99%)]\tLoss: 0.035365\n",
            "epoch 98 training loss: 0.019949706167810492\n",
            "epoch 98 validation loss: 0.024263680991479904\n",
            "Train Epoch: 99 [0/14860 (0%)]\tLoss: 0.021244\n",
            "Train Epoch: 99 [128/14860 (1%)]\tLoss: 0.029688\n",
            "Train Epoch: 99 [256/14860 (2%)]\tLoss: 0.018775\n",
            "Train Epoch: 99 [384/14860 (3%)]\tLoss: 0.026005\n",
            "Train Epoch: 99 [512/14860 (3%)]\tLoss: 0.017655\n",
            "Train Epoch: 99 [640/14860 (4%)]\tLoss: 0.016974\n",
            "Train Epoch: 99 [768/14860 (5%)]\tLoss: 0.026809\n",
            "Train Epoch: 99 [896/14860 (6%)]\tLoss: 0.018736\n",
            "Train Epoch: 99 [1024/14860 (7%)]\tLoss: 0.019348\n",
            "Train Epoch: 99 [1152/14860 (8%)]\tLoss: 0.015510\n",
            "Train Epoch: 99 [1280/14860 (9%)]\tLoss: 0.034104\n",
            "Train Epoch: 99 [1408/14860 (9%)]\tLoss: 0.018634\n",
            "Train Epoch: 99 [1536/14860 (10%)]\tLoss: 0.014958\n",
            "Train Epoch: 99 [1664/14860 (11%)]\tLoss: 0.020493\n",
            "Train Epoch: 99 [1792/14860 (12%)]\tLoss: 0.020326\n",
            "Train Epoch: 99 [1920/14860 (13%)]\tLoss: 0.013668\n",
            "Train Epoch: 99 [2048/14860 (14%)]\tLoss: 0.015381\n",
            "Train Epoch: 99 [2176/14860 (15%)]\tLoss: 0.017922\n",
            "Train Epoch: 99 [2304/14860 (15%)]\tLoss: 0.014613\n",
            "Train Epoch: 99 [2432/14860 (16%)]\tLoss: 0.017485\n",
            "Train Epoch: 99 [2560/14860 (17%)]\tLoss: 0.021524\n",
            "Train Epoch: 99 [2688/14860 (18%)]\tLoss: 0.028901\n",
            "Train Epoch: 99 [2816/14860 (19%)]\tLoss: 0.013501\n",
            "Train Epoch: 99 [2944/14860 (20%)]\tLoss: 0.012251\n",
            "Train Epoch: 99 [3072/14860 (21%)]\tLoss: 0.020218\n",
            "Train Epoch: 99 [3200/14860 (21%)]\tLoss: 0.027174\n",
            "Train Epoch: 99 [3328/14860 (22%)]\tLoss: 0.016465\n",
            "Train Epoch: 99 [3456/14860 (23%)]\tLoss: 0.012427\n",
            "Train Epoch: 99 [3584/14860 (24%)]\tLoss: 0.016902\n",
            "Train Epoch: 99 [3712/14860 (25%)]\tLoss: 0.015998\n",
            "Train Epoch: 99 [3840/14860 (26%)]\tLoss: 0.017166\n",
            "Train Epoch: 99 [3968/14860 (26%)]\tLoss: 0.020152\n",
            "Train Epoch: 99 [4096/14860 (27%)]\tLoss: 0.016817\n",
            "Train Epoch: 99 [4224/14860 (28%)]\tLoss: 0.018841\n",
            "Train Epoch: 99 [4352/14860 (29%)]\tLoss: 0.026096\n",
            "Train Epoch: 99 [4480/14860 (30%)]\tLoss: 0.017062\n",
            "Train Epoch: 99 [4608/14860 (31%)]\tLoss: 0.025493\n",
            "Train Epoch: 99 [4736/14860 (32%)]\tLoss: 0.025357\n",
            "Train Epoch: 99 [4864/14860 (32%)]\tLoss: 0.015419\n",
            "Train Epoch: 99 [4992/14860 (33%)]\tLoss: 0.021455\n",
            "Train Epoch: 99 [5120/14860 (34%)]\tLoss: 0.016927\n",
            "Train Epoch: 99 [5248/14860 (35%)]\tLoss: 0.014878\n",
            "Train Epoch: 99 [5376/14860 (36%)]\tLoss: 0.019459\n",
            "Train Epoch: 99 [5504/14860 (37%)]\tLoss: 0.017074\n",
            "Train Epoch: 99 [5632/14860 (38%)]\tLoss: 0.019789\n",
            "Train Epoch: 99 [5760/14860 (38%)]\tLoss: 0.021387\n",
            "Train Epoch: 99 [5888/14860 (39%)]\tLoss: 0.016378\n",
            "Train Epoch: 99 [6016/14860 (40%)]\tLoss: 0.020959\n",
            "Train Epoch: 99 [6144/14860 (41%)]\tLoss: 0.021892\n",
            "Train Epoch: 99 [6272/14860 (42%)]\tLoss: 0.015775\n",
            "Train Epoch: 99 [6400/14860 (43%)]\tLoss: 0.025857\n",
            "Train Epoch: 99 [6528/14860 (44%)]\tLoss: 0.019533\n",
            "Train Epoch: 99 [6656/14860 (44%)]\tLoss: 0.014871\n",
            "Train Epoch: 99 [6784/14860 (45%)]\tLoss: 0.026006\n",
            "Train Epoch: 99 [6912/14860 (46%)]\tLoss: 0.020979\n",
            "Train Epoch: 99 [7040/14860 (47%)]\tLoss: 0.019253\n",
            "Train Epoch: 99 [7168/14860 (48%)]\tLoss: 0.018682\n",
            "Train Epoch: 99 [7296/14860 (49%)]\tLoss: 0.025003\n",
            "Train Epoch: 99 [7424/14860 (50%)]\tLoss: 0.016054\n",
            "Train Epoch: 99 [7552/14860 (50%)]\tLoss: 0.018216\n",
            "Train Epoch: 99 [7680/14860 (51%)]\tLoss: 0.018033\n",
            "Train Epoch: 99 [7808/14860 (52%)]\tLoss: 0.018365\n",
            "Train Epoch: 99 [7936/14860 (53%)]\tLoss: 0.022261\n",
            "Train Epoch: 99 [8064/14860 (54%)]\tLoss: 0.014424\n",
            "Train Epoch: 99 [8192/14860 (55%)]\tLoss: 0.019834\n",
            "Train Epoch: 99 [8320/14860 (56%)]\tLoss: 0.015180\n",
            "Train Epoch: 99 [8448/14860 (56%)]\tLoss: 0.021286\n",
            "Train Epoch: 99 [8576/14860 (57%)]\tLoss: 0.021341\n",
            "Train Epoch: 99 [8704/14860 (58%)]\tLoss: 0.018418\n",
            "Train Epoch: 99 [8832/14860 (59%)]\tLoss: 0.017176\n",
            "Train Epoch: 99 [8960/14860 (60%)]\tLoss: 0.012114\n",
            "Train Epoch: 99 [9088/14860 (61%)]\tLoss: 0.023000\n",
            "Train Epoch: 99 [9216/14860 (62%)]\tLoss: 0.020558\n",
            "Train Epoch: 99 [9344/14860 (62%)]\tLoss: 0.018195\n",
            "Train Epoch: 99 [9472/14860 (63%)]\tLoss: 0.020587\n",
            "Train Epoch: 99 [9600/14860 (64%)]\tLoss: 0.015111\n",
            "Train Epoch: 99 [9728/14860 (65%)]\tLoss: 0.015419\n",
            "Train Epoch: 99 [9856/14860 (66%)]\tLoss: 0.016684\n",
            "Train Epoch: 99 [9984/14860 (67%)]\tLoss: 0.013130\n",
            "Train Epoch: 99 [10112/14860 (68%)]\tLoss: 0.015621\n",
            "Train Epoch: 99 [10240/14860 (68%)]\tLoss: 0.022110\n",
            "Train Epoch: 99 [10368/14860 (69%)]\tLoss: 0.015234\n",
            "Train Epoch: 99 [10496/14860 (70%)]\tLoss: 0.023205\n",
            "Train Epoch: 99 [10624/14860 (71%)]\tLoss: 0.019357\n",
            "Train Epoch: 99 [10752/14860 (72%)]\tLoss: 0.022993\n",
            "Train Epoch: 99 [10880/14860 (73%)]\tLoss: 0.022830\n",
            "Train Epoch: 99 [11008/14860 (74%)]\tLoss: 0.028446\n",
            "Train Epoch: 99 [11136/14860 (74%)]\tLoss: 0.026499\n",
            "Train Epoch: 99 [11264/14860 (75%)]\tLoss: 0.015847\n",
            "Train Epoch: 99 [11392/14860 (76%)]\tLoss: 0.018962\n",
            "Train Epoch: 99 [11520/14860 (77%)]\tLoss: 0.023786\n",
            "Train Epoch: 99 [11648/14860 (78%)]\tLoss: 0.011159\n",
            "Train Epoch: 99 [11776/14860 (79%)]\tLoss: 0.012321\n",
            "Train Epoch: 99 [11904/14860 (79%)]\tLoss: 0.020937\n",
            "Train Epoch: 99 [12032/14860 (80%)]\tLoss: 0.015993\n",
            "Train Epoch: 99 [12160/14860 (81%)]\tLoss: 0.015205\n",
            "Train Epoch: 99 [12288/14860 (82%)]\tLoss: 0.017086\n",
            "Train Epoch: 99 [12416/14860 (83%)]\tLoss: 0.018074\n",
            "Train Epoch: 99 [12544/14860 (84%)]\tLoss: 0.014073\n",
            "Train Epoch: 99 [12672/14860 (85%)]\tLoss: 0.022563\n",
            "Train Epoch: 99 [12800/14860 (85%)]\tLoss: 0.017169\n",
            "Train Epoch: 99 [12928/14860 (86%)]\tLoss: 0.024864\n",
            "Train Epoch: 99 [13056/14860 (87%)]\tLoss: 0.024612\n",
            "Train Epoch: 99 [13184/14860 (88%)]\tLoss: 0.018693\n",
            "Train Epoch: 99 [13312/14860 (89%)]\tLoss: 0.026824\n",
            "Train Epoch: 99 [13440/14860 (90%)]\tLoss: 0.019427\n",
            "Train Epoch: 99 [13568/14860 (91%)]\tLoss: 0.020615\n",
            "Train Epoch: 99 [13696/14860 (91%)]\tLoss: 0.014362\n",
            "Train Epoch: 99 [13824/14860 (92%)]\tLoss: 0.018941\n",
            "Train Epoch: 99 [13952/14860 (93%)]\tLoss: 0.023720\n",
            "Train Epoch: 99 [14080/14860 (94%)]\tLoss: 0.019046\n",
            "Train Epoch: 99 [14208/14860 (95%)]\tLoss: 0.016803\n",
            "Train Epoch: 99 [14336/14860 (96%)]\tLoss: 0.022493\n",
            "Train Epoch: 99 [14464/14860 (97%)]\tLoss: 0.026531\n",
            "Train Epoch: 99 [14592/14860 (97%)]\tLoss: 0.015582\n",
            "Train Epoch: 99 [14720/14860 (98%)]\tLoss: 0.016909\n",
            "Train Epoch: 99 [1392/14860 (99%)]\tLoss: 0.007214\n",
            "epoch 99 training loss: 0.019262777112074133\n",
            "epoch 99 validation loss: 0.020569150369912026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.arange(0,len(loss_train_list)), loss_train_list, '-b', label='training loss')\n",
        "ax.plot(np.arange(0,len(loss_val_list)), loss_val_list, '-r', label='validation loss')\n",
        "ax.set_xlabel('epoch',fontsize=16)\n",
        "ax.legend(fontsize=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FaKqsPKOSmPw",
        "outputId": "93c6dcca-8cd9-478a-b143-b02f44cfeb5c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79e76bbce6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yp_test=[]\n",
        "with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
        "    for batch_idx, (X, Y) in enumerate(dataloader_test):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        Yp = model(X)#forward pass\n",
        "        Yp_test.append(Yp.detach().cpu().numpy())\n",
        "Yp_test=np.concatenate(Yp_test, axis=0).squeeze()"
      ],
      "metadata": {
        "id": "RgFJVJuESpHO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluate model on testing set')\n",
        "mse_test, mae_test,mape_test = test(model, dataloader_test, device)\n",
        "print('MSE=', mse_test)\n",
        "print('MAE=', mae_test)\n",
        "print('MAPE=', mape_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnWTVxiCSrYH",
        "outputId": "b9cd5c10-7958-4485-dcec-801e24dfc632"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on testing set\n",
            "MSE= 0.019154333805506542\n",
            "MAE= 0.10219303691803022\n",
            "MAPE= 0.26613945300264874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(Y_test, Yp_test, '.')\n",
        "ax.plot(Y_test, Y_test, 'r-')\n",
        "ax.set_xlabel('Y_test', fontsize=16)\n",
        "ax.set_ylabel('Yp_test', fontsize=16)\n",
        "ax.grid(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "AvGuQ9yeStam",
        "outputId": "f0bf0a04-265a-42cc-eb57-7dcccc2322a0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset as torch_dataset\n",
        "class MyDataset(torch_dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X=X\n",
        "        self.Y=Y.reshape(-1, 1) #this is very important\n",
        "    def __len__(self):\n",
        "        #return the number of data points\n",
        "        return self.X.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        # use the notation DatasetName[idx]\n",
        "        # to get a data point (x,y) by idx\n",
        "        # we need to convert numpy array to torch tensor\n",
        "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y=torch.tensor(self.Y[idx], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "j_6Hoh30SwJ4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train= MyDataset(X_train,Y_train)\n",
        "dataset_val = MyDataset(X_val, Y_val)\n",
        "dataset_test = MyDataset(X_test, Y_test)"
      ],
      "metadata": {
        "id": "NidjYZyFSyRP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset as torch_dataset\n",
        "from torch.utils.data import DataLoader as torch_dataloader\n",
        "\n",
        "dataloader_train = torch_dataloader(dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
        "dataloader_val = torch_dataloader(dataset_val, batch_size=128, shuffle=False, num_workers=0)\n",
        "dataloader_test = torch_dataloader(dataset_test, batch_size=128, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "R8101ISdS0Yu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (X, Y) in enumerate(dataloader_train):\n",
        "    print(batch_idx, X.size(), Y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmhunUkCS2dx",
        "outputId": "25a5bcbe-5f8f-49eb-cebb-0f087441ae11"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "1 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "2 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "3 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "4 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "5 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "6 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "7 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "8 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "9 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "10 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "11 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "12 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "13 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "14 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "15 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "16 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "17 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "18 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "19 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "20 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "21 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "22 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "23 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "24 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "25 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "26 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "27 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "28 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "29 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "30 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "31 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "32 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "33 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "34 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "35 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "36 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "37 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "38 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "39 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "40 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "41 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "42 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "43 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "44 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "45 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "46 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "47 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "48 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "49 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "50 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "51 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "52 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "53 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "54 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "55 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "56 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "57 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "58 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "59 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "60 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "61 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "62 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "63 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "64 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "65 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "66 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "67 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "68 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "69 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "70 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "71 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "72 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "73 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "74 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "75 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "76 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "77 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "78 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "79 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "80 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "81 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "82 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "83 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "84 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "85 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "86 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "87 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "88 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "89 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "90 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "91 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "92 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "93 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "94 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "95 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "96 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "97 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "98 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "99 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "100 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "101 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "102 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "103 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "104 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "105 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "106 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "107 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "108 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "109 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "110 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "111 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "112 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "113 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "114 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "115 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "116 torch.Size([12, 13]) torch.Size([12, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnF\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, n_units):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, n_units)\n",
        "        self.layer2 = nn.Linear(n_units, n_units)\n",
        "        self.layer3 = nn.Linear(n_units, n_units)\n",
        "        self.layer4 = nn.Linear(n_units, output_dim)\n",
        "    def forward(self, x):\n",
        "        x=self.layer1(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        x=self.layer2(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        x=self.layer3(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        y=self.layer4(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "QneaJ0CoS6j4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net(input_dim=13, output_dim=1, n_units=128)\n"
      ],
      "metadata": {
        "id": "bdkftAHtS8iw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfSHlL3jS-W0",
        "outputId": "14931667-2327-4adc-cfe7-04bc78de2871"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer1): Linear(in_features=13, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    loss_train=0\n",
        "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        Yp = model(X)\n",
        "        loss = torch.mean((Yp-Y)**2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_train+=loss.item()\n",
        "        if batch_idx % 1 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * X.size(0), len(dataloader.dataset),\n",
        "                    100. * batch_idx / len(dataloader), loss.item()))\n",
        "    loss_train/=len(dataloader)\n",
        "    return loss_train"
      ],
      "metadata": {
        "id": "oASE3Iv-TBKZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, device):\n",
        "    model.eval()#set model to evaluation mode\n",
        "    loss_test=0\n",
        "    mae_test=0\n",
        "    mape_test=0\n",
        "    sample_count=0\n",
        "    with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
        "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            Yp = model(X)#forward pass\n",
        "            loss_test+=torch.sum((Yp-Y)**2).item()\n",
        "            mae_test+= torch.sum((Yp-Y).abs()).item()\n",
        "            mape_test+= torch.sum(((Yp-Y)/Yp).abs()).item()\n",
        "            sample_count+=X.size(0)\n",
        "    loss_test/=sample_count\n",
        "    mae_test/=sample_count\n",
        "    mape_test/=sample_count\n",
        "    return loss_test, mae_test ,mape_test"
      ],
      "metadata": {
        "id": "F-57blxgTDt-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(Y_test, Yp_test, '.')\n",
        "ax.plot(Y_test, Y_test, 'r-')\n",
        "ax.set_xlabel('Y_test', fontsize=16)\n",
        "ax.set_ylabel('Yp_test', fontsize=16)\n",
        "ax.grid(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "w7yGRnwNTFPV",
        "outputId": "35450ef8-2aa9-41b8-9a94-124eb41a10e1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset as torch_dataset\n",
        "class MyDataset(torch_dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X=X\n",
        "        self.Y=Y.reshape(-1, 1) #this is very important\n",
        "    def __len__(self):\n",
        "        #return the number of data points\n",
        "        return self.X.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        # use the notation DatasetName[idx]\n",
        "        # to get a data point (x,y) by idx\n",
        "        # we need to convert numpy array to torch tensor\n",
        "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y=torch.tensor(self.Y[idx], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "Ce7vpMJlTrzu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train= MyDataset(X_train,Y_train)\n",
        "dataset_val = MyDataset(X_val, Y_val)\n",
        "dataset_test = MyDataset(X_test, Y_test)"
      ],
      "metadata": {
        "id": "p2LCJo0XTuNf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset as torch_dataset\n",
        "from torch.utils.data import DataLoader as torch_dataloader\n",
        "\n",
        "dataloader_train = torch_dataloader(dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
        "dataloader_val = torch_dataloader(dataset_val, batch_size=128, shuffle=False, num_workers=0)\n",
        "dataloader_test = torch_dataloader(dataset_test, batch_size=128, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "7WDOOQk-Twp1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (X, Y) in enumerate(dataloader_train):\n",
        "    print(batch_idx, X.size(), Y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEAMTOpbTyr2",
        "outputId": "ad8af225-3f83-4b5d-c98c-890e344eda20"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "1 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "2 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "3 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "4 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "5 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "6 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "7 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "8 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "9 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "10 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "11 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "12 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "13 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "14 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "15 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "16 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "17 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "18 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "19 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "20 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "21 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "22 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "23 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "24 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "25 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "26 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "27 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "28 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "29 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "30 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "31 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "32 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "33 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "34 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "35 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "36 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "37 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "38 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "39 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "40 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "41 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "42 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "43 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "44 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "45 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "46 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "47 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "48 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "49 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "50 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "51 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "52 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "53 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "54 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "55 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "56 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "57 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "58 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "59 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "60 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "61 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "62 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "63 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "64 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "65 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "66 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "67 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "68 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "69 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "70 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "71 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "72 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "73 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "74 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "75 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "76 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "77 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "78 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "79 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "80 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "81 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "82 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "83 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "84 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "85 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "86 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "87 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "88 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "89 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "90 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "91 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "92 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "93 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "94 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "95 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "96 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "97 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "98 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "99 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "100 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "101 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "102 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "103 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "104 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "105 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "106 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "107 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "108 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "109 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "110 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "111 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "112 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "113 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "114 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "115 torch.Size([128, 13]) torch.Size([128, 1])\n",
            "116 torch.Size([12, 13]) torch.Size([12, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnF\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, n_units):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, n_units)\n",
        "        self.layer2 = nn.Linear(n_units, n_units)\n",
        "        self.layer3 = nn.Linear(n_units, n_units)\n",
        "        self.layer4 = nn.Linear(n_units, output_dim)\n",
        "    def forward(self, x):\n",
        "        x=self.layer1(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        x=self.layer2(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        x=self.layer3(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        y=self.layer4(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "CxBKBwx9T2iH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net(input_dim=13, output_dim=1, n_units=128)\n"
      ],
      "metadata": {
        "id": "XsrtxLupT5K5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5agj-QrT7TA",
        "outputId": "7c7a5e30-18af-40eb-a1cc-e70f4cf534cc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer1): Linear(in_features=13, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    loss_train=0\n",
        "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        Yp = model(X)\n",
        "        loss = torch.mean((Yp-Y)**2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_train+=loss.item()\n",
        "        if batch_idx % 1 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * X.size(0), len(dataloader.dataset),\n",
        "                    100. * batch_idx / len(dataloader), loss.item()))\n",
        "    loss_train/=len(dataloader)\n",
        "    return loss_train"
      ],
      "metadata": {
        "id": "h4ytaS_ET-BX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, device):\n",
        "    model.eval()#set model to evaluation mode\n",
        "    loss_test=0\n",
        "    mae_test=0\n",
        "    mape_test=0\n",
        "    sample_count=0\n",
        "    with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
        "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            Yp = model(X)#forward pass\n",
        "            loss_test+=torch.sum((Yp-Y)**2).item()\n",
        "            mae_test+= torch.sum((Yp-Y).abs()).item()\n",
        "            mape_test+= torch.sum(((Yp-Y)/Yp).abs()).item()\n",
        "            sample_count+=X.size(0)\n",
        "    loss_test/=sample_count\n",
        "    mae_test/=sample_count\n",
        "    mape_test/=sample_count\n",
        "    return loss_test, mae_test ,mape_test"
      ],
      "metadata": {
        "id": "OQ674HPtUBkQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "yzIou66tUEFj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_list=[]\n",
        "loss_val_list=[]\n",
        "mae_val_list=[]"
      ],
      "metadata": {
        "id": "P0hhJ2WKUGDX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 100):\n",
        "\n",
        "    loss_train=train(model, optimizer, dataloader_train, device, epoch)\n",
        "    loss_train_list.append(loss_train)\n",
        "    print('epoch', epoch, 'training loss:', loss_train)\n",
        "\n",
        "\n",
        "    loss_val, mae_val,mape_test = test(model, dataloader_val, device)\n",
        "    loss_val_list.append(loss_val)\n",
        "    mae_val_list.append(mae_val)\n",
        "    print('epoch', epoch, 'validation loss:', loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCINrinzUIaS",
        "outputId": "8b16ad8d-d5c9-4cb2-87d7-0733f53f14c2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch 57 training loss: 0.021809717051239096\n",
            "epoch 57 validation loss: 0.10606746350304555\n",
            "Train Epoch: 58 [0/14860 (0%)]\tLoss: 0.106134\n",
            "Train Epoch: 58 [128/14860 (1%)]\tLoss: 0.025902\n",
            "Train Epoch: 58 [256/14860 (2%)]\tLoss: 0.079732\n",
            "Train Epoch: 58 [384/14860 (3%)]\tLoss: 0.016780\n",
            "Train Epoch: 58 [512/14860 (3%)]\tLoss: 0.055283\n",
            "Train Epoch: 58 [640/14860 (4%)]\tLoss: 0.018718\n",
            "Train Epoch: 58 [768/14860 (5%)]\tLoss: 0.033659\n",
            "Train Epoch: 58 [896/14860 (6%)]\tLoss: 0.051679\n",
            "Train Epoch: 58 [1024/14860 (7%)]\tLoss: 0.029247\n",
            "Train Epoch: 58 [1152/14860 (8%)]\tLoss: 0.041210\n",
            "Train Epoch: 58 [1280/14860 (9%)]\tLoss: 0.019963\n",
            "Train Epoch: 58 [1408/14860 (9%)]\tLoss: 0.047143\n",
            "Train Epoch: 58 [1536/14860 (10%)]\tLoss: 0.030274\n",
            "Train Epoch: 58 [1664/14860 (11%)]\tLoss: 0.023556\n",
            "Train Epoch: 58 [1792/14860 (12%)]\tLoss: 0.035008\n",
            "Train Epoch: 58 [1920/14860 (13%)]\tLoss: 0.016365\n",
            "Train Epoch: 58 [2048/14860 (14%)]\tLoss: 0.041974\n",
            "Train Epoch: 58 [2176/14860 (15%)]\tLoss: 0.027254\n",
            "Train Epoch: 58 [2304/14860 (15%)]\tLoss: 0.018790\n",
            "Train Epoch: 58 [2432/14860 (16%)]\tLoss: 0.023236\n",
            "Train Epoch: 58 [2560/14860 (17%)]\tLoss: 0.020706\n",
            "Train Epoch: 58 [2688/14860 (18%)]\tLoss: 0.023819\n",
            "Train Epoch: 58 [2816/14860 (19%)]\tLoss: 0.027085\n",
            "Train Epoch: 58 [2944/14860 (20%)]\tLoss: 0.024715\n",
            "Train Epoch: 58 [3072/14860 (21%)]\tLoss: 0.023133\n",
            "Train Epoch: 58 [3200/14860 (21%)]\tLoss: 0.026457\n",
            "Train Epoch: 58 [3328/14860 (22%)]\tLoss: 0.034510\n",
            "Train Epoch: 58 [3456/14860 (23%)]\tLoss: 0.024515\n",
            "Train Epoch: 58 [3584/14860 (24%)]\tLoss: 0.022817\n",
            "Train Epoch: 58 [3712/14860 (25%)]\tLoss: 0.030167\n",
            "Train Epoch: 58 [3840/14860 (26%)]\tLoss: 0.022395\n",
            "Train Epoch: 58 [3968/14860 (26%)]\tLoss: 0.031284\n",
            "Train Epoch: 58 [4096/14860 (27%)]\tLoss: 0.023404\n",
            "Train Epoch: 58 [4224/14860 (28%)]\tLoss: 0.021007\n",
            "Train Epoch: 58 [4352/14860 (29%)]\tLoss: 0.025748\n",
            "Train Epoch: 58 [4480/14860 (30%)]\tLoss: 0.015335\n",
            "Train Epoch: 58 [4608/14860 (31%)]\tLoss: 0.037943\n",
            "Train Epoch: 58 [4736/14860 (32%)]\tLoss: 0.018161\n",
            "Train Epoch: 58 [4864/14860 (32%)]\tLoss: 0.018450\n",
            "Train Epoch: 58 [4992/14860 (33%)]\tLoss: 0.023332\n",
            "Train Epoch: 58 [5120/14860 (34%)]\tLoss: 0.019087\n",
            "Train Epoch: 58 [5248/14860 (35%)]\tLoss: 0.018460\n",
            "Train Epoch: 58 [5376/14860 (36%)]\tLoss: 0.012773\n",
            "Train Epoch: 58 [5504/14860 (37%)]\tLoss: 0.012617\n",
            "Train Epoch: 58 [5632/14860 (38%)]\tLoss: 0.020313\n",
            "Train Epoch: 58 [5760/14860 (38%)]\tLoss: 0.019992\n",
            "Train Epoch: 58 [5888/14860 (39%)]\tLoss: 0.025530\n",
            "Train Epoch: 58 [6016/14860 (40%)]\tLoss: 0.016482\n",
            "Train Epoch: 58 [6144/14860 (41%)]\tLoss: 0.028342\n",
            "Train Epoch: 58 [6272/14860 (42%)]\tLoss: 0.022726\n",
            "Train Epoch: 58 [6400/14860 (43%)]\tLoss: 0.019004\n",
            "Train Epoch: 58 [6528/14860 (44%)]\tLoss: 0.017613\n",
            "Train Epoch: 58 [6656/14860 (44%)]\tLoss: 0.019184\n",
            "Train Epoch: 58 [6784/14860 (45%)]\tLoss: 0.027334\n",
            "Train Epoch: 58 [6912/14860 (46%)]\tLoss: 0.029879\n",
            "Train Epoch: 58 [7040/14860 (47%)]\tLoss: 0.021091\n",
            "Train Epoch: 58 [7168/14860 (48%)]\tLoss: 0.020591\n",
            "Train Epoch: 58 [7296/14860 (49%)]\tLoss: 0.018135\n",
            "Train Epoch: 58 [7424/14860 (50%)]\tLoss: 0.015158\n",
            "Train Epoch: 58 [7552/14860 (50%)]\tLoss: 0.021135\n",
            "Train Epoch: 58 [7680/14860 (51%)]\tLoss: 0.013133\n",
            "Train Epoch: 58 [7808/14860 (52%)]\tLoss: 0.021078\n",
            "Train Epoch: 58 [7936/14860 (53%)]\tLoss: 0.023277\n",
            "Train Epoch: 58 [8064/14860 (54%)]\tLoss: 0.025007\n",
            "Train Epoch: 58 [8192/14860 (55%)]\tLoss: 0.025080\n",
            "Train Epoch: 58 [8320/14860 (56%)]\tLoss: 0.016921\n",
            "Train Epoch: 58 [8448/14860 (56%)]\tLoss: 0.021761\n",
            "Train Epoch: 58 [8576/14860 (57%)]\tLoss: 0.021803\n",
            "Train Epoch: 58 [8704/14860 (58%)]\tLoss: 0.019868\n",
            "Train Epoch: 58 [8832/14860 (59%)]\tLoss: 0.023316\n",
            "Train Epoch: 58 [8960/14860 (60%)]\tLoss: 0.029686\n",
            "Train Epoch: 58 [9088/14860 (61%)]\tLoss: 0.018018\n",
            "Train Epoch: 58 [9216/14860 (62%)]\tLoss: 0.018492\n",
            "Train Epoch: 58 [9344/14860 (62%)]\tLoss: 0.017128\n",
            "Train Epoch: 58 [9472/14860 (63%)]\tLoss: 0.022119\n",
            "Train Epoch: 58 [9600/14860 (64%)]\tLoss: 0.021103\n",
            "Train Epoch: 58 [9728/14860 (65%)]\tLoss: 0.028057\n",
            "Train Epoch: 58 [9856/14860 (66%)]\tLoss: 0.025037\n",
            "Train Epoch: 58 [9984/14860 (67%)]\tLoss: 0.017995\n",
            "Train Epoch: 58 [10112/14860 (68%)]\tLoss: 0.024230\n",
            "Train Epoch: 58 [10240/14860 (68%)]\tLoss: 0.030185\n",
            "Train Epoch: 58 [10368/14860 (69%)]\tLoss: 0.020362\n",
            "Train Epoch: 58 [10496/14860 (70%)]\tLoss: 0.019865\n",
            "Train Epoch: 58 [10624/14860 (71%)]\tLoss: 0.021356\n",
            "Train Epoch: 58 [10752/14860 (72%)]\tLoss: 0.019336\n",
            "Train Epoch: 58 [10880/14860 (73%)]\tLoss: 0.022362\n",
            "Train Epoch: 58 [11008/14860 (74%)]\tLoss: 0.020086\n",
            "Train Epoch: 58 [11136/14860 (74%)]\tLoss: 0.018048\n",
            "Train Epoch: 58 [11264/14860 (75%)]\tLoss: 0.016441\n",
            "Train Epoch: 58 [11392/14860 (76%)]\tLoss: 0.016181\n",
            "Train Epoch: 58 [11520/14860 (77%)]\tLoss: 0.017883\n",
            "Train Epoch: 58 [11648/14860 (78%)]\tLoss: 0.019487\n",
            "Train Epoch: 58 [11776/14860 (79%)]\tLoss: 0.017320\n",
            "Train Epoch: 58 [11904/14860 (79%)]\tLoss: 0.016414\n",
            "Train Epoch: 58 [12032/14860 (80%)]\tLoss: 0.014556\n",
            "Train Epoch: 58 [12160/14860 (81%)]\tLoss: 0.019863\n",
            "Train Epoch: 58 [12288/14860 (82%)]\tLoss: 0.018409\n",
            "Train Epoch: 58 [12416/14860 (83%)]\tLoss: 0.026776\n",
            "Train Epoch: 58 [12544/14860 (84%)]\tLoss: 0.018799\n",
            "Train Epoch: 58 [12672/14860 (85%)]\tLoss: 0.020378\n",
            "Train Epoch: 58 [12800/14860 (85%)]\tLoss: 0.015091\n",
            "Train Epoch: 58 [12928/14860 (86%)]\tLoss: 0.016290\n",
            "Train Epoch: 58 [13056/14860 (87%)]\tLoss: 0.031638\n",
            "Train Epoch: 58 [13184/14860 (88%)]\tLoss: 0.028885\n",
            "Train Epoch: 58 [13312/14860 (89%)]\tLoss: 0.017953\n",
            "Train Epoch: 58 [13440/14860 (90%)]\tLoss: 0.033757\n",
            "Train Epoch: 58 [13568/14860 (91%)]\tLoss: 0.019666\n",
            "Train Epoch: 58 [13696/14860 (91%)]\tLoss: 0.030827\n",
            "Train Epoch: 58 [13824/14860 (92%)]\tLoss: 0.021401\n",
            "Train Epoch: 58 [13952/14860 (93%)]\tLoss: 0.027502\n",
            "Train Epoch: 58 [14080/14860 (94%)]\tLoss: 0.015063\n",
            "Train Epoch: 58 [14208/14860 (95%)]\tLoss: 0.022513\n",
            "Train Epoch: 58 [14336/14860 (96%)]\tLoss: 0.018522\n",
            "Train Epoch: 58 [14464/14860 (97%)]\tLoss: 0.013924\n",
            "Train Epoch: 58 [14592/14860 (97%)]\tLoss: 0.020637\n",
            "Train Epoch: 58 [14720/14860 (98%)]\tLoss: 0.023577\n",
            "Train Epoch: 58 [1392/14860 (99%)]\tLoss: 0.018415\n",
            "epoch 58 training loss: 0.024318027158832956\n",
            "epoch 58 validation loss: 0.0303767711717915\n",
            "Train Epoch: 59 [0/14860 (0%)]\tLoss: 0.027937\n",
            "Train Epoch: 59 [128/14860 (1%)]\tLoss: 0.025893\n",
            "Train Epoch: 59 [256/14860 (2%)]\tLoss: 0.025933\n",
            "Train Epoch: 59 [384/14860 (3%)]\tLoss: 0.030228\n",
            "Train Epoch: 59 [512/14860 (3%)]\tLoss: 0.027222\n",
            "Train Epoch: 59 [640/14860 (4%)]\tLoss: 0.024743\n",
            "Train Epoch: 59 [768/14860 (5%)]\tLoss: 0.021445\n",
            "Train Epoch: 59 [896/14860 (6%)]\tLoss: 0.025899\n",
            "Train Epoch: 59 [1024/14860 (7%)]\tLoss: 0.019650\n",
            "Train Epoch: 59 [1152/14860 (8%)]\tLoss: 0.019920\n",
            "Train Epoch: 59 [1280/14860 (9%)]\tLoss: 0.026502\n",
            "Train Epoch: 59 [1408/14860 (9%)]\tLoss: 0.021416\n",
            "Train Epoch: 59 [1536/14860 (10%)]\tLoss: 0.028081\n",
            "Train Epoch: 59 [1664/14860 (11%)]\tLoss: 0.019176\n",
            "Train Epoch: 59 [1792/14860 (12%)]\tLoss: 0.015563\n",
            "Train Epoch: 59 [1920/14860 (13%)]\tLoss: 0.018228\n",
            "Train Epoch: 59 [2048/14860 (14%)]\tLoss: 0.018220\n",
            "Train Epoch: 59 [2176/14860 (15%)]\tLoss: 0.031850\n",
            "Train Epoch: 59 [2304/14860 (15%)]\tLoss: 0.022189\n",
            "Train Epoch: 59 [2432/14860 (16%)]\tLoss: 0.030864\n",
            "Train Epoch: 59 [2560/14860 (17%)]\tLoss: 0.033557\n",
            "Train Epoch: 59 [2688/14860 (18%)]\tLoss: 0.033399\n",
            "Train Epoch: 59 [2816/14860 (19%)]\tLoss: 0.021694\n",
            "Train Epoch: 59 [2944/14860 (20%)]\tLoss: 0.021361\n",
            "Train Epoch: 59 [3072/14860 (21%)]\tLoss: 0.023229\n",
            "Train Epoch: 59 [3200/14860 (21%)]\tLoss: 0.018985\n",
            "Train Epoch: 59 [3328/14860 (22%)]\tLoss: 0.015180\n",
            "Train Epoch: 59 [3456/14860 (23%)]\tLoss: 0.030448\n",
            "Train Epoch: 59 [3584/14860 (24%)]\tLoss: 0.023343\n",
            "Train Epoch: 59 [3712/14860 (25%)]\tLoss: 0.018789\n",
            "Train Epoch: 59 [3840/14860 (26%)]\tLoss: 0.017580\n",
            "Train Epoch: 59 [3968/14860 (26%)]\tLoss: 0.022467\n",
            "Train Epoch: 59 [4096/14860 (27%)]\tLoss: 0.017749\n",
            "Train Epoch: 59 [4224/14860 (28%)]\tLoss: 0.022428\n",
            "Train Epoch: 59 [4352/14860 (29%)]\tLoss: 0.024864\n",
            "Train Epoch: 59 [4480/14860 (30%)]\tLoss: 0.018501\n",
            "Train Epoch: 59 [4608/14860 (31%)]\tLoss: 0.020287\n",
            "Train Epoch: 59 [4736/14860 (32%)]\tLoss: 0.029369\n",
            "Train Epoch: 59 [4864/14860 (32%)]\tLoss: 0.033436\n",
            "Train Epoch: 59 [4992/14860 (33%)]\tLoss: 0.015622\n",
            "Train Epoch: 59 [5120/14860 (34%)]\tLoss: 0.030999\n",
            "Train Epoch: 59 [5248/14860 (35%)]\tLoss: 0.017702\n",
            "Train Epoch: 59 [5376/14860 (36%)]\tLoss: 0.027473\n",
            "Train Epoch: 59 [5504/14860 (37%)]\tLoss: 0.021037\n",
            "Train Epoch: 59 [5632/14860 (38%)]\tLoss: 0.020355\n",
            "Train Epoch: 59 [5760/14860 (38%)]\tLoss: 0.034147\n",
            "Train Epoch: 59 [5888/14860 (39%)]\tLoss: 0.020877\n",
            "Train Epoch: 59 [6016/14860 (40%)]\tLoss: 0.027989\n",
            "Train Epoch: 59 [6144/14860 (41%)]\tLoss: 0.016255\n",
            "Train Epoch: 59 [6272/14860 (42%)]\tLoss: 0.037157\n",
            "Train Epoch: 59 [6400/14860 (43%)]\tLoss: 0.019714\n",
            "Train Epoch: 59 [6528/14860 (44%)]\tLoss: 0.024735\n",
            "Train Epoch: 59 [6656/14860 (44%)]\tLoss: 0.033843\n",
            "Train Epoch: 59 [6784/14860 (45%)]\tLoss: 0.016332\n",
            "Train Epoch: 59 [6912/14860 (46%)]\tLoss: 0.020510\n",
            "Train Epoch: 59 [7040/14860 (47%)]\tLoss: 0.021101\n",
            "Train Epoch: 59 [7168/14860 (48%)]\tLoss: 0.023228\n",
            "Train Epoch: 59 [7296/14860 (49%)]\tLoss: 0.018457\n",
            "Train Epoch: 59 [7424/14860 (50%)]\tLoss: 0.018573\n",
            "Train Epoch: 59 [7552/14860 (50%)]\tLoss: 0.014051\n",
            "Train Epoch: 59 [7680/14860 (51%)]\tLoss: 0.016941\n",
            "Train Epoch: 59 [7808/14860 (52%)]\tLoss: 0.015185\n",
            "Train Epoch: 59 [7936/14860 (53%)]\tLoss: 0.015679\n",
            "Train Epoch: 59 [8064/14860 (54%)]\tLoss: 0.014097\n",
            "Train Epoch: 59 [8192/14860 (55%)]\tLoss: 0.025913\n",
            "Train Epoch: 59 [8320/14860 (56%)]\tLoss: 0.021933\n",
            "Train Epoch: 59 [8448/14860 (56%)]\tLoss: 0.017466\n",
            "Train Epoch: 59 [8576/14860 (57%)]\tLoss: 0.022596\n",
            "Train Epoch: 59 [8704/14860 (58%)]\tLoss: 0.022196\n",
            "Train Epoch: 59 [8832/14860 (59%)]\tLoss: 0.019472\n",
            "Train Epoch: 59 [8960/14860 (60%)]\tLoss: 0.016831\n",
            "Train Epoch: 59 [9088/14860 (61%)]\tLoss: 0.017635\n",
            "Train Epoch: 59 [9216/14860 (62%)]\tLoss: 0.020799\n",
            "Train Epoch: 59 [9344/14860 (62%)]\tLoss: 0.020223\n",
            "Train Epoch: 59 [9472/14860 (63%)]\tLoss: 0.025691\n",
            "Train Epoch: 59 [9600/14860 (64%)]\tLoss: 0.023408\n",
            "Train Epoch: 59 [9728/14860 (65%)]\tLoss: 0.019964\n",
            "Train Epoch: 59 [9856/14860 (66%)]\tLoss: 0.022052\n",
            "Train Epoch: 59 [9984/14860 (67%)]\tLoss: 0.017421\n",
            "Train Epoch: 59 [10112/14860 (68%)]\tLoss: 0.020081\n",
            "Train Epoch: 59 [10240/14860 (68%)]\tLoss: 0.019928\n",
            "Train Epoch: 59 [10368/14860 (69%)]\tLoss: 0.018533\n",
            "Train Epoch: 59 [10496/14860 (70%)]\tLoss: 0.017517\n",
            "Train Epoch: 59 [10624/14860 (71%)]\tLoss: 0.028850\n",
            "Train Epoch: 59 [10752/14860 (72%)]\tLoss: 0.023185\n",
            "Train Epoch: 59 [10880/14860 (73%)]\tLoss: 0.019325\n",
            "Train Epoch: 59 [11008/14860 (74%)]\tLoss: 0.024376\n",
            "Train Epoch: 59 [11136/14860 (74%)]\tLoss: 0.015364\n",
            "Train Epoch: 59 [11264/14860 (75%)]\tLoss: 0.023071\n",
            "Train Epoch: 59 [11392/14860 (76%)]\tLoss: 0.015882\n",
            "Train Epoch: 59 [11520/14860 (77%)]\tLoss: 0.016178\n",
            "Train Epoch: 59 [11648/14860 (78%)]\tLoss: 0.025639\n",
            "Train Epoch: 59 [11776/14860 (79%)]\tLoss: 0.015203\n",
            "Train Epoch: 59 [11904/14860 (79%)]\tLoss: 0.018309\n",
            "Train Epoch: 59 [12032/14860 (80%)]\tLoss: 0.022683\n",
            "Train Epoch: 59 [12160/14860 (81%)]\tLoss: 0.016973\n",
            "Train Epoch: 59 [12288/14860 (82%)]\tLoss: 0.019287\n",
            "Train Epoch: 59 [12416/14860 (83%)]\tLoss: 0.021861\n",
            "Train Epoch: 59 [12544/14860 (84%)]\tLoss: 0.019918\n",
            "Train Epoch: 59 [12672/14860 (85%)]\tLoss: 0.012250\n",
            "Train Epoch: 59 [12800/14860 (85%)]\tLoss: 0.020430\n",
            "Train Epoch: 59 [12928/14860 (86%)]\tLoss: 0.021208\n",
            "Train Epoch: 59 [13056/14860 (87%)]\tLoss: 0.023634\n",
            "Train Epoch: 59 [13184/14860 (88%)]\tLoss: 0.018615\n",
            "Train Epoch: 59 [13312/14860 (89%)]\tLoss: 0.024241\n",
            "Train Epoch: 59 [13440/14860 (90%)]\tLoss: 0.015342\n",
            "Train Epoch: 59 [13568/14860 (91%)]\tLoss: 0.019636\n",
            "Train Epoch: 59 [13696/14860 (91%)]\tLoss: 0.025444\n",
            "Train Epoch: 59 [13824/14860 (92%)]\tLoss: 0.017363\n",
            "Train Epoch: 59 [13952/14860 (93%)]\tLoss: 0.027030\n",
            "Train Epoch: 59 [14080/14860 (94%)]\tLoss: 0.014373\n",
            "Train Epoch: 59 [14208/14860 (95%)]\tLoss: 0.016800\n",
            "Train Epoch: 59 [14336/14860 (96%)]\tLoss: 0.024050\n",
            "Train Epoch: 59 [14464/14860 (97%)]\tLoss: 0.015070\n",
            "Train Epoch: 59 [14592/14860 (97%)]\tLoss: 0.018968\n",
            "Train Epoch: 59 [14720/14860 (98%)]\tLoss: 0.012632\n",
            "Train Epoch: 59 [1392/14860 (99%)]\tLoss: 0.033296\n",
            "epoch 59 training loss: 0.021759217899515588\n",
            "epoch 59 validation loss: 0.034111414925526766\n",
            "Train Epoch: 60 [0/14860 (0%)]\tLoss: 0.031780\n",
            "Train Epoch: 60 [128/14860 (1%)]\tLoss: 0.016141\n",
            "Train Epoch: 60 [256/14860 (2%)]\tLoss: 0.039537\n",
            "Train Epoch: 60 [384/14860 (3%)]\tLoss: 0.021215\n",
            "Train Epoch: 60 [512/14860 (3%)]\tLoss: 0.028236\n",
            "Train Epoch: 60 [640/14860 (4%)]\tLoss: 0.015639\n",
            "Train Epoch: 60 [768/14860 (5%)]\tLoss: 0.017019\n",
            "Train Epoch: 60 [896/14860 (6%)]\tLoss: 0.020166\n",
            "Train Epoch: 60 [1024/14860 (7%)]\tLoss: 0.023551\n",
            "Train Epoch: 60 [1152/14860 (8%)]\tLoss: 0.015180\n",
            "Train Epoch: 60 [1280/14860 (9%)]\tLoss: 0.021028\n",
            "Train Epoch: 60 [1408/14860 (9%)]\tLoss: 0.032395\n",
            "Train Epoch: 60 [1536/14860 (10%)]\tLoss: 0.027818\n",
            "Train Epoch: 60 [1664/14860 (11%)]\tLoss: 0.017376\n",
            "Train Epoch: 60 [1792/14860 (12%)]\tLoss: 0.024125\n",
            "Train Epoch: 60 [1920/14860 (13%)]\tLoss: 0.023360\n",
            "Train Epoch: 60 [2048/14860 (14%)]\tLoss: 0.018854\n",
            "Train Epoch: 60 [2176/14860 (15%)]\tLoss: 0.022149\n",
            "Train Epoch: 60 [2304/14860 (15%)]\tLoss: 0.015995\n",
            "Train Epoch: 60 [2432/14860 (16%)]\tLoss: 0.025738\n",
            "Train Epoch: 60 [2560/14860 (17%)]\tLoss: 0.017969\n",
            "Train Epoch: 60 [2688/14860 (18%)]\tLoss: 0.023964\n",
            "Train Epoch: 60 [2816/14860 (19%)]\tLoss: 0.018167\n",
            "Train Epoch: 60 [2944/14860 (20%)]\tLoss: 0.016758\n",
            "Train Epoch: 60 [3072/14860 (21%)]\tLoss: 0.014636\n",
            "Train Epoch: 60 [3200/14860 (21%)]\tLoss: 0.021622\n",
            "Train Epoch: 60 [3328/14860 (22%)]\tLoss: 0.021881\n",
            "Train Epoch: 60 [3456/14860 (23%)]\tLoss: 0.026659\n",
            "Train Epoch: 60 [3584/14860 (24%)]\tLoss: 0.027625\n",
            "Train Epoch: 60 [3712/14860 (25%)]\tLoss: 0.020628\n",
            "Train Epoch: 60 [3840/14860 (26%)]\tLoss: 0.020044\n",
            "Train Epoch: 60 [3968/14860 (26%)]\tLoss: 0.021298\n",
            "Train Epoch: 60 [4096/14860 (27%)]\tLoss: 0.015931\n",
            "Train Epoch: 60 [4224/14860 (28%)]\tLoss: 0.024198\n",
            "Train Epoch: 60 [4352/14860 (29%)]\tLoss: 0.026436\n",
            "Train Epoch: 60 [4480/14860 (30%)]\tLoss: 0.021399\n",
            "Train Epoch: 60 [4608/14860 (31%)]\tLoss: 0.018457\n",
            "Train Epoch: 60 [4736/14860 (32%)]\tLoss: 0.021482\n",
            "Train Epoch: 60 [4864/14860 (32%)]\tLoss: 0.019867\n",
            "Train Epoch: 60 [4992/14860 (33%)]\tLoss: 0.033866\n",
            "Train Epoch: 60 [5120/14860 (34%)]\tLoss: 0.025153\n",
            "Train Epoch: 60 [5248/14860 (35%)]\tLoss: 0.023961\n",
            "Train Epoch: 60 [5376/14860 (36%)]\tLoss: 0.020171\n",
            "Train Epoch: 60 [5504/14860 (37%)]\tLoss: 0.034990\n",
            "Train Epoch: 60 [5632/14860 (38%)]\tLoss: 0.024129\n",
            "Train Epoch: 60 [5760/14860 (38%)]\tLoss: 0.028092\n",
            "Train Epoch: 60 [5888/14860 (39%)]\tLoss: 0.029038\n",
            "Train Epoch: 60 [6016/14860 (40%)]\tLoss: 0.030410\n",
            "Train Epoch: 60 [6144/14860 (41%)]\tLoss: 0.013315\n",
            "Train Epoch: 60 [6272/14860 (42%)]\tLoss: 0.022371\n",
            "Train Epoch: 60 [6400/14860 (43%)]\tLoss: 0.016643\n",
            "Train Epoch: 60 [6528/14860 (44%)]\tLoss: 0.026145\n",
            "Train Epoch: 60 [6656/14860 (44%)]\tLoss: 0.025705\n",
            "Train Epoch: 60 [6784/14860 (45%)]\tLoss: 0.022906\n",
            "Train Epoch: 60 [6912/14860 (46%)]\tLoss: 0.019737\n",
            "Train Epoch: 60 [7040/14860 (47%)]\tLoss: 0.023392\n",
            "Train Epoch: 60 [7168/14860 (48%)]\tLoss: 0.018411\n",
            "Train Epoch: 60 [7296/14860 (49%)]\tLoss: 0.021598\n",
            "Train Epoch: 60 [7424/14860 (50%)]\tLoss: 0.020117\n",
            "Train Epoch: 60 [7552/14860 (50%)]\tLoss: 0.017662\n",
            "Train Epoch: 60 [7680/14860 (51%)]\tLoss: 0.023419\n",
            "Train Epoch: 60 [7808/14860 (52%)]\tLoss: 0.019852\n",
            "Train Epoch: 60 [7936/14860 (53%)]\tLoss: 0.017889\n",
            "Train Epoch: 60 [8064/14860 (54%)]\tLoss: 0.024072\n",
            "Train Epoch: 60 [8192/14860 (55%)]\tLoss: 0.029323\n",
            "Train Epoch: 60 [8320/14860 (56%)]\tLoss: 0.017914\n",
            "Train Epoch: 60 [8448/14860 (56%)]\tLoss: 0.020301\n",
            "Train Epoch: 60 [8576/14860 (57%)]\tLoss: 0.018360\n",
            "Train Epoch: 60 [8704/14860 (58%)]\tLoss: 0.026351\n",
            "Train Epoch: 60 [8832/14860 (59%)]\tLoss: 0.018870\n",
            "Train Epoch: 60 [8960/14860 (60%)]\tLoss: 0.020822\n",
            "Train Epoch: 60 [9088/14860 (61%)]\tLoss: 0.028442\n",
            "Train Epoch: 60 [9216/14860 (62%)]\tLoss: 0.022943\n",
            "Train Epoch: 60 [9344/14860 (62%)]\tLoss: 0.021436\n",
            "Train Epoch: 60 [9472/14860 (63%)]\tLoss: 0.019619\n",
            "Train Epoch: 60 [9600/14860 (64%)]\tLoss: 0.026867\n",
            "Train Epoch: 60 [9728/14860 (65%)]\tLoss: 0.023178\n",
            "Train Epoch: 60 [9856/14860 (66%)]\tLoss: 0.030368\n",
            "Train Epoch: 60 [9984/14860 (67%)]\tLoss: 0.012927\n",
            "Train Epoch: 60 [10112/14860 (68%)]\tLoss: 0.036833\n",
            "Train Epoch: 60 [10240/14860 (68%)]\tLoss: 0.017905\n",
            "Train Epoch: 60 [10368/14860 (69%)]\tLoss: 0.022563\n",
            "Train Epoch: 60 [10496/14860 (70%)]\tLoss: 0.017802\n",
            "Train Epoch: 60 [10624/14860 (71%)]\tLoss: 0.035955\n",
            "Train Epoch: 60 [10752/14860 (72%)]\tLoss: 0.013799\n",
            "Train Epoch: 60 [10880/14860 (73%)]\tLoss: 0.019884\n",
            "Train Epoch: 60 [11008/14860 (74%)]\tLoss: 0.017650\n",
            "Train Epoch: 60 [11136/14860 (74%)]\tLoss: 0.015333\n",
            "Train Epoch: 60 [11264/14860 (75%)]\tLoss: 0.029205\n",
            "Train Epoch: 60 [11392/14860 (76%)]\tLoss: 0.022689\n",
            "Train Epoch: 60 [11520/14860 (77%)]\tLoss: 0.021553\n",
            "Train Epoch: 60 [11648/14860 (78%)]\tLoss: 0.019621\n",
            "Train Epoch: 60 [11776/14860 (79%)]\tLoss: 0.014229\n",
            "Train Epoch: 60 [11904/14860 (79%)]\tLoss: 0.018206\n",
            "Train Epoch: 60 [12032/14860 (80%)]\tLoss: 0.018708\n",
            "Train Epoch: 60 [12160/14860 (81%)]\tLoss: 0.020592\n",
            "Train Epoch: 60 [12288/14860 (82%)]\tLoss: 0.019856\n",
            "Train Epoch: 60 [12416/14860 (83%)]\tLoss: 0.023528\n",
            "Train Epoch: 60 [12544/14860 (84%)]\tLoss: 0.026720\n",
            "Train Epoch: 60 [12672/14860 (85%)]\tLoss: 0.020782\n",
            "Train Epoch: 60 [12800/14860 (85%)]\tLoss: 0.012749\n",
            "Train Epoch: 60 [12928/14860 (86%)]\tLoss: 0.019996\n",
            "Train Epoch: 60 [13056/14860 (87%)]\tLoss: 0.018597\n",
            "Train Epoch: 60 [13184/14860 (88%)]\tLoss: 0.029532\n",
            "Train Epoch: 60 [13312/14860 (89%)]\tLoss: 0.020813\n",
            "Train Epoch: 60 [13440/14860 (90%)]\tLoss: 0.017314\n",
            "Train Epoch: 60 [13568/14860 (91%)]\tLoss: 0.022108\n",
            "Train Epoch: 60 [13696/14860 (91%)]\tLoss: 0.019304\n",
            "Train Epoch: 60 [13824/14860 (92%)]\tLoss: 0.016108\n",
            "Train Epoch: 60 [13952/14860 (93%)]\tLoss: 0.020039\n",
            "Train Epoch: 60 [14080/14860 (94%)]\tLoss: 0.019840\n",
            "Train Epoch: 60 [14208/14860 (95%)]\tLoss: 0.031024\n",
            "Train Epoch: 60 [14336/14860 (96%)]\tLoss: 0.018288\n",
            "Train Epoch: 60 [14464/14860 (97%)]\tLoss: 0.027051\n",
            "Train Epoch: 60 [14592/14860 (97%)]\tLoss: 0.019309\n",
            "Train Epoch: 60 [14720/14860 (98%)]\tLoss: 0.026810\n",
            "Train Epoch: 60 [1392/14860 (99%)]\tLoss: 0.018106\n",
            "epoch 60 training loss: 0.022115288740103572\n",
            "epoch 60 validation loss: 0.02049931385903901\n",
            "Train Epoch: 61 [0/14860 (0%)]\tLoss: 0.017717\n",
            "Train Epoch: 61 [128/14860 (1%)]\tLoss: 0.021851\n",
            "Train Epoch: 61 [256/14860 (2%)]\tLoss: 0.027278\n",
            "Train Epoch: 61 [384/14860 (3%)]\tLoss: 0.027485\n",
            "Train Epoch: 61 [512/14860 (3%)]\tLoss: 0.015086\n",
            "Train Epoch: 61 [640/14860 (4%)]\tLoss: 0.021088\n",
            "Train Epoch: 61 [768/14860 (5%)]\tLoss: 0.019962\n",
            "Train Epoch: 61 [896/14860 (6%)]\tLoss: 0.019876\n",
            "Train Epoch: 61 [1024/14860 (7%)]\tLoss: 0.025411\n",
            "Train Epoch: 61 [1152/14860 (8%)]\tLoss: 0.018801\n",
            "Train Epoch: 61 [1280/14860 (9%)]\tLoss: 0.017682\n",
            "Train Epoch: 61 [1408/14860 (9%)]\tLoss: 0.019050\n",
            "Train Epoch: 61 [1536/14860 (10%)]\tLoss: 0.020831\n",
            "Train Epoch: 61 [1664/14860 (11%)]\tLoss: 0.021036\n",
            "Train Epoch: 61 [1792/14860 (12%)]\tLoss: 0.022492\n",
            "Train Epoch: 61 [1920/14860 (13%)]\tLoss: 0.021170\n",
            "Train Epoch: 61 [2048/14860 (14%)]\tLoss: 0.016453\n",
            "Train Epoch: 61 [2176/14860 (15%)]\tLoss: 0.015133\n",
            "Train Epoch: 61 [2304/14860 (15%)]\tLoss: 0.019572\n",
            "Train Epoch: 61 [2432/14860 (16%)]\tLoss: 0.017904\n",
            "Train Epoch: 61 [2560/14860 (17%)]\tLoss: 0.024029\n",
            "Train Epoch: 61 [2688/14860 (18%)]\tLoss: 0.018406\n",
            "Train Epoch: 61 [2816/14860 (19%)]\tLoss: 0.022104\n",
            "Train Epoch: 61 [2944/14860 (20%)]\tLoss: 0.018395\n",
            "Train Epoch: 61 [3072/14860 (21%)]\tLoss: 0.019739\n",
            "Train Epoch: 61 [3200/14860 (21%)]\tLoss: 0.018807\n",
            "Train Epoch: 61 [3328/14860 (22%)]\tLoss: 0.023476\n",
            "Train Epoch: 61 [3456/14860 (23%)]\tLoss: 0.020755\n",
            "Train Epoch: 61 [3584/14860 (24%)]\tLoss: 0.015261\n",
            "Train Epoch: 61 [3712/14860 (25%)]\tLoss: 0.021404\n",
            "Train Epoch: 61 [3840/14860 (26%)]\tLoss: 0.016769\n",
            "Train Epoch: 61 [3968/14860 (26%)]\tLoss: 0.019167\n",
            "Train Epoch: 61 [4096/14860 (27%)]\tLoss: 0.023496\n",
            "Train Epoch: 61 [4224/14860 (28%)]\tLoss: 0.022768\n",
            "Train Epoch: 61 [4352/14860 (29%)]\tLoss: 0.027854\n",
            "Train Epoch: 61 [4480/14860 (30%)]\tLoss: 0.022315\n",
            "Train Epoch: 61 [4608/14860 (31%)]\tLoss: 0.037139\n",
            "Train Epoch: 61 [4736/14860 (32%)]\tLoss: 0.015875\n",
            "Train Epoch: 61 [4864/14860 (32%)]\tLoss: 0.035677\n",
            "Train Epoch: 61 [4992/14860 (33%)]\tLoss: 0.023381\n",
            "Train Epoch: 61 [5120/14860 (34%)]\tLoss: 0.023027\n",
            "Train Epoch: 61 [5248/14860 (35%)]\tLoss: 0.024285\n",
            "Train Epoch: 61 [5376/14860 (36%)]\tLoss: 0.029818\n",
            "Train Epoch: 61 [5504/14860 (37%)]\tLoss: 0.021654\n",
            "Train Epoch: 61 [5632/14860 (38%)]\tLoss: 0.030301\n",
            "Train Epoch: 61 [5760/14860 (38%)]\tLoss: 0.015151\n",
            "Train Epoch: 61 [5888/14860 (39%)]\tLoss: 0.041174\n",
            "Train Epoch: 61 [6016/14860 (40%)]\tLoss: 0.026416\n",
            "Train Epoch: 61 [6144/14860 (41%)]\tLoss: 0.036675\n",
            "Train Epoch: 61 [6272/14860 (42%)]\tLoss: 0.016064\n",
            "Train Epoch: 61 [6400/14860 (43%)]\tLoss: 0.047845\n",
            "Train Epoch: 61 [6528/14860 (44%)]\tLoss: 0.036053\n",
            "Train Epoch: 61 [6656/14860 (44%)]\tLoss: 0.035806\n",
            "Train Epoch: 61 [6784/14860 (45%)]\tLoss: 0.037105\n",
            "Train Epoch: 61 [6912/14860 (46%)]\tLoss: 0.024692\n",
            "Train Epoch: 61 [7040/14860 (47%)]\tLoss: 0.022440\n",
            "Train Epoch: 61 [7168/14860 (48%)]\tLoss: 0.016889\n",
            "Train Epoch: 61 [7296/14860 (49%)]\tLoss: 0.034431\n",
            "Train Epoch: 61 [7424/14860 (50%)]\tLoss: 0.022979\n",
            "Train Epoch: 61 [7552/14860 (50%)]\tLoss: 0.030086\n",
            "Train Epoch: 61 [7680/14860 (51%)]\tLoss: 0.032383\n",
            "Train Epoch: 61 [7808/14860 (52%)]\tLoss: 0.021809\n",
            "Train Epoch: 61 [7936/14860 (53%)]\tLoss: 0.022539\n",
            "Train Epoch: 61 [8064/14860 (54%)]\tLoss: 0.024061\n",
            "Train Epoch: 61 [8192/14860 (55%)]\tLoss: 0.027736\n",
            "Train Epoch: 61 [8320/14860 (56%)]\tLoss: 0.024386\n",
            "Train Epoch: 61 [8448/14860 (56%)]\tLoss: 0.030962\n",
            "Train Epoch: 61 [8576/14860 (57%)]\tLoss: 0.024870\n",
            "Train Epoch: 61 [8704/14860 (58%)]\tLoss: 0.025403\n",
            "Train Epoch: 61 [8832/14860 (59%)]\tLoss: 0.023280\n",
            "Train Epoch: 61 [8960/14860 (60%)]\tLoss: 0.018978\n",
            "Train Epoch: 61 [9088/14860 (61%)]\tLoss: 0.026730\n",
            "Train Epoch: 61 [9216/14860 (62%)]\tLoss: 0.017855\n",
            "Train Epoch: 61 [9344/14860 (62%)]\tLoss: 0.016722\n",
            "Train Epoch: 61 [9472/14860 (63%)]\tLoss: 0.023236\n",
            "Train Epoch: 61 [9600/14860 (64%)]\tLoss: 0.023180\n",
            "Train Epoch: 61 [9728/14860 (65%)]\tLoss: 0.036842\n",
            "Train Epoch: 61 [9856/14860 (66%)]\tLoss: 0.012801\n",
            "Train Epoch: 61 [9984/14860 (67%)]\tLoss: 0.033399\n",
            "Train Epoch: 61 [10112/14860 (68%)]\tLoss: 0.031133\n",
            "Train Epoch: 61 [10240/14860 (68%)]\tLoss: 0.029980\n",
            "Train Epoch: 61 [10368/14860 (69%)]\tLoss: 0.025083\n",
            "Train Epoch: 61 [10496/14860 (70%)]\tLoss: 0.025320\n",
            "Train Epoch: 61 [10624/14860 (71%)]\tLoss: 0.015681\n",
            "Train Epoch: 61 [10752/14860 (72%)]\tLoss: 0.016590\n",
            "Train Epoch: 61 [10880/14860 (73%)]\tLoss: 0.024116\n",
            "Train Epoch: 61 [11008/14860 (74%)]\tLoss: 0.015643\n",
            "Train Epoch: 61 [11136/14860 (74%)]\tLoss: 0.028942\n",
            "Train Epoch: 61 [11264/14860 (75%)]\tLoss: 0.020371\n",
            "Train Epoch: 61 [11392/14860 (76%)]\tLoss: 0.028129\n",
            "Train Epoch: 61 [11520/14860 (77%)]\tLoss: 0.020600\n",
            "Train Epoch: 61 [11648/14860 (78%)]\tLoss: 0.025991\n",
            "Train Epoch: 61 [11776/14860 (79%)]\tLoss: 0.033502\n",
            "Train Epoch: 61 [11904/14860 (79%)]\tLoss: 0.018845\n",
            "Train Epoch: 61 [12032/14860 (80%)]\tLoss: 0.028386\n",
            "Train Epoch: 61 [12160/14860 (81%)]\tLoss: 0.016758\n",
            "Train Epoch: 61 [12288/14860 (82%)]\tLoss: 0.024009\n",
            "Train Epoch: 61 [12416/14860 (83%)]\tLoss: 0.024584\n",
            "Train Epoch: 61 [12544/14860 (84%)]\tLoss: 0.019086\n",
            "Train Epoch: 61 [12672/14860 (85%)]\tLoss: 0.024074\n",
            "Train Epoch: 61 [12800/14860 (85%)]\tLoss: 0.012490\n",
            "Train Epoch: 61 [12928/14860 (86%)]\tLoss: 0.025221\n",
            "Train Epoch: 61 [13056/14860 (87%)]\tLoss: 0.019723\n",
            "Train Epoch: 61 [13184/14860 (88%)]\tLoss: 0.018532\n",
            "Train Epoch: 61 [13312/14860 (89%)]\tLoss: 0.018706\n",
            "Train Epoch: 61 [13440/14860 (90%)]\tLoss: 0.019626\n",
            "Train Epoch: 61 [13568/14860 (91%)]\tLoss: 0.015796\n",
            "Train Epoch: 61 [13696/14860 (91%)]\tLoss: 0.018951\n",
            "Train Epoch: 61 [13824/14860 (92%)]\tLoss: 0.013755\n",
            "Train Epoch: 61 [13952/14860 (93%)]\tLoss: 0.028441\n",
            "Train Epoch: 61 [14080/14860 (94%)]\tLoss: 0.013848\n",
            "Train Epoch: 61 [14208/14860 (95%)]\tLoss: 0.023565\n",
            "Train Epoch: 61 [14336/14860 (96%)]\tLoss: 0.014822\n",
            "Train Epoch: 61 [14464/14860 (97%)]\tLoss: 0.018700\n",
            "Train Epoch: 61 [14592/14860 (97%)]\tLoss: 0.015496\n",
            "Train Epoch: 61 [14720/14860 (98%)]\tLoss: 0.021272\n",
            "Train Epoch: 61 [1392/14860 (99%)]\tLoss: 0.017004\n",
            "epoch 61 training loss: 0.023124192379669756\n",
            "epoch 61 validation loss: 0.026800359276824656\n",
            "Train Epoch: 62 [0/14860 (0%)]\tLoss: 0.022127\n",
            "Train Epoch: 62 [128/14860 (1%)]\tLoss: 0.025699\n",
            "Train Epoch: 62 [256/14860 (2%)]\tLoss: 0.034200\n",
            "Train Epoch: 62 [384/14860 (3%)]\tLoss: 0.016264\n",
            "Train Epoch: 62 [512/14860 (3%)]\tLoss: 0.030309\n",
            "Train Epoch: 62 [640/14860 (4%)]\tLoss: 0.020867\n",
            "Train Epoch: 62 [768/14860 (5%)]\tLoss: 0.021745\n",
            "Train Epoch: 62 [896/14860 (6%)]\tLoss: 0.021811\n",
            "Train Epoch: 62 [1024/14860 (7%)]\tLoss: 0.021257\n",
            "Train Epoch: 62 [1152/14860 (8%)]\tLoss: 0.021699\n",
            "Train Epoch: 62 [1280/14860 (9%)]\tLoss: 0.016764\n",
            "Train Epoch: 62 [1408/14860 (9%)]\tLoss: 0.023031\n",
            "Train Epoch: 62 [1536/14860 (10%)]\tLoss: 0.018036\n",
            "Train Epoch: 62 [1664/14860 (11%)]\tLoss: 0.019618\n",
            "Train Epoch: 62 [1792/14860 (12%)]\tLoss: 0.020448\n",
            "Train Epoch: 62 [1920/14860 (13%)]\tLoss: 0.021820\n",
            "Train Epoch: 62 [2048/14860 (14%)]\tLoss: 0.021585\n",
            "Train Epoch: 62 [2176/14860 (15%)]\tLoss: 0.015656\n",
            "Train Epoch: 62 [2304/14860 (15%)]\tLoss: 0.015281\n",
            "Train Epoch: 62 [2432/14860 (16%)]\tLoss: 0.016718\n",
            "Train Epoch: 62 [2560/14860 (17%)]\tLoss: 0.022794\n",
            "Train Epoch: 62 [2688/14860 (18%)]\tLoss: 0.027778\n",
            "Train Epoch: 62 [2816/14860 (19%)]\tLoss: 0.018519\n",
            "Train Epoch: 62 [2944/14860 (20%)]\tLoss: 0.017801\n",
            "Train Epoch: 62 [3072/14860 (21%)]\tLoss: 0.018220\n",
            "Train Epoch: 62 [3200/14860 (21%)]\tLoss: 0.015970\n",
            "Train Epoch: 62 [3328/14860 (22%)]\tLoss: 0.023924\n",
            "Train Epoch: 62 [3456/14860 (23%)]\tLoss: 0.017452\n",
            "Train Epoch: 62 [3584/14860 (24%)]\tLoss: 0.019254\n",
            "Train Epoch: 62 [3712/14860 (25%)]\tLoss: 0.015068\n",
            "Train Epoch: 62 [3840/14860 (26%)]\tLoss: 0.024166\n",
            "Train Epoch: 62 [3968/14860 (26%)]\tLoss: 0.016987\n",
            "Train Epoch: 62 [4096/14860 (27%)]\tLoss: 0.022207\n",
            "Train Epoch: 62 [4224/14860 (28%)]\tLoss: 0.018235\n",
            "Train Epoch: 62 [4352/14860 (29%)]\tLoss: 0.015950\n",
            "Train Epoch: 62 [4480/14860 (30%)]\tLoss: 0.026013\n",
            "Train Epoch: 62 [4608/14860 (31%)]\tLoss: 0.017391\n",
            "Train Epoch: 62 [4736/14860 (32%)]\tLoss: 0.031192\n",
            "Train Epoch: 62 [4864/14860 (32%)]\tLoss: 0.019061\n",
            "Train Epoch: 62 [4992/14860 (33%)]\tLoss: 0.013434\n",
            "Train Epoch: 62 [5120/14860 (34%)]\tLoss: 0.016142\n",
            "Train Epoch: 62 [5248/14860 (35%)]\tLoss: 0.019345\n",
            "Train Epoch: 62 [5376/14860 (36%)]\tLoss: 0.020908\n",
            "Train Epoch: 62 [5504/14860 (37%)]\tLoss: 0.014611\n",
            "Train Epoch: 62 [5632/14860 (38%)]\tLoss: 0.022869\n",
            "Train Epoch: 62 [5760/14860 (38%)]\tLoss: 0.026963\n",
            "Train Epoch: 62 [5888/14860 (39%)]\tLoss: 0.019034\n",
            "Train Epoch: 62 [6016/14860 (40%)]\tLoss: 0.014645\n",
            "Train Epoch: 62 [6144/14860 (41%)]\tLoss: 0.025164\n",
            "Train Epoch: 62 [6272/14860 (42%)]\tLoss: 0.014932\n",
            "Train Epoch: 62 [6400/14860 (43%)]\tLoss: 0.018050\n",
            "Train Epoch: 62 [6528/14860 (44%)]\tLoss: 0.016066\n",
            "Train Epoch: 62 [6656/14860 (44%)]\tLoss: 0.027437\n",
            "Train Epoch: 62 [6784/14860 (45%)]\tLoss: 0.027575\n",
            "Train Epoch: 62 [6912/14860 (46%)]\tLoss: 0.020889\n",
            "Train Epoch: 62 [7040/14860 (47%)]\tLoss: 0.018545\n",
            "Train Epoch: 62 [7168/14860 (48%)]\tLoss: 0.023415\n",
            "Train Epoch: 62 [7296/14860 (49%)]\tLoss: 0.021155\n",
            "Train Epoch: 62 [7424/14860 (50%)]\tLoss: 0.032191\n",
            "Train Epoch: 62 [7552/14860 (50%)]\tLoss: 0.024993\n",
            "Train Epoch: 62 [7680/14860 (51%)]\tLoss: 0.016757\n",
            "Train Epoch: 62 [7808/14860 (52%)]\tLoss: 0.016555\n",
            "Train Epoch: 62 [7936/14860 (53%)]\tLoss: 0.018293\n",
            "Train Epoch: 62 [8064/14860 (54%)]\tLoss: 0.019200\n",
            "Train Epoch: 62 [8192/14860 (55%)]\tLoss: 0.020145\n",
            "Train Epoch: 62 [8320/14860 (56%)]\tLoss: 0.030482\n",
            "Train Epoch: 62 [8448/14860 (56%)]\tLoss: 0.022025\n",
            "Train Epoch: 62 [8576/14860 (57%)]\tLoss: 0.020059\n",
            "Train Epoch: 62 [8704/14860 (58%)]\tLoss: 0.013469\n",
            "Train Epoch: 62 [8832/14860 (59%)]\tLoss: 0.020386\n",
            "Train Epoch: 62 [8960/14860 (60%)]\tLoss: 0.019928\n",
            "Train Epoch: 62 [9088/14860 (61%)]\tLoss: 0.016893\n",
            "Train Epoch: 62 [9216/14860 (62%)]\tLoss: 0.021380\n",
            "Train Epoch: 62 [9344/14860 (62%)]\tLoss: 0.015310\n",
            "Train Epoch: 62 [9472/14860 (63%)]\tLoss: 0.014437\n",
            "Train Epoch: 62 [9600/14860 (64%)]\tLoss: 0.020037\n",
            "Train Epoch: 62 [9728/14860 (65%)]\tLoss: 0.028896\n",
            "Train Epoch: 62 [9856/14860 (66%)]\tLoss: 0.024812\n",
            "Train Epoch: 62 [9984/14860 (67%)]\tLoss: 0.029654\n",
            "Train Epoch: 62 [10112/14860 (68%)]\tLoss: 0.025199\n",
            "Train Epoch: 62 [10240/14860 (68%)]\tLoss: 0.019370\n",
            "Train Epoch: 62 [10368/14860 (69%)]\tLoss: 0.026342\n",
            "Train Epoch: 62 [10496/14860 (70%)]\tLoss: 0.028548\n",
            "Train Epoch: 62 [10624/14860 (71%)]\tLoss: 0.024552\n",
            "Train Epoch: 62 [10752/14860 (72%)]\tLoss: 0.028029\n",
            "Train Epoch: 62 [10880/14860 (73%)]\tLoss: 0.028098\n",
            "Train Epoch: 62 [11008/14860 (74%)]\tLoss: 0.034597\n",
            "Train Epoch: 62 [11136/14860 (74%)]\tLoss: 0.024029\n",
            "Train Epoch: 62 [11264/14860 (75%)]\tLoss: 0.020186\n",
            "Train Epoch: 62 [11392/14860 (76%)]\tLoss: 0.024138\n",
            "Train Epoch: 62 [11520/14860 (77%)]\tLoss: 0.021408\n",
            "Train Epoch: 62 [11648/14860 (78%)]\tLoss: 0.017888\n",
            "Train Epoch: 62 [11776/14860 (79%)]\tLoss: 0.022702\n",
            "Train Epoch: 62 [11904/14860 (79%)]\tLoss: 0.028366\n",
            "Train Epoch: 62 [12032/14860 (80%)]\tLoss: 0.018529\n",
            "Train Epoch: 62 [12160/14860 (81%)]\tLoss: 0.023791\n",
            "Train Epoch: 62 [12288/14860 (82%)]\tLoss: 0.018530\n",
            "Train Epoch: 62 [12416/14860 (83%)]\tLoss: 0.011679\n",
            "Train Epoch: 62 [12544/14860 (84%)]\tLoss: 0.026531\n",
            "Train Epoch: 62 [12672/14860 (85%)]\tLoss: 0.021201\n",
            "Train Epoch: 62 [12800/14860 (85%)]\tLoss: 0.025371\n",
            "Train Epoch: 62 [12928/14860 (86%)]\tLoss: 0.015060\n",
            "Train Epoch: 62 [13056/14860 (87%)]\tLoss: 0.024371\n",
            "Train Epoch: 62 [13184/14860 (88%)]\tLoss: 0.017669\n",
            "Train Epoch: 62 [13312/14860 (89%)]\tLoss: 0.021953\n",
            "Train Epoch: 62 [13440/14860 (90%)]\tLoss: 0.025112\n",
            "Train Epoch: 62 [13568/14860 (91%)]\tLoss: 0.019069\n",
            "Train Epoch: 62 [13696/14860 (91%)]\tLoss: 0.020093\n",
            "Train Epoch: 62 [13824/14860 (92%)]\tLoss: 0.022728\n",
            "Train Epoch: 62 [13952/14860 (93%)]\tLoss: 0.022115\n",
            "Train Epoch: 62 [14080/14860 (94%)]\tLoss: 0.021697\n",
            "Train Epoch: 62 [14208/14860 (95%)]\tLoss: 0.016464\n",
            "Train Epoch: 62 [14336/14860 (96%)]\tLoss: 0.038624\n",
            "Train Epoch: 62 [14464/14860 (97%)]\tLoss: 0.021188\n",
            "Train Epoch: 62 [14592/14860 (97%)]\tLoss: 0.022548\n",
            "Train Epoch: 62 [14720/14860 (98%)]\tLoss: 0.022071\n",
            "Train Epoch: 62 [1392/14860 (99%)]\tLoss: 0.012892\n",
            "epoch 62 training loss: 0.02139090377296138\n",
            "epoch 62 validation loss: 0.020769468952899408\n",
            "Train Epoch: 63 [0/14860 (0%)]\tLoss: 0.020489\n",
            "Train Epoch: 63 [128/14860 (1%)]\tLoss: 0.027556\n",
            "Train Epoch: 63 [256/14860 (2%)]\tLoss: 0.021320\n",
            "Train Epoch: 63 [384/14860 (3%)]\tLoss: 0.018842\n",
            "Train Epoch: 63 [512/14860 (3%)]\tLoss: 0.014869\n",
            "Train Epoch: 63 [640/14860 (4%)]\tLoss: 0.016898\n",
            "Train Epoch: 63 [768/14860 (5%)]\tLoss: 0.020889\n",
            "Train Epoch: 63 [896/14860 (6%)]\tLoss: 0.023346\n",
            "Train Epoch: 63 [1024/14860 (7%)]\tLoss: 0.025532\n",
            "Train Epoch: 63 [1152/14860 (8%)]\tLoss: 0.017544\n",
            "Train Epoch: 63 [1280/14860 (9%)]\tLoss: 0.015380\n",
            "Train Epoch: 63 [1408/14860 (9%)]\tLoss: 0.023005\n",
            "Train Epoch: 63 [1536/14860 (10%)]\tLoss: 0.020393\n",
            "Train Epoch: 63 [1664/14860 (11%)]\tLoss: 0.014252\n",
            "Train Epoch: 63 [1792/14860 (12%)]\tLoss: 0.024676\n",
            "Train Epoch: 63 [1920/14860 (13%)]\tLoss: 0.021714\n",
            "Train Epoch: 63 [2048/14860 (14%)]\tLoss: 0.024205\n",
            "Train Epoch: 63 [2176/14860 (15%)]\tLoss: 0.018609\n",
            "Train Epoch: 63 [2304/14860 (15%)]\tLoss: 0.025875\n",
            "Train Epoch: 63 [2432/14860 (16%)]\tLoss: 0.022289\n",
            "Train Epoch: 63 [2560/14860 (17%)]\tLoss: 0.017220\n",
            "Train Epoch: 63 [2688/14860 (18%)]\tLoss: 0.024155\n",
            "Train Epoch: 63 [2816/14860 (19%)]\tLoss: 0.021113\n",
            "Train Epoch: 63 [2944/14860 (20%)]\tLoss: 0.028622\n",
            "Train Epoch: 63 [3072/14860 (21%)]\tLoss: 0.030205\n",
            "Train Epoch: 63 [3200/14860 (21%)]\tLoss: 0.017740\n",
            "Train Epoch: 63 [3328/14860 (22%)]\tLoss: 0.020572\n",
            "Train Epoch: 63 [3456/14860 (23%)]\tLoss: 0.017145\n",
            "Train Epoch: 63 [3584/14860 (24%)]\tLoss: 0.021644\n",
            "Train Epoch: 63 [3712/14860 (25%)]\tLoss: 0.013130\n",
            "Train Epoch: 63 [3840/14860 (26%)]\tLoss: 0.026056\n",
            "Train Epoch: 63 [3968/14860 (26%)]\tLoss: 0.014001\n",
            "Train Epoch: 63 [4096/14860 (27%)]\tLoss: 0.020118\n",
            "Train Epoch: 63 [4224/14860 (28%)]\tLoss: 0.015909\n",
            "Train Epoch: 63 [4352/14860 (29%)]\tLoss: 0.016222\n",
            "Train Epoch: 63 [4480/14860 (30%)]\tLoss: 0.035348\n",
            "Train Epoch: 63 [4608/14860 (31%)]\tLoss: 0.026244\n",
            "Train Epoch: 63 [4736/14860 (32%)]\tLoss: 0.029691\n",
            "Train Epoch: 63 [4864/14860 (32%)]\tLoss: 0.021614\n",
            "Train Epoch: 63 [4992/14860 (33%)]\tLoss: 0.025091\n",
            "Train Epoch: 63 [5120/14860 (34%)]\tLoss: 0.013018\n",
            "Train Epoch: 63 [5248/14860 (35%)]\tLoss: 0.018895\n",
            "Train Epoch: 63 [5376/14860 (36%)]\tLoss: 0.016777\n",
            "Train Epoch: 63 [5504/14860 (37%)]\tLoss: 0.024132\n",
            "Train Epoch: 63 [5632/14860 (38%)]\tLoss: 0.021090\n",
            "Train Epoch: 63 [5760/14860 (38%)]\tLoss: 0.021897\n",
            "Train Epoch: 63 [5888/14860 (39%)]\tLoss: 0.019141\n",
            "Train Epoch: 63 [6016/14860 (40%)]\tLoss: 0.023924\n",
            "Train Epoch: 63 [6144/14860 (41%)]\tLoss: 0.026097\n",
            "Train Epoch: 63 [6272/14860 (42%)]\tLoss: 0.024531\n",
            "Train Epoch: 63 [6400/14860 (43%)]\tLoss: 0.022142\n",
            "Train Epoch: 63 [6528/14860 (44%)]\tLoss: 0.022002\n",
            "Train Epoch: 63 [6656/14860 (44%)]\tLoss: 0.018262\n",
            "Train Epoch: 63 [6784/14860 (45%)]\tLoss: 0.022867\n",
            "Train Epoch: 63 [6912/14860 (46%)]\tLoss: 0.025481\n",
            "Train Epoch: 63 [7040/14860 (47%)]\tLoss: 0.027127\n",
            "Train Epoch: 63 [7168/14860 (48%)]\tLoss: 0.026802\n",
            "Train Epoch: 63 [7296/14860 (49%)]\tLoss: 0.018876\n",
            "Train Epoch: 63 [7424/14860 (50%)]\tLoss: 0.020619\n",
            "Train Epoch: 63 [7552/14860 (50%)]\tLoss: 0.025447\n",
            "Train Epoch: 63 [7680/14860 (51%)]\tLoss: 0.023648\n",
            "Train Epoch: 63 [7808/14860 (52%)]\tLoss: 0.018285\n",
            "Train Epoch: 63 [7936/14860 (53%)]\tLoss: 0.028111\n",
            "Train Epoch: 63 [8064/14860 (54%)]\tLoss: 0.018515\n",
            "Train Epoch: 63 [8192/14860 (55%)]\tLoss: 0.032045\n",
            "Train Epoch: 63 [8320/14860 (56%)]\tLoss: 0.023131\n",
            "Train Epoch: 63 [8448/14860 (56%)]\tLoss: 0.016646\n",
            "Train Epoch: 63 [8576/14860 (57%)]\tLoss: 0.020541\n",
            "Train Epoch: 63 [8704/14860 (58%)]\tLoss: 0.016572\n",
            "Train Epoch: 63 [8832/14860 (59%)]\tLoss: 0.016912\n",
            "Train Epoch: 63 [8960/14860 (60%)]\tLoss: 0.024176\n",
            "Train Epoch: 63 [9088/14860 (61%)]\tLoss: 0.017971\n",
            "Train Epoch: 63 [9216/14860 (62%)]\tLoss: 0.019080\n",
            "Train Epoch: 63 [9344/14860 (62%)]\tLoss: 0.023856\n",
            "Train Epoch: 63 [9472/14860 (63%)]\tLoss: 0.021742\n",
            "Train Epoch: 63 [9600/14860 (64%)]\tLoss: 0.023295\n",
            "Train Epoch: 63 [9728/14860 (65%)]\tLoss: 0.015719\n",
            "Train Epoch: 63 [9856/14860 (66%)]\tLoss: 0.030058\n",
            "Train Epoch: 63 [9984/14860 (67%)]\tLoss: 0.015573\n",
            "Train Epoch: 63 [10112/14860 (68%)]\tLoss: 0.027190\n",
            "Train Epoch: 63 [10240/14860 (68%)]\tLoss: 0.025057\n",
            "Train Epoch: 63 [10368/14860 (69%)]\tLoss: 0.016090\n",
            "Train Epoch: 63 [10496/14860 (70%)]\tLoss: 0.020802\n",
            "Train Epoch: 63 [10624/14860 (71%)]\tLoss: 0.016313\n",
            "Train Epoch: 63 [10752/14860 (72%)]\tLoss: 0.020576\n",
            "Train Epoch: 63 [10880/14860 (73%)]\tLoss: 0.024864\n",
            "Train Epoch: 63 [11008/14860 (74%)]\tLoss: 0.015437\n",
            "Train Epoch: 63 [11136/14860 (74%)]\tLoss: 0.025170\n",
            "Train Epoch: 63 [11264/14860 (75%)]\tLoss: 0.021311\n",
            "Train Epoch: 63 [11392/14860 (76%)]\tLoss: 0.021636\n",
            "Train Epoch: 63 [11520/14860 (77%)]\tLoss: 0.017940\n",
            "Train Epoch: 63 [11648/14860 (78%)]\tLoss: 0.030269\n",
            "Train Epoch: 63 [11776/14860 (79%)]\tLoss: 0.020887\n",
            "Train Epoch: 63 [11904/14860 (79%)]\tLoss: 0.030050\n",
            "Train Epoch: 63 [12032/14860 (80%)]\tLoss: 0.019252\n",
            "Train Epoch: 63 [12160/14860 (81%)]\tLoss: 0.024625\n",
            "Train Epoch: 63 [12288/14860 (82%)]\tLoss: 0.015682\n",
            "Train Epoch: 63 [12416/14860 (83%)]\tLoss: 0.022001\n",
            "Train Epoch: 63 [12544/14860 (84%)]\tLoss: 0.021182\n",
            "Train Epoch: 63 [12672/14860 (85%)]\tLoss: 0.036987\n",
            "Train Epoch: 63 [12800/14860 (85%)]\tLoss: 0.019053\n",
            "Train Epoch: 63 [12928/14860 (86%)]\tLoss: 0.018565\n",
            "Train Epoch: 63 [13056/14860 (87%)]\tLoss: 0.023729\n",
            "Train Epoch: 63 [13184/14860 (88%)]\tLoss: 0.012644\n",
            "Train Epoch: 63 [13312/14860 (89%)]\tLoss: 0.022570\n",
            "Train Epoch: 63 [13440/14860 (90%)]\tLoss: 0.023295\n",
            "Train Epoch: 63 [13568/14860 (91%)]\tLoss: 0.020471\n",
            "Train Epoch: 63 [13696/14860 (91%)]\tLoss: 0.016025\n",
            "Train Epoch: 63 [13824/14860 (92%)]\tLoss: 0.016923\n",
            "Train Epoch: 63 [13952/14860 (93%)]\tLoss: 0.015772\n",
            "Train Epoch: 63 [14080/14860 (94%)]\tLoss: 0.021651\n",
            "Train Epoch: 63 [14208/14860 (95%)]\tLoss: 0.017777\n",
            "Train Epoch: 63 [14336/14860 (96%)]\tLoss: 0.012929\n",
            "Train Epoch: 63 [14464/14860 (97%)]\tLoss: 0.020661\n",
            "Train Epoch: 63 [14592/14860 (97%)]\tLoss: 0.018655\n",
            "Train Epoch: 63 [14720/14860 (98%)]\tLoss: 0.018083\n",
            "Train Epoch: 63 [1392/14860 (99%)]\tLoss: 0.027583\n",
            "epoch 63 training loss: 0.02140368586485712\n",
            "epoch 63 validation loss: 0.03126032257195535\n",
            "Train Epoch: 64 [0/14860 (0%)]\tLoss: 0.029403\n",
            "Train Epoch: 64 [128/14860 (1%)]\tLoss: 0.021129\n",
            "Train Epoch: 64 [256/14860 (2%)]\tLoss: 0.048923\n",
            "Train Epoch: 64 [384/14860 (3%)]\tLoss: 0.035566\n",
            "Train Epoch: 64 [512/14860 (3%)]\tLoss: 0.026114\n",
            "Train Epoch: 64 [640/14860 (4%)]\tLoss: 0.028516\n",
            "Train Epoch: 64 [768/14860 (5%)]\tLoss: 0.027145\n",
            "Train Epoch: 64 [896/14860 (6%)]\tLoss: 0.028603\n",
            "Train Epoch: 64 [1024/14860 (7%)]\tLoss: 0.022662\n",
            "Train Epoch: 64 [1152/14860 (8%)]\tLoss: 0.020680\n",
            "Train Epoch: 64 [1280/14860 (9%)]\tLoss: 0.032141\n",
            "Train Epoch: 64 [1408/14860 (9%)]\tLoss: 0.021455\n",
            "Train Epoch: 64 [1536/14860 (10%)]\tLoss: 0.027443\n",
            "Train Epoch: 64 [1664/14860 (11%)]\tLoss: 0.019274\n",
            "Train Epoch: 64 [1792/14860 (12%)]\tLoss: 0.021964\n",
            "Train Epoch: 64 [1920/14860 (13%)]\tLoss: 0.016313\n",
            "Train Epoch: 64 [2048/14860 (14%)]\tLoss: 0.017941\n",
            "Train Epoch: 64 [2176/14860 (15%)]\tLoss: 0.029953\n",
            "Train Epoch: 64 [2304/14860 (15%)]\tLoss: 0.021706\n",
            "Train Epoch: 64 [2432/14860 (16%)]\tLoss: 0.018581\n",
            "Train Epoch: 64 [2560/14860 (17%)]\tLoss: 0.032153\n",
            "Train Epoch: 64 [2688/14860 (18%)]\tLoss: 0.022272\n",
            "Train Epoch: 64 [2816/14860 (19%)]\tLoss: 0.026301\n",
            "Train Epoch: 64 [2944/14860 (20%)]\tLoss: 0.014256\n",
            "Train Epoch: 64 [3072/14860 (21%)]\tLoss: 0.025410\n",
            "Train Epoch: 64 [3200/14860 (21%)]\tLoss: 0.017591\n",
            "Train Epoch: 64 [3328/14860 (22%)]\tLoss: 0.022939\n",
            "Train Epoch: 64 [3456/14860 (23%)]\tLoss: 0.017273\n",
            "Train Epoch: 64 [3584/14860 (24%)]\tLoss: 0.022830\n",
            "Train Epoch: 64 [3712/14860 (25%)]\tLoss: 0.019773\n",
            "Train Epoch: 64 [3840/14860 (26%)]\tLoss: 0.013715\n",
            "Train Epoch: 64 [3968/14860 (26%)]\tLoss: 0.030899\n",
            "Train Epoch: 64 [4096/14860 (27%)]\tLoss: 0.018141\n",
            "Train Epoch: 64 [4224/14860 (28%)]\tLoss: 0.026912\n",
            "Train Epoch: 64 [4352/14860 (29%)]\tLoss: 0.013601\n",
            "Train Epoch: 64 [4480/14860 (30%)]\tLoss: 0.020155\n",
            "Train Epoch: 64 [4608/14860 (31%)]\tLoss: 0.017569\n",
            "Train Epoch: 64 [4736/14860 (32%)]\tLoss: 0.021450\n",
            "Train Epoch: 64 [4864/14860 (32%)]\tLoss: 0.023862\n",
            "Train Epoch: 64 [4992/14860 (33%)]\tLoss: 0.013467\n",
            "Train Epoch: 64 [5120/14860 (34%)]\tLoss: 0.025851\n",
            "Train Epoch: 64 [5248/14860 (35%)]\tLoss: 0.019037\n",
            "Train Epoch: 64 [5376/14860 (36%)]\tLoss: 0.027697\n",
            "Train Epoch: 64 [5504/14860 (37%)]\tLoss: 0.021329\n",
            "Train Epoch: 64 [5632/14860 (38%)]\tLoss: 0.026293\n",
            "Train Epoch: 64 [5760/14860 (38%)]\tLoss: 0.017498\n",
            "Train Epoch: 64 [5888/14860 (39%)]\tLoss: 0.025299\n",
            "Train Epoch: 64 [6016/14860 (40%)]\tLoss: 0.019418\n",
            "Train Epoch: 64 [6144/14860 (41%)]\tLoss: 0.020175\n",
            "Train Epoch: 64 [6272/14860 (42%)]\tLoss: 0.017468\n",
            "Train Epoch: 64 [6400/14860 (43%)]\tLoss: 0.023830\n",
            "Train Epoch: 64 [6528/14860 (44%)]\tLoss: 0.018138\n",
            "Train Epoch: 64 [6656/14860 (44%)]\tLoss: 0.020213\n",
            "Train Epoch: 64 [6784/14860 (45%)]\tLoss: 0.023083\n",
            "Train Epoch: 64 [6912/14860 (46%)]\tLoss: 0.022926\n",
            "Train Epoch: 64 [7040/14860 (47%)]\tLoss: 0.026730\n",
            "Train Epoch: 64 [7168/14860 (48%)]\tLoss: 0.021454\n",
            "Train Epoch: 64 [7296/14860 (49%)]\tLoss: 0.026721\n",
            "Train Epoch: 64 [7424/14860 (50%)]\tLoss: 0.019463\n",
            "Train Epoch: 64 [7552/14860 (50%)]\tLoss: 0.017767\n",
            "Train Epoch: 64 [7680/14860 (51%)]\tLoss: 0.012554\n",
            "Train Epoch: 64 [7808/14860 (52%)]\tLoss: 0.025348\n",
            "Train Epoch: 64 [7936/14860 (53%)]\tLoss: 0.031122\n",
            "Train Epoch: 64 [8064/14860 (54%)]\tLoss: 0.022235\n",
            "Train Epoch: 64 [8192/14860 (55%)]\tLoss: 0.021437\n",
            "Train Epoch: 64 [8320/14860 (56%)]\tLoss: 0.030188\n",
            "Train Epoch: 64 [8448/14860 (56%)]\tLoss: 0.023703\n",
            "Train Epoch: 64 [8576/14860 (57%)]\tLoss: 0.022247\n",
            "Train Epoch: 64 [8704/14860 (58%)]\tLoss: 0.019724\n",
            "Train Epoch: 64 [8832/14860 (59%)]\tLoss: 0.022594\n",
            "Train Epoch: 64 [8960/14860 (60%)]\tLoss: 0.021273\n",
            "Train Epoch: 64 [9088/14860 (61%)]\tLoss: 0.024026\n",
            "Train Epoch: 64 [9216/14860 (62%)]\tLoss: 0.020046\n",
            "Train Epoch: 64 [9344/14860 (62%)]\tLoss: 0.016669\n",
            "Train Epoch: 64 [9472/14860 (63%)]\tLoss: 0.016772\n",
            "Train Epoch: 64 [9600/14860 (64%)]\tLoss: 0.016783\n",
            "Train Epoch: 64 [9728/14860 (65%)]\tLoss: 0.022115\n",
            "Train Epoch: 64 [9856/14860 (66%)]\tLoss: 0.019039\n",
            "Train Epoch: 64 [9984/14860 (67%)]\tLoss: 0.019129\n",
            "Train Epoch: 64 [10112/14860 (68%)]\tLoss: 0.018607\n",
            "Train Epoch: 64 [10240/14860 (68%)]\tLoss: 0.014535\n",
            "Train Epoch: 64 [10368/14860 (69%)]\tLoss: 0.020219\n",
            "Train Epoch: 64 [10496/14860 (70%)]\tLoss: 0.020232\n",
            "Train Epoch: 64 [10624/14860 (71%)]\tLoss: 0.016562\n",
            "Train Epoch: 64 [10752/14860 (72%)]\tLoss: 0.016282\n",
            "Train Epoch: 64 [10880/14860 (73%)]\tLoss: 0.016838\n",
            "Train Epoch: 64 [11008/14860 (74%)]\tLoss: 0.023365\n",
            "Train Epoch: 64 [11136/14860 (74%)]\tLoss: 0.023783\n",
            "Train Epoch: 64 [11264/14860 (75%)]\tLoss: 0.015023\n",
            "Train Epoch: 64 [11392/14860 (76%)]\tLoss: 0.016877\n",
            "Train Epoch: 64 [11520/14860 (77%)]\tLoss: 0.023461\n",
            "Train Epoch: 64 [11648/14860 (78%)]\tLoss: 0.027556\n",
            "Train Epoch: 64 [11776/14860 (79%)]\tLoss: 0.026153\n",
            "Train Epoch: 64 [11904/14860 (79%)]\tLoss: 0.019707\n",
            "Train Epoch: 64 [12032/14860 (80%)]\tLoss: 0.028253\n",
            "Train Epoch: 64 [12160/14860 (81%)]\tLoss: 0.023515\n",
            "Train Epoch: 64 [12288/14860 (82%)]\tLoss: 0.015504\n",
            "Train Epoch: 64 [12416/14860 (83%)]\tLoss: 0.026709\n",
            "Train Epoch: 64 [12544/14860 (84%)]\tLoss: 0.019947\n",
            "Train Epoch: 64 [12672/14860 (85%)]\tLoss: 0.026515\n",
            "Train Epoch: 64 [12800/14860 (85%)]\tLoss: 0.030479\n",
            "Train Epoch: 64 [12928/14860 (86%)]\tLoss: 0.021092\n",
            "Train Epoch: 64 [13056/14860 (87%)]\tLoss: 0.026022\n",
            "Train Epoch: 64 [13184/14860 (88%)]\tLoss: 0.023350\n",
            "Train Epoch: 64 [13312/14860 (89%)]\tLoss: 0.026958\n",
            "Train Epoch: 64 [13440/14860 (90%)]\tLoss: 0.017384\n",
            "Train Epoch: 64 [13568/14860 (91%)]\tLoss: 0.027082\n",
            "Train Epoch: 64 [13696/14860 (91%)]\tLoss: 0.016144\n",
            "Train Epoch: 64 [13824/14860 (92%)]\tLoss: 0.024629\n",
            "Train Epoch: 64 [13952/14860 (93%)]\tLoss: 0.024578\n",
            "Train Epoch: 64 [14080/14860 (94%)]\tLoss: 0.020006\n",
            "Train Epoch: 64 [14208/14860 (95%)]\tLoss: 0.019967\n",
            "Train Epoch: 64 [14336/14860 (96%)]\tLoss: 0.024229\n",
            "Train Epoch: 64 [14464/14860 (97%)]\tLoss: 0.022668\n",
            "Train Epoch: 64 [14592/14860 (97%)]\tLoss: 0.017307\n",
            "Train Epoch: 64 [14720/14860 (98%)]\tLoss: 0.017511\n",
            "Train Epoch: 64 [1392/14860 (99%)]\tLoss: 0.018017\n",
            "epoch 64 training loss: 0.02222686627895659\n",
            "epoch 64 validation loss: 0.02993877228466708\n",
            "Train Epoch: 65 [0/14860 (0%)]\tLoss: 0.030849\n",
            "Train Epoch: 65 [128/14860 (1%)]\tLoss: 0.024855\n",
            "Train Epoch: 65 [256/14860 (2%)]\tLoss: 0.022149\n",
            "Train Epoch: 65 [384/14860 (3%)]\tLoss: 0.029361\n",
            "Train Epoch: 65 [512/14860 (3%)]\tLoss: 0.021963\n",
            "Train Epoch: 65 [640/14860 (4%)]\tLoss: 0.015855\n",
            "Train Epoch: 65 [768/14860 (5%)]\tLoss: 0.018451\n",
            "Train Epoch: 65 [896/14860 (6%)]\tLoss: 0.018157\n",
            "Train Epoch: 65 [1024/14860 (7%)]\tLoss: 0.025190\n",
            "Train Epoch: 65 [1152/14860 (8%)]\tLoss: 0.026697\n",
            "Train Epoch: 65 [1280/14860 (9%)]\tLoss: 0.017442\n",
            "Train Epoch: 65 [1408/14860 (9%)]\tLoss: 0.029625\n",
            "Train Epoch: 65 [1536/14860 (10%)]\tLoss: 0.022686\n",
            "Train Epoch: 65 [1664/14860 (11%)]\tLoss: 0.034922\n",
            "Train Epoch: 65 [1792/14860 (12%)]\tLoss: 0.031093\n",
            "Train Epoch: 65 [1920/14860 (13%)]\tLoss: 0.018148\n",
            "Train Epoch: 65 [2048/14860 (14%)]\tLoss: 0.018274\n",
            "Train Epoch: 65 [2176/14860 (15%)]\tLoss: 0.027131\n",
            "Train Epoch: 65 [2304/14860 (15%)]\tLoss: 0.031594\n",
            "Train Epoch: 65 [2432/14860 (16%)]\tLoss: 0.019103\n",
            "Train Epoch: 65 [2560/14860 (17%)]\tLoss: 0.031837\n",
            "Train Epoch: 65 [2688/14860 (18%)]\tLoss: 0.016472\n",
            "Train Epoch: 65 [2816/14860 (19%)]\tLoss: 0.021391\n",
            "Train Epoch: 65 [2944/14860 (20%)]\tLoss: 0.029198\n",
            "Train Epoch: 65 [3072/14860 (21%)]\tLoss: 0.018314\n",
            "Train Epoch: 65 [3200/14860 (21%)]\tLoss: 0.017137\n",
            "Train Epoch: 65 [3328/14860 (22%)]\tLoss: 0.025979\n",
            "Train Epoch: 65 [3456/14860 (23%)]\tLoss: 0.026666\n",
            "Train Epoch: 65 [3584/14860 (24%)]\tLoss: 0.022027\n",
            "Train Epoch: 65 [3712/14860 (25%)]\tLoss: 0.029619\n",
            "Train Epoch: 65 [3840/14860 (26%)]\tLoss: 0.026318\n",
            "Train Epoch: 65 [3968/14860 (26%)]\tLoss: 0.028150\n",
            "Train Epoch: 65 [4096/14860 (27%)]\tLoss: 0.019166\n",
            "Train Epoch: 65 [4224/14860 (28%)]\tLoss: 0.020770\n",
            "Train Epoch: 65 [4352/14860 (29%)]\tLoss: 0.025137\n",
            "Train Epoch: 65 [4480/14860 (30%)]\tLoss: 0.019745\n",
            "Train Epoch: 65 [4608/14860 (31%)]\tLoss: 0.025955\n",
            "Train Epoch: 65 [4736/14860 (32%)]\tLoss: 0.025168\n",
            "Train Epoch: 65 [4864/14860 (32%)]\tLoss: 0.018403\n",
            "Train Epoch: 65 [4992/14860 (33%)]\tLoss: 0.025236\n",
            "Train Epoch: 65 [5120/14860 (34%)]\tLoss: 0.021895\n",
            "Train Epoch: 65 [5248/14860 (35%)]\tLoss: 0.015981\n",
            "Train Epoch: 65 [5376/14860 (36%)]\tLoss: 0.029639\n",
            "Train Epoch: 65 [5504/14860 (37%)]\tLoss: 0.012501\n",
            "Train Epoch: 65 [5632/14860 (38%)]\tLoss: 0.020724\n",
            "Train Epoch: 65 [5760/14860 (38%)]\tLoss: 0.021720\n",
            "Train Epoch: 65 [5888/14860 (39%)]\tLoss: 0.019923\n",
            "Train Epoch: 65 [6016/14860 (40%)]\tLoss: 0.029540\n",
            "Train Epoch: 65 [6144/14860 (41%)]\tLoss: 0.020774\n",
            "Train Epoch: 65 [6272/14860 (42%)]\tLoss: 0.027639\n",
            "Train Epoch: 65 [6400/14860 (43%)]\tLoss: 0.018762\n",
            "Train Epoch: 65 [6528/14860 (44%)]\tLoss: 0.017497\n",
            "Train Epoch: 65 [6656/14860 (44%)]\tLoss: 0.015374\n",
            "Train Epoch: 65 [6784/14860 (45%)]\tLoss: 0.023063\n",
            "Train Epoch: 65 [6912/14860 (46%)]\tLoss: 0.016247\n",
            "Train Epoch: 65 [7040/14860 (47%)]\tLoss: 0.018243\n",
            "Train Epoch: 65 [7168/14860 (48%)]\tLoss: 0.019190\n",
            "Train Epoch: 65 [7296/14860 (49%)]\tLoss: 0.019721\n",
            "Train Epoch: 65 [7424/14860 (50%)]\tLoss: 0.018366\n",
            "Train Epoch: 65 [7552/14860 (50%)]\tLoss: 0.017218\n",
            "Train Epoch: 65 [7680/14860 (51%)]\tLoss: 0.024490\n",
            "Train Epoch: 65 [7808/14860 (52%)]\tLoss: 0.015255\n",
            "Train Epoch: 65 [7936/14860 (53%)]\tLoss: 0.023250\n",
            "Train Epoch: 65 [8064/14860 (54%)]\tLoss: 0.018282\n",
            "Train Epoch: 65 [8192/14860 (55%)]\tLoss: 0.017344\n",
            "Train Epoch: 65 [8320/14860 (56%)]\tLoss: 0.024564\n",
            "Train Epoch: 65 [8448/14860 (56%)]\tLoss: 0.017666\n",
            "Train Epoch: 65 [8576/14860 (57%)]\tLoss: 0.029001\n",
            "Train Epoch: 65 [8704/14860 (58%)]\tLoss: 0.025063\n",
            "Train Epoch: 65 [8832/14860 (59%)]\tLoss: 0.027278\n",
            "Train Epoch: 65 [8960/14860 (60%)]\tLoss: 0.017069\n",
            "Train Epoch: 65 [9088/14860 (61%)]\tLoss: 0.017496\n",
            "Train Epoch: 65 [9216/14860 (62%)]\tLoss: 0.013007\n",
            "Train Epoch: 65 [9344/14860 (62%)]\tLoss: 0.018645\n",
            "Train Epoch: 65 [9472/14860 (63%)]\tLoss: 0.016833\n",
            "Train Epoch: 65 [9600/14860 (64%)]\tLoss: 0.018777\n",
            "Train Epoch: 65 [9728/14860 (65%)]\tLoss: 0.020857\n",
            "Train Epoch: 65 [9856/14860 (66%)]\tLoss: 0.018667\n",
            "Train Epoch: 65 [9984/14860 (67%)]\tLoss: 0.013428\n",
            "Train Epoch: 65 [10112/14860 (68%)]\tLoss: 0.027348\n",
            "Train Epoch: 65 [10240/14860 (68%)]\tLoss: 0.018877\n",
            "Train Epoch: 65 [10368/14860 (69%)]\tLoss: 0.014331\n",
            "Train Epoch: 65 [10496/14860 (70%)]\tLoss: 0.019223\n",
            "Train Epoch: 65 [10624/14860 (71%)]\tLoss: 0.022321\n",
            "Train Epoch: 65 [10752/14860 (72%)]\tLoss: 0.016776\n",
            "Train Epoch: 65 [10880/14860 (73%)]\tLoss: 0.018736\n",
            "Train Epoch: 65 [11008/14860 (74%)]\tLoss: 0.010815\n",
            "Train Epoch: 65 [11136/14860 (74%)]\tLoss: 0.023405\n",
            "Train Epoch: 65 [11264/14860 (75%)]\tLoss: 0.029369\n",
            "Train Epoch: 65 [11392/14860 (76%)]\tLoss: 0.021259\n",
            "Train Epoch: 65 [11520/14860 (77%)]\tLoss: 0.015246\n",
            "Train Epoch: 65 [11648/14860 (78%)]\tLoss: 0.019331\n",
            "Train Epoch: 65 [11776/14860 (79%)]\tLoss: 0.021197\n",
            "Train Epoch: 65 [11904/14860 (79%)]\tLoss: 0.015089\n",
            "Train Epoch: 65 [12032/14860 (80%)]\tLoss: 0.036925\n",
            "Train Epoch: 65 [12160/14860 (81%)]\tLoss: 0.014775\n",
            "Train Epoch: 65 [12288/14860 (82%)]\tLoss: 0.024687\n",
            "Train Epoch: 65 [12416/14860 (83%)]\tLoss: 0.020730\n",
            "Train Epoch: 65 [12544/14860 (84%)]\tLoss: 0.020708\n",
            "Train Epoch: 65 [12672/14860 (85%)]\tLoss: 0.018534\n",
            "Train Epoch: 65 [12800/14860 (85%)]\tLoss: 0.019460\n",
            "Train Epoch: 65 [12928/14860 (86%)]\tLoss: 0.017008\n",
            "Train Epoch: 65 [13056/14860 (87%)]\tLoss: 0.013475\n",
            "Train Epoch: 65 [13184/14860 (88%)]\tLoss: 0.014145\n",
            "Train Epoch: 65 [13312/14860 (89%)]\tLoss: 0.019581\n",
            "Train Epoch: 65 [13440/14860 (90%)]\tLoss: 0.018831\n",
            "Train Epoch: 65 [13568/14860 (91%)]\tLoss: 0.027304\n",
            "Train Epoch: 65 [13696/14860 (91%)]\tLoss: 0.015472\n",
            "Train Epoch: 65 [13824/14860 (92%)]\tLoss: 0.018637\n",
            "Train Epoch: 65 [13952/14860 (93%)]\tLoss: 0.021223\n",
            "Train Epoch: 65 [14080/14860 (94%)]\tLoss: 0.019822\n",
            "Train Epoch: 65 [14208/14860 (95%)]\tLoss: 0.018310\n",
            "Train Epoch: 65 [14336/14860 (96%)]\tLoss: 0.023711\n",
            "Train Epoch: 65 [14464/14860 (97%)]\tLoss: 0.017171\n",
            "Train Epoch: 65 [14592/14860 (97%)]\tLoss: 0.022035\n",
            "Train Epoch: 65 [14720/14860 (98%)]\tLoss: 0.025658\n",
            "Train Epoch: 65 [1392/14860 (99%)]\tLoss: 0.007435\n",
            "epoch 65 training loss: 0.02124940240596477\n",
            "epoch 65 validation loss: 0.02069684798145987\n",
            "Train Epoch: 66 [0/14860 (0%)]\tLoss: 0.018962\n",
            "Train Epoch: 66 [128/14860 (1%)]\tLoss: 0.018534\n",
            "Train Epoch: 66 [256/14860 (2%)]\tLoss: 0.020833\n",
            "Train Epoch: 66 [384/14860 (3%)]\tLoss: 0.024690\n",
            "Train Epoch: 66 [512/14860 (3%)]\tLoss: 0.023343\n",
            "Train Epoch: 66 [640/14860 (4%)]\tLoss: 0.027941\n",
            "Train Epoch: 66 [768/14860 (5%)]\tLoss: 0.016263\n",
            "Train Epoch: 66 [896/14860 (6%)]\tLoss: 0.023440\n",
            "Train Epoch: 66 [1024/14860 (7%)]\tLoss: 0.034190\n",
            "Train Epoch: 66 [1152/14860 (8%)]\tLoss: 0.022809\n",
            "Train Epoch: 66 [1280/14860 (9%)]\tLoss: 0.030062\n",
            "Train Epoch: 66 [1408/14860 (9%)]\tLoss: 0.022351\n",
            "Train Epoch: 66 [1536/14860 (10%)]\tLoss: 0.026591\n",
            "Train Epoch: 66 [1664/14860 (11%)]\tLoss: 0.017071\n",
            "Train Epoch: 66 [1792/14860 (12%)]\tLoss: 0.025383\n",
            "Train Epoch: 66 [1920/14860 (13%)]\tLoss: 0.017492\n",
            "Train Epoch: 66 [2048/14860 (14%)]\tLoss: 0.025891\n",
            "Train Epoch: 66 [2176/14860 (15%)]\tLoss: 0.020474\n",
            "Train Epoch: 66 [2304/14860 (15%)]\tLoss: 0.020977\n",
            "Train Epoch: 66 [2432/14860 (16%)]\tLoss: 0.022269\n",
            "Train Epoch: 66 [2560/14860 (17%)]\tLoss: 0.023691\n",
            "Train Epoch: 66 [2688/14860 (18%)]\tLoss: 0.024038\n",
            "Train Epoch: 66 [2816/14860 (19%)]\tLoss: 0.021695\n",
            "Train Epoch: 66 [2944/14860 (20%)]\tLoss: 0.019094\n",
            "Train Epoch: 66 [3072/14860 (21%)]\tLoss: 0.023651\n",
            "Train Epoch: 66 [3200/14860 (21%)]\tLoss: 0.013001\n",
            "Train Epoch: 66 [3328/14860 (22%)]\tLoss: 0.015172\n",
            "Train Epoch: 66 [3456/14860 (23%)]\tLoss: 0.017274\n",
            "Train Epoch: 66 [3584/14860 (24%)]\tLoss: 0.024938\n",
            "Train Epoch: 66 [3712/14860 (25%)]\tLoss: 0.018140\n",
            "Train Epoch: 66 [3840/14860 (26%)]\tLoss: 0.015726\n",
            "Train Epoch: 66 [3968/14860 (26%)]\tLoss: 0.027447\n",
            "Train Epoch: 66 [4096/14860 (27%)]\tLoss: 0.017066\n",
            "Train Epoch: 66 [4224/14860 (28%)]\tLoss: 0.027668\n",
            "Train Epoch: 66 [4352/14860 (29%)]\tLoss: 0.017319\n",
            "Train Epoch: 66 [4480/14860 (30%)]\tLoss: 0.016440\n",
            "Train Epoch: 66 [4608/14860 (31%)]\tLoss: 0.024165\n",
            "Train Epoch: 66 [4736/14860 (32%)]\tLoss: 0.023162\n",
            "Train Epoch: 66 [4864/14860 (32%)]\tLoss: 0.021741\n",
            "Train Epoch: 66 [4992/14860 (33%)]\tLoss: 0.018210\n",
            "Train Epoch: 66 [5120/14860 (34%)]\tLoss: 0.022601\n",
            "Train Epoch: 66 [5248/14860 (35%)]\tLoss: 0.022427\n",
            "Train Epoch: 66 [5376/14860 (36%)]\tLoss: 0.016978\n",
            "Train Epoch: 66 [5504/14860 (37%)]\tLoss: 0.020007\n",
            "Train Epoch: 66 [5632/14860 (38%)]\tLoss: 0.020623\n",
            "Train Epoch: 66 [5760/14860 (38%)]\tLoss: 0.023385\n",
            "Train Epoch: 66 [5888/14860 (39%)]\tLoss: 0.017837\n",
            "Train Epoch: 66 [6016/14860 (40%)]\tLoss: 0.029994\n",
            "Train Epoch: 66 [6144/14860 (41%)]\tLoss: 0.022564\n",
            "Train Epoch: 66 [6272/14860 (42%)]\tLoss: 0.030169\n",
            "Train Epoch: 66 [6400/14860 (43%)]\tLoss: 0.024283\n",
            "Train Epoch: 66 [6528/14860 (44%)]\tLoss: 0.018067\n",
            "Train Epoch: 66 [6656/14860 (44%)]\tLoss: 0.020827\n",
            "Train Epoch: 66 [6784/14860 (45%)]\tLoss: 0.028989\n",
            "Train Epoch: 66 [6912/14860 (46%)]\tLoss: 0.018383\n",
            "Train Epoch: 66 [7040/14860 (47%)]\tLoss: 0.039670\n",
            "Train Epoch: 66 [7168/14860 (48%)]\tLoss: 0.030598\n",
            "Train Epoch: 66 [7296/14860 (49%)]\tLoss: 0.046514\n",
            "Train Epoch: 66 [7424/14860 (50%)]\tLoss: 0.022456\n",
            "Train Epoch: 66 [7552/14860 (50%)]\tLoss: 0.029929\n",
            "Train Epoch: 66 [7680/14860 (51%)]\tLoss: 0.019525\n",
            "Train Epoch: 66 [7808/14860 (52%)]\tLoss: 0.027171\n",
            "Train Epoch: 66 [7936/14860 (53%)]\tLoss: 0.026170\n",
            "Train Epoch: 66 [8064/14860 (54%)]\tLoss: 0.021011\n",
            "Train Epoch: 66 [8192/14860 (55%)]\tLoss: 0.018305\n",
            "Train Epoch: 66 [8320/14860 (56%)]\tLoss: 0.027821\n",
            "Train Epoch: 66 [8448/14860 (56%)]\tLoss: 0.032161\n",
            "Train Epoch: 66 [8576/14860 (57%)]\tLoss: 0.023757\n",
            "Train Epoch: 66 [8704/14860 (58%)]\tLoss: 0.028414\n",
            "Train Epoch: 66 [8832/14860 (59%)]\tLoss: 0.022173\n",
            "Train Epoch: 66 [8960/14860 (60%)]\tLoss: 0.021937\n",
            "Train Epoch: 66 [9088/14860 (61%)]\tLoss: 0.026871\n",
            "Train Epoch: 66 [9216/14860 (62%)]\tLoss: 0.016865\n",
            "Train Epoch: 66 [9344/14860 (62%)]\tLoss: 0.023050\n",
            "Train Epoch: 66 [9472/14860 (63%)]\tLoss: 0.014185\n",
            "Train Epoch: 66 [9600/14860 (64%)]\tLoss: 0.026815\n",
            "Train Epoch: 66 [9728/14860 (65%)]\tLoss: 0.016286\n",
            "Train Epoch: 66 [9856/14860 (66%)]\tLoss: 0.026625\n",
            "Train Epoch: 66 [9984/14860 (67%)]\tLoss: 0.019301\n",
            "Train Epoch: 66 [10112/14860 (68%)]\tLoss: 0.018306\n",
            "Train Epoch: 66 [10240/14860 (68%)]\tLoss: 0.015254\n",
            "Train Epoch: 66 [10368/14860 (69%)]\tLoss: 0.024491\n",
            "Train Epoch: 66 [10496/14860 (70%)]\tLoss: 0.018454\n",
            "Train Epoch: 66 [10624/14860 (71%)]\tLoss: 0.018376\n",
            "Train Epoch: 66 [10752/14860 (72%)]\tLoss: 0.024033\n",
            "Train Epoch: 66 [10880/14860 (73%)]\tLoss: 0.015031\n",
            "Train Epoch: 66 [11008/14860 (74%)]\tLoss: 0.033165\n",
            "Train Epoch: 66 [11136/14860 (74%)]\tLoss: 0.017583\n",
            "Train Epoch: 66 [11264/14860 (75%)]\tLoss: 0.018180\n",
            "Train Epoch: 66 [11392/14860 (76%)]\tLoss: 0.015548\n",
            "Train Epoch: 66 [11520/14860 (77%)]\tLoss: 0.022037\n",
            "Train Epoch: 66 [11648/14860 (78%)]\tLoss: 0.014556\n",
            "Train Epoch: 66 [11776/14860 (79%)]\tLoss: 0.018779\n",
            "Train Epoch: 66 [11904/14860 (79%)]\tLoss: 0.016980\n",
            "Train Epoch: 66 [12032/14860 (80%)]\tLoss: 0.025829\n",
            "Train Epoch: 66 [12160/14860 (81%)]\tLoss: 0.029173\n",
            "Train Epoch: 66 [12288/14860 (82%)]\tLoss: 0.031119\n",
            "Train Epoch: 66 [12416/14860 (83%)]\tLoss: 0.019755\n",
            "Train Epoch: 66 [12544/14860 (84%)]\tLoss: 0.018513\n",
            "Train Epoch: 66 [12672/14860 (85%)]\tLoss: 0.024047\n",
            "Train Epoch: 66 [12800/14860 (85%)]\tLoss: 0.023717\n",
            "Train Epoch: 66 [12928/14860 (86%)]\tLoss: 0.025961\n",
            "Train Epoch: 66 [13056/14860 (87%)]\tLoss: 0.021434\n",
            "Train Epoch: 66 [13184/14860 (88%)]\tLoss: 0.021644\n",
            "Train Epoch: 66 [13312/14860 (89%)]\tLoss: 0.020396\n",
            "Train Epoch: 66 [13440/14860 (90%)]\tLoss: 0.028687\n",
            "Train Epoch: 66 [13568/14860 (91%)]\tLoss: 0.031429\n",
            "Train Epoch: 66 [13696/14860 (91%)]\tLoss: 0.022606\n",
            "Train Epoch: 66 [13824/14860 (92%)]\tLoss: 0.023915\n",
            "Train Epoch: 66 [13952/14860 (93%)]\tLoss: 0.027557\n",
            "Train Epoch: 66 [14080/14860 (94%)]\tLoss: 0.019629\n",
            "Train Epoch: 66 [14208/14860 (95%)]\tLoss: 0.018970\n",
            "Train Epoch: 66 [14336/14860 (96%)]\tLoss: 0.022689\n",
            "Train Epoch: 66 [14464/14860 (97%)]\tLoss: 0.019790\n",
            "Train Epoch: 66 [14592/14860 (97%)]\tLoss: 0.026619\n",
            "Train Epoch: 66 [14720/14860 (98%)]\tLoss: 0.020372\n",
            "Train Epoch: 66 [1392/14860 (99%)]\tLoss: 0.040987\n",
            "epoch 66 training loss: 0.022816759661540516\n",
            "epoch 66 validation loss: 0.021807399991060863\n",
            "Train Epoch: 67 [0/14860 (0%)]\tLoss: 0.023901\n",
            "Train Epoch: 67 [128/14860 (1%)]\tLoss: 0.025253\n",
            "Train Epoch: 67 [256/14860 (2%)]\tLoss: 0.021780\n",
            "Train Epoch: 67 [384/14860 (3%)]\tLoss: 0.036190\n",
            "Train Epoch: 67 [512/14860 (3%)]\tLoss: 0.020886\n",
            "Train Epoch: 67 [640/14860 (4%)]\tLoss: 0.021691\n",
            "Train Epoch: 67 [768/14860 (5%)]\tLoss: 0.025919\n",
            "Train Epoch: 67 [896/14860 (6%)]\tLoss: 0.017724\n",
            "Train Epoch: 67 [1024/14860 (7%)]\tLoss: 0.019856\n",
            "Train Epoch: 67 [1152/14860 (8%)]\tLoss: 0.023896\n",
            "Train Epoch: 67 [1280/14860 (9%)]\tLoss: 0.014836\n",
            "Train Epoch: 67 [1408/14860 (9%)]\tLoss: 0.029112\n",
            "Train Epoch: 67 [1536/14860 (10%)]\tLoss: 0.017199\n",
            "Train Epoch: 67 [1664/14860 (11%)]\tLoss: 0.023735\n",
            "Train Epoch: 67 [1792/14860 (12%)]\tLoss: 0.017003\n",
            "Train Epoch: 67 [1920/14860 (13%)]\tLoss: 0.027840\n",
            "Train Epoch: 67 [2048/14860 (14%)]\tLoss: 0.023628\n",
            "Train Epoch: 67 [2176/14860 (15%)]\tLoss: 0.030953\n",
            "Train Epoch: 67 [2304/14860 (15%)]\tLoss: 0.019741\n",
            "Train Epoch: 67 [2432/14860 (16%)]\tLoss: 0.040490\n",
            "Train Epoch: 67 [2560/14860 (17%)]\tLoss: 0.023209\n",
            "Train Epoch: 67 [2688/14860 (18%)]\tLoss: 0.035500\n",
            "Train Epoch: 67 [2816/14860 (19%)]\tLoss: 0.022138\n",
            "Train Epoch: 67 [2944/14860 (20%)]\tLoss: 0.013638\n",
            "Train Epoch: 67 [3072/14860 (21%)]\tLoss: 0.018117\n",
            "Train Epoch: 67 [3200/14860 (21%)]\tLoss: 0.024510\n",
            "Train Epoch: 67 [3328/14860 (22%)]\tLoss: 0.020763\n",
            "Train Epoch: 67 [3456/14860 (23%)]\tLoss: 0.018487\n",
            "Train Epoch: 67 [3584/14860 (24%)]\tLoss: 0.015409\n",
            "Train Epoch: 67 [3712/14860 (25%)]\tLoss: 0.022389\n",
            "Train Epoch: 67 [3840/14860 (26%)]\tLoss: 0.021744\n",
            "Train Epoch: 67 [3968/14860 (26%)]\tLoss: 0.022443\n",
            "Train Epoch: 67 [4096/14860 (27%)]\tLoss: 0.022696\n",
            "Train Epoch: 67 [4224/14860 (28%)]\tLoss: 0.014293\n",
            "Train Epoch: 67 [4352/14860 (29%)]\tLoss: 0.020698\n",
            "Train Epoch: 67 [4480/14860 (30%)]\tLoss: 0.027645\n",
            "Train Epoch: 67 [4608/14860 (31%)]\tLoss: 0.018346\n",
            "Train Epoch: 67 [4736/14860 (32%)]\tLoss: 0.029232\n",
            "Train Epoch: 67 [4864/14860 (32%)]\tLoss: 0.032290\n",
            "Train Epoch: 67 [4992/14860 (33%)]\tLoss: 0.025189\n",
            "Train Epoch: 67 [5120/14860 (34%)]\tLoss: 0.030141\n",
            "Train Epoch: 67 [5248/14860 (35%)]\tLoss: 0.017747\n",
            "Train Epoch: 67 [5376/14860 (36%)]\tLoss: 0.020945\n",
            "Train Epoch: 67 [5504/14860 (37%)]\tLoss: 0.024031\n",
            "Train Epoch: 67 [5632/14860 (38%)]\tLoss: 0.023668\n",
            "Train Epoch: 67 [5760/14860 (38%)]\tLoss: 0.023222\n",
            "Train Epoch: 67 [5888/14860 (39%)]\tLoss: 0.015415\n",
            "Train Epoch: 67 [6016/14860 (40%)]\tLoss: 0.014639\n",
            "Train Epoch: 67 [6144/14860 (41%)]\tLoss: 0.016562\n",
            "Train Epoch: 67 [6272/14860 (42%)]\tLoss: 0.025057\n",
            "Train Epoch: 67 [6400/14860 (43%)]\tLoss: 0.028016\n",
            "Train Epoch: 67 [6528/14860 (44%)]\tLoss: 0.020968\n",
            "Train Epoch: 67 [6656/14860 (44%)]\tLoss: 0.013904\n",
            "Train Epoch: 67 [6784/14860 (45%)]\tLoss: 0.024137\n",
            "Train Epoch: 67 [6912/14860 (46%)]\tLoss: 0.019487\n",
            "Train Epoch: 67 [7040/14860 (47%)]\tLoss: 0.021796\n",
            "Train Epoch: 67 [7168/14860 (48%)]\tLoss: 0.019997\n",
            "Train Epoch: 67 [7296/14860 (49%)]\tLoss: 0.020352\n",
            "Train Epoch: 67 [7424/14860 (50%)]\tLoss: 0.021965\n",
            "Train Epoch: 67 [7552/14860 (50%)]\tLoss: 0.025288\n",
            "Train Epoch: 67 [7680/14860 (51%)]\tLoss: 0.019345\n",
            "Train Epoch: 67 [7808/14860 (52%)]\tLoss: 0.025620\n",
            "Train Epoch: 67 [7936/14860 (53%)]\tLoss: 0.021112\n",
            "Train Epoch: 67 [8064/14860 (54%)]\tLoss: 0.016780\n",
            "Train Epoch: 67 [8192/14860 (55%)]\tLoss: 0.019578\n",
            "Train Epoch: 67 [8320/14860 (56%)]\tLoss: 0.015238\n",
            "Train Epoch: 67 [8448/14860 (56%)]\tLoss: 0.020173\n",
            "Train Epoch: 67 [8576/14860 (57%)]\tLoss: 0.022404\n",
            "Train Epoch: 67 [8704/14860 (58%)]\tLoss: 0.013603\n",
            "Train Epoch: 67 [8832/14860 (59%)]\tLoss: 0.020425\n",
            "Train Epoch: 67 [8960/14860 (60%)]\tLoss: 0.018077\n",
            "Train Epoch: 67 [9088/14860 (61%)]\tLoss: 0.016298\n",
            "Train Epoch: 67 [9216/14860 (62%)]\tLoss: 0.021770\n",
            "Train Epoch: 67 [9344/14860 (62%)]\tLoss: 0.020518\n",
            "Train Epoch: 67 [9472/14860 (63%)]\tLoss: 0.018121\n",
            "Train Epoch: 67 [9600/14860 (64%)]\tLoss: 0.023856\n",
            "Train Epoch: 67 [9728/14860 (65%)]\tLoss: 0.013522\n",
            "Train Epoch: 67 [9856/14860 (66%)]\tLoss: 0.022779\n",
            "Train Epoch: 67 [9984/14860 (67%)]\tLoss: 0.017124\n",
            "Train Epoch: 67 [10112/14860 (68%)]\tLoss: 0.024890\n",
            "Train Epoch: 67 [10240/14860 (68%)]\tLoss: 0.024072\n",
            "Train Epoch: 67 [10368/14860 (69%)]\tLoss: 0.017138\n",
            "Train Epoch: 67 [10496/14860 (70%)]\tLoss: 0.021486\n",
            "Train Epoch: 67 [10624/14860 (71%)]\tLoss: 0.020148\n",
            "Train Epoch: 67 [10752/14860 (72%)]\tLoss: 0.019173\n",
            "Train Epoch: 67 [10880/14860 (73%)]\tLoss: 0.031080\n",
            "Train Epoch: 67 [11008/14860 (74%)]\tLoss: 0.029733\n",
            "Train Epoch: 67 [11136/14860 (74%)]\tLoss: 0.022370\n",
            "Train Epoch: 67 [11264/14860 (75%)]\tLoss: 0.021691\n",
            "Train Epoch: 67 [11392/14860 (76%)]\tLoss: 0.020182\n",
            "Train Epoch: 67 [11520/14860 (77%)]\tLoss: 0.019851\n",
            "Train Epoch: 67 [11648/14860 (78%)]\tLoss: 0.017461\n",
            "Train Epoch: 67 [11776/14860 (79%)]\tLoss: 0.022405\n",
            "Train Epoch: 67 [11904/14860 (79%)]\tLoss: 0.019082\n",
            "Train Epoch: 67 [12032/14860 (80%)]\tLoss: 0.015153\n",
            "Train Epoch: 67 [12160/14860 (81%)]\tLoss: 0.018508\n",
            "Train Epoch: 67 [12288/14860 (82%)]\tLoss: 0.016999\n",
            "Train Epoch: 67 [12416/14860 (83%)]\tLoss: 0.018425\n",
            "Train Epoch: 67 [12544/14860 (84%)]\tLoss: 0.024122\n",
            "Train Epoch: 67 [12672/14860 (85%)]\tLoss: 0.021437\n",
            "Train Epoch: 67 [12800/14860 (85%)]\tLoss: 0.018913\n",
            "Train Epoch: 67 [12928/14860 (86%)]\tLoss: 0.024063\n",
            "Train Epoch: 67 [13056/14860 (87%)]\tLoss: 0.025092\n",
            "Train Epoch: 67 [13184/14860 (88%)]\tLoss: 0.030775\n",
            "Train Epoch: 67 [13312/14860 (89%)]\tLoss: 0.012613\n",
            "Train Epoch: 67 [13440/14860 (90%)]\tLoss: 0.028509\n",
            "Train Epoch: 67 [13568/14860 (91%)]\tLoss: 0.022016\n",
            "Train Epoch: 67 [13696/14860 (91%)]\tLoss: 0.029496\n",
            "Train Epoch: 67 [13824/14860 (92%)]\tLoss: 0.022805\n",
            "Train Epoch: 67 [13952/14860 (93%)]\tLoss: 0.032170\n",
            "Train Epoch: 67 [14080/14860 (94%)]\tLoss: 0.014155\n",
            "Train Epoch: 67 [14208/14860 (95%)]\tLoss: 0.023485\n",
            "Train Epoch: 67 [14336/14860 (96%)]\tLoss: 0.022782\n",
            "Train Epoch: 67 [14464/14860 (97%)]\tLoss: 0.026050\n",
            "Train Epoch: 67 [14592/14860 (97%)]\tLoss: 0.016494\n",
            "Train Epoch: 67 [14720/14860 (98%)]\tLoss: 0.028259\n",
            "Train Epoch: 67 [1392/14860 (99%)]\tLoss: 0.039998\n",
            "epoch 67 training loss: 0.02211224764553655\n",
            "epoch 67 validation loss: 0.02092472577499131\n",
            "Train Epoch: 68 [0/14860 (0%)]\tLoss: 0.013314\n",
            "Train Epoch: 68 [128/14860 (1%)]\tLoss: 0.034220\n",
            "Train Epoch: 68 [256/14860 (2%)]\tLoss: 0.020653\n",
            "Train Epoch: 68 [384/14860 (3%)]\tLoss: 0.026375\n",
            "Train Epoch: 68 [512/14860 (3%)]\tLoss: 0.026534\n",
            "Train Epoch: 68 [640/14860 (4%)]\tLoss: 0.018544\n",
            "Train Epoch: 68 [768/14860 (5%)]\tLoss: 0.030731\n",
            "Train Epoch: 68 [896/14860 (6%)]\tLoss: 0.018363\n",
            "Train Epoch: 68 [1024/14860 (7%)]\tLoss: 0.027245\n",
            "Train Epoch: 68 [1152/14860 (8%)]\tLoss: 0.019312\n",
            "Train Epoch: 68 [1280/14860 (9%)]\tLoss: 0.026668\n",
            "Train Epoch: 68 [1408/14860 (9%)]\tLoss: 0.021190\n",
            "Train Epoch: 68 [1536/14860 (10%)]\tLoss: 0.019997\n",
            "Train Epoch: 68 [1664/14860 (11%)]\tLoss: 0.017872\n",
            "Train Epoch: 68 [1792/14860 (12%)]\tLoss: 0.027452\n",
            "Train Epoch: 68 [1920/14860 (13%)]\tLoss: 0.020996\n",
            "Train Epoch: 68 [2048/14860 (14%)]\tLoss: 0.027191\n",
            "Train Epoch: 68 [2176/14860 (15%)]\tLoss: 0.018835\n",
            "Train Epoch: 68 [2304/14860 (15%)]\tLoss: 0.020058\n",
            "Train Epoch: 68 [2432/14860 (16%)]\tLoss: 0.021079\n",
            "Train Epoch: 68 [2560/14860 (17%)]\tLoss: 0.017941\n",
            "Train Epoch: 68 [2688/14860 (18%)]\tLoss: 0.022527\n",
            "Train Epoch: 68 [2816/14860 (19%)]\tLoss: 0.015270\n",
            "Train Epoch: 68 [2944/14860 (20%)]\tLoss: 0.027061\n",
            "Train Epoch: 68 [3072/14860 (21%)]\tLoss: 0.020356\n",
            "Train Epoch: 68 [3200/14860 (21%)]\tLoss: 0.024448\n",
            "Train Epoch: 68 [3328/14860 (22%)]\tLoss: 0.017690\n",
            "Train Epoch: 68 [3456/14860 (23%)]\tLoss: 0.024017\n",
            "Train Epoch: 68 [3584/14860 (24%)]\tLoss: 0.014039\n",
            "Train Epoch: 68 [3712/14860 (25%)]\tLoss: 0.021536\n",
            "Train Epoch: 68 [3840/14860 (26%)]\tLoss: 0.025662\n",
            "Train Epoch: 68 [3968/14860 (26%)]\tLoss: 0.023818\n",
            "Train Epoch: 68 [4096/14860 (27%)]\tLoss: 0.016438\n",
            "Train Epoch: 68 [4224/14860 (28%)]\tLoss: 0.020036\n",
            "Train Epoch: 68 [4352/14860 (29%)]\tLoss: 0.027665\n",
            "Train Epoch: 68 [4480/14860 (30%)]\tLoss: 0.015715\n",
            "Train Epoch: 68 [4608/14860 (31%)]\tLoss: 0.020997\n",
            "Train Epoch: 68 [4736/14860 (32%)]\tLoss: 0.017613\n",
            "Train Epoch: 68 [4864/14860 (32%)]\tLoss: 0.014419\n",
            "Train Epoch: 68 [4992/14860 (33%)]\tLoss: 0.013546\n",
            "Train Epoch: 68 [5120/14860 (34%)]\tLoss: 0.028337\n",
            "Train Epoch: 68 [5248/14860 (35%)]\tLoss: 0.017073\n",
            "Train Epoch: 68 [5376/14860 (36%)]\tLoss: 0.022332\n",
            "Train Epoch: 68 [5504/14860 (37%)]\tLoss: 0.012596\n",
            "Train Epoch: 68 [5632/14860 (38%)]\tLoss: 0.020027\n",
            "Train Epoch: 68 [5760/14860 (38%)]\tLoss: 0.019941\n",
            "Train Epoch: 68 [5888/14860 (39%)]\tLoss: 0.029417\n",
            "Train Epoch: 68 [6016/14860 (40%)]\tLoss: 0.016711\n",
            "Train Epoch: 68 [6144/14860 (41%)]\tLoss: 0.032126\n",
            "Train Epoch: 68 [6272/14860 (42%)]\tLoss: 0.018034\n",
            "Train Epoch: 68 [6400/14860 (43%)]\tLoss: 0.024518\n",
            "Train Epoch: 68 [6528/14860 (44%)]\tLoss: 0.025030\n",
            "Train Epoch: 68 [6656/14860 (44%)]\tLoss: 0.022844\n",
            "Train Epoch: 68 [6784/14860 (45%)]\tLoss: 0.011592\n",
            "Train Epoch: 68 [6912/14860 (46%)]\tLoss: 0.019217\n",
            "Train Epoch: 68 [7040/14860 (47%)]\tLoss: 0.016307\n",
            "Train Epoch: 68 [7168/14860 (48%)]\tLoss: 0.020643\n",
            "Train Epoch: 68 [7296/14860 (49%)]\tLoss: 0.022085\n",
            "Train Epoch: 68 [7424/14860 (50%)]\tLoss: 0.026348\n",
            "Train Epoch: 68 [7552/14860 (50%)]\tLoss: 0.021646\n",
            "Train Epoch: 68 [7680/14860 (51%)]\tLoss: 0.022860\n",
            "Train Epoch: 68 [7808/14860 (52%)]\tLoss: 0.012933\n",
            "Train Epoch: 68 [7936/14860 (53%)]\tLoss: 0.017397\n",
            "Train Epoch: 68 [8064/14860 (54%)]\tLoss: 0.019742\n",
            "Train Epoch: 68 [8192/14860 (55%)]\tLoss: 0.024857\n",
            "Train Epoch: 68 [8320/14860 (56%)]\tLoss: 0.018748\n",
            "Train Epoch: 68 [8448/14860 (56%)]\tLoss: 0.024992\n",
            "Train Epoch: 68 [8576/14860 (57%)]\tLoss: 0.020871\n",
            "Train Epoch: 68 [8704/14860 (58%)]\tLoss: 0.026733\n",
            "Train Epoch: 68 [8832/14860 (59%)]\tLoss: 0.016053\n",
            "Train Epoch: 68 [8960/14860 (60%)]\tLoss: 0.022219\n",
            "Train Epoch: 68 [9088/14860 (61%)]\tLoss: 0.025844\n",
            "Train Epoch: 68 [9216/14860 (62%)]\tLoss: 0.019403\n",
            "Train Epoch: 68 [9344/14860 (62%)]\tLoss: 0.019266\n",
            "Train Epoch: 68 [9472/14860 (63%)]\tLoss: 0.021928\n",
            "Train Epoch: 68 [9600/14860 (64%)]\tLoss: 0.020704\n",
            "Train Epoch: 68 [9728/14860 (65%)]\tLoss: 0.027786\n",
            "Train Epoch: 68 [9856/14860 (66%)]\tLoss: 0.027036\n",
            "Train Epoch: 68 [9984/14860 (67%)]\tLoss: 0.017099\n",
            "Train Epoch: 68 [10112/14860 (68%)]\tLoss: 0.017788\n",
            "Train Epoch: 68 [10240/14860 (68%)]\tLoss: 0.016909\n",
            "Train Epoch: 68 [10368/14860 (69%)]\tLoss: 0.024065\n",
            "Train Epoch: 68 [10496/14860 (70%)]\tLoss: 0.018130\n",
            "Train Epoch: 68 [10624/14860 (71%)]\tLoss: 0.021935\n",
            "Train Epoch: 68 [10752/14860 (72%)]\tLoss: 0.019971\n",
            "Train Epoch: 68 [10880/14860 (73%)]\tLoss: 0.020517\n",
            "Train Epoch: 68 [11008/14860 (74%)]\tLoss: 0.017436\n",
            "Train Epoch: 68 [11136/14860 (74%)]\tLoss: 0.022417\n",
            "Train Epoch: 68 [11264/14860 (75%)]\tLoss: 0.020517\n",
            "Train Epoch: 68 [11392/14860 (76%)]\tLoss: 0.026031\n",
            "Train Epoch: 68 [11520/14860 (77%)]\tLoss: 0.022226\n",
            "Train Epoch: 68 [11648/14860 (78%)]\tLoss: 0.017361\n",
            "Train Epoch: 68 [11776/14860 (79%)]\tLoss: 0.033425\n",
            "Train Epoch: 68 [11904/14860 (79%)]\tLoss: 0.021126\n",
            "Train Epoch: 68 [12032/14860 (80%)]\tLoss: 0.028223\n",
            "Train Epoch: 68 [12160/14860 (81%)]\tLoss: 0.028595\n",
            "Train Epoch: 68 [12288/14860 (82%)]\tLoss: 0.027309\n",
            "Train Epoch: 68 [12416/14860 (83%)]\tLoss: 0.016050\n",
            "Train Epoch: 68 [12544/14860 (84%)]\tLoss: 0.022082\n",
            "Train Epoch: 68 [12672/14860 (85%)]\tLoss: 0.021859\n",
            "Train Epoch: 68 [12800/14860 (85%)]\tLoss: 0.013633\n",
            "Train Epoch: 68 [12928/14860 (86%)]\tLoss: 0.028198\n",
            "Train Epoch: 68 [13056/14860 (87%)]\tLoss: 0.016084\n",
            "Train Epoch: 68 [13184/14860 (88%)]\tLoss: 0.023020\n",
            "Train Epoch: 68 [13312/14860 (89%)]\tLoss: 0.018772\n",
            "Train Epoch: 68 [13440/14860 (90%)]\tLoss: 0.015956\n",
            "Train Epoch: 68 [13568/14860 (91%)]\tLoss: 0.016339\n",
            "Train Epoch: 68 [13696/14860 (91%)]\tLoss: 0.020276\n",
            "Train Epoch: 68 [13824/14860 (92%)]\tLoss: 0.017799\n",
            "Train Epoch: 68 [13952/14860 (93%)]\tLoss: 0.013265\n",
            "Train Epoch: 68 [14080/14860 (94%)]\tLoss: 0.018090\n",
            "Train Epoch: 68 [14208/14860 (95%)]\tLoss: 0.018894\n",
            "Train Epoch: 68 [14336/14860 (96%)]\tLoss: 0.020982\n",
            "Train Epoch: 68 [14464/14860 (97%)]\tLoss: 0.023136\n",
            "Train Epoch: 68 [14592/14860 (97%)]\tLoss: 0.036514\n",
            "Train Epoch: 68 [14720/14860 (98%)]\tLoss: 0.015112\n",
            "Train Epoch: 68 [1392/14860 (99%)]\tLoss: 0.057292\n",
            "epoch 68 training loss: 0.02160726872901631\n",
            "epoch 68 validation loss: 0.021214259883104745\n",
            "Train Epoch: 69 [0/14860 (0%)]\tLoss: 0.025892\n",
            "Train Epoch: 69 [128/14860 (1%)]\tLoss: 0.022160\n",
            "Train Epoch: 69 [256/14860 (2%)]\tLoss: 0.014839\n",
            "Train Epoch: 69 [384/14860 (3%)]\tLoss: 0.016672\n",
            "Train Epoch: 69 [512/14860 (3%)]\tLoss: 0.021691\n",
            "Train Epoch: 69 [640/14860 (4%)]\tLoss: 0.013238\n",
            "Train Epoch: 69 [768/14860 (5%)]\tLoss: 0.017310\n",
            "Train Epoch: 69 [896/14860 (6%)]\tLoss: 0.013579\n",
            "Train Epoch: 69 [1024/14860 (7%)]\tLoss: 0.020967\n",
            "Train Epoch: 69 [1152/14860 (8%)]\tLoss: 0.018468\n",
            "Train Epoch: 69 [1280/14860 (9%)]\tLoss: 0.019319\n",
            "Train Epoch: 69 [1408/14860 (9%)]\tLoss: 0.016189\n",
            "Train Epoch: 69 [1536/14860 (10%)]\tLoss: 0.028613\n",
            "Train Epoch: 69 [1664/14860 (11%)]\tLoss: 0.023190\n",
            "Train Epoch: 69 [1792/14860 (12%)]\tLoss: 0.021680\n",
            "Train Epoch: 69 [1920/14860 (13%)]\tLoss: 0.026150\n",
            "Train Epoch: 69 [2048/14860 (14%)]\tLoss: 0.017636\n",
            "Train Epoch: 69 [2176/14860 (15%)]\tLoss: 0.018558\n",
            "Train Epoch: 69 [2304/14860 (15%)]\tLoss: 0.019703\n",
            "Train Epoch: 69 [2432/14860 (16%)]\tLoss: 0.019888\n",
            "Train Epoch: 69 [2560/14860 (17%)]\tLoss: 0.021948\n",
            "Train Epoch: 69 [2688/14860 (18%)]\tLoss: 0.015970\n",
            "Train Epoch: 69 [2816/14860 (19%)]\tLoss: 0.021901\n",
            "Train Epoch: 69 [2944/14860 (20%)]\tLoss: 0.016761\n",
            "Train Epoch: 69 [3072/14860 (21%)]\tLoss: 0.025773\n",
            "Train Epoch: 69 [3200/14860 (21%)]\tLoss: 0.026365\n",
            "Train Epoch: 69 [3328/14860 (22%)]\tLoss: 0.020995\n",
            "Train Epoch: 69 [3456/14860 (23%)]\tLoss: 0.011377\n",
            "Train Epoch: 69 [3584/14860 (24%)]\tLoss: 0.016509\n",
            "Train Epoch: 69 [3712/14860 (25%)]\tLoss: 0.020757\n",
            "Train Epoch: 69 [3840/14860 (26%)]\tLoss: 0.021059\n",
            "Train Epoch: 69 [3968/14860 (26%)]\tLoss: 0.023029\n",
            "Train Epoch: 69 [4096/14860 (27%)]\tLoss: 0.014527\n",
            "Train Epoch: 69 [4224/14860 (28%)]\tLoss: 0.015631\n",
            "Train Epoch: 69 [4352/14860 (29%)]\tLoss: 0.014646\n",
            "Train Epoch: 69 [4480/14860 (30%)]\tLoss: 0.019601\n",
            "Train Epoch: 69 [4608/14860 (31%)]\tLoss: 0.015844\n",
            "Train Epoch: 69 [4736/14860 (32%)]\tLoss: 0.019449\n",
            "Train Epoch: 69 [4864/14860 (32%)]\tLoss: 0.016036\n",
            "Train Epoch: 69 [4992/14860 (33%)]\tLoss: 0.016784\n",
            "Train Epoch: 69 [5120/14860 (34%)]\tLoss: 0.024154\n",
            "Train Epoch: 69 [5248/14860 (35%)]\tLoss: 0.019918\n",
            "Train Epoch: 69 [5376/14860 (36%)]\tLoss: 0.014843\n",
            "Train Epoch: 69 [5504/14860 (37%)]\tLoss: 0.014997\n",
            "Train Epoch: 69 [5632/14860 (38%)]\tLoss: 0.024709\n",
            "Train Epoch: 69 [5760/14860 (38%)]\tLoss: 0.017736\n",
            "Train Epoch: 69 [5888/14860 (39%)]\tLoss: 0.027961\n",
            "Train Epoch: 69 [6016/14860 (40%)]\tLoss: 0.020318\n",
            "Train Epoch: 69 [6144/14860 (41%)]\tLoss: 0.020425\n",
            "Train Epoch: 69 [6272/14860 (42%)]\tLoss: 0.018673\n",
            "Train Epoch: 69 [6400/14860 (43%)]\tLoss: 0.035711\n",
            "Train Epoch: 69 [6528/14860 (44%)]\tLoss: 0.024760\n",
            "Train Epoch: 69 [6656/14860 (44%)]\tLoss: 0.032668\n",
            "Train Epoch: 69 [6784/14860 (45%)]\tLoss: 0.016178\n",
            "Train Epoch: 69 [6912/14860 (46%)]\tLoss: 0.024802\n",
            "Train Epoch: 69 [7040/14860 (47%)]\tLoss: 0.017281\n",
            "Train Epoch: 69 [7168/14860 (48%)]\tLoss: 0.025150\n",
            "Train Epoch: 69 [7296/14860 (49%)]\tLoss: 0.020288\n",
            "Train Epoch: 69 [7424/14860 (50%)]\tLoss: 0.019556\n",
            "Train Epoch: 69 [7552/14860 (50%)]\tLoss: 0.024371\n",
            "Train Epoch: 69 [7680/14860 (51%)]\tLoss: 0.025358\n",
            "Train Epoch: 69 [7808/14860 (52%)]\tLoss: 0.020607\n",
            "Train Epoch: 69 [7936/14860 (53%)]\tLoss: 0.021095\n",
            "Train Epoch: 69 [8064/14860 (54%)]\tLoss: 0.027805\n",
            "Train Epoch: 69 [8192/14860 (55%)]\tLoss: 0.021878\n",
            "Train Epoch: 69 [8320/14860 (56%)]\tLoss: 0.019121\n",
            "Train Epoch: 69 [8448/14860 (56%)]\tLoss: 0.024828\n",
            "Train Epoch: 69 [8576/14860 (57%)]\tLoss: 0.016618\n",
            "Train Epoch: 69 [8704/14860 (58%)]\tLoss: 0.023184\n",
            "Train Epoch: 69 [8832/14860 (59%)]\tLoss: 0.021487\n",
            "Train Epoch: 69 [8960/14860 (60%)]\tLoss: 0.027908\n",
            "Train Epoch: 69 [9088/14860 (61%)]\tLoss: 0.015073\n",
            "Train Epoch: 69 [9216/14860 (62%)]\tLoss: 0.021380\n",
            "Train Epoch: 69 [9344/14860 (62%)]\tLoss: 0.017963\n",
            "Train Epoch: 69 [9472/14860 (63%)]\tLoss: 0.022253\n",
            "Train Epoch: 69 [9600/14860 (64%)]\tLoss: 0.017191\n",
            "Train Epoch: 69 [9728/14860 (65%)]\tLoss: 0.022848\n",
            "Train Epoch: 69 [9856/14860 (66%)]\tLoss: 0.018276\n",
            "Train Epoch: 69 [9984/14860 (67%)]\tLoss: 0.029376\n",
            "Train Epoch: 69 [10112/14860 (68%)]\tLoss: 0.016320\n",
            "Train Epoch: 69 [10240/14860 (68%)]\tLoss: 0.015874\n",
            "Train Epoch: 69 [10368/14860 (69%)]\tLoss: 0.021312\n",
            "Train Epoch: 69 [10496/14860 (70%)]\tLoss: 0.019127\n",
            "Train Epoch: 69 [10624/14860 (71%)]\tLoss: 0.030325\n",
            "Train Epoch: 69 [10752/14860 (72%)]\tLoss: 0.021874\n",
            "Train Epoch: 69 [10880/14860 (73%)]\tLoss: 0.044348\n",
            "Train Epoch: 69 [11008/14860 (74%)]\tLoss: 0.024629\n",
            "Train Epoch: 69 [11136/14860 (74%)]\tLoss: 0.019325\n",
            "Train Epoch: 69 [11264/14860 (75%)]\tLoss: 0.012160\n",
            "Train Epoch: 69 [11392/14860 (76%)]\tLoss: 0.031288\n",
            "Train Epoch: 69 [11520/14860 (77%)]\tLoss: 0.017760\n",
            "Train Epoch: 69 [11648/14860 (78%)]\tLoss: 0.020455\n",
            "Train Epoch: 69 [11776/14860 (79%)]\tLoss: 0.022263\n",
            "Train Epoch: 69 [11904/14860 (79%)]\tLoss: 0.025904\n",
            "Train Epoch: 69 [12032/14860 (80%)]\tLoss: 0.021161\n",
            "Train Epoch: 69 [12160/14860 (81%)]\tLoss: 0.025659\n",
            "Train Epoch: 69 [12288/14860 (82%)]\tLoss: 0.027167\n",
            "Train Epoch: 69 [12416/14860 (83%)]\tLoss: 0.024320\n",
            "Train Epoch: 69 [12544/14860 (84%)]\tLoss: 0.024319\n",
            "Train Epoch: 69 [12672/14860 (85%)]\tLoss: 0.024648\n",
            "Train Epoch: 69 [12800/14860 (85%)]\tLoss: 0.026228\n",
            "Train Epoch: 69 [12928/14860 (86%)]\tLoss: 0.018887\n",
            "Train Epoch: 69 [13056/14860 (87%)]\tLoss: 0.026989\n",
            "Train Epoch: 69 [13184/14860 (88%)]\tLoss: 0.023629\n",
            "Train Epoch: 69 [13312/14860 (89%)]\tLoss: 0.028162\n",
            "Train Epoch: 69 [13440/14860 (90%)]\tLoss: 0.019152\n",
            "Train Epoch: 69 [13568/14860 (91%)]\tLoss: 0.027138\n",
            "Train Epoch: 69 [13696/14860 (91%)]\tLoss: 0.024772\n",
            "Train Epoch: 69 [13824/14860 (92%)]\tLoss: 0.028632\n",
            "Train Epoch: 69 [13952/14860 (93%)]\tLoss: 0.028071\n",
            "Train Epoch: 69 [14080/14860 (94%)]\tLoss: 0.026208\n",
            "Train Epoch: 69 [14208/14860 (95%)]\tLoss: 0.018746\n",
            "Train Epoch: 69 [14336/14860 (96%)]\tLoss: 0.014474\n",
            "Train Epoch: 69 [14464/14860 (97%)]\tLoss: 0.021863\n",
            "Train Epoch: 69 [14592/14860 (97%)]\tLoss: 0.028635\n",
            "Train Epoch: 69 [14720/14860 (98%)]\tLoss: 0.017048\n",
            "Train Epoch: 69 [1392/14860 (99%)]\tLoss: 0.007073\n",
            "epoch 69 training loss: 0.0214136955447686\n",
            "epoch 69 validation loss: 0.020958115344474736\n",
            "Train Epoch: 70 [0/14860 (0%)]\tLoss: 0.013997\n",
            "Train Epoch: 70 [128/14860 (1%)]\tLoss: 0.017037\n",
            "Train Epoch: 70 [256/14860 (2%)]\tLoss: 0.013922\n",
            "Train Epoch: 70 [384/14860 (3%)]\tLoss: 0.015392\n",
            "Train Epoch: 70 [512/14860 (3%)]\tLoss: 0.024984\n",
            "Train Epoch: 70 [640/14860 (4%)]\tLoss: 0.016251\n",
            "Train Epoch: 70 [768/14860 (5%)]\tLoss: 0.019596\n",
            "Train Epoch: 70 [896/14860 (6%)]\tLoss: 0.023811\n",
            "Train Epoch: 70 [1024/14860 (7%)]\tLoss: 0.030001\n",
            "Train Epoch: 70 [1152/14860 (8%)]\tLoss: 0.033880\n",
            "Train Epoch: 70 [1280/14860 (9%)]\tLoss: 0.025984\n",
            "Train Epoch: 70 [1408/14860 (9%)]\tLoss: 0.020606\n",
            "Train Epoch: 70 [1536/14860 (10%)]\tLoss: 0.024150\n",
            "Train Epoch: 70 [1664/14860 (11%)]\tLoss: 0.023773\n",
            "Train Epoch: 70 [1792/14860 (12%)]\tLoss: 0.019164\n",
            "Train Epoch: 70 [1920/14860 (13%)]\tLoss: 0.024091\n",
            "Train Epoch: 70 [2048/14860 (14%)]\tLoss: 0.023345\n",
            "Train Epoch: 70 [2176/14860 (15%)]\tLoss: 0.028119\n",
            "Train Epoch: 70 [2304/14860 (15%)]\tLoss: 0.022288\n",
            "Train Epoch: 70 [2432/14860 (16%)]\tLoss: 0.012796\n",
            "Train Epoch: 70 [2560/14860 (17%)]\tLoss: 0.015246\n",
            "Train Epoch: 70 [2688/14860 (18%)]\tLoss: 0.022457\n",
            "Train Epoch: 70 [2816/14860 (19%)]\tLoss: 0.021727\n",
            "Train Epoch: 70 [2944/14860 (20%)]\tLoss: 0.024522\n",
            "Train Epoch: 70 [3072/14860 (21%)]\tLoss: 0.020003\n",
            "Train Epoch: 70 [3200/14860 (21%)]\tLoss: 0.013737\n",
            "Train Epoch: 70 [3328/14860 (22%)]\tLoss: 0.012921\n",
            "Train Epoch: 70 [3456/14860 (23%)]\tLoss: 0.018664\n",
            "Train Epoch: 70 [3584/14860 (24%)]\tLoss: 0.020983\n",
            "Train Epoch: 70 [3712/14860 (25%)]\tLoss: 0.017192\n",
            "Train Epoch: 70 [3840/14860 (26%)]\tLoss: 0.017747\n",
            "Train Epoch: 70 [3968/14860 (26%)]\tLoss: 0.019651\n",
            "Train Epoch: 70 [4096/14860 (27%)]\tLoss: 0.021424\n",
            "Train Epoch: 70 [4224/14860 (28%)]\tLoss: 0.019764\n",
            "Train Epoch: 70 [4352/14860 (29%)]\tLoss: 0.022600\n",
            "Train Epoch: 70 [4480/14860 (30%)]\tLoss: 0.017044\n",
            "Train Epoch: 70 [4608/14860 (31%)]\tLoss: 0.019686\n",
            "Train Epoch: 70 [4736/14860 (32%)]\tLoss: 0.032495\n",
            "Train Epoch: 70 [4864/14860 (32%)]\tLoss: 0.025644\n",
            "Train Epoch: 70 [4992/14860 (33%)]\tLoss: 0.019182\n",
            "Train Epoch: 70 [5120/14860 (34%)]\tLoss: 0.022256\n",
            "Train Epoch: 70 [5248/14860 (35%)]\tLoss: 0.018447\n",
            "Train Epoch: 70 [5376/14860 (36%)]\tLoss: 0.017603\n",
            "Train Epoch: 70 [5504/14860 (37%)]\tLoss: 0.013169\n",
            "Train Epoch: 70 [5632/14860 (38%)]\tLoss: 0.021584\n",
            "Train Epoch: 70 [5760/14860 (38%)]\tLoss: 0.020103\n",
            "Train Epoch: 70 [5888/14860 (39%)]\tLoss: 0.018819\n",
            "Train Epoch: 70 [6016/14860 (40%)]\tLoss: 0.017231\n",
            "Train Epoch: 70 [6144/14860 (41%)]\tLoss: 0.032999\n",
            "Train Epoch: 70 [6272/14860 (42%)]\tLoss: 0.022570\n",
            "Train Epoch: 70 [6400/14860 (43%)]\tLoss: 0.027640\n",
            "Train Epoch: 70 [6528/14860 (44%)]\tLoss: 0.027445\n",
            "Train Epoch: 70 [6656/14860 (44%)]\tLoss: 0.015683\n",
            "Train Epoch: 70 [6784/14860 (45%)]\tLoss: 0.022673\n",
            "Train Epoch: 70 [6912/14860 (46%)]\tLoss: 0.020819\n",
            "Train Epoch: 70 [7040/14860 (47%)]\tLoss: 0.015274\n",
            "Train Epoch: 70 [7168/14860 (48%)]\tLoss: 0.023877\n",
            "Train Epoch: 70 [7296/14860 (49%)]\tLoss: 0.025619\n",
            "Train Epoch: 70 [7424/14860 (50%)]\tLoss: 0.017946\n",
            "Train Epoch: 70 [7552/14860 (50%)]\tLoss: 0.028706\n",
            "Train Epoch: 70 [7680/14860 (51%)]\tLoss: 0.027416\n",
            "Train Epoch: 70 [7808/14860 (52%)]\tLoss: 0.024182\n",
            "Train Epoch: 70 [7936/14860 (53%)]\tLoss: 0.020738\n",
            "Train Epoch: 70 [8064/14860 (54%)]\tLoss: 0.025128\n",
            "Train Epoch: 70 [8192/14860 (55%)]\tLoss: 0.027920\n",
            "Train Epoch: 70 [8320/14860 (56%)]\tLoss: 0.025057\n",
            "Train Epoch: 70 [8448/14860 (56%)]\tLoss: 0.016442\n",
            "Train Epoch: 70 [8576/14860 (57%)]\tLoss: 0.017938\n",
            "Train Epoch: 70 [8704/14860 (58%)]\tLoss: 0.029299\n",
            "Train Epoch: 70 [8832/14860 (59%)]\tLoss: 0.018809\n",
            "Train Epoch: 70 [8960/14860 (60%)]\tLoss: 0.017124\n",
            "Train Epoch: 70 [9088/14860 (61%)]\tLoss: 0.025910\n",
            "Train Epoch: 70 [9216/14860 (62%)]\tLoss: 0.026283\n",
            "Train Epoch: 70 [9344/14860 (62%)]\tLoss: 0.025994\n",
            "Train Epoch: 70 [9472/14860 (63%)]\tLoss: 0.041689\n",
            "Train Epoch: 70 [9600/14860 (64%)]\tLoss: 0.023768\n",
            "Train Epoch: 70 [9728/14860 (65%)]\tLoss: 0.051215\n",
            "Train Epoch: 70 [9856/14860 (66%)]\tLoss: 0.018303\n",
            "Train Epoch: 70 [9984/14860 (67%)]\tLoss: 0.054851\n",
            "Train Epoch: 70 [10112/14860 (68%)]\tLoss: 0.021393\n",
            "Train Epoch: 70 [10240/14860 (68%)]\tLoss: 0.035368\n",
            "Train Epoch: 70 [10368/14860 (69%)]\tLoss: 0.032051\n",
            "Train Epoch: 70 [10496/14860 (70%)]\tLoss: 0.028828\n",
            "Train Epoch: 70 [10624/14860 (71%)]\tLoss: 0.049957\n",
            "Train Epoch: 70 [10752/14860 (72%)]\tLoss: 0.017839\n",
            "Train Epoch: 70 [10880/14860 (73%)]\tLoss: 0.035486\n",
            "Train Epoch: 70 [11008/14860 (74%)]\tLoss: 0.019941\n",
            "Train Epoch: 70 [11136/14860 (74%)]\tLoss: 0.032478\n",
            "Train Epoch: 70 [11264/14860 (75%)]\tLoss: 0.026147\n",
            "Train Epoch: 70 [11392/14860 (76%)]\tLoss: 0.024029\n",
            "Train Epoch: 70 [11520/14860 (77%)]\tLoss: 0.026375\n",
            "Train Epoch: 70 [11648/14860 (78%)]\tLoss: 0.018666\n",
            "Train Epoch: 70 [11776/14860 (79%)]\tLoss: 0.026007\n",
            "Train Epoch: 70 [11904/14860 (79%)]\tLoss: 0.024576\n",
            "Train Epoch: 70 [12032/14860 (80%)]\tLoss: 0.023410\n",
            "Train Epoch: 70 [12160/14860 (81%)]\tLoss: 0.018314\n",
            "Train Epoch: 70 [12288/14860 (82%)]\tLoss: 0.011955\n",
            "Train Epoch: 70 [12416/14860 (83%)]\tLoss: 0.020397\n",
            "Train Epoch: 70 [12544/14860 (84%)]\tLoss: 0.021465\n",
            "Train Epoch: 70 [12672/14860 (85%)]\tLoss: 0.016310\n",
            "Train Epoch: 70 [12800/14860 (85%)]\tLoss: 0.025123\n",
            "Train Epoch: 70 [12928/14860 (86%)]\tLoss: 0.012725\n",
            "Train Epoch: 70 [13056/14860 (87%)]\tLoss: 0.018339\n",
            "Train Epoch: 70 [13184/14860 (88%)]\tLoss: 0.018476\n",
            "Train Epoch: 70 [13312/14860 (89%)]\tLoss: 0.019226\n",
            "Train Epoch: 70 [13440/14860 (90%)]\tLoss: 0.025528\n",
            "Train Epoch: 70 [13568/14860 (91%)]\tLoss: 0.015606\n",
            "Train Epoch: 70 [13696/14860 (91%)]\tLoss: 0.023025\n",
            "Train Epoch: 70 [13824/14860 (92%)]\tLoss: 0.019805\n",
            "Train Epoch: 70 [13952/14860 (93%)]\tLoss: 0.017310\n",
            "Train Epoch: 70 [14080/14860 (94%)]\tLoss: 0.021878\n",
            "Train Epoch: 70 [14208/14860 (95%)]\tLoss: 0.018366\n",
            "Train Epoch: 70 [14336/14860 (96%)]\tLoss: 0.017083\n",
            "Train Epoch: 70 [14464/14860 (97%)]\tLoss: 0.016546\n",
            "Train Epoch: 70 [14592/14860 (97%)]\tLoss: 0.022021\n",
            "Train Epoch: 70 [14720/14860 (98%)]\tLoss: 0.018717\n",
            "Train Epoch: 70 [1392/14860 (99%)]\tLoss: 0.008869\n",
            "epoch 70 training loss: 0.022513137238784734\n",
            "epoch 70 validation loss: 0.029454254209273664\n",
            "Train Epoch: 71 [0/14860 (0%)]\tLoss: 0.031201\n",
            "Train Epoch: 71 [128/14860 (1%)]\tLoss: 0.020882\n",
            "Train Epoch: 71 [256/14860 (2%)]\tLoss: 0.029252\n",
            "Train Epoch: 71 [384/14860 (3%)]\tLoss: 0.017383\n",
            "Train Epoch: 71 [512/14860 (3%)]\tLoss: 0.030185\n",
            "Train Epoch: 71 [640/14860 (4%)]\tLoss: 0.021231\n",
            "Train Epoch: 71 [768/14860 (5%)]\tLoss: 0.023376\n",
            "Train Epoch: 71 [896/14860 (6%)]\tLoss: 0.015108\n",
            "Train Epoch: 71 [1024/14860 (7%)]\tLoss: 0.017906\n",
            "Train Epoch: 71 [1152/14860 (8%)]\tLoss: 0.014300\n",
            "Train Epoch: 71 [1280/14860 (9%)]\tLoss: 0.018319\n",
            "Train Epoch: 71 [1408/14860 (9%)]\tLoss: 0.019165\n",
            "Train Epoch: 71 [1536/14860 (10%)]\tLoss: 0.018100\n",
            "Train Epoch: 71 [1664/14860 (11%)]\tLoss: 0.021128\n",
            "Train Epoch: 71 [1792/14860 (12%)]\tLoss: 0.017790\n",
            "Train Epoch: 71 [1920/14860 (13%)]\tLoss: 0.014792\n",
            "Train Epoch: 71 [2048/14860 (14%)]\tLoss: 0.018423\n",
            "Train Epoch: 71 [2176/14860 (15%)]\tLoss: 0.013968\n",
            "Train Epoch: 71 [2304/14860 (15%)]\tLoss: 0.021979\n",
            "Train Epoch: 71 [2432/14860 (16%)]\tLoss: 0.023140\n",
            "Train Epoch: 71 [2560/14860 (17%)]\tLoss: 0.026774\n",
            "Train Epoch: 71 [2688/14860 (18%)]\tLoss: 0.023474\n",
            "Train Epoch: 71 [2816/14860 (19%)]\tLoss: 0.021134\n",
            "Train Epoch: 71 [2944/14860 (20%)]\tLoss: 0.017577\n",
            "Train Epoch: 71 [3072/14860 (21%)]\tLoss: 0.016693\n",
            "Train Epoch: 71 [3200/14860 (21%)]\tLoss: 0.018117\n",
            "Train Epoch: 71 [3328/14860 (22%)]\tLoss: 0.027864\n",
            "Train Epoch: 71 [3456/14860 (23%)]\tLoss: 0.026111\n",
            "Train Epoch: 71 [3584/14860 (24%)]\tLoss: 0.019247\n",
            "Train Epoch: 71 [3712/14860 (25%)]\tLoss: 0.018894\n",
            "Train Epoch: 71 [3840/14860 (26%)]\tLoss: 0.032063\n",
            "Train Epoch: 71 [3968/14860 (26%)]\tLoss: 0.021203\n",
            "Train Epoch: 71 [4096/14860 (27%)]\tLoss: 0.025209\n",
            "Train Epoch: 71 [4224/14860 (28%)]\tLoss: 0.027605\n",
            "Train Epoch: 71 [4352/14860 (29%)]\tLoss: 0.017850\n",
            "Train Epoch: 71 [4480/14860 (30%)]\tLoss: 0.017241\n",
            "Train Epoch: 71 [4608/14860 (31%)]\tLoss: 0.022645\n",
            "Train Epoch: 71 [4736/14860 (32%)]\tLoss: 0.015659\n",
            "Train Epoch: 71 [4864/14860 (32%)]\tLoss: 0.018315\n",
            "Train Epoch: 71 [4992/14860 (33%)]\tLoss: 0.011766\n",
            "Train Epoch: 71 [5120/14860 (34%)]\tLoss: 0.013299\n",
            "Train Epoch: 71 [5248/14860 (35%)]\tLoss: 0.017910\n",
            "Train Epoch: 71 [5376/14860 (36%)]\tLoss: 0.014743\n",
            "Train Epoch: 71 [5504/14860 (37%)]\tLoss: 0.024808\n",
            "Train Epoch: 71 [5632/14860 (38%)]\tLoss: 0.027545\n",
            "Train Epoch: 71 [5760/14860 (38%)]\tLoss: 0.019419\n",
            "Train Epoch: 71 [5888/14860 (39%)]\tLoss: 0.019394\n",
            "Train Epoch: 71 [6016/14860 (40%)]\tLoss: 0.022595\n",
            "Train Epoch: 71 [6144/14860 (41%)]\tLoss: 0.022894\n",
            "Train Epoch: 71 [6272/14860 (42%)]\tLoss: 0.019320\n",
            "Train Epoch: 71 [6400/14860 (43%)]\tLoss: 0.023139\n",
            "Train Epoch: 71 [6528/14860 (44%)]\tLoss: 0.019388\n",
            "Train Epoch: 71 [6656/14860 (44%)]\tLoss: 0.017849\n",
            "Train Epoch: 71 [6784/14860 (45%)]\tLoss: 0.019829\n",
            "Train Epoch: 71 [6912/14860 (46%)]\tLoss: 0.015731\n",
            "Train Epoch: 71 [7040/14860 (47%)]\tLoss: 0.015441\n",
            "Train Epoch: 71 [7168/14860 (48%)]\tLoss: 0.025486\n",
            "Train Epoch: 71 [7296/14860 (49%)]\tLoss: 0.022728\n",
            "Train Epoch: 71 [7424/14860 (50%)]\tLoss: 0.021184\n",
            "Train Epoch: 71 [7552/14860 (50%)]\tLoss: 0.023756\n",
            "Train Epoch: 71 [7680/14860 (51%)]\tLoss: 0.016006\n",
            "Train Epoch: 71 [7808/14860 (52%)]\tLoss: 0.017203\n",
            "Train Epoch: 71 [7936/14860 (53%)]\tLoss: 0.027123\n",
            "Train Epoch: 71 [8064/14860 (54%)]\tLoss: 0.017522\n",
            "Train Epoch: 71 [8192/14860 (55%)]\tLoss: 0.022906\n",
            "Train Epoch: 71 [8320/14860 (56%)]\tLoss: 0.025913\n",
            "Train Epoch: 71 [8448/14860 (56%)]\tLoss: 0.022951\n",
            "Train Epoch: 71 [8576/14860 (57%)]\tLoss: 0.027662\n",
            "Train Epoch: 71 [8704/14860 (58%)]\tLoss: 0.017419\n",
            "Train Epoch: 71 [8832/14860 (59%)]\tLoss: 0.020931\n",
            "Train Epoch: 71 [8960/14860 (60%)]\tLoss: 0.015418\n",
            "Train Epoch: 71 [9088/14860 (61%)]\tLoss: 0.024805\n",
            "Train Epoch: 71 [9216/14860 (62%)]\tLoss: 0.021661\n",
            "Train Epoch: 71 [9344/14860 (62%)]\tLoss: 0.028686\n",
            "Train Epoch: 71 [9472/14860 (63%)]\tLoss: 0.025830\n",
            "Train Epoch: 71 [9600/14860 (64%)]\tLoss: 0.033980\n",
            "Train Epoch: 71 [9728/14860 (65%)]\tLoss: 0.017235\n",
            "Train Epoch: 71 [9856/14860 (66%)]\tLoss: 0.028182\n",
            "Train Epoch: 71 [9984/14860 (67%)]\tLoss: 0.025757\n",
            "Train Epoch: 71 [10112/14860 (68%)]\tLoss: 0.019914\n",
            "Train Epoch: 71 [10240/14860 (68%)]\tLoss: 0.016776\n",
            "Train Epoch: 71 [10368/14860 (69%)]\tLoss: 0.025866\n",
            "Train Epoch: 71 [10496/14860 (70%)]\tLoss: 0.015659\n",
            "Train Epoch: 71 [10624/14860 (71%)]\tLoss: 0.022444\n",
            "Train Epoch: 71 [10752/14860 (72%)]\tLoss: 0.019922\n",
            "Train Epoch: 71 [10880/14860 (73%)]\tLoss: 0.030146\n",
            "Train Epoch: 71 [11008/14860 (74%)]\tLoss: 0.021985\n",
            "Train Epoch: 71 [11136/14860 (74%)]\tLoss: 0.021342\n",
            "Train Epoch: 71 [11264/14860 (75%)]\tLoss: 0.021618\n",
            "Train Epoch: 71 [11392/14860 (76%)]\tLoss: 0.017365\n",
            "Train Epoch: 71 [11520/14860 (77%)]\tLoss: 0.017596\n",
            "Train Epoch: 71 [11648/14860 (78%)]\tLoss: 0.031822\n",
            "Train Epoch: 71 [11776/14860 (79%)]\tLoss: 0.018312\n",
            "Train Epoch: 71 [11904/14860 (79%)]\tLoss: 0.024392\n",
            "Train Epoch: 71 [12032/14860 (80%)]\tLoss: 0.017265\n",
            "Train Epoch: 71 [12160/14860 (81%)]\tLoss: 0.020461\n",
            "Train Epoch: 71 [12288/14860 (82%)]\tLoss: 0.016501\n",
            "Train Epoch: 71 [12416/14860 (83%)]\tLoss: 0.020391\n",
            "Train Epoch: 71 [12544/14860 (84%)]\tLoss: 0.025873\n",
            "Train Epoch: 71 [12672/14860 (85%)]\tLoss: 0.030339\n",
            "Train Epoch: 71 [12800/14860 (85%)]\tLoss: 0.021945\n",
            "Train Epoch: 71 [12928/14860 (86%)]\tLoss: 0.024674\n",
            "Train Epoch: 71 [13056/14860 (87%)]\tLoss: 0.022164\n",
            "Train Epoch: 71 [13184/14860 (88%)]\tLoss: 0.021054\n",
            "Train Epoch: 71 [13312/14860 (89%)]\tLoss: 0.028595\n",
            "Train Epoch: 71 [13440/14860 (90%)]\tLoss: 0.017207\n",
            "Train Epoch: 71 [13568/14860 (91%)]\tLoss: 0.018246\n",
            "Train Epoch: 71 [13696/14860 (91%)]\tLoss: 0.022427\n",
            "Train Epoch: 71 [13824/14860 (92%)]\tLoss: 0.024308\n",
            "Train Epoch: 71 [13952/14860 (93%)]\tLoss: 0.016175\n",
            "Train Epoch: 71 [14080/14860 (94%)]\tLoss: 0.025719\n",
            "Train Epoch: 71 [14208/14860 (95%)]\tLoss: 0.025733\n",
            "Train Epoch: 71 [14336/14860 (96%)]\tLoss: 0.024900\n",
            "Train Epoch: 71 [14464/14860 (97%)]\tLoss: 0.018699\n",
            "Train Epoch: 71 [14592/14860 (97%)]\tLoss: 0.020605\n",
            "Train Epoch: 71 [14720/14860 (98%)]\tLoss: 0.021959\n",
            "Train Epoch: 71 [1392/14860 (99%)]\tLoss: 0.018170\n",
            "epoch 71 training loss: 0.02141267804699576\n",
            "epoch 71 validation loss: 0.021537692292839215\n",
            "Train Epoch: 72 [0/14860 (0%)]\tLoss: 0.018042\n",
            "Train Epoch: 72 [128/14860 (1%)]\tLoss: 0.026429\n",
            "Train Epoch: 72 [256/14860 (2%)]\tLoss: 0.021689\n",
            "Train Epoch: 72 [384/14860 (3%)]\tLoss: 0.022124\n",
            "Train Epoch: 72 [512/14860 (3%)]\tLoss: 0.025814\n",
            "Train Epoch: 72 [640/14860 (4%)]\tLoss: 0.028544\n",
            "Train Epoch: 72 [768/14860 (5%)]\tLoss: 0.024427\n",
            "Train Epoch: 72 [896/14860 (6%)]\tLoss: 0.015903\n",
            "Train Epoch: 72 [1024/14860 (7%)]\tLoss: 0.032397\n",
            "Train Epoch: 72 [1152/14860 (8%)]\tLoss: 0.017895\n",
            "Train Epoch: 72 [1280/14860 (9%)]\tLoss: 0.024421\n",
            "Train Epoch: 72 [1408/14860 (9%)]\tLoss: 0.026017\n",
            "Train Epoch: 72 [1536/14860 (10%)]\tLoss: 0.031026\n",
            "Train Epoch: 72 [1664/14860 (11%)]\tLoss: 0.017742\n",
            "Train Epoch: 72 [1792/14860 (12%)]\tLoss: 0.019890\n",
            "Train Epoch: 72 [1920/14860 (13%)]\tLoss: 0.018709\n",
            "Train Epoch: 72 [2048/14860 (14%)]\tLoss: 0.016128\n",
            "Train Epoch: 72 [2176/14860 (15%)]\tLoss: 0.024160\n",
            "Train Epoch: 72 [2304/14860 (15%)]\tLoss: 0.021789\n",
            "Train Epoch: 72 [2432/14860 (16%)]\tLoss: 0.027227\n",
            "Train Epoch: 72 [2560/14860 (17%)]\tLoss: 0.017604\n",
            "Train Epoch: 72 [2688/14860 (18%)]\tLoss: 0.027979\n",
            "Train Epoch: 72 [2816/14860 (19%)]\tLoss: 0.022539\n",
            "Train Epoch: 72 [2944/14860 (20%)]\tLoss: 0.017196\n",
            "Train Epoch: 72 [3072/14860 (21%)]\tLoss: 0.010881\n",
            "Train Epoch: 72 [3200/14860 (21%)]\tLoss: 0.020753\n",
            "Train Epoch: 72 [3328/14860 (22%)]\tLoss: 0.024729\n",
            "Train Epoch: 72 [3456/14860 (23%)]\tLoss: 0.023083\n",
            "Train Epoch: 72 [3584/14860 (24%)]\tLoss: 0.018480\n",
            "Train Epoch: 72 [3712/14860 (25%)]\tLoss: 0.020031\n",
            "Train Epoch: 72 [3840/14860 (26%)]\tLoss: 0.020398\n",
            "Train Epoch: 72 [3968/14860 (26%)]\tLoss: 0.026155\n",
            "Train Epoch: 72 [4096/14860 (27%)]\tLoss: 0.015595\n",
            "Train Epoch: 72 [4224/14860 (28%)]\tLoss: 0.012737\n",
            "Train Epoch: 72 [4352/14860 (29%)]\tLoss: 0.022068\n",
            "Train Epoch: 72 [4480/14860 (30%)]\tLoss: 0.017927\n",
            "Train Epoch: 72 [4608/14860 (31%)]\tLoss: 0.025970\n",
            "Train Epoch: 72 [4736/14860 (32%)]\tLoss: 0.024449\n",
            "Train Epoch: 72 [4864/14860 (32%)]\tLoss: 0.021395\n",
            "Train Epoch: 72 [4992/14860 (33%)]\tLoss: 0.020625\n",
            "Train Epoch: 72 [5120/14860 (34%)]\tLoss: 0.022844\n",
            "Train Epoch: 72 [5248/14860 (35%)]\tLoss: 0.021105\n",
            "Train Epoch: 72 [5376/14860 (36%)]\tLoss: 0.020385\n",
            "Train Epoch: 72 [5504/14860 (37%)]\tLoss: 0.022674\n",
            "Train Epoch: 72 [5632/14860 (38%)]\tLoss: 0.010158\n",
            "Train Epoch: 72 [5760/14860 (38%)]\tLoss: 0.024244\n",
            "Train Epoch: 72 [5888/14860 (39%)]\tLoss: 0.020993\n",
            "Train Epoch: 72 [6016/14860 (40%)]\tLoss: 0.013228\n",
            "Train Epoch: 72 [6144/14860 (41%)]\tLoss: 0.025257\n",
            "Train Epoch: 72 [6272/14860 (42%)]\tLoss: 0.021582\n",
            "Train Epoch: 72 [6400/14860 (43%)]\tLoss: 0.035262\n",
            "Train Epoch: 72 [6528/14860 (44%)]\tLoss: 0.017887\n",
            "Train Epoch: 72 [6656/14860 (44%)]\tLoss: 0.029029\n",
            "Train Epoch: 72 [6784/14860 (45%)]\tLoss: 0.018336\n",
            "Train Epoch: 72 [6912/14860 (46%)]\tLoss: 0.027094\n",
            "Train Epoch: 72 [7040/14860 (47%)]\tLoss: 0.022905\n",
            "Train Epoch: 72 [7168/14860 (48%)]\tLoss: 0.025637\n",
            "Train Epoch: 72 [7296/14860 (49%)]\tLoss: 0.020082\n",
            "Train Epoch: 72 [7424/14860 (50%)]\tLoss: 0.017400\n",
            "Train Epoch: 72 [7552/14860 (50%)]\tLoss: 0.023682\n",
            "Train Epoch: 72 [7680/14860 (51%)]\tLoss: 0.014755\n",
            "Train Epoch: 72 [7808/14860 (52%)]\tLoss: 0.023306\n",
            "Train Epoch: 72 [7936/14860 (53%)]\tLoss: 0.020108\n",
            "Train Epoch: 72 [8064/14860 (54%)]\tLoss: 0.028397\n",
            "Train Epoch: 72 [8192/14860 (55%)]\tLoss: 0.024489\n",
            "Train Epoch: 72 [8320/14860 (56%)]\tLoss: 0.021082\n",
            "Train Epoch: 72 [8448/14860 (56%)]\tLoss: 0.017818\n",
            "Train Epoch: 72 [8576/14860 (57%)]\tLoss: 0.026624\n",
            "Train Epoch: 72 [8704/14860 (58%)]\tLoss: 0.024996\n",
            "Train Epoch: 72 [8832/14860 (59%)]\tLoss: 0.021965\n",
            "Train Epoch: 72 [8960/14860 (60%)]\tLoss: 0.022421\n",
            "Train Epoch: 72 [9088/14860 (61%)]\tLoss: 0.024677\n",
            "Train Epoch: 72 [9216/14860 (62%)]\tLoss: 0.021902\n",
            "Train Epoch: 72 [9344/14860 (62%)]\tLoss: 0.017646\n",
            "Train Epoch: 72 [9472/14860 (63%)]\tLoss: 0.020614\n",
            "Train Epoch: 72 [9600/14860 (64%)]\tLoss: 0.018698\n",
            "Train Epoch: 72 [9728/14860 (65%)]\tLoss: 0.015213\n",
            "Train Epoch: 72 [9856/14860 (66%)]\tLoss: 0.011521\n",
            "Train Epoch: 72 [9984/14860 (67%)]\tLoss: 0.021176\n",
            "Train Epoch: 72 [10112/14860 (68%)]\tLoss: 0.020676\n",
            "Train Epoch: 72 [10240/14860 (68%)]\tLoss: 0.022147\n",
            "Train Epoch: 72 [10368/14860 (69%)]\tLoss: 0.032465\n",
            "Train Epoch: 72 [10496/14860 (70%)]\tLoss: 0.022220\n",
            "Train Epoch: 72 [10624/14860 (71%)]\tLoss: 0.016465\n",
            "Train Epoch: 72 [10752/14860 (72%)]\tLoss: 0.023122\n",
            "Train Epoch: 72 [10880/14860 (73%)]\tLoss: 0.028646\n",
            "Train Epoch: 72 [11008/14860 (74%)]\tLoss: 0.019616\n",
            "Train Epoch: 72 [11136/14860 (74%)]\tLoss: 0.021617\n",
            "Train Epoch: 72 [11264/14860 (75%)]\tLoss: 0.017783\n",
            "Train Epoch: 72 [11392/14860 (76%)]\tLoss: 0.015444\n",
            "Train Epoch: 72 [11520/14860 (77%)]\tLoss: 0.018812\n",
            "Train Epoch: 72 [11648/14860 (78%)]\tLoss: 0.019791\n",
            "Train Epoch: 72 [11776/14860 (79%)]\tLoss: 0.018368\n",
            "Train Epoch: 72 [11904/14860 (79%)]\tLoss: 0.018670\n",
            "Train Epoch: 72 [12032/14860 (80%)]\tLoss: 0.016004\n",
            "Train Epoch: 72 [12160/14860 (81%)]\tLoss: 0.019811\n",
            "Train Epoch: 72 [12288/14860 (82%)]\tLoss: 0.017290\n",
            "Train Epoch: 72 [12416/14860 (83%)]\tLoss: 0.022470\n",
            "Train Epoch: 72 [12544/14860 (84%)]\tLoss: 0.025391\n",
            "Train Epoch: 72 [12672/14860 (85%)]\tLoss: 0.015586\n",
            "Train Epoch: 72 [12800/14860 (85%)]\tLoss: 0.017147\n",
            "Train Epoch: 72 [12928/14860 (86%)]\tLoss: 0.021759\n",
            "Train Epoch: 72 [13056/14860 (87%)]\tLoss: 0.019716\n",
            "Train Epoch: 72 [13184/14860 (88%)]\tLoss: 0.015206\n",
            "Train Epoch: 72 [13312/14860 (89%)]\tLoss: 0.018173\n",
            "Train Epoch: 72 [13440/14860 (90%)]\tLoss: 0.017072\n",
            "Train Epoch: 72 [13568/14860 (91%)]\tLoss: 0.019945\n",
            "Train Epoch: 72 [13696/14860 (91%)]\tLoss: 0.022211\n",
            "Train Epoch: 72 [13824/14860 (92%)]\tLoss: 0.030818\n",
            "Train Epoch: 72 [13952/14860 (93%)]\tLoss: 0.033332\n",
            "Train Epoch: 72 [14080/14860 (94%)]\tLoss: 0.013372\n",
            "Train Epoch: 72 [14208/14860 (95%)]\tLoss: 0.016685\n",
            "Train Epoch: 72 [14336/14860 (96%)]\tLoss: 0.018123\n",
            "Train Epoch: 72 [14464/14860 (97%)]\tLoss: 0.019046\n",
            "Train Epoch: 72 [14592/14860 (97%)]\tLoss: 0.025763\n",
            "Train Epoch: 72 [14720/14860 (98%)]\tLoss: 0.016301\n",
            "Train Epoch: 72 [1392/14860 (99%)]\tLoss: 0.035978\n",
            "epoch 72 training loss: 0.021377744264582284\n",
            "epoch 72 validation loss: 0.02133375911389367\n",
            "Train Epoch: 73 [0/14860 (0%)]\tLoss: 0.019092\n",
            "Train Epoch: 73 [128/14860 (1%)]\tLoss: 0.021944\n",
            "Train Epoch: 73 [256/14860 (2%)]\tLoss: 0.016253\n",
            "Train Epoch: 73 [384/14860 (3%)]\tLoss: 0.025083\n",
            "Train Epoch: 73 [512/14860 (3%)]\tLoss: 0.015123\n",
            "Train Epoch: 73 [640/14860 (4%)]\tLoss: 0.019633\n",
            "Train Epoch: 73 [768/14860 (5%)]\tLoss: 0.021004\n",
            "Train Epoch: 73 [896/14860 (6%)]\tLoss: 0.025772\n",
            "Train Epoch: 73 [1024/14860 (7%)]\tLoss: 0.029235\n",
            "Train Epoch: 73 [1152/14860 (8%)]\tLoss: 0.018607\n",
            "Train Epoch: 73 [1280/14860 (9%)]\tLoss: 0.025145\n",
            "Train Epoch: 73 [1408/14860 (9%)]\tLoss: 0.023580\n",
            "Train Epoch: 73 [1536/14860 (10%)]\tLoss: 0.015021\n",
            "Train Epoch: 73 [1664/14860 (11%)]\tLoss: 0.017894\n",
            "Train Epoch: 73 [1792/14860 (12%)]\tLoss: 0.029521\n",
            "Train Epoch: 73 [1920/14860 (13%)]\tLoss: 0.021437\n",
            "Train Epoch: 73 [2048/14860 (14%)]\tLoss: 0.017314\n",
            "Train Epoch: 73 [2176/14860 (15%)]\tLoss: 0.023973\n",
            "Train Epoch: 73 [2304/14860 (15%)]\tLoss: 0.023337\n",
            "Train Epoch: 73 [2432/14860 (16%)]\tLoss: 0.013939\n",
            "Train Epoch: 73 [2560/14860 (17%)]\tLoss: 0.024972\n",
            "Train Epoch: 73 [2688/14860 (18%)]\tLoss: 0.026922\n",
            "Train Epoch: 73 [2816/14860 (19%)]\tLoss: 0.022625\n",
            "Train Epoch: 73 [2944/14860 (20%)]\tLoss: 0.021135\n",
            "Train Epoch: 73 [3072/14860 (21%)]\tLoss: 0.018822\n",
            "Train Epoch: 73 [3200/14860 (21%)]\tLoss: 0.020966\n",
            "Train Epoch: 73 [3328/14860 (22%)]\tLoss: 0.021220\n",
            "Train Epoch: 73 [3456/14860 (23%)]\tLoss: 0.015314\n",
            "Train Epoch: 73 [3584/14860 (24%)]\tLoss: 0.016853\n",
            "Train Epoch: 73 [3712/14860 (25%)]\tLoss: 0.020278\n",
            "Train Epoch: 73 [3840/14860 (26%)]\tLoss: 0.023726\n",
            "Train Epoch: 73 [3968/14860 (26%)]\tLoss: 0.017197\n",
            "Train Epoch: 73 [4096/14860 (27%)]\tLoss: 0.025924\n",
            "Train Epoch: 73 [4224/14860 (28%)]\tLoss: 0.014970\n",
            "Train Epoch: 73 [4352/14860 (29%)]\tLoss: 0.016329\n",
            "Train Epoch: 73 [4480/14860 (30%)]\tLoss: 0.020735\n",
            "Train Epoch: 73 [4608/14860 (31%)]\tLoss: 0.021176\n",
            "Train Epoch: 73 [4736/14860 (32%)]\tLoss: 0.022279\n",
            "Train Epoch: 73 [4864/14860 (32%)]\tLoss: 0.027154\n",
            "Train Epoch: 73 [4992/14860 (33%)]\tLoss: 0.014936\n",
            "Train Epoch: 73 [5120/14860 (34%)]\tLoss: 0.018409\n",
            "Train Epoch: 73 [5248/14860 (35%)]\tLoss: 0.015496\n",
            "Train Epoch: 73 [5376/14860 (36%)]\tLoss: 0.024390\n",
            "Train Epoch: 73 [5504/14860 (37%)]\tLoss: 0.026251\n",
            "Train Epoch: 73 [5632/14860 (38%)]\tLoss: 0.016281\n",
            "Train Epoch: 73 [5760/14860 (38%)]\tLoss: 0.021916\n",
            "Train Epoch: 73 [5888/14860 (39%)]\tLoss: 0.017327\n",
            "Train Epoch: 73 [6016/14860 (40%)]\tLoss: 0.020879\n",
            "Train Epoch: 73 [6144/14860 (41%)]\tLoss: 0.021770\n",
            "Train Epoch: 73 [6272/14860 (42%)]\tLoss: 0.017436\n",
            "Train Epoch: 73 [6400/14860 (43%)]\tLoss: 0.019533\n",
            "Train Epoch: 73 [6528/14860 (44%)]\tLoss: 0.016127\n",
            "Train Epoch: 73 [6656/14860 (44%)]\tLoss: 0.025183\n",
            "Train Epoch: 73 [6784/14860 (45%)]\tLoss: 0.021057\n",
            "Train Epoch: 73 [6912/14860 (46%)]\tLoss: 0.020901\n",
            "Train Epoch: 73 [7040/14860 (47%)]\tLoss: 0.016384\n",
            "Train Epoch: 73 [7168/14860 (48%)]\tLoss: 0.015299\n",
            "Train Epoch: 73 [7296/14860 (49%)]\tLoss: 0.017375\n",
            "Train Epoch: 73 [7424/14860 (50%)]\tLoss: 0.020591\n",
            "Train Epoch: 73 [7552/14860 (50%)]\tLoss: 0.020267\n",
            "Train Epoch: 73 [7680/14860 (51%)]\tLoss: 0.019118\n",
            "Train Epoch: 73 [7808/14860 (52%)]\tLoss: 0.032789\n",
            "Train Epoch: 73 [7936/14860 (53%)]\tLoss: 0.025772\n",
            "Train Epoch: 73 [8064/14860 (54%)]\tLoss: 0.013783\n",
            "Train Epoch: 73 [8192/14860 (55%)]\tLoss: 0.027537\n",
            "Train Epoch: 73 [8320/14860 (56%)]\tLoss: 0.017189\n",
            "Train Epoch: 73 [8448/14860 (56%)]\tLoss: 0.023185\n",
            "Train Epoch: 73 [8576/14860 (57%)]\tLoss: 0.016155\n",
            "Train Epoch: 73 [8704/14860 (58%)]\tLoss: 0.019938\n",
            "Train Epoch: 73 [8832/14860 (59%)]\tLoss: 0.020714\n",
            "Train Epoch: 73 [8960/14860 (60%)]\tLoss: 0.023366\n",
            "Train Epoch: 73 [9088/14860 (61%)]\tLoss: 0.024454\n",
            "Train Epoch: 73 [9216/14860 (62%)]\tLoss: 0.016958\n",
            "Train Epoch: 73 [9344/14860 (62%)]\tLoss: 0.020212\n",
            "Train Epoch: 73 [9472/14860 (63%)]\tLoss: 0.023435\n",
            "Train Epoch: 73 [9600/14860 (64%)]\tLoss: 0.026499\n",
            "Train Epoch: 73 [9728/14860 (65%)]\tLoss: 0.020946\n",
            "Train Epoch: 73 [9856/14860 (66%)]\tLoss: 0.041783\n",
            "Train Epoch: 73 [9984/14860 (67%)]\tLoss: 0.035808\n",
            "Train Epoch: 73 [10112/14860 (68%)]\tLoss: 0.025067\n",
            "Train Epoch: 73 [10240/14860 (68%)]\tLoss: 0.020473\n",
            "Train Epoch: 73 [10368/14860 (69%)]\tLoss: 0.025582\n",
            "Train Epoch: 73 [10496/14860 (70%)]\tLoss: 0.025631\n",
            "Train Epoch: 73 [10624/14860 (71%)]\tLoss: 0.029827\n",
            "Train Epoch: 73 [10752/14860 (72%)]\tLoss: 0.028974\n",
            "Train Epoch: 73 [10880/14860 (73%)]\tLoss: 0.024396\n",
            "Train Epoch: 73 [11008/14860 (74%)]\tLoss: 0.018425\n",
            "Train Epoch: 73 [11136/14860 (74%)]\tLoss: 0.027078\n",
            "Train Epoch: 73 [11264/14860 (75%)]\tLoss: 0.020201\n",
            "Train Epoch: 73 [11392/14860 (76%)]\tLoss: 0.020422\n",
            "Train Epoch: 73 [11520/14860 (77%)]\tLoss: 0.030066\n",
            "Train Epoch: 73 [11648/14860 (78%)]\tLoss: 0.031891\n",
            "Train Epoch: 73 [11776/14860 (79%)]\tLoss: 0.025939\n",
            "Train Epoch: 73 [11904/14860 (79%)]\tLoss: 0.029363\n",
            "Train Epoch: 73 [12032/14860 (80%)]\tLoss: 0.032590\n",
            "Train Epoch: 73 [12160/14860 (81%)]\tLoss: 0.020755\n",
            "Train Epoch: 73 [12288/14860 (82%)]\tLoss: 0.029148\n",
            "Train Epoch: 73 [12416/14860 (83%)]\tLoss: 0.018418\n",
            "Train Epoch: 73 [12544/14860 (84%)]\tLoss: 0.027518\n",
            "Train Epoch: 73 [12672/14860 (85%)]\tLoss: 0.021184\n",
            "Train Epoch: 73 [12800/14860 (85%)]\tLoss: 0.020347\n",
            "Train Epoch: 73 [12928/14860 (86%)]\tLoss: 0.028429\n",
            "Train Epoch: 73 [13056/14860 (87%)]\tLoss: 0.018704\n",
            "Train Epoch: 73 [13184/14860 (88%)]\tLoss: 0.024067\n",
            "Train Epoch: 73 [13312/14860 (89%)]\tLoss: 0.017248\n",
            "Train Epoch: 73 [13440/14860 (90%)]\tLoss: 0.022779\n",
            "Train Epoch: 73 [13568/14860 (91%)]\tLoss: 0.021528\n",
            "Train Epoch: 73 [13696/14860 (91%)]\tLoss: 0.025360\n",
            "Train Epoch: 73 [13824/14860 (92%)]\tLoss: 0.018924\n",
            "Train Epoch: 73 [13952/14860 (93%)]\tLoss: 0.018590\n",
            "Train Epoch: 73 [14080/14860 (94%)]\tLoss: 0.014103\n",
            "Train Epoch: 73 [14208/14860 (95%)]\tLoss: 0.028663\n",
            "Train Epoch: 73 [14336/14860 (96%)]\tLoss: 0.018377\n",
            "Train Epoch: 73 [14464/14860 (97%)]\tLoss: 0.021510\n",
            "Train Epoch: 73 [14592/14860 (97%)]\tLoss: 0.023768\n",
            "Train Epoch: 73 [14720/14860 (98%)]\tLoss: 0.021560\n",
            "Train Epoch: 73 [1392/14860 (99%)]\tLoss: 0.034390\n",
            "epoch 73 training loss: 0.02213890612539318\n",
            "epoch 73 validation loss: 0.024577084378526518\n",
            "Train Epoch: 74 [0/14860 (0%)]\tLoss: 0.037442\n",
            "Train Epoch: 74 [128/14860 (1%)]\tLoss: 0.022334\n",
            "Train Epoch: 74 [256/14860 (2%)]\tLoss: 0.027222\n",
            "Train Epoch: 74 [384/14860 (3%)]\tLoss: 0.027367\n",
            "Train Epoch: 74 [512/14860 (3%)]\tLoss: 0.028319\n",
            "Train Epoch: 74 [640/14860 (4%)]\tLoss: 0.017389\n",
            "Train Epoch: 74 [768/14860 (5%)]\tLoss: 0.030204\n",
            "Train Epoch: 74 [896/14860 (6%)]\tLoss: 0.019523\n",
            "Train Epoch: 74 [1024/14860 (7%)]\tLoss: 0.030525\n",
            "Train Epoch: 74 [1152/14860 (8%)]\tLoss: 0.012167\n",
            "Train Epoch: 74 [1280/14860 (9%)]\tLoss: 0.023154\n",
            "Train Epoch: 74 [1408/14860 (9%)]\tLoss: 0.024854\n",
            "Train Epoch: 74 [1536/14860 (10%)]\tLoss: 0.016662\n",
            "Train Epoch: 74 [1664/14860 (11%)]\tLoss: 0.032796\n",
            "Train Epoch: 74 [1792/14860 (12%)]\tLoss: 0.025131\n",
            "Train Epoch: 74 [1920/14860 (13%)]\tLoss: 0.031858\n",
            "Train Epoch: 74 [2048/14860 (14%)]\tLoss: 0.027760\n",
            "Train Epoch: 74 [2176/14860 (15%)]\tLoss: 0.028995\n",
            "Train Epoch: 74 [2304/14860 (15%)]\tLoss: 0.017034\n",
            "Train Epoch: 74 [2432/14860 (16%)]\tLoss: 0.023922\n",
            "Train Epoch: 74 [2560/14860 (17%)]\tLoss: 0.012729\n",
            "Train Epoch: 74 [2688/14860 (18%)]\tLoss: 0.028346\n",
            "Train Epoch: 74 [2816/14860 (19%)]\tLoss: 0.019503\n",
            "Train Epoch: 74 [2944/14860 (20%)]\tLoss: 0.019339\n",
            "Train Epoch: 74 [3072/14860 (21%)]\tLoss: 0.022014\n",
            "Train Epoch: 74 [3200/14860 (21%)]\tLoss: 0.014157\n",
            "Train Epoch: 74 [3328/14860 (22%)]\tLoss: 0.021183\n",
            "Train Epoch: 74 [3456/14860 (23%)]\tLoss: 0.021828\n",
            "Train Epoch: 74 [3584/14860 (24%)]\tLoss: 0.018058\n",
            "Train Epoch: 74 [3712/14860 (25%)]\tLoss: 0.023773\n",
            "Train Epoch: 74 [3840/14860 (26%)]\tLoss: 0.030201\n",
            "Train Epoch: 74 [3968/14860 (26%)]\tLoss: 0.022904\n",
            "Train Epoch: 74 [4096/14860 (27%)]\tLoss: 0.019344\n",
            "Train Epoch: 74 [4224/14860 (28%)]\tLoss: 0.026744\n",
            "Train Epoch: 74 [4352/14860 (29%)]\tLoss: 0.018615\n",
            "Train Epoch: 74 [4480/14860 (30%)]\tLoss: 0.022476\n",
            "Train Epoch: 74 [4608/14860 (31%)]\tLoss: 0.020573\n",
            "Train Epoch: 74 [4736/14860 (32%)]\tLoss: 0.025775\n",
            "Train Epoch: 74 [4864/14860 (32%)]\tLoss: 0.018575\n",
            "Train Epoch: 74 [4992/14860 (33%)]\tLoss: 0.021889\n",
            "Train Epoch: 74 [5120/14860 (34%)]\tLoss: 0.018547\n",
            "Train Epoch: 74 [5248/14860 (35%)]\tLoss: 0.023685\n",
            "Train Epoch: 74 [5376/14860 (36%)]\tLoss: 0.018917\n",
            "Train Epoch: 74 [5504/14860 (37%)]\tLoss: 0.014544\n",
            "Train Epoch: 74 [5632/14860 (38%)]\tLoss: 0.029793\n",
            "Train Epoch: 74 [5760/14860 (38%)]\tLoss: 0.021236\n",
            "Train Epoch: 74 [5888/14860 (39%)]\tLoss: 0.016684\n",
            "Train Epoch: 74 [6016/14860 (40%)]\tLoss: 0.019803\n",
            "Train Epoch: 74 [6144/14860 (41%)]\tLoss: 0.019169\n",
            "Train Epoch: 74 [6272/14860 (42%)]\tLoss: 0.021525\n",
            "Train Epoch: 74 [6400/14860 (43%)]\tLoss: 0.019814\n",
            "Train Epoch: 74 [6528/14860 (44%)]\tLoss: 0.015837\n",
            "Train Epoch: 74 [6656/14860 (44%)]\tLoss: 0.025987\n",
            "Train Epoch: 74 [6784/14860 (45%)]\tLoss: 0.020940\n",
            "Train Epoch: 74 [6912/14860 (46%)]\tLoss: 0.021695\n",
            "Train Epoch: 74 [7040/14860 (47%)]\tLoss: 0.018700\n",
            "Train Epoch: 74 [7168/14860 (48%)]\tLoss: 0.014993\n",
            "Train Epoch: 74 [7296/14860 (49%)]\tLoss: 0.017938\n",
            "Train Epoch: 74 [7424/14860 (50%)]\tLoss: 0.025765\n",
            "Train Epoch: 74 [7552/14860 (50%)]\tLoss: 0.025019\n",
            "Train Epoch: 74 [7680/14860 (51%)]\tLoss: 0.022150\n",
            "Train Epoch: 74 [7808/14860 (52%)]\tLoss: 0.019034\n",
            "Train Epoch: 74 [7936/14860 (53%)]\tLoss: 0.008723\n",
            "Train Epoch: 74 [8064/14860 (54%)]\tLoss: 0.019976\n",
            "Train Epoch: 74 [8192/14860 (55%)]\tLoss: 0.019686\n",
            "Train Epoch: 74 [8320/14860 (56%)]\tLoss: 0.019345\n",
            "Train Epoch: 74 [8448/14860 (56%)]\tLoss: 0.023194\n",
            "Train Epoch: 74 [8576/14860 (57%)]\tLoss: 0.024040\n",
            "Train Epoch: 74 [8704/14860 (58%)]\tLoss: 0.014097\n",
            "Train Epoch: 74 [8832/14860 (59%)]\tLoss: 0.013891\n",
            "Train Epoch: 74 [8960/14860 (60%)]\tLoss: 0.028824\n",
            "Train Epoch: 74 [9088/14860 (61%)]\tLoss: 0.026654\n",
            "Train Epoch: 74 [9216/14860 (62%)]\tLoss: 0.025505\n",
            "Train Epoch: 74 [9344/14860 (62%)]\tLoss: 0.022264\n",
            "Train Epoch: 74 [9472/14860 (63%)]\tLoss: 0.019153\n",
            "Train Epoch: 74 [9600/14860 (64%)]\tLoss: 0.021557\n",
            "Train Epoch: 74 [9728/14860 (65%)]\tLoss: 0.020669\n",
            "Train Epoch: 74 [9856/14860 (66%)]\tLoss: 0.022180\n",
            "Train Epoch: 74 [9984/14860 (67%)]\tLoss: 0.019016\n",
            "Train Epoch: 74 [10112/14860 (68%)]\tLoss: 0.026096\n",
            "Train Epoch: 74 [10240/14860 (68%)]\tLoss: 0.018969\n",
            "Train Epoch: 74 [10368/14860 (69%)]\tLoss: 0.015800\n",
            "Train Epoch: 74 [10496/14860 (70%)]\tLoss: 0.015418\n",
            "Train Epoch: 74 [10624/14860 (71%)]\tLoss: 0.024483\n",
            "Train Epoch: 74 [10752/14860 (72%)]\tLoss: 0.025021\n",
            "Train Epoch: 74 [10880/14860 (73%)]\tLoss: 0.021022\n",
            "Train Epoch: 74 [11008/14860 (74%)]\tLoss: 0.020244\n",
            "Train Epoch: 74 [11136/14860 (74%)]\tLoss: 0.021525\n",
            "Train Epoch: 74 [11264/14860 (75%)]\tLoss: 0.017942\n",
            "Train Epoch: 74 [11392/14860 (76%)]\tLoss: 0.019419\n",
            "Train Epoch: 74 [11520/14860 (77%)]\tLoss: 0.026552\n",
            "Train Epoch: 74 [11648/14860 (78%)]\tLoss: 0.017245\n",
            "Train Epoch: 74 [11776/14860 (79%)]\tLoss: 0.017370\n",
            "Train Epoch: 74 [11904/14860 (79%)]\tLoss: 0.027716\n",
            "Train Epoch: 74 [12032/14860 (80%)]\tLoss: 0.017607\n",
            "Train Epoch: 74 [12160/14860 (81%)]\tLoss: 0.018418\n",
            "Train Epoch: 74 [12288/14860 (82%)]\tLoss: 0.023237\n",
            "Train Epoch: 74 [12416/14860 (83%)]\tLoss: 0.021575\n",
            "Train Epoch: 74 [12544/14860 (84%)]\tLoss: 0.016471\n",
            "Train Epoch: 74 [12672/14860 (85%)]\tLoss: 0.030146\n",
            "Train Epoch: 74 [12800/14860 (85%)]\tLoss: 0.020359\n",
            "Train Epoch: 74 [12928/14860 (86%)]\tLoss: 0.022569\n",
            "Train Epoch: 74 [13056/14860 (87%)]\tLoss: 0.027422\n",
            "Train Epoch: 74 [13184/14860 (88%)]\tLoss: 0.017194\n",
            "Train Epoch: 74 [13312/14860 (89%)]\tLoss: 0.025809\n",
            "Train Epoch: 74 [13440/14860 (90%)]\tLoss: 0.021806\n",
            "Train Epoch: 74 [13568/14860 (91%)]\tLoss: 0.020129\n",
            "Train Epoch: 74 [13696/14860 (91%)]\tLoss: 0.023193\n",
            "Train Epoch: 74 [13824/14860 (92%)]\tLoss: 0.014513\n",
            "Train Epoch: 74 [13952/14860 (93%)]\tLoss: 0.020722\n",
            "Train Epoch: 74 [14080/14860 (94%)]\tLoss: 0.018731\n",
            "Train Epoch: 74 [14208/14860 (95%)]\tLoss: 0.027249\n",
            "Train Epoch: 74 [14336/14860 (96%)]\tLoss: 0.022925\n",
            "Train Epoch: 74 [14464/14860 (97%)]\tLoss: 0.024609\n",
            "Train Epoch: 74 [14592/14860 (97%)]\tLoss: 0.020698\n",
            "Train Epoch: 74 [14720/14860 (98%)]\tLoss: 0.017831\n",
            "Train Epoch: 74 [1392/14860 (99%)]\tLoss: 0.011494\n",
            "epoch 74 training loss: 0.021647547403525595\n",
            "epoch 74 validation loss: 0.02926973367141465\n",
            "Train Epoch: 75 [0/14860 (0%)]\tLoss: 0.031514\n",
            "Train Epoch: 75 [128/14860 (1%)]\tLoss: 0.018233\n",
            "Train Epoch: 75 [256/14860 (2%)]\tLoss: 0.028882\n",
            "Train Epoch: 75 [384/14860 (3%)]\tLoss: 0.013066\n",
            "Train Epoch: 75 [512/14860 (3%)]\tLoss: 0.026406\n",
            "Train Epoch: 75 [640/14860 (4%)]\tLoss: 0.023267\n",
            "Train Epoch: 75 [768/14860 (5%)]\tLoss: 0.026432\n",
            "Train Epoch: 75 [896/14860 (6%)]\tLoss: 0.022156\n",
            "Train Epoch: 75 [1024/14860 (7%)]\tLoss: 0.020883\n",
            "Train Epoch: 75 [1152/14860 (8%)]\tLoss: 0.024179\n",
            "Train Epoch: 75 [1280/14860 (9%)]\tLoss: 0.019158\n",
            "Train Epoch: 75 [1408/14860 (9%)]\tLoss: 0.027140\n",
            "Train Epoch: 75 [1536/14860 (10%)]\tLoss: 0.017362\n",
            "Train Epoch: 75 [1664/14860 (11%)]\tLoss: 0.021732\n",
            "Train Epoch: 75 [1792/14860 (12%)]\tLoss: 0.022104\n",
            "Train Epoch: 75 [1920/14860 (13%)]\tLoss: 0.025998\n",
            "Train Epoch: 75 [2048/14860 (14%)]\tLoss: 0.015399\n",
            "Train Epoch: 75 [2176/14860 (15%)]\tLoss: 0.015671\n",
            "Train Epoch: 75 [2304/14860 (15%)]\tLoss: 0.023905\n",
            "Train Epoch: 75 [2432/14860 (16%)]\tLoss: 0.014306\n",
            "Train Epoch: 75 [2560/14860 (17%)]\tLoss: 0.023311\n",
            "Train Epoch: 75 [2688/14860 (18%)]\tLoss: 0.016362\n",
            "Train Epoch: 75 [2816/14860 (19%)]\tLoss: 0.016974\n",
            "Train Epoch: 75 [2944/14860 (20%)]\tLoss: 0.024633\n",
            "Train Epoch: 75 [3072/14860 (21%)]\tLoss: 0.015309\n",
            "Train Epoch: 75 [3200/14860 (21%)]\tLoss: 0.013447\n",
            "Train Epoch: 75 [3328/14860 (22%)]\tLoss: 0.013242\n",
            "Train Epoch: 75 [3456/14860 (23%)]\tLoss: 0.015763\n",
            "Train Epoch: 75 [3584/14860 (24%)]\tLoss: 0.020387\n",
            "Train Epoch: 75 [3712/14860 (25%)]\tLoss: 0.022799\n",
            "Train Epoch: 75 [3840/14860 (26%)]\tLoss: 0.019636\n",
            "Train Epoch: 75 [3968/14860 (26%)]\tLoss: 0.014161\n",
            "Train Epoch: 75 [4096/14860 (27%)]\tLoss: 0.020232\n",
            "Train Epoch: 75 [4224/14860 (28%)]\tLoss: 0.014521\n",
            "Train Epoch: 75 [4352/14860 (29%)]\tLoss: 0.014925\n",
            "Train Epoch: 75 [4480/14860 (30%)]\tLoss: 0.015380\n",
            "Train Epoch: 75 [4608/14860 (31%)]\tLoss: 0.025370\n",
            "Train Epoch: 75 [4736/14860 (32%)]\tLoss: 0.029281\n",
            "Train Epoch: 75 [4864/14860 (32%)]\tLoss: 0.015154\n",
            "Train Epoch: 75 [4992/14860 (33%)]\tLoss: 0.029623\n",
            "Train Epoch: 75 [5120/14860 (34%)]\tLoss: 0.033082\n",
            "Train Epoch: 75 [5248/14860 (35%)]\tLoss: 0.014833\n",
            "Train Epoch: 75 [5376/14860 (36%)]\tLoss: 0.026582\n",
            "Train Epoch: 75 [5504/14860 (37%)]\tLoss: 0.017306\n",
            "Train Epoch: 75 [5632/14860 (38%)]\tLoss: 0.019931\n",
            "Train Epoch: 75 [5760/14860 (38%)]\tLoss: 0.016528\n",
            "Train Epoch: 75 [5888/14860 (39%)]\tLoss: 0.015527\n",
            "Train Epoch: 75 [6016/14860 (40%)]\tLoss: 0.029573\n",
            "Train Epoch: 75 [6144/14860 (41%)]\tLoss: 0.029901\n",
            "Train Epoch: 75 [6272/14860 (42%)]\tLoss: 0.032252\n",
            "Train Epoch: 75 [6400/14860 (43%)]\tLoss: 0.021976\n",
            "Train Epoch: 75 [6528/14860 (44%)]\tLoss: 0.027188\n",
            "Train Epoch: 75 [6656/14860 (44%)]\tLoss: 0.015483\n",
            "Train Epoch: 75 [6784/14860 (45%)]\tLoss: 0.020744\n",
            "Train Epoch: 75 [6912/14860 (46%)]\tLoss: 0.025570\n",
            "Train Epoch: 75 [7040/14860 (47%)]\tLoss: 0.015725\n",
            "Train Epoch: 75 [7168/14860 (48%)]\tLoss: 0.022934\n",
            "Train Epoch: 75 [7296/14860 (49%)]\tLoss: 0.019590\n",
            "Train Epoch: 75 [7424/14860 (50%)]\tLoss: 0.029505\n",
            "Train Epoch: 75 [7552/14860 (50%)]\tLoss: 0.017890\n",
            "Train Epoch: 75 [7680/14860 (51%)]\tLoss: 0.030024\n",
            "Train Epoch: 75 [7808/14860 (52%)]\tLoss: 0.023807\n",
            "Train Epoch: 75 [7936/14860 (53%)]\tLoss: 0.035682\n",
            "Train Epoch: 75 [8064/14860 (54%)]\tLoss: 0.023077\n",
            "Train Epoch: 75 [8192/14860 (55%)]\tLoss: 0.026575\n",
            "Train Epoch: 75 [8320/14860 (56%)]\tLoss: 0.020969\n",
            "Train Epoch: 75 [8448/14860 (56%)]\tLoss: 0.019308\n",
            "Train Epoch: 75 [8576/14860 (57%)]\tLoss: 0.022460\n",
            "Train Epoch: 75 [8704/14860 (58%)]\tLoss: 0.016245\n",
            "Train Epoch: 75 [8832/14860 (59%)]\tLoss: 0.020723\n",
            "Train Epoch: 75 [8960/14860 (60%)]\tLoss: 0.017136\n",
            "Train Epoch: 75 [9088/14860 (61%)]\tLoss: 0.030188\n",
            "Train Epoch: 75 [9216/14860 (62%)]\tLoss: 0.017445\n",
            "Train Epoch: 75 [9344/14860 (62%)]\tLoss: 0.014020\n",
            "Train Epoch: 75 [9472/14860 (63%)]\tLoss: 0.019515\n",
            "Train Epoch: 75 [9600/14860 (64%)]\tLoss: 0.018379\n",
            "Train Epoch: 75 [9728/14860 (65%)]\tLoss: 0.015484\n",
            "Train Epoch: 75 [9856/14860 (66%)]\tLoss: 0.016080\n",
            "Train Epoch: 75 [9984/14860 (67%)]\tLoss: 0.013408\n",
            "Train Epoch: 75 [10112/14860 (68%)]\tLoss: 0.019396\n",
            "Train Epoch: 75 [10240/14860 (68%)]\tLoss: 0.020124\n",
            "Train Epoch: 75 [10368/14860 (69%)]\tLoss: 0.025101\n",
            "Train Epoch: 75 [10496/14860 (70%)]\tLoss: 0.017820\n",
            "Train Epoch: 75 [10624/14860 (71%)]\tLoss: 0.018795\n",
            "Train Epoch: 75 [10752/14860 (72%)]\tLoss: 0.017155\n",
            "Train Epoch: 75 [10880/14860 (73%)]\tLoss: 0.018966\n",
            "Train Epoch: 75 [11008/14860 (74%)]\tLoss: 0.019681\n",
            "Train Epoch: 75 [11136/14860 (74%)]\tLoss: 0.025368\n",
            "Train Epoch: 75 [11264/14860 (75%)]\tLoss: 0.019840\n",
            "Train Epoch: 75 [11392/14860 (76%)]\tLoss: 0.024714\n",
            "Train Epoch: 75 [11520/14860 (77%)]\tLoss: 0.020791\n",
            "Train Epoch: 75 [11648/14860 (78%)]\tLoss: 0.031053\n",
            "Train Epoch: 75 [11776/14860 (79%)]\tLoss: 0.023022\n",
            "Train Epoch: 75 [11904/14860 (79%)]\tLoss: 0.017464\n",
            "Train Epoch: 75 [12032/14860 (80%)]\tLoss: 0.014939\n",
            "Train Epoch: 75 [12160/14860 (81%)]\tLoss: 0.036543\n",
            "Train Epoch: 75 [12288/14860 (82%)]\tLoss: 0.017101\n",
            "Train Epoch: 75 [12416/14860 (83%)]\tLoss: 0.028065\n",
            "Train Epoch: 75 [12544/14860 (84%)]\tLoss: 0.019435\n",
            "Train Epoch: 75 [12672/14860 (85%)]\tLoss: 0.021526\n",
            "Train Epoch: 75 [12800/14860 (85%)]\tLoss: 0.016613\n",
            "Train Epoch: 75 [12928/14860 (86%)]\tLoss: 0.017045\n",
            "Train Epoch: 75 [13056/14860 (87%)]\tLoss: 0.026593\n",
            "Train Epoch: 75 [13184/14860 (88%)]\tLoss: 0.024837\n",
            "Train Epoch: 75 [13312/14860 (89%)]\tLoss: 0.020012\n",
            "Train Epoch: 75 [13440/14860 (90%)]\tLoss: 0.015271\n",
            "Train Epoch: 75 [13568/14860 (91%)]\tLoss: 0.020319\n",
            "Train Epoch: 75 [13696/14860 (91%)]\tLoss: 0.016331\n",
            "Train Epoch: 75 [13824/14860 (92%)]\tLoss: 0.023264\n",
            "Train Epoch: 75 [13952/14860 (93%)]\tLoss: 0.018376\n",
            "Train Epoch: 75 [14080/14860 (94%)]\tLoss: 0.014434\n",
            "Train Epoch: 75 [14208/14860 (95%)]\tLoss: 0.020876\n",
            "Train Epoch: 75 [14336/14860 (96%)]\tLoss: 0.028207\n",
            "Train Epoch: 75 [14464/14860 (97%)]\tLoss: 0.020755\n",
            "Train Epoch: 75 [14592/14860 (97%)]\tLoss: 0.029443\n",
            "Train Epoch: 75 [14720/14860 (98%)]\tLoss: 0.016988\n",
            "Train Epoch: 75 [1392/14860 (99%)]\tLoss: 0.026957\n",
            "epoch 75 training loss: 0.021232210593218476\n",
            "epoch 75 validation loss: 0.027618436923038583\n",
            "Train Epoch: 76 [0/14860 (0%)]\tLoss: 0.018498\n",
            "Train Epoch: 76 [128/14860 (1%)]\tLoss: 0.029256\n",
            "Train Epoch: 76 [256/14860 (2%)]\tLoss: 0.027104\n",
            "Train Epoch: 76 [384/14860 (3%)]\tLoss: 0.026560\n",
            "Train Epoch: 76 [512/14860 (3%)]\tLoss: 0.014192\n",
            "Train Epoch: 76 [640/14860 (4%)]\tLoss: 0.033305\n",
            "Train Epoch: 76 [768/14860 (5%)]\tLoss: 0.015182\n",
            "Train Epoch: 76 [896/14860 (6%)]\tLoss: 0.031140\n",
            "Train Epoch: 76 [1024/14860 (7%)]\tLoss: 0.016015\n",
            "Train Epoch: 76 [1152/14860 (8%)]\tLoss: 0.027351\n",
            "Train Epoch: 76 [1280/14860 (9%)]\tLoss: 0.021658\n",
            "Train Epoch: 76 [1408/14860 (9%)]\tLoss: 0.019881\n",
            "Train Epoch: 76 [1536/14860 (10%)]\tLoss: 0.030753\n",
            "Train Epoch: 76 [1664/14860 (11%)]\tLoss: 0.023603\n",
            "Train Epoch: 76 [1792/14860 (12%)]\tLoss: 0.027254\n",
            "Train Epoch: 76 [1920/14860 (13%)]\tLoss: 0.020337\n",
            "Train Epoch: 76 [2048/14860 (14%)]\tLoss: 0.023663\n",
            "Train Epoch: 76 [2176/14860 (15%)]\tLoss: 0.022355\n",
            "Train Epoch: 76 [2304/14860 (15%)]\tLoss: 0.023124\n",
            "Train Epoch: 76 [2432/14860 (16%)]\tLoss: 0.021976\n",
            "Train Epoch: 76 [2560/14860 (17%)]\tLoss: 0.022530\n",
            "Train Epoch: 76 [2688/14860 (18%)]\tLoss: 0.026557\n",
            "Train Epoch: 76 [2816/14860 (19%)]\tLoss: 0.016346\n",
            "Train Epoch: 76 [2944/14860 (20%)]\tLoss: 0.024509\n",
            "Train Epoch: 76 [3072/14860 (21%)]\tLoss: 0.019283\n",
            "Train Epoch: 76 [3200/14860 (21%)]\tLoss: 0.024327\n",
            "Train Epoch: 76 [3328/14860 (22%)]\tLoss: 0.020633\n",
            "Train Epoch: 76 [3456/14860 (23%)]\tLoss: 0.021323\n",
            "Train Epoch: 76 [3584/14860 (24%)]\tLoss: 0.025777\n",
            "Train Epoch: 76 [3712/14860 (25%)]\tLoss: 0.033711\n",
            "Train Epoch: 76 [3840/14860 (26%)]\tLoss: 0.020451\n",
            "Train Epoch: 76 [3968/14860 (26%)]\tLoss: 0.018230\n",
            "Train Epoch: 76 [4096/14860 (27%)]\tLoss: 0.016200\n",
            "Train Epoch: 76 [4224/14860 (28%)]\tLoss: 0.026155\n",
            "Train Epoch: 76 [4352/14860 (29%)]\tLoss: 0.023022\n",
            "Train Epoch: 76 [4480/14860 (30%)]\tLoss: 0.019754\n",
            "Train Epoch: 76 [4608/14860 (31%)]\tLoss: 0.021810\n",
            "Train Epoch: 76 [4736/14860 (32%)]\tLoss: 0.023857\n",
            "Train Epoch: 76 [4864/14860 (32%)]\tLoss: 0.024442\n",
            "Train Epoch: 76 [4992/14860 (33%)]\tLoss: 0.021523\n",
            "Train Epoch: 76 [5120/14860 (34%)]\tLoss: 0.026505\n",
            "Train Epoch: 76 [5248/14860 (35%)]\tLoss: 0.021700\n",
            "Train Epoch: 76 [5376/14860 (36%)]\tLoss: 0.020198\n",
            "Train Epoch: 76 [5504/14860 (37%)]\tLoss: 0.020174\n",
            "Train Epoch: 76 [5632/14860 (38%)]\tLoss: 0.019604\n",
            "Train Epoch: 76 [5760/14860 (38%)]\tLoss: 0.024057\n",
            "Train Epoch: 76 [5888/14860 (39%)]\tLoss: 0.022158\n",
            "Train Epoch: 76 [6016/14860 (40%)]\tLoss: 0.016036\n",
            "Train Epoch: 76 [6144/14860 (41%)]\tLoss: 0.029399\n",
            "Train Epoch: 76 [6272/14860 (42%)]\tLoss: 0.022892\n",
            "Train Epoch: 76 [6400/14860 (43%)]\tLoss: 0.024701\n",
            "Train Epoch: 76 [6528/14860 (44%)]\tLoss: 0.020242\n",
            "Train Epoch: 76 [6656/14860 (44%)]\tLoss: 0.035732\n",
            "Train Epoch: 76 [6784/14860 (45%)]\tLoss: 0.032350\n",
            "Train Epoch: 76 [6912/14860 (46%)]\tLoss: 0.031743\n",
            "Train Epoch: 76 [7040/14860 (47%)]\tLoss: 0.016711\n",
            "Train Epoch: 76 [7168/14860 (48%)]\tLoss: 0.041102\n",
            "Train Epoch: 76 [7296/14860 (49%)]\tLoss: 0.018142\n",
            "Train Epoch: 76 [7424/14860 (50%)]\tLoss: 0.031908\n",
            "Train Epoch: 76 [7552/14860 (50%)]\tLoss: 0.020409\n",
            "Train Epoch: 76 [7680/14860 (51%)]\tLoss: 0.025434\n",
            "Train Epoch: 76 [7808/14860 (52%)]\tLoss: 0.016239\n",
            "Train Epoch: 76 [7936/14860 (53%)]\tLoss: 0.019395\n",
            "Train Epoch: 76 [8064/14860 (54%)]\tLoss: 0.027002\n",
            "Train Epoch: 76 [8192/14860 (55%)]\tLoss: 0.026287\n",
            "Train Epoch: 76 [8320/14860 (56%)]\tLoss: 0.017514\n",
            "Train Epoch: 76 [8448/14860 (56%)]\tLoss: 0.023059\n",
            "Train Epoch: 76 [8576/14860 (57%)]\tLoss: 0.032727\n",
            "Train Epoch: 76 [8704/14860 (58%)]\tLoss: 0.017830\n",
            "Train Epoch: 76 [8832/14860 (59%)]\tLoss: 0.032504\n",
            "Train Epoch: 76 [8960/14860 (60%)]\tLoss: 0.028621\n",
            "Train Epoch: 76 [9088/14860 (61%)]\tLoss: 0.026236\n",
            "Train Epoch: 76 [9216/14860 (62%)]\tLoss: 0.029604\n",
            "Train Epoch: 76 [9344/14860 (62%)]\tLoss: 0.026266\n",
            "Train Epoch: 76 [9472/14860 (63%)]\tLoss: 0.027726\n",
            "Train Epoch: 76 [9600/14860 (64%)]\tLoss: 0.016834\n",
            "Train Epoch: 76 [9728/14860 (65%)]\tLoss: 0.021076\n",
            "Train Epoch: 76 [9856/14860 (66%)]\tLoss: 0.019377\n",
            "Train Epoch: 76 [9984/14860 (67%)]\tLoss: 0.020136\n",
            "Train Epoch: 76 [10112/14860 (68%)]\tLoss: 0.014941\n",
            "Train Epoch: 76 [10240/14860 (68%)]\tLoss: 0.017709\n",
            "Train Epoch: 76 [10368/14860 (69%)]\tLoss: 0.014295\n",
            "Train Epoch: 76 [10496/14860 (70%)]\tLoss: 0.023599\n",
            "Train Epoch: 76 [10624/14860 (71%)]\tLoss: 0.018825\n",
            "Train Epoch: 76 [10752/14860 (72%)]\tLoss: 0.020361\n",
            "Train Epoch: 76 [10880/14860 (73%)]\tLoss: 0.022399\n",
            "Train Epoch: 76 [11008/14860 (74%)]\tLoss: 0.019960\n",
            "Train Epoch: 76 [11136/14860 (74%)]\tLoss: 0.018129\n",
            "Train Epoch: 76 [11264/14860 (75%)]\tLoss: 0.017243\n",
            "Train Epoch: 76 [11392/14860 (76%)]\tLoss: 0.021333\n",
            "Train Epoch: 76 [11520/14860 (77%)]\tLoss: 0.017400\n",
            "Train Epoch: 76 [11648/14860 (78%)]\tLoss: 0.026299\n",
            "Train Epoch: 76 [11776/14860 (79%)]\tLoss: 0.015711\n",
            "Train Epoch: 76 [11904/14860 (79%)]\tLoss: 0.019501\n",
            "Train Epoch: 76 [12032/14860 (80%)]\tLoss: 0.028377\n",
            "Train Epoch: 76 [12160/14860 (81%)]\tLoss: 0.037726\n",
            "Train Epoch: 76 [12288/14860 (82%)]\tLoss: 0.014908\n",
            "Train Epoch: 76 [12416/14860 (83%)]\tLoss: 0.034169\n",
            "Train Epoch: 76 [12544/14860 (84%)]\tLoss: 0.026951\n",
            "Train Epoch: 76 [12672/14860 (85%)]\tLoss: 0.036741\n",
            "Train Epoch: 76 [12800/14860 (85%)]\tLoss: 0.014335\n",
            "Train Epoch: 76 [12928/14860 (86%)]\tLoss: 0.052632\n",
            "Train Epoch: 76 [13056/14860 (87%)]\tLoss: 0.017372\n",
            "Train Epoch: 76 [13184/14860 (88%)]\tLoss: 0.036152\n",
            "Train Epoch: 76 [13312/14860 (89%)]\tLoss: 0.026524\n",
            "Train Epoch: 76 [13440/14860 (90%)]\tLoss: 0.032981\n",
            "Train Epoch: 76 [13568/14860 (91%)]\tLoss: 0.034258\n",
            "Train Epoch: 76 [13696/14860 (91%)]\tLoss: 0.018453\n",
            "Train Epoch: 76 [13824/14860 (92%)]\tLoss: 0.032572\n",
            "Train Epoch: 76 [13952/14860 (93%)]\tLoss: 0.021761\n",
            "Train Epoch: 76 [14080/14860 (94%)]\tLoss: 0.023289\n",
            "Train Epoch: 76 [14208/14860 (95%)]\tLoss: 0.025603\n",
            "Train Epoch: 76 [14336/14860 (96%)]\tLoss: 0.021562\n",
            "Train Epoch: 76 [14464/14860 (97%)]\tLoss: 0.028382\n",
            "Train Epoch: 76 [14592/14860 (97%)]\tLoss: 0.013713\n",
            "Train Epoch: 76 [14720/14860 (98%)]\tLoss: 0.030137\n",
            "Train Epoch: 76 [1392/14860 (99%)]\tLoss: 0.013827\n",
            "epoch 76 training loss: 0.023789781145751476\n",
            "epoch 76 validation loss: 0.026000891845970986\n",
            "Train Epoch: 77 [0/14860 (0%)]\tLoss: 0.031936\n",
            "Train Epoch: 77 [128/14860 (1%)]\tLoss: 0.021141\n",
            "Train Epoch: 77 [256/14860 (2%)]\tLoss: 0.016996\n",
            "Train Epoch: 77 [384/14860 (3%)]\tLoss: 0.019872\n",
            "Train Epoch: 77 [512/14860 (3%)]\tLoss: 0.012815\n",
            "Train Epoch: 77 [640/14860 (4%)]\tLoss: 0.022422\n",
            "Train Epoch: 77 [768/14860 (5%)]\tLoss: 0.020525\n",
            "Train Epoch: 77 [896/14860 (6%)]\tLoss: 0.025878\n",
            "Train Epoch: 77 [1024/14860 (7%)]\tLoss: 0.021815\n",
            "Train Epoch: 77 [1152/14860 (8%)]\tLoss: 0.014844\n",
            "Train Epoch: 77 [1280/14860 (9%)]\tLoss: 0.014536\n",
            "Train Epoch: 77 [1408/14860 (9%)]\tLoss: 0.014914\n",
            "Train Epoch: 77 [1536/14860 (10%)]\tLoss: 0.016526\n",
            "Train Epoch: 77 [1664/14860 (11%)]\tLoss: 0.035004\n",
            "Train Epoch: 77 [1792/14860 (12%)]\tLoss: 0.021971\n",
            "Train Epoch: 77 [1920/14860 (13%)]\tLoss: 0.028288\n",
            "Train Epoch: 77 [2048/14860 (14%)]\tLoss: 0.025254\n",
            "Train Epoch: 77 [2176/14860 (15%)]\tLoss: 0.034665\n",
            "Train Epoch: 77 [2304/14860 (15%)]\tLoss: 0.018169\n",
            "Train Epoch: 77 [2432/14860 (16%)]\tLoss: 0.028795\n",
            "Train Epoch: 77 [2560/14860 (17%)]\tLoss: 0.021488\n",
            "Train Epoch: 77 [2688/14860 (18%)]\tLoss: 0.032654\n",
            "Train Epoch: 77 [2816/14860 (19%)]\tLoss: 0.015061\n",
            "Train Epoch: 77 [2944/14860 (20%)]\tLoss: 0.021304\n",
            "Train Epoch: 77 [3072/14860 (21%)]\tLoss: 0.017261\n",
            "Train Epoch: 77 [3200/14860 (21%)]\tLoss: 0.024935\n",
            "Train Epoch: 77 [3328/14860 (22%)]\tLoss: 0.019517\n",
            "Train Epoch: 77 [3456/14860 (23%)]\tLoss: 0.027687\n",
            "Train Epoch: 77 [3584/14860 (24%)]\tLoss: 0.021206\n",
            "Train Epoch: 77 [3712/14860 (25%)]\tLoss: 0.016698\n",
            "Train Epoch: 77 [3840/14860 (26%)]\tLoss: 0.020140\n",
            "Train Epoch: 77 [3968/14860 (26%)]\tLoss: 0.025569\n",
            "Train Epoch: 77 [4096/14860 (27%)]\tLoss: 0.025780\n",
            "Train Epoch: 77 [4224/14860 (28%)]\tLoss: 0.029037\n",
            "Train Epoch: 77 [4352/14860 (29%)]\tLoss: 0.029015\n",
            "Train Epoch: 77 [4480/14860 (30%)]\tLoss: 0.018739\n",
            "Train Epoch: 77 [4608/14860 (31%)]\tLoss: 0.018108\n",
            "Train Epoch: 77 [4736/14860 (32%)]\tLoss: 0.019283\n",
            "Train Epoch: 77 [4864/14860 (32%)]\tLoss: 0.036857\n",
            "Train Epoch: 77 [4992/14860 (33%)]\tLoss: 0.029133\n",
            "Train Epoch: 77 [5120/14860 (34%)]\tLoss: 0.022034\n",
            "Train Epoch: 77 [5248/14860 (35%)]\tLoss: 0.023150\n",
            "Train Epoch: 77 [5376/14860 (36%)]\tLoss: 0.025278\n",
            "Train Epoch: 77 [5504/14860 (37%)]\tLoss: 0.016800\n",
            "Train Epoch: 77 [5632/14860 (38%)]\tLoss: 0.031652\n",
            "Train Epoch: 77 [5760/14860 (38%)]\tLoss: 0.023156\n",
            "Train Epoch: 77 [5888/14860 (39%)]\tLoss: 0.014314\n",
            "Train Epoch: 77 [6016/14860 (40%)]\tLoss: 0.028891\n",
            "Train Epoch: 77 [6144/14860 (41%)]\tLoss: 0.015798\n",
            "Train Epoch: 77 [6272/14860 (42%)]\tLoss: 0.020357\n",
            "Train Epoch: 77 [6400/14860 (43%)]\tLoss: 0.017141\n",
            "Train Epoch: 77 [6528/14860 (44%)]\tLoss: 0.021409\n",
            "Train Epoch: 77 [6656/14860 (44%)]\tLoss: 0.017817\n",
            "Train Epoch: 77 [6784/14860 (45%)]\tLoss: 0.023517\n",
            "Train Epoch: 77 [6912/14860 (46%)]\tLoss: 0.031059\n",
            "Train Epoch: 77 [7040/14860 (47%)]\tLoss: 0.018328\n",
            "Train Epoch: 77 [7168/14860 (48%)]\tLoss: 0.023773\n",
            "Train Epoch: 77 [7296/14860 (49%)]\tLoss: 0.021419\n",
            "Train Epoch: 77 [7424/14860 (50%)]\tLoss: 0.028870\n",
            "Train Epoch: 77 [7552/14860 (50%)]\tLoss: 0.015262\n",
            "Train Epoch: 77 [7680/14860 (51%)]\tLoss: 0.032370\n",
            "Train Epoch: 77 [7808/14860 (52%)]\tLoss: 0.016701\n",
            "Train Epoch: 77 [7936/14860 (53%)]\tLoss: 0.021415\n",
            "Train Epoch: 77 [8064/14860 (54%)]\tLoss: 0.020562\n",
            "Train Epoch: 77 [8192/14860 (55%)]\tLoss: 0.020682\n",
            "Train Epoch: 77 [8320/14860 (56%)]\tLoss: 0.026886\n",
            "Train Epoch: 77 [8448/14860 (56%)]\tLoss: 0.024426\n",
            "Train Epoch: 77 [8576/14860 (57%)]\tLoss: 0.022688\n",
            "Train Epoch: 77 [8704/14860 (58%)]\tLoss: 0.020156\n",
            "Train Epoch: 77 [8832/14860 (59%)]\tLoss: 0.025559\n",
            "Train Epoch: 77 [8960/14860 (60%)]\tLoss: 0.020565\n",
            "Train Epoch: 77 [9088/14860 (61%)]\tLoss: 0.018295\n",
            "Train Epoch: 77 [9216/14860 (62%)]\tLoss: 0.016777\n",
            "Train Epoch: 77 [9344/14860 (62%)]\tLoss: 0.015190\n",
            "Train Epoch: 77 [9472/14860 (63%)]\tLoss: 0.017132\n",
            "Train Epoch: 77 [9600/14860 (64%)]\tLoss: 0.020276\n",
            "Train Epoch: 77 [9728/14860 (65%)]\tLoss: 0.017100\n",
            "Train Epoch: 77 [9856/14860 (66%)]\tLoss: 0.028199\n",
            "Train Epoch: 77 [9984/14860 (67%)]\tLoss: 0.018499\n",
            "Train Epoch: 77 [10112/14860 (68%)]\tLoss: 0.023455\n",
            "Train Epoch: 77 [10240/14860 (68%)]\tLoss: 0.020926\n",
            "Train Epoch: 77 [10368/14860 (69%)]\tLoss: 0.024317\n",
            "Train Epoch: 77 [10496/14860 (70%)]\tLoss: 0.018750\n",
            "Train Epoch: 77 [10624/14860 (71%)]\tLoss: 0.021876\n",
            "Train Epoch: 77 [10752/14860 (72%)]\tLoss: 0.030837\n",
            "Train Epoch: 77 [10880/14860 (73%)]\tLoss: 0.014474\n",
            "Train Epoch: 77 [11008/14860 (74%)]\tLoss: 0.024752\n",
            "Train Epoch: 77 [11136/14860 (74%)]\tLoss: 0.017228\n",
            "Train Epoch: 77 [11264/14860 (75%)]\tLoss: 0.029696\n",
            "Train Epoch: 77 [11392/14860 (76%)]\tLoss: 0.022079\n",
            "Train Epoch: 77 [11520/14860 (77%)]\tLoss: 0.021339\n",
            "Train Epoch: 77 [11648/14860 (78%)]\tLoss: 0.019089\n",
            "Train Epoch: 77 [11776/14860 (79%)]\tLoss: 0.016105\n",
            "Train Epoch: 77 [11904/14860 (79%)]\tLoss: 0.021234\n",
            "Train Epoch: 77 [12032/14860 (80%)]\tLoss: 0.020159\n",
            "Train Epoch: 77 [12160/14860 (81%)]\tLoss: 0.009381\n",
            "Train Epoch: 77 [12288/14860 (82%)]\tLoss: 0.019576\n",
            "Train Epoch: 77 [12416/14860 (83%)]\tLoss: 0.016212\n",
            "Train Epoch: 77 [12544/14860 (84%)]\tLoss: 0.019228\n",
            "Train Epoch: 77 [12672/14860 (85%)]\tLoss: 0.015198\n",
            "Train Epoch: 77 [12800/14860 (85%)]\tLoss: 0.019737\n",
            "Train Epoch: 77 [12928/14860 (86%)]\tLoss: 0.019476\n",
            "Train Epoch: 77 [13056/14860 (87%)]\tLoss: 0.015715\n",
            "Train Epoch: 77 [13184/14860 (88%)]\tLoss: 0.019827\n",
            "Train Epoch: 77 [13312/14860 (89%)]\tLoss: 0.024765\n",
            "Train Epoch: 77 [13440/14860 (90%)]\tLoss: 0.017405\n",
            "Train Epoch: 77 [13568/14860 (91%)]\tLoss: 0.018314\n",
            "Train Epoch: 77 [13696/14860 (91%)]\tLoss: 0.019210\n",
            "Train Epoch: 77 [13824/14860 (92%)]\tLoss: 0.020399\n",
            "Train Epoch: 77 [13952/14860 (93%)]\tLoss: 0.021585\n",
            "Train Epoch: 77 [14080/14860 (94%)]\tLoss: 0.023318\n",
            "Train Epoch: 77 [14208/14860 (95%)]\tLoss: 0.019833\n",
            "Train Epoch: 77 [14336/14860 (96%)]\tLoss: 0.019985\n",
            "Train Epoch: 77 [14464/14860 (97%)]\tLoss: 0.030039\n",
            "Train Epoch: 77 [14592/14860 (97%)]\tLoss: 0.026711\n",
            "Train Epoch: 77 [14720/14860 (98%)]\tLoss: 0.032359\n",
            "Train Epoch: 77 [1392/14860 (99%)]\tLoss: 0.003879\n",
            "epoch 77 training loss: 0.021690668679503165\n",
            "epoch 77 validation loss: 0.020673321032350922\n",
            "Train Epoch: 78 [0/14860 (0%)]\tLoss: 0.023718\n",
            "Train Epoch: 78 [128/14860 (1%)]\tLoss: 0.018566\n",
            "Train Epoch: 78 [256/14860 (2%)]\tLoss: 0.034371\n",
            "Train Epoch: 78 [384/14860 (3%)]\tLoss: 0.017693\n",
            "Train Epoch: 78 [512/14860 (3%)]\tLoss: 0.030641\n",
            "Train Epoch: 78 [640/14860 (4%)]\tLoss: 0.024498\n",
            "Train Epoch: 78 [768/14860 (5%)]\tLoss: 0.023436\n",
            "Train Epoch: 78 [896/14860 (6%)]\tLoss: 0.023273\n",
            "Train Epoch: 78 [1024/14860 (7%)]\tLoss: 0.018683\n",
            "Train Epoch: 78 [1152/14860 (8%)]\tLoss: 0.021234\n",
            "Train Epoch: 78 [1280/14860 (9%)]\tLoss: 0.020194\n",
            "Train Epoch: 78 [1408/14860 (9%)]\tLoss: 0.024601\n",
            "Train Epoch: 78 [1536/14860 (10%)]\tLoss: 0.012938\n",
            "Train Epoch: 78 [1664/14860 (11%)]\tLoss: 0.017636\n",
            "Train Epoch: 78 [1792/14860 (12%)]\tLoss: 0.020062\n",
            "Train Epoch: 78 [1920/14860 (13%)]\tLoss: 0.019340\n",
            "Train Epoch: 78 [2048/14860 (14%)]\tLoss: 0.021515\n",
            "Train Epoch: 78 [2176/14860 (15%)]\tLoss: 0.017287\n",
            "Train Epoch: 78 [2304/14860 (15%)]\tLoss: 0.021991\n",
            "Train Epoch: 78 [2432/14860 (16%)]\tLoss: 0.032003\n",
            "Train Epoch: 78 [2560/14860 (17%)]\tLoss: 0.026135\n",
            "Train Epoch: 78 [2688/14860 (18%)]\tLoss: 0.027973\n",
            "Train Epoch: 78 [2816/14860 (19%)]\tLoss: 0.026731\n",
            "Train Epoch: 78 [2944/14860 (20%)]\tLoss: 0.023815\n",
            "Train Epoch: 78 [3072/14860 (21%)]\tLoss: 0.022125\n",
            "Train Epoch: 78 [3200/14860 (21%)]\tLoss: 0.011588\n",
            "Train Epoch: 78 [3328/14860 (22%)]\tLoss: 0.018008\n",
            "Train Epoch: 78 [3456/14860 (23%)]\tLoss: 0.012537\n",
            "Train Epoch: 78 [3584/14860 (24%)]\tLoss: 0.024111\n",
            "Train Epoch: 78 [3712/14860 (25%)]\tLoss: 0.020370\n",
            "Train Epoch: 78 [3840/14860 (26%)]\tLoss: 0.020932\n",
            "Train Epoch: 78 [3968/14860 (26%)]\tLoss: 0.017344\n",
            "Train Epoch: 78 [4096/14860 (27%)]\tLoss: 0.015048\n",
            "Train Epoch: 78 [4224/14860 (28%)]\tLoss: 0.022143\n",
            "Train Epoch: 78 [4352/14860 (29%)]\tLoss: 0.023053\n",
            "Train Epoch: 78 [4480/14860 (30%)]\tLoss: 0.026446\n",
            "Train Epoch: 78 [4608/14860 (31%)]\tLoss: 0.027943\n",
            "Train Epoch: 78 [4736/14860 (32%)]\tLoss: 0.018721\n",
            "Train Epoch: 78 [4864/14860 (32%)]\tLoss: 0.022046\n",
            "Train Epoch: 78 [4992/14860 (33%)]\tLoss: 0.011744\n",
            "Train Epoch: 78 [5120/14860 (34%)]\tLoss: 0.025233\n",
            "Train Epoch: 78 [5248/14860 (35%)]\tLoss: 0.015899\n",
            "Train Epoch: 78 [5376/14860 (36%)]\tLoss: 0.023212\n",
            "Train Epoch: 78 [5504/14860 (37%)]\tLoss: 0.023735\n",
            "Train Epoch: 78 [5632/14860 (38%)]\tLoss: 0.020277\n",
            "Train Epoch: 78 [5760/14860 (38%)]\tLoss: 0.020218\n",
            "Train Epoch: 78 [5888/14860 (39%)]\tLoss: 0.023490\n",
            "Train Epoch: 78 [6016/14860 (40%)]\tLoss: 0.020822\n",
            "Train Epoch: 78 [6144/14860 (41%)]\tLoss: 0.018573\n",
            "Train Epoch: 78 [6272/14860 (42%)]\tLoss: 0.018262\n",
            "Train Epoch: 78 [6400/14860 (43%)]\tLoss: 0.024463\n",
            "Train Epoch: 78 [6528/14860 (44%)]\tLoss: 0.029510\n",
            "Train Epoch: 78 [6656/14860 (44%)]\tLoss: 0.014946\n",
            "Train Epoch: 78 [6784/14860 (45%)]\tLoss: 0.013627\n",
            "Train Epoch: 78 [6912/14860 (46%)]\tLoss: 0.024967\n",
            "Train Epoch: 78 [7040/14860 (47%)]\tLoss: 0.026612\n",
            "Train Epoch: 78 [7168/14860 (48%)]\tLoss: 0.019256\n",
            "Train Epoch: 78 [7296/14860 (49%)]\tLoss: 0.026512\n",
            "Train Epoch: 78 [7424/14860 (50%)]\tLoss: 0.014532\n",
            "Train Epoch: 78 [7552/14860 (50%)]\tLoss: 0.028455\n",
            "Train Epoch: 78 [7680/14860 (51%)]\tLoss: 0.014372\n",
            "Train Epoch: 78 [7808/14860 (52%)]\tLoss: 0.017514\n",
            "Train Epoch: 78 [7936/14860 (53%)]\tLoss: 0.015432\n",
            "Train Epoch: 78 [8064/14860 (54%)]\tLoss: 0.014600\n",
            "Train Epoch: 78 [8192/14860 (55%)]\tLoss: 0.017308\n",
            "Train Epoch: 78 [8320/14860 (56%)]\tLoss: 0.017426\n",
            "Train Epoch: 78 [8448/14860 (56%)]\tLoss: 0.015918\n",
            "Train Epoch: 78 [8576/14860 (57%)]\tLoss: 0.015406\n",
            "Train Epoch: 78 [8704/14860 (58%)]\tLoss: 0.022919\n",
            "Train Epoch: 78 [8832/14860 (59%)]\tLoss: 0.018714\n",
            "Train Epoch: 78 [8960/14860 (60%)]\tLoss: 0.016200\n",
            "Train Epoch: 78 [9088/14860 (61%)]\tLoss: 0.019144\n",
            "Train Epoch: 78 [9216/14860 (62%)]\tLoss: 0.024384\n",
            "Train Epoch: 78 [9344/14860 (62%)]\tLoss: 0.014806\n",
            "Train Epoch: 78 [9472/14860 (63%)]\tLoss: 0.014899\n",
            "Train Epoch: 78 [9600/14860 (64%)]\tLoss: 0.016756\n",
            "Train Epoch: 78 [9728/14860 (65%)]\tLoss: 0.021587\n",
            "Train Epoch: 78 [9856/14860 (66%)]\tLoss: 0.015265\n",
            "Train Epoch: 78 [9984/14860 (67%)]\tLoss: 0.021147\n",
            "Train Epoch: 78 [10112/14860 (68%)]\tLoss: 0.016701\n",
            "Train Epoch: 78 [10240/14860 (68%)]\tLoss: 0.018638\n",
            "Train Epoch: 78 [10368/14860 (69%)]\tLoss: 0.014181\n",
            "Train Epoch: 78 [10496/14860 (70%)]\tLoss: 0.021466\n",
            "Train Epoch: 78 [10624/14860 (71%)]\tLoss: 0.016361\n",
            "Train Epoch: 78 [10752/14860 (72%)]\tLoss: 0.020496\n",
            "Train Epoch: 78 [10880/14860 (73%)]\tLoss: 0.023651\n",
            "Train Epoch: 78 [11008/14860 (74%)]\tLoss: 0.024130\n",
            "Train Epoch: 78 [11136/14860 (74%)]\tLoss: 0.020500\n",
            "Train Epoch: 78 [11264/14860 (75%)]\tLoss: 0.021692\n",
            "Train Epoch: 78 [11392/14860 (76%)]\tLoss: 0.023094\n",
            "Train Epoch: 78 [11520/14860 (77%)]\tLoss: 0.019079\n",
            "Train Epoch: 78 [11648/14860 (78%)]\tLoss: 0.016732\n",
            "Train Epoch: 78 [11776/14860 (79%)]\tLoss: 0.013643\n",
            "Train Epoch: 78 [11904/14860 (79%)]\tLoss: 0.016811\n",
            "Train Epoch: 78 [12032/14860 (80%)]\tLoss: 0.017649\n",
            "Train Epoch: 78 [12160/14860 (81%)]\tLoss: 0.011194\n",
            "Train Epoch: 78 [12288/14860 (82%)]\tLoss: 0.025024\n",
            "Train Epoch: 78 [12416/14860 (83%)]\tLoss: 0.018322\n",
            "Train Epoch: 78 [12544/14860 (84%)]\tLoss: 0.019491\n",
            "Train Epoch: 78 [12672/14860 (85%)]\tLoss: 0.014697\n",
            "Train Epoch: 78 [12800/14860 (85%)]\tLoss: 0.034211\n",
            "Train Epoch: 78 [12928/14860 (86%)]\tLoss: 0.024442\n",
            "Train Epoch: 78 [13056/14860 (87%)]\tLoss: 0.016924\n",
            "Train Epoch: 78 [13184/14860 (88%)]\tLoss: 0.029824\n",
            "Train Epoch: 78 [13312/14860 (89%)]\tLoss: 0.022618\n",
            "Train Epoch: 78 [13440/14860 (90%)]\tLoss: 0.018094\n",
            "Train Epoch: 78 [13568/14860 (91%)]\tLoss: 0.023660\n",
            "Train Epoch: 78 [13696/14860 (91%)]\tLoss: 0.031024\n",
            "Train Epoch: 78 [13824/14860 (92%)]\tLoss: 0.020756\n",
            "Train Epoch: 78 [13952/14860 (93%)]\tLoss: 0.018529\n",
            "Train Epoch: 78 [14080/14860 (94%)]\tLoss: 0.019677\n",
            "Train Epoch: 78 [14208/14860 (95%)]\tLoss: 0.021639\n",
            "Train Epoch: 78 [14336/14860 (96%)]\tLoss: 0.020921\n",
            "Train Epoch: 78 [14464/14860 (97%)]\tLoss: 0.023944\n",
            "Train Epoch: 78 [14592/14860 (97%)]\tLoss: 0.019853\n",
            "Train Epoch: 78 [14720/14860 (98%)]\tLoss: 0.017842\n",
            "Train Epoch: 78 [1392/14860 (99%)]\tLoss: 0.020680\n",
            "epoch 78 training loss: 0.020573350481497936\n",
            "epoch 78 validation loss: 0.03471427419861062\n",
            "Train Epoch: 79 [0/14860 (0%)]\tLoss: 0.029185\n",
            "Train Epoch: 79 [128/14860 (1%)]\tLoss: 0.023216\n",
            "Train Epoch: 79 [256/14860 (2%)]\tLoss: 0.029517\n",
            "Train Epoch: 79 [384/14860 (3%)]\tLoss: 0.015303\n",
            "Train Epoch: 79 [512/14860 (3%)]\tLoss: 0.021737\n",
            "Train Epoch: 79 [640/14860 (4%)]\tLoss: 0.017703\n",
            "Train Epoch: 79 [768/14860 (5%)]\tLoss: 0.025768\n",
            "Train Epoch: 79 [896/14860 (6%)]\tLoss: 0.022662\n",
            "Train Epoch: 79 [1024/14860 (7%)]\tLoss: 0.020692\n",
            "Train Epoch: 79 [1152/14860 (8%)]\tLoss: 0.017594\n",
            "Train Epoch: 79 [1280/14860 (9%)]\tLoss: 0.025963\n",
            "Train Epoch: 79 [1408/14860 (9%)]\tLoss: 0.026120\n",
            "Train Epoch: 79 [1536/14860 (10%)]\tLoss: 0.026517\n",
            "Train Epoch: 79 [1664/14860 (11%)]\tLoss: 0.020156\n",
            "Train Epoch: 79 [1792/14860 (12%)]\tLoss: 0.018179\n",
            "Train Epoch: 79 [1920/14860 (13%)]\tLoss: 0.022349\n",
            "Train Epoch: 79 [2048/14860 (14%)]\tLoss: 0.030381\n",
            "Train Epoch: 79 [2176/14860 (15%)]\tLoss: 0.026086\n",
            "Train Epoch: 79 [2304/14860 (15%)]\tLoss: 0.017274\n",
            "Train Epoch: 79 [2432/14860 (16%)]\tLoss: 0.023467\n",
            "Train Epoch: 79 [2560/14860 (17%)]\tLoss: 0.022956\n",
            "Train Epoch: 79 [2688/14860 (18%)]\tLoss: 0.025435\n",
            "Train Epoch: 79 [2816/14860 (19%)]\tLoss: 0.015555\n",
            "Train Epoch: 79 [2944/14860 (20%)]\tLoss: 0.022485\n",
            "Train Epoch: 79 [3072/14860 (21%)]\tLoss: 0.026507\n",
            "Train Epoch: 79 [3200/14860 (21%)]\tLoss: 0.026062\n",
            "Train Epoch: 79 [3328/14860 (22%)]\tLoss: 0.033992\n",
            "Train Epoch: 79 [3456/14860 (23%)]\tLoss: 0.020150\n",
            "Train Epoch: 79 [3584/14860 (24%)]\tLoss: 0.035576\n",
            "Train Epoch: 79 [3712/14860 (25%)]\tLoss: 0.016054\n",
            "Train Epoch: 79 [3840/14860 (26%)]\tLoss: 0.037614\n",
            "Train Epoch: 79 [3968/14860 (26%)]\tLoss: 0.024105\n",
            "Train Epoch: 79 [4096/14860 (27%)]\tLoss: 0.023872\n",
            "Train Epoch: 79 [4224/14860 (28%)]\tLoss: 0.022987\n",
            "Train Epoch: 79 [4352/14860 (29%)]\tLoss: 0.021938\n",
            "Train Epoch: 79 [4480/14860 (30%)]\tLoss: 0.025385\n",
            "Train Epoch: 79 [4608/14860 (31%)]\tLoss: 0.024710\n",
            "Train Epoch: 79 [4736/14860 (32%)]\tLoss: 0.019196\n",
            "Train Epoch: 79 [4864/14860 (32%)]\tLoss: 0.020106\n",
            "Train Epoch: 79 [4992/14860 (33%)]\tLoss: 0.017546\n",
            "Train Epoch: 79 [5120/14860 (34%)]\tLoss: 0.029793\n",
            "Train Epoch: 79 [5248/14860 (35%)]\tLoss: 0.022552\n",
            "Train Epoch: 79 [5376/14860 (36%)]\tLoss: 0.018211\n",
            "Train Epoch: 79 [5504/14860 (37%)]\tLoss: 0.020048\n",
            "Train Epoch: 79 [5632/14860 (38%)]\tLoss: 0.015589\n",
            "Train Epoch: 79 [5760/14860 (38%)]\tLoss: 0.023900\n",
            "Train Epoch: 79 [5888/14860 (39%)]\tLoss: 0.025946\n",
            "Train Epoch: 79 [6016/14860 (40%)]\tLoss: 0.025266\n",
            "Train Epoch: 79 [6144/14860 (41%)]\tLoss: 0.026903\n",
            "Train Epoch: 79 [6272/14860 (42%)]\tLoss: 0.024347\n",
            "Train Epoch: 79 [6400/14860 (43%)]\tLoss: 0.019680\n",
            "Train Epoch: 79 [6528/14860 (44%)]\tLoss: 0.021035\n",
            "Train Epoch: 79 [6656/14860 (44%)]\tLoss: 0.021293\n",
            "Train Epoch: 79 [6784/14860 (45%)]\tLoss: 0.022477\n",
            "Train Epoch: 79 [6912/14860 (46%)]\tLoss: 0.030706\n",
            "Train Epoch: 79 [7040/14860 (47%)]\tLoss: 0.019105\n",
            "Train Epoch: 79 [7168/14860 (48%)]\tLoss: 0.022636\n",
            "Train Epoch: 79 [7296/14860 (49%)]\tLoss: 0.024440\n",
            "Train Epoch: 79 [7424/14860 (50%)]\tLoss: 0.017501\n",
            "Train Epoch: 79 [7552/14860 (50%)]\tLoss: 0.020853\n",
            "Train Epoch: 79 [7680/14860 (51%)]\tLoss: 0.023244\n",
            "Train Epoch: 79 [7808/14860 (52%)]\tLoss: 0.014078\n",
            "Train Epoch: 79 [7936/14860 (53%)]\tLoss: 0.013575\n",
            "Train Epoch: 79 [8064/14860 (54%)]\tLoss: 0.014653\n",
            "Train Epoch: 79 [8192/14860 (55%)]\tLoss: 0.015704\n",
            "Train Epoch: 79 [8320/14860 (56%)]\tLoss: 0.019754\n",
            "Train Epoch: 79 [8448/14860 (56%)]\tLoss: 0.021063\n",
            "Train Epoch: 79 [8576/14860 (57%)]\tLoss: 0.018998\n",
            "Train Epoch: 79 [8704/14860 (58%)]\tLoss: 0.010395\n",
            "Train Epoch: 79 [8832/14860 (59%)]\tLoss: 0.024489\n",
            "Train Epoch: 79 [8960/14860 (60%)]\tLoss: 0.023840\n",
            "Train Epoch: 79 [9088/14860 (61%)]\tLoss: 0.027366\n",
            "Train Epoch: 79 [9216/14860 (62%)]\tLoss: 0.016814\n",
            "Train Epoch: 79 [9344/14860 (62%)]\tLoss: 0.028516\n",
            "Train Epoch: 79 [9472/14860 (63%)]\tLoss: 0.015809\n",
            "Train Epoch: 79 [9600/14860 (64%)]\tLoss: 0.022005\n",
            "Train Epoch: 79 [9728/14860 (65%)]\tLoss: 0.019693\n",
            "Train Epoch: 79 [9856/14860 (66%)]\tLoss: 0.017467\n",
            "Train Epoch: 79 [9984/14860 (67%)]\tLoss: 0.017822\n",
            "Train Epoch: 79 [10112/14860 (68%)]\tLoss: 0.019209\n",
            "Train Epoch: 79 [10240/14860 (68%)]\tLoss: 0.020951\n",
            "Train Epoch: 79 [10368/14860 (69%)]\tLoss: 0.023640\n",
            "Train Epoch: 79 [10496/14860 (70%)]\tLoss: 0.016268\n",
            "Train Epoch: 79 [10624/14860 (71%)]\tLoss: 0.019933\n",
            "Train Epoch: 79 [10752/14860 (72%)]\tLoss: 0.018403\n",
            "Train Epoch: 79 [10880/14860 (73%)]\tLoss: 0.018760\n",
            "Train Epoch: 79 [11008/14860 (74%)]\tLoss: 0.021558\n",
            "Train Epoch: 79 [11136/14860 (74%)]\tLoss: 0.016313\n",
            "Train Epoch: 79 [11264/14860 (75%)]\tLoss: 0.025234\n",
            "Train Epoch: 79 [11392/14860 (76%)]\tLoss: 0.025710\n",
            "Train Epoch: 79 [11520/14860 (77%)]\tLoss: 0.022298\n",
            "Train Epoch: 79 [11648/14860 (78%)]\tLoss: 0.016058\n",
            "Train Epoch: 79 [11776/14860 (79%)]\tLoss: 0.022053\n",
            "Train Epoch: 79 [11904/14860 (79%)]\tLoss: 0.022252\n",
            "Train Epoch: 79 [12032/14860 (80%)]\tLoss: 0.019545\n",
            "Train Epoch: 79 [12160/14860 (81%)]\tLoss: 0.022269\n",
            "Train Epoch: 79 [12288/14860 (82%)]\tLoss: 0.018252\n",
            "Train Epoch: 79 [12416/14860 (83%)]\tLoss: 0.033145\n",
            "Train Epoch: 79 [12544/14860 (84%)]\tLoss: 0.025018\n",
            "Train Epoch: 79 [12672/14860 (85%)]\tLoss: 0.025258\n",
            "Train Epoch: 79 [12800/14860 (85%)]\tLoss: 0.012305\n",
            "Train Epoch: 79 [12928/14860 (86%)]\tLoss: 0.012419\n",
            "Train Epoch: 79 [13056/14860 (87%)]\tLoss: 0.016337\n",
            "Train Epoch: 79 [13184/14860 (88%)]\tLoss: 0.024052\n",
            "Train Epoch: 79 [13312/14860 (89%)]\tLoss: 0.015360\n",
            "Train Epoch: 79 [13440/14860 (90%)]\tLoss: 0.017140\n",
            "Train Epoch: 79 [13568/14860 (91%)]\tLoss: 0.020924\n",
            "Train Epoch: 79 [13696/14860 (91%)]\tLoss: 0.020985\n",
            "Train Epoch: 79 [13824/14860 (92%)]\tLoss: 0.019163\n",
            "Train Epoch: 79 [13952/14860 (93%)]\tLoss: 0.017409\n",
            "Train Epoch: 79 [14080/14860 (94%)]\tLoss: 0.018097\n",
            "Train Epoch: 79 [14208/14860 (95%)]\tLoss: 0.023943\n",
            "Train Epoch: 79 [14336/14860 (96%)]\tLoss: 0.020256\n",
            "Train Epoch: 79 [14464/14860 (97%)]\tLoss: 0.027298\n",
            "Train Epoch: 79 [14592/14860 (97%)]\tLoss: 0.022287\n",
            "Train Epoch: 79 [14720/14860 (98%)]\tLoss: 0.023968\n",
            "Train Epoch: 79 [1392/14860 (99%)]\tLoss: 0.004434\n",
            "epoch 79 training loss: 0.0216082837472423\n",
            "epoch 79 validation loss: 0.021092824295127075\n",
            "Train Epoch: 80 [0/14860 (0%)]\tLoss: 0.013421\n",
            "Train Epoch: 80 [128/14860 (1%)]\tLoss: 0.025235\n",
            "Train Epoch: 80 [256/14860 (2%)]\tLoss: 0.023550\n",
            "Train Epoch: 80 [384/14860 (3%)]\tLoss: 0.023859\n",
            "Train Epoch: 80 [512/14860 (3%)]\tLoss: 0.019885\n",
            "Train Epoch: 80 [640/14860 (4%)]\tLoss: 0.021715\n",
            "Train Epoch: 80 [768/14860 (5%)]\tLoss: 0.019551\n",
            "Train Epoch: 80 [896/14860 (6%)]\tLoss: 0.019282\n",
            "Train Epoch: 80 [1024/14860 (7%)]\tLoss: 0.019419\n",
            "Train Epoch: 80 [1152/14860 (8%)]\tLoss: 0.025722\n",
            "Train Epoch: 80 [1280/14860 (9%)]\tLoss: 0.018886\n",
            "Train Epoch: 80 [1408/14860 (9%)]\tLoss: 0.021411\n",
            "Train Epoch: 80 [1536/14860 (10%)]\tLoss: 0.016534\n",
            "Train Epoch: 80 [1664/14860 (11%)]\tLoss: 0.018923\n",
            "Train Epoch: 80 [1792/14860 (12%)]\tLoss: 0.021662\n",
            "Train Epoch: 80 [1920/14860 (13%)]\tLoss: 0.018634\n",
            "Train Epoch: 80 [2048/14860 (14%)]\tLoss: 0.018392\n",
            "Train Epoch: 80 [2176/14860 (15%)]\tLoss: 0.019948\n",
            "Train Epoch: 80 [2304/14860 (15%)]\tLoss: 0.027004\n",
            "Train Epoch: 80 [2432/14860 (16%)]\tLoss: 0.015224\n",
            "Train Epoch: 80 [2560/14860 (17%)]\tLoss: 0.028304\n",
            "Train Epoch: 80 [2688/14860 (18%)]\tLoss: 0.022434\n",
            "Train Epoch: 80 [2816/14860 (19%)]\tLoss: 0.012741\n",
            "Train Epoch: 80 [2944/14860 (20%)]\tLoss: 0.020438\n",
            "Train Epoch: 80 [3072/14860 (21%)]\tLoss: 0.019025\n",
            "Train Epoch: 80 [3200/14860 (21%)]\tLoss: 0.019630\n",
            "Train Epoch: 80 [3328/14860 (22%)]\tLoss: 0.015180\n",
            "Train Epoch: 80 [3456/14860 (23%)]\tLoss: 0.024447\n",
            "Train Epoch: 80 [3584/14860 (24%)]\tLoss: 0.027117\n",
            "Train Epoch: 80 [3712/14860 (25%)]\tLoss: 0.010198\n",
            "Train Epoch: 80 [3840/14860 (26%)]\tLoss: 0.025767\n",
            "Train Epoch: 80 [3968/14860 (26%)]\tLoss: 0.022583\n",
            "Train Epoch: 80 [4096/14860 (27%)]\tLoss: 0.027498\n",
            "Train Epoch: 80 [4224/14860 (28%)]\tLoss: 0.024546\n",
            "Train Epoch: 80 [4352/14860 (29%)]\tLoss: 0.023933\n",
            "Train Epoch: 80 [4480/14860 (30%)]\tLoss: 0.023895\n",
            "Train Epoch: 80 [4608/14860 (31%)]\tLoss: 0.021057\n",
            "Train Epoch: 80 [4736/14860 (32%)]\tLoss: 0.025275\n",
            "Train Epoch: 80 [4864/14860 (32%)]\tLoss: 0.013988\n",
            "Train Epoch: 80 [4992/14860 (33%)]\tLoss: 0.019625\n",
            "Train Epoch: 80 [5120/14860 (34%)]\tLoss: 0.022333\n",
            "Train Epoch: 80 [5248/14860 (35%)]\tLoss: 0.020600\n",
            "Train Epoch: 80 [5376/14860 (36%)]\tLoss: 0.028403\n",
            "Train Epoch: 80 [5504/14860 (37%)]\tLoss: 0.021995\n",
            "Train Epoch: 80 [5632/14860 (38%)]\tLoss: 0.021199\n",
            "Train Epoch: 80 [5760/14860 (38%)]\tLoss: 0.020410\n",
            "Train Epoch: 80 [5888/14860 (39%)]\tLoss: 0.016743\n",
            "Train Epoch: 80 [6016/14860 (40%)]\tLoss: 0.019277\n",
            "Train Epoch: 80 [6144/14860 (41%)]\tLoss: 0.018644\n",
            "Train Epoch: 80 [6272/14860 (42%)]\tLoss: 0.022919\n",
            "Train Epoch: 80 [6400/14860 (43%)]\tLoss: 0.022380\n",
            "Train Epoch: 80 [6528/14860 (44%)]\tLoss: 0.013187\n",
            "Train Epoch: 80 [6656/14860 (44%)]\tLoss: 0.020711\n",
            "Train Epoch: 80 [6784/14860 (45%)]\tLoss: 0.024940\n",
            "Train Epoch: 80 [6912/14860 (46%)]\tLoss: 0.014760\n",
            "Train Epoch: 80 [7040/14860 (47%)]\tLoss: 0.024097\n",
            "Train Epoch: 80 [7168/14860 (48%)]\tLoss: 0.019349\n",
            "Train Epoch: 80 [7296/14860 (49%)]\tLoss: 0.022438\n",
            "Train Epoch: 80 [7424/14860 (50%)]\tLoss: 0.018115\n",
            "Train Epoch: 80 [7552/14860 (50%)]\tLoss: 0.016724\n",
            "Train Epoch: 80 [7680/14860 (51%)]\tLoss: 0.017642\n",
            "Train Epoch: 80 [7808/14860 (52%)]\tLoss: 0.019252\n",
            "Train Epoch: 80 [7936/14860 (53%)]\tLoss: 0.018556\n",
            "Train Epoch: 80 [8064/14860 (54%)]\tLoss: 0.017618\n",
            "Train Epoch: 80 [8192/14860 (55%)]\tLoss: 0.024767\n",
            "Train Epoch: 80 [8320/14860 (56%)]\tLoss: 0.015949\n",
            "Train Epoch: 80 [8448/14860 (56%)]\tLoss: 0.028223\n",
            "Train Epoch: 80 [8576/14860 (57%)]\tLoss: 0.029258\n",
            "Train Epoch: 80 [8704/14860 (58%)]\tLoss: 0.014608\n",
            "Train Epoch: 80 [8832/14860 (59%)]\tLoss: 0.035709\n",
            "Train Epoch: 80 [8960/14860 (60%)]\tLoss: 0.027113\n",
            "Train Epoch: 80 [9088/14860 (61%)]\tLoss: 0.028615\n",
            "Train Epoch: 80 [9216/14860 (62%)]\tLoss: 0.024551\n",
            "Train Epoch: 80 [9344/14860 (62%)]\tLoss: 0.039158\n",
            "Train Epoch: 80 [9472/14860 (63%)]\tLoss: 0.025528\n",
            "Train Epoch: 80 [9600/14860 (64%)]\tLoss: 0.022223\n",
            "Train Epoch: 80 [9728/14860 (65%)]\tLoss: 0.025217\n",
            "Train Epoch: 80 [9856/14860 (66%)]\tLoss: 0.025963\n",
            "Train Epoch: 80 [9984/14860 (67%)]\tLoss: 0.021041\n",
            "Train Epoch: 80 [10112/14860 (68%)]\tLoss: 0.022161\n",
            "Train Epoch: 80 [10240/14860 (68%)]\tLoss: 0.015096\n",
            "Train Epoch: 80 [10368/14860 (69%)]\tLoss: 0.022789\n",
            "Train Epoch: 80 [10496/14860 (70%)]\tLoss: 0.031679\n",
            "Train Epoch: 80 [10624/14860 (71%)]\tLoss: 0.027912\n",
            "Train Epoch: 80 [10752/14860 (72%)]\tLoss: 0.030143\n",
            "Train Epoch: 80 [10880/14860 (73%)]\tLoss: 0.010966\n",
            "Train Epoch: 80 [11008/14860 (74%)]\tLoss: 0.029571\n",
            "Train Epoch: 80 [11136/14860 (74%)]\tLoss: 0.026043\n",
            "Train Epoch: 80 [11264/14860 (75%)]\tLoss: 0.025746\n",
            "Train Epoch: 80 [11392/14860 (76%)]\tLoss: 0.019112\n",
            "Train Epoch: 80 [11520/14860 (77%)]\tLoss: 0.019748\n",
            "Train Epoch: 80 [11648/14860 (78%)]\tLoss: 0.025912\n",
            "Train Epoch: 80 [11776/14860 (79%)]\tLoss: 0.022036\n",
            "Train Epoch: 80 [11904/14860 (79%)]\tLoss: 0.035479\n",
            "Train Epoch: 80 [12032/14860 (80%)]\tLoss: 0.021234\n",
            "Train Epoch: 80 [12160/14860 (81%)]\tLoss: 0.028748\n",
            "Train Epoch: 80 [12288/14860 (82%)]\tLoss: 0.018266\n",
            "Train Epoch: 80 [12416/14860 (83%)]\tLoss: 0.020819\n",
            "Train Epoch: 80 [12544/14860 (84%)]\tLoss: 0.016702\n",
            "Train Epoch: 80 [12672/14860 (85%)]\tLoss: 0.017159\n",
            "Train Epoch: 80 [12800/14860 (85%)]\tLoss: 0.018981\n",
            "Train Epoch: 80 [12928/14860 (86%)]\tLoss: 0.022223\n",
            "Train Epoch: 80 [13056/14860 (87%)]\tLoss: 0.021439\n",
            "Train Epoch: 80 [13184/14860 (88%)]\tLoss: 0.018403\n",
            "Train Epoch: 80 [13312/14860 (89%)]\tLoss: 0.020519\n",
            "Train Epoch: 80 [13440/14860 (90%)]\tLoss: 0.020593\n",
            "Train Epoch: 80 [13568/14860 (91%)]\tLoss: 0.024891\n",
            "Train Epoch: 80 [13696/14860 (91%)]\tLoss: 0.034668\n",
            "Train Epoch: 80 [13824/14860 (92%)]\tLoss: 0.022396\n",
            "Train Epoch: 80 [13952/14860 (93%)]\tLoss: 0.030762\n",
            "Train Epoch: 80 [14080/14860 (94%)]\tLoss: 0.020289\n",
            "Train Epoch: 80 [14208/14860 (95%)]\tLoss: 0.037600\n",
            "Train Epoch: 80 [14336/14860 (96%)]\tLoss: 0.035394\n",
            "Train Epoch: 80 [14464/14860 (97%)]\tLoss: 0.020118\n",
            "Train Epoch: 80 [14592/14860 (97%)]\tLoss: 0.059419\n",
            "Train Epoch: 80 [14720/14860 (98%)]\tLoss: 0.027753\n",
            "Train Epoch: 80 [1392/14860 (99%)]\tLoss: 0.051140\n",
            "epoch 80 training loss: 0.02290653369715835\n",
            "epoch 80 validation loss: 0.0705127837294239\n",
            "Train Epoch: 81 [0/14860 (0%)]\tLoss: 0.070483\n",
            "Train Epoch: 81 [128/14860 (1%)]\tLoss: 0.022476\n",
            "Train Epoch: 81 [256/14860 (2%)]\tLoss: 0.071392\n",
            "Train Epoch: 81 [384/14860 (3%)]\tLoss: 0.027541\n",
            "Train Epoch: 81 [512/14860 (3%)]\tLoss: 0.033846\n",
            "Train Epoch: 81 [640/14860 (4%)]\tLoss: 0.034407\n",
            "Train Epoch: 81 [768/14860 (5%)]\tLoss: 0.016448\n",
            "Train Epoch: 81 [896/14860 (6%)]\tLoss: 0.035961\n",
            "Train Epoch: 81 [1024/14860 (7%)]\tLoss: 0.019421\n",
            "Train Epoch: 81 [1152/14860 (8%)]\tLoss: 0.028139\n",
            "Train Epoch: 81 [1280/14860 (9%)]\tLoss: 0.029369\n",
            "Train Epoch: 81 [1408/14860 (9%)]\tLoss: 0.017644\n",
            "Train Epoch: 81 [1536/14860 (10%)]\tLoss: 0.027239\n",
            "Train Epoch: 81 [1664/14860 (11%)]\tLoss: 0.022065\n",
            "Train Epoch: 81 [1792/14860 (12%)]\tLoss: 0.021398\n",
            "Train Epoch: 81 [1920/14860 (13%)]\tLoss: 0.025605\n",
            "Train Epoch: 81 [2048/14860 (14%)]\tLoss: 0.020906\n",
            "Train Epoch: 81 [2176/14860 (15%)]\tLoss: 0.026382\n",
            "Train Epoch: 81 [2304/14860 (15%)]\tLoss: 0.027142\n",
            "Train Epoch: 81 [2432/14860 (16%)]\tLoss: 0.022095\n",
            "Train Epoch: 81 [2560/14860 (17%)]\tLoss: 0.028995\n",
            "Train Epoch: 81 [2688/14860 (18%)]\tLoss: 0.022417\n",
            "Train Epoch: 81 [2816/14860 (19%)]\tLoss: 0.020125\n",
            "Train Epoch: 81 [2944/14860 (20%)]\tLoss: 0.016966\n",
            "Train Epoch: 81 [3072/14860 (21%)]\tLoss: 0.019709\n",
            "Train Epoch: 81 [3200/14860 (21%)]\tLoss: 0.012837\n",
            "Train Epoch: 81 [3328/14860 (22%)]\tLoss: 0.030804\n",
            "Train Epoch: 81 [3456/14860 (23%)]\tLoss: 0.022878\n",
            "Train Epoch: 81 [3584/14860 (24%)]\tLoss: 0.018561\n",
            "Train Epoch: 81 [3712/14860 (25%)]\tLoss: 0.027131\n",
            "Train Epoch: 81 [3840/14860 (26%)]\tLoss: 0.023162\n",
            "Train Epoch: 81 [3968/14860 (26%)]\tLoss: 0.019931\n",
            "Train Epoch: 81 [4096/14860 (27%)]\tLoss: 0.018455\n",
            "Train Epoch: 81 [4224/14860 (28%)]\tLoss: 0.015464\n",
            "Train Epoch: 81 [4352/14860 (29%)]\tLoss: 0.023056\n",
            "Train Epoch: 81 [4480/14860 (30%)]\tLoss: 0.022479\n",
            "Train Epoch: 81 [4608/14860 (31%)]\tLoss: 0.020411\n",
            "Train Epoch: 81 [4736/14860 (32%)]\tLoss: 0.018246\n",
            "Train Epoch: 81 [4864/14860 (32%)]\tLoss: 0.025426\n",
            "Train Epoch: 81 [4992/14860 (33%)]\tLoss: 0.013663\n",
            "Train Epoch: 81 [5120/14860 (34%)]\tLoss: 0.022232\n",
            "Train Epoch: 81 [5248/14860 (35%)]\tLoss: 0.020641\n",
            "Train Epoch: 81 [5376/14860 (36%)]\tLoss: 0.021763\n",
            "Train Epoch: 81 [5504/14860 (37%)]\tLoss: 0.021579\n",
            "Train Epoch: 81 [5632/14860 (38%)]\tLoss: 0.024451\n",
            "Train Epoch: 81 [5760/14860 (38%)]\tLoss: 0.024691\n",
            "Train Epoch: 81 [5888/14860 (39%)]\tLoss: 0.014686\n",
            "Train Epoch: 81 [6016/14860 (40%)]\tLoss: 0.020317\n",
            "Train Epoch: 81 [6144/14860 (41%)]\tLoss: 0.023582\n",
            "Train Epoch: 81 [6272/14860 (42%)]\tLoss: 0.017896\n",
            "Train Epoch: 81 [6400/14860 (43%)]\tLoss: 0.020115\n",
            "Train Epoch: 81 [6528/14860 (44%)]\tLoss: 0.029145\n",
            "Train Epoch: 81 [6656/14860 (44%)]\tLoss: 0.037391\n",
            "Train Epoch: 81 [6784/14860 (45%)]\tLoss: 0.022535\n",
            "Train Epoch: 81 [6912/14860 (46%)]\tLoss: 0.026756\n",
            "Train Epoch: 81 [7040/14860 (47%)]\tLoss: 0.013547\n",
            "Train Epoch: 81 [7168/14860 (48%)]\tLoss: 0.042409\n",
            "Train Epoch: 81 [7296/14860 (49%)]\tLoss: 0.016636\n",
            "Train Epoch: 81 [7424/14860 (50%)]\tLoss: 0.028633\n",
            "Train Epoch: 81 [7552/14860 (50%)]\tLoss: 0.020335\n",
            "Train Epoch: 81 [7680/14860 (51%)]\tLoss: 0.036731\n",
            "Train Epoch: 81 [7808/14860 (52%)]\tLoss: 0.024323\n",
            "Train Epoch: 81 [7936/14860 (53%)]\tLoss: 0.035915\n",
            "Train Epoch: 81 [8064/14860 (54%)]\tLoss: 0.025381\n",
            "Train Epoch: 81 [8192/14860 (55%)]\tLoss: 0.023705\n",
            "Train Epoch: 81 [8320/14860 (56%)]\tLoss: 0.033850\n",
            "Train Epoch: 81 [8448/14860 (56%)]\tLoss: 0.022827\n",
            "Train Epoch: 81 [8576/14860 (57%)]\tLoss: 0.031271\n",
            "Train Epoch: 81 [8704/14860 (58%)]\tLoss: 0.015745\n",
            "Train Epoch: 81 [8832/14860 (59%)]\tLoss: 0.030140\n",
            "Train Epoch: 81 [8960/14860 (60%)]\tLoss: 0.020130\n",
            "Train Epoch: 81 [9088/14860 (61%)]\tLoss: 0.018062\n",
            "Train Epoch: 81 [9216/14860 (62%)]\tLoss: 0.026449\n",
            "Train Epoch: 81 [9344/14860 (62%)]\tLoss: 0.019748\n",
            "Train Epoch: 81 [9472/14860 (63%)]\tLoss: 0.026038\n",
            "Train Epoch: 81 [9600/14860 (64%)]\tLoss: 0.019870\n",
            "Train Epoch: 81 [9728/14860 (65%)]\tLoss: 0.019102\n",
            "Train Epoch: 81 [9856/14860 (66%)]\tLoss: 0.024050\n",
            "Train Epoch: 81 [9984/14860 (67%)]\tLoss: 0.017656\n",
            "Train Epoch: 81 [10112/14860 (68%)]\tLoss: 0.022888\n",
            "Train Epoch: 81 [10240/14860 (68%)]\tLoss: 0.012019\n",
            "Train Epoch: 81 [10368/14860 (69%)]\tLoss: 0.013767\n",
            "Train Epoch: 81 [10496/14860 (70%)]\tLoss: 0.026151\n",
            "Train Epoch: 81 [10624/14860 (71%)]\tLoss: 0.016433\n",
            "Train Epoch: 81 [10752/14860 (72%)]\tLoss: 0.025774\n",
            "Train Epoch: 81 [10880/14860 (73%)]\tLoss: 0.017801\n",
            "Train Epoch: 81 [11008/14860 (74%)]\tLoss: 0.019993\n",
            "Train Epoch: 81 [11136/14860 (74%)]\tLoss: 0.020605\n",
            "Train Epoch: 81 [11264/14860 (75%)]\tLoss: 0.016407\n",
            "Train Epoch: 81 [11392/14860 (76%)]\tLoss: 0.016925\n",
            "Train Epoch: 81 [11520/14860 (77%)]\tLoss: 0.019884\n",
            "Train Epoch: 81 [11648/14860 (78%)]\tLoss: 0.018570\n",
            "Train Epoch: 81 [11776/14860 (79%)]\tLoss: 0.019240\n",
            "Train Epoch: 81 [11904/14860 (79%)]\tLoss: 0.018377\n",
            "Train Epoch: 81 [12032/14860 (80%)]\tLoss: 0.017764\n",
            "Train Epoch: 81 [12160/14860 (81%)]\tLoss: 0.019089\n",
            "Train Epoch: 81 [12288/14860 (82%)]\tLoss: 0.022403\n",
            "Train Epoch: 81 [12416/14860 (83%)]\tLoss: 0.020645\n",
            "Train Epoch: 81 [12544/14860 (84%)]\tLoss: 0.024758\n",
            "Train Epoch: 81 [12672/14860 (85%)]\tLoss: 0.023553\n",
            "Train Epoch: 81 [12800/14860 (85%)]\tLoss: 0.025579\n",
            "Train Epoch: 81 [12928/14860 (86%)]\tLoss: 0.024025\n",
            "Train Epoch: 81 [13056/14860 (87%)]\tLoss: 0.017601\n",
            "Train Epoch: 81 [13184/14860 (88%)]\tLoss: 0.034803\n",
            "Train Epoch: 81 [13312/14860 (89%)]\tLoss: 0.017788\n",
            "Train Epoch: 81 [13440/14860 (90%)]\tLoss: 0.033109\n",
            "Train Epoch: 81 [13568/14860 (91%)]\tLoss: 0.017574\n",
            "Train Epoch: 81 [13696/14860 (91%)]\tLoss: 0.036533\n",
            "Train Epoch: 81 [13824/14860 (92%)]\tLoss: 0.028181\n",
            "Train Epoch: 81 [13952/14860 (93%)]\tLoss: 0.029029\n",
            "Train Epoch: 81 [14080/14860 (94%)]\tLoss: 0.019776\n",
            "Train Epoch: 81 [14208/14860 (95%)]\tLoss: 0.030272\n",
            "Train Epoch: 81 [14336/14860 (96%)]\tLoss: 0.026249\n",
            "Train Epoch: 81 [14464/14860 (97%)]\tLoss: 0.018478\n",
            "Train Epoch: 81 [14592/14860 (97%)]\tLoss: 0.020195\n",
            "Train Epoch: 81 [14720/14860 (98%)]\tLoss: 0.020901\n",
            "Train Epoch: 81 [1392/14860 (99%)]\tLoss: 0.007733\n",
            "epoch 81 training loss: 0.023776762020320464\n",
            "epoch 81 validation loss: 0.03640937574261903\n",
            "Train Epoch: 82 [0/14860 (0%)]\tLoss: 0.037158\n",
            "Train Epoch: 82 [128/14860 (1%)]\tLoss: 0.016294\n",
            "Train Epoch: 82 [256/14860 (2%)]\tLoss: 0.040533\n",
            "Train Epoch: 82 [384/14860 (3%)]\tLoss: 0.015157\n",
            "Train Epoch: 82 [512/14860 (3%)]\tLoss: 0.024154\n",
            "Train Epoch: 82 [640/14860 (4%)]\tLoss: 0.026636\n",
            "Train Epoch: 82 [768/14860 (5%)]\tLoss: 0.022099\n",
            "Train Epoch: 82 [896/14860 (6%)]\tLoss: 0.025864\n",
            "Train Epoch: 82 [1024/14860 (7%)]\tLoss: 0.021484\n",
            "Train Epoch: 82 [1152/14860 (8%)]\tLoss: 0.021621\n",
            "Train Epoch: 82 [1280/14860 (9%)]\tLoss: 0.022625\n",
            "Train Epoch: 82 [1408/14860 (9%)]\tLoss: 0.019753\n",
            "Train Epoch: 82 [1536/14860 (10%)]\tLoss: 0.020870\n",
            "Train Epoch: 82 [1664/14860 (11%)]\tLoss: 0.015813\n",
            "Train Epoch: 82 [1792/14860 (12%)]\tLoss: 0.015855\n",
            "Train Epoch: 82 [1920/14860 (13%)]\tLoss: 0.029833\n",
            "Train Epoch: 82 [2048/14860 (14%)]\tLoss: 0.019172\n",
            "Train Epoch: 82 [2176/14860 (15%)]\tLoss: 0.024041\n",
            "Train Epoch: 82 [2304/14860 (15%)]\tLoss: 0.024822\n",
            "Train Epoch: 82 [2432/14860 (16%)]\tLoss: 0.015886\n",
            "Train Epoch: 82 [2560/14860 (17%)]\tLoss: 0.025426\n",
            "Train Epoch: 82 [2688/14860 (18%)]\tLoss: 0.017323\n",
            "Train Epoch: 82 [2816/14860 (19%)]\tLoss: 0.015044\n",
            "Train Epoch: 82 [2944/14860 (20%)]\tLoss: 0.022786\n",
            "Train Epoch: 82 [3072/14860 (21%)]\tLoss: 0.021887\n",
            "Train Epoch: 82 [3200/14860 (21%)]\tLoss: 0.018607\n",
            "Train Epoch: 82 [3328/14860 (22%)]\tLoss: 0.022024\n",
            "Train Epoch: 82 [3456/14860 (23%)]\tLoss: 0.017357\n",
            "Train Epoch: 82 [3584/14860 (24%)]\tLoss: 0.021988\n",
            "Train Epoch: 82 [3712/14860 (25%)]\tLoss: 0.023665\n",
            "Train Epoch: 82 [3840/14860 (26%)]\tLoss: 0.017443\n",
            "Train Epoch: 82 [3968/14860 (26%)]\tLoss: 0.027875\n",
            "Train Epoch: 82 [4096/14860 (27%)]\tLoss: 0.017555\n",
            "Train Epoch: 82 [4224/14860 (28%)]\tLoss: 0.019531\n",
            "Train Epoch: 82 [4352/14860 (29%)]\tLoss: 0.026465\n",
            "Train Epoch: 82 [4480/14860 (30%)]\tLoss: 0.025721\n",
            "Train Epoch: 82 [4608/14860 (31%)]\tLoss: 0.016529\n",
            "Train Epoch: 82 [4736/14860 (32%)]\tLoss: 0.025834\n",
            "Train Epoch: 82 [4864/14860 (32%)]\tLoss: 0.020188\n",
            "Train Epoch: 82 [4992/14860 (33%)]\tLoss: 0.022302\n",
            "Train Epoch: 82 [5120/14860 (34%)]\tLoss: 0.027760\n",
            "Train Epoch: 82 [5248/14860 (35%)]\tLoss: 0.025765\n",
            "Train Epoch: 82 [5376/14860 (36%)]\tLoss: 0.015412\n",
            "Train Epoch: 82 [5504/14860 (37%)]\tLoss: 0.018534\n",
            "Train Epoch: 82 [5632/14860 (38%)]\tLoss: 0.025931\n",
            "Train Epoch: 82 [5760/14860 (38%)]\tLoss: 0.018615\n",
            "Train Epoch: 82 [5888/14860 (39%)]\tLoss: 0.021184\n",
            "Train Epoch: 82 [6016/14860 (40%)]\tLoss: 0.017346\n",
            "Train Epoch: 82 [6144/14860 (41%)]\tLoss: 0.017675\n",
            "Train Epoch: 82 [6272/14860 (42%)]\tLoss: 0.028212\n",
            "Train Epoch: 82 [6400/14860 (43%)]\tLoss: 0.021399\n",
            "Train Epoch: 82 [6528/14860 (44%)]\tLoss: 0.022220\n",
            "Train Epoch: 82 [6656/14860 (44%)]\tLoss: 0.024027\n",
            "Train Epoch: 82 [6784/14860 (45%)]\tLoss: 0.023677\n",
            "Train Epoch: 82 [6912/14860 (46%)]\tLoss: 0.021832\n",
            "Train Epoch: 82 [7040/14860 (47%)]\tLoss: 0.015292\n",
            "Train Epoch: 82 [7168/14860 (48%)]\tLoss: 0.019550\n",
            "Train Epoch: 82 [7296/14860 (49%)]\tLoss: 0.014274\n",
            "Train Epoch: 82 [7424/14860 (50%)]\tLoss: 0.015786\n",
            "Train Epoch: 82 [7552/14860 (50%)]\tLoss: 0.015756\n",
            "Train Epoch: 82 [7680/14860 (51%)]\tLoss: 0.010327\n",
            "Train Epoch: 82 [7808/14860 (52%)]\tLoss: 0.016148\n",
            "Train Epoch: 82 [7936/14860 (53%)]\tLoss: 0.018536\n",
            "Train Epoch: 82 [8064/14860 (54%)]\tLoss: 0.023141\n",
            "Train Epoch: 82 [8192/14860 (55%)]\tLoss: 0.019622\n",
            "Train Epoch: 82 [8320/14860 (56%)]\tLoss: 0.025059\n",
            "Train Epoch: 82 [8448/14860 (56%)]\tLoss: 0.018050\n",
            "Train Epoch: 82 [8576/14860 (57%)]\tLoss: 0.018598\n",
            "Train Epoch: 82 [8704/14860 (58%)]\tLoss: 0.023689\n",
            "Train Epoch: 82 [8832/14860 (59%)]\tLoss: 0.021445\n",
            "Train Epoch: 82 [8960/14860 (60%)]\tLoss: 0.019820\n",
            "Train Epoch: 82 [9088/14860 (61%)]\tLoss: 0.022890\n",
            "Train Epoch: 82 [9216/14860 (62%)]\tLoss: 0.019114\n",
            "Train Epoch: 82 [9344/14860 (62%)]\tLoss: 0.022884\n",
            "Train Epoch: 82 [9472/14860 (63%)]\tLoss: 0.020474\n",
            "Train Epoch: 82 [9600/14860 (64%)]\tLoss: 0.031041\n",
            "Train Epoch: 82 [9728/14860 (65%)]\tLoss: 0.017118\n",
            "Train Epoch: 82 [9856/14860 (66%)]\tLoss: 0.025282\n",
            "Train Epoch: 82 [9984/14860 (67%)]\tLoss: 0.028006\n",
            "Train Epoch: 82 [10112/14860 (68%)]\tLoss: 0.023573\n",
            "Train Epoch: 82 [10240/14860 (68%)]\tLoss: 0.018084\n",
            "Train Epoch: 82 [10368/14860 (69%)]\tLoss: 0.016964\n",
            "Train Epoch: 82 [10496/14860 (70%)]\tLoss: 0.020899\n",
            "Train Epoch: 82 [10624/14860 (71%)]\tLoss: 0.026883\n",
            "Train Epoch: 82 [10752/14860 (72%)]\tLoss: 0.022859\n",
            "Train Epoch: 82 [10880/14860 (73%)]\tLoss: 0.013526\n",
            "Train Epoch: 82 [11008/14860 (74%)]\tLoss: 0.029288\n",
            "Train Epoch: 82 [11136/14860 (74%)]\tLoss: 0.028532\n",
            "Train Epoch: 82 [11264/14860 (75%)]\tLoss: 0.024938\n",
            "Train Epoch: 82 [11392/14860 (76%)]\tLoss: 0.015717\n",
            "Train Epoch: 82 [11520/14860 (77%)]\tLoss: 0.024476\n",
            "Train Epoch: 82 [11648/14860 (78%)]\tLoss: 0.016442\n",
            "Train Epoch: 82 [11776/14860 (79%)]\tLoss: 0.023581\n",
            "Train Epoch: 82 [11904/14860 (79%)]\tLoss: 0.015255\n",
            "Train Epoch: 82 [12032/14860 (80%)]\tLoss: 0.026463\n",
            "Train Epoch: 82 [12160/14860 (81%)]\tLoss: 0.014866\n",
            "Train Epoch: 82 [12288/14860 (82%)]\tLoss: 0.023565\n",
            "Train Epoch: 82 [12416/14860 (83%)]\tLoss: 0.019328\n",
            "Train Epoch: 82 [12544/14860 (84%)]\tLoss: 0.018057\n",
            "Train Epoch: 82 [12672/14860 (85%)]\tLoss: 0.025784\n",
            "Train Epoch: 82 [12800/14860 (85%)]\tLoss: 0.020587\n",
            "Train Epoch: 82 [12928/14860 (86%)]\tLoss: 0.022048\n",
            "Train Epoch: 82 [13056/14860 (87%)]\tLoss: 0.018962\n",
            "Train Epoch: 82 [13184/14860 (88%)]\tLoss: 0.012956\n",
            "Train Epoch: 82 [13312/14860 (89%)]\tLoss: 0.020528\n",
            "Train Epoch: 82 [13440/14860 (90%)]\tLoss: 0.022233\n",
            "Train Epoch: 82 [13568/14860 (91%)]\tLoss: 0.024159\n",
            "Train Epoch: 82 [13696/14860 (91%)]\tLoss: 0.019590\n",
            "Train Epoch: 82 [13824/14860 (92%)]\tLoss: 0.036627\n",
            "Train Epoch: 82 [13952/14860 (93%)]\tLoss: 0.019686\n",
            "Train Epoch: 82 [14080/14860 (94%)]\tLoss: 0.032149\n",
            "Train Epoch: 82 [14208/14860 (95%)]\tLoss: 0.019702\n",
            "Train Epoch: 82 [14336/14860 (96%)]\tLoss: 0.011839\n",
            "Train Epoch: 82 [14464/14860 (97%)]\tLoss: 0.018255\n",
            "Train Epoch: 82 [14592/14860 (97%)]\tLoss: 0.021013\n",
            "Train Epoch: 82 [14720/14860 (98%)]\tLoss: 0.020393\n",
            "Train Epoch: 82 [1392/14860 (99%)]\tLoss: 0.008271\n",
            "epoch 82 training loss: 0.0213229488581419\n",
            "epoch 82 validation loss: 0.025814243869689127\n",
            "Train Epoch: 83 [0/14860 (0%)]\tLoss: 0.028833\n",
            "Train Epoch: 83 [128/14860 (1%)]\tLoss: 0.019976\n",
            "Train Epoch: 83 [256/14860 (2%)]\tLoss: 0.023668\n",
            "Train Epoch: 83 [384/14860 (3%)]\tLoss: 0.017481\n",
            "Train Epoch: 83 [512/14860 (3%)]\tLoss: 0.025107\n",
            "Train Epoch: 83 [640/14860 (4%)]\tLoss: 0.019467\n",
            "Train Epoch: 83 [768/14860 (5%)]\tLoss: 0.021751\n",
            "Train Epoch: 83 [896/14860 (6%)]\tLoss: 0.018517\n",
            "Train Epoch: 83 [1024/14860 (7%)]\tLoss: 0.020784\n",
            "Train Epoch: 83 [1152/14860 (8%)]\tLoss: 0.022659\n",
            "Train Epoch: 83 [1280/14860 (9%)]\tLoss: 0.023921\n",
            "Train Epoch: 83 [1408/14860 (9%)]\tLoss: 0.020006\n",
            "Train Epoch: 83 [1536/14860 (10%)]\tLoss: 0.024756\n",
            "Train Epoch: 83 [1664/14860 (11%)]\tLoss: 0.016011\n",
            "Train Epoch: 83 [1792/14860 (12%)]\tLoss: 0.019367\n",
            "Train Epoch: 83 [1920/14860 (13%)]\tLoss: 0.021261\n",
            "Train Epoch: 83 [2048/14860 (14%)]\tLoss: 0.011709\n",
            "Train Epoch: 83 [2176/14860 (15%)]\tLoss: 0.029831\n",
            "Train Epoch: 83 [2304/14860 (15%)]\tLoss: 0.014449\n",
            "Train Epoch: 83 [2432/14860 (16%)]\tLoss: 0.020173\n",
            "Train Epoch: 83 [2560/14860 (17%)]\tLoss: 0.021840\n",
            "Train Epoch: 83 [2688/14860 (18%)]\tLoss: 0.020865\n",
            "Train Epoch: 83 [2816/14860 (19%)]\tLoss: 0.016318\n",
            "Train Epoch: 83 [2944/14860 (20%)]\tLoss: 0.017861\n",
            "Train Epoch: 83 [3072/14860 (21%)]\tLoss: 0.018774\n",
            "Train Epoch: 83 [3200/14860 (21%)]\tLoss: 0.019923\n",
            "Train Epoch: 83 [3328/14860 (22%)]\tLoss: 0.023464\n",
            "Train Epoch: 83 [3456/14860 (23%)]\tLoss: 0.020609\n",
            "Train Epoch: 83 [3584/14860 (24%)]\tLoss: 0.023800\n",
            "Train Epoch: 83 [3712/14860 (25%)]\tLoss: 0.016497\n",
            "Train Epoch: 83 [3840/14860 (26%)]\tLoss: 0.026234\n",
            "Train Epoch: 83 [3968/14860 (26%)]\tLoss: 0.017859\n",
            "Train Epoch: 83 [4096/14860 (27%)]\tLoss: 0.037154\n",
            "Train Epoch: 83 [4224/14860 (28%)]\tLoss: 0.021601\n",
            "Train Epoch: 83 [4352/14860 (29%)]\tLoss: 0.032805\n",
            "Train Epoch: 83 [4480/14860 (30%)]\tLoss: 0.014350\n",
            "Train Epoch: 83 [4608/14860 (31%)]\tLoss: 0.026970\n",
            "Train Epoch: 83 [4736/14860 (32%)]\tLoss: 0.024384\n",
            "Train Epoch: 83 [4864/14860 (32%)]\tLoss: 0.019088\n",
            "Train Epoch: 83 [4992/14860 (33%)]\tLoss: 0.011237\n",
            "Train Epoch: 83 [5120/14860 (34%)]\tLoss: 0.033328\n",
            "Train Epoch: 83 [5248/14860 (35%)]\tLoss: 0.017164\n",
            "Train Epoch: 83 [5376/14860 (36%)]\tLoss: 0.016221\n",
            "Train Epoch: 83 [5504/14860 (37%)]\tLoss: 0.021921\n",
            "Train Epoch: 83 [5632/14860 (38%)]\tLoss: 0.024242\n",
            "Train Epoch: 83 [5760/14860 (38%)]\tLoss: 0.022264\n",
            "Train Epoch: 83 [5888/14860 (39%)]\tLoss: 0.023272\n",
            "Train Epoch: 83 [6016/14860 (40%)]\tLoss: 0.019911\n",
            "Train Epoch: 83 [6144/14860 (41%)]\tLoss: 0.022744\n",
            "Train Epoch: 83 [6272/14860 (42%)]\tLoss: 0.025602\n",
            "Train Epoch: 83 [6400/14860 (43%)]\tLoss: 0.027201\n",
            "Train Epoch: 83 [6528/14860 (44%)]\tLoss: 0.022096\n",
            "Train Epoch: 83 [6656/14860 (44%)]\tLoss: 0.013466\n",
            "Train Epoch: 83 [6784/14860 (45%)]\tLoss: 0.018598\n",
            "Train Epoch: 83 [6912/14860 (46%)]\tLoss: 0.025008\n",
            "Train Epoch: 83 [7040/14860 (47%)]\tLoss: 0.022077\n",
            "Train Epoch: 83 [7168/14860 (48%)]\tLoss: 0.020538\n",
            "Train Epoch: 83 [7296/14860 (49%)]\tLoss: 0.024648\n",
            "Train Epoch: 83 [7424/14860 (50%)]\tLoss: 0.020850\n",
            "Train Epoch: 83 [7552/14860 (50%)]\tLoss: 0.022407\n",
            "Train Epoch: 83 [7680/14860 (51%)]\tLoss: 0.016455\n",
            "Train Epoch: 83 [7808/14860 (52%)]\tLoss: 0.017811\n",
            "Train Epoch: 83 [7936/14860 (53%)]\tLoss: 0.021987\n",
            "Train Epoch: 83 [8064/14860 (54%)]\tLoss: 0.019062\n",
            "Train Epoch: 83 [8192/14860 (55%)]\tLoss: 0.018237\n",
            "Train Epoch: 83 [8320/14860 (56%)]\tLoss: 0.011759\n",
            "Train Epoch: 83 [8448/14860 (56%)]\tLoss: 0.026262\n",
            "Train Epoch: 83 [8576/14860 (57%)]\tLoss: 0.017176\n",
            "Train Epoch: 83 [8704/14860 (58%)]\tLoss: 0.016857\n",
            "Train Epoch: 83 [8832/14860 (59%)]\tLoss: 0.026745\n",
            "Train Epoch: 83 [8960/14860 (60%)]\tLoss: 0.013635\n",
            "Train Epoch: 83 [9088/14860 (61%)]\tLoss: 0.026574\n",
            "Train Epoch: 83 [9216/14860 (62%)]\tLoss: 0.019203\n",
            "Train Epoch: 83 [9344/14860 (62%)]\tLoss: 0.018403\n",
            "Train Epoch: 83 [9472/14860 (63%)]\tLoss: 0.027926\n",
            "Train Epoch: 83 [9600/14860 (64%)]\tLoss: 0.018971\n",
            "Train Epoch: 83 [9728/14860 (65%)]\tLoss: 0.028144\n",
            "Train Epoch: 83 [9856/14860 (66%)]\tLoss: 0.016556\n",
            "Train Epoch: 83 [9984/14860 (67%)]\tLoss: 0.016592\n",
            "Train Epoch: 83 [10112/14860 (68%)]\tLoss: 0.018766\n",
            "Train Epoch: 83 [10240/14860 (68%)]\tLoss: 0.025418\n",
            "Train Epoch: 83 [10368/14860 (69%)]\tLoss: 0.019372\n",
            "Train Epoch: 83 [10496/14860 (70%)]\tLoss: 0.033306\n",
            "Train Epoch: 83 [10624/14860 (71%)]\tLoss: 0.014832\n",
            "Train Epoch: 83 [10752/14860 (72%)]\tLoss: 0.028150\n",
            "Train Epoch: 83 [10880/14860 (73%)]\tLoss: 0.020075\n",
            "Train Epoch: 83 [11008/14860 (74%)]\tLoss: 0.022262\n",
            "Train Epoch: 83 [11136/14860 (74%)]\tLoss: 0.016170\n",
            "Train Epoch: 83 [11264/14860 (75%)]\tLoss: 0.017028\n",
            "Train Epoch: 83 [11392/14860 (76%)]\tLoss: 0.026617\n",
            "Train Epoch: 83 [11520/14860 (77%)]\tLoss: 0.024135\n",
            "Train Epoch: 83 [11648/14860 (78%)]\tLoss: 0.017790\n",
            "Train Epoch: 83 [11776/14860 (79%)]\tLoss: 0.017462\n",
            "Train Epoch: 83 [11904/14860 (79%)]\tLoss: 0.022009\n",
            "Train Epoch: 83 [12032/14860 (80%)]\tLoss: 0.014703\n",
            "Train Epoch: 83 [12160/14860 (81%)]\tLoss: 0.018497\n",
            "Train Epoch: 83 [12288/14860 (82%)]\tLoss: 0.020821\n",
            "Train Epoch: 83 [12416/14860 (83%)]\tLoss: 0.020500\n",
            "Train Epoch: 83 [12544/14860 (84%)]\tLoss: 0.011707\n",
            "Train Epoch: 83 [12672/14860 (85%)]\tLoss: 0.014869\n",
            "Train Epoch: 83 [12800/14860 (85%)]\tLoss: 0.036517\n",
            "Train Epoch: 83 [12928/14860 (86%)]\tLoss: 0.022730\n",
            "Train Epoch: 83 [13056/14860 (87%)]\tLoss: 0.021669\n",
            "Train Epoch: 83 [13184/14860 (88%)]\tLoss: 0.024575\n",
            "Train Epoch: 83 [13312/14860 (89%)]\tLoss: 0.019348\n",
            "Train Epoch: 83 [13440/14860 (90%)]\tLoss: 0.028708\n",
            "Train Epoch: 83 [13568/14860 (91%)]\tLoss: 0.015731\n",
            "Train Epoch: 83 [13696/14860 (91%)]\tLoss: 0.018296\n",
            "Train Epoch: 83 [13824/14860 (92%)]\tLoss: 0.021138\n",
            "Train Epoch: 83 [13952/14860 (93%)]\tLoss: 0.023938\n",
            "Train Epoch: 83 [14080/14860 (94%)]\tLoss: 0.021225\n",
            "Train Epoch: 83 [14208/14860 (95%)]\tLoss: 0.033008\n",
            "Train Epoch: 83 [14336/14860 (96%)]\tLoss: 0.022643\n",
            "Train Epoch: 83 [14464/14860 (97%)]\tLoss: 0.014491\n",
            "Train Epoch: 83 [14592/14860 (97%)]\tLoss: 0.020149\n",
            "Train Epoch: 83 [14720/14860 (98%)]\tLoss: 0.017740\n",
            "Train Epoch: 83 [1392/14860 (99%)]\tLoss: 0.030732\n",
            "epoch 83 training loss: 0.021285489798547365\n",
            "epoch 83 validation loss: 0.020403309971021973\n",
            "Train Epoch: 84 [0/14860 (0%)]\tLoss: 0.015289\n",
            "Train Epoch: 84 [128/14860 (1%)]\tLoss: 0.027106\n",
            "Train Epoch: 84 [256/14860 (2%)]\tLoss: 0.018384\n",
            "Train Epoch: 84 [384/14860 (3%)]\tLoss: 0.027010\n",
            "Train Epoch: 84 [512/14860 (3%)]\tLoss: 0.019865\n",
            "Train Epoch: 84 [640/14860 (4%)]\tLoss: 0.017107\n",
            "Train Epoch: 84 [768/14860 (5%)]\tLoss: 0.022224\n",
            "Train Epoch: 84 [896/14860 (6%)]\tLoss: 0.017282\n",
            "Train Epoch: 84 [1024/14860 (7%)]\tLoss: 0.031665\n",
            "Train Epoch: 84 [1152/14860 (8%)]\tLoss: 0.015250\n",
            "Train Epoch: 84 [1280/14860 (9%)]\tLoss: 0.021299\n",
            "Train Epoch: 84 [1408/14860 (9%)]\tLoss: 0.018049\n",
            "Train Epoch: 84 [1536/14860 (10%)]\tLoss: 0.017057\n",
            "Train Epoch: 84 [1664/14860 (11%)]\tLoss: 0.022503\n",
            "Train Epoch: 84 [1792/14860 (12%)]\tLoss: 0.017324\n",
            "Train Epoch: 84 [1920/14860 (13%)]\tLoss: 0.014882\n",
            "Train Epoch: 84 [2048/14860 (14%)]\tLoss: 0.020608\n",
            "Train Epoch: 84 [2176/14860 (15%)]\tLoss: 0.023684\n",
            "Train Epoch: 84 [2304/14860 (15%)]\tLoss: 0.023388\n",
            "Train Epoch: 84 [2432/14860 (16%)]\tLoss: 0.020872\n",
            "Train Epoch: 84 [2560/14860 (17%)]\tLoss: 0.024880\n",
            "Train Epoch: 84 [2688/14860 (18%)]\tLoss: 0.034978\n",
            "Train Epoch: 84 [2816/14860 (19%)]\tLoss: 0.019922\n",
            "Train Epoch: 84 [2944/14860 (20%)]\tLoss: 0.029650\n",
            "Train Epoch: 84 [3072/14860 (21%)]\tLoss: 0.023300\n",
            "Train Epoch: 84 [3200/14860 (21%)]\tLoss: 0.035583\n",
            "Train Epoch: 84 [3328/14860 (22%)]\tLoss: 0.017401\n",
            "Train Epoch: 84 [3456/14860 (23%)]\tLoss: 0.038777\n",
            "Train Epoch: 84 [3584/14860 (24%)]\tLoss: 0.024066\n",
            "Train Epoch: 84 [3712/14860 (25%)]\tLoss: 0.033580\n",
            "Train Epoch: 84 [3840/14860 (26%)]\tLoss: 0.023160\n",
            "Train Epoch: 84 [3968/14860 (26%)]\tLoss: 0.027553\n",
            "Train Epoch: 84 [4096/14860 (27%)]\tLoss: 0.015166\n",
            "Train Epoch: 84 [4224/14860 (28%)]\tLoss: 0.020882\n",
            "Train Epoch: 84 [4352/14860 (29%)]\tLoss: 0.023649\n",
            "Train Epoch: 84 [4480/14860 (30%)]\tLoss: 0.021464\n",
            "Train Epoch: 84 [4608/14860 (31%)]\tLoss: 0.016126\n",
            "Train Epoch: 84 [4736/14860 (32%)]\tLoss: 0.037645\n",
            "Train Epoch: 84 [4864/14860 (32%)]\tLoss: 0.019642\n",
            "Train Epoch: 84 [4992/14860 (33%)]\tLoss: 0.025008\n",
            "Train Epoch: 84 [5120/14860 (34%)]\tLoss: 0.013385\n",
            "Train Epoch: 84 [5248/14860 (35%)]\tLoss: 0.024880\n",
            "Train Epoch: 84 [5376/14860 (36%)]\tLoss: 0.020462\n",
            "Train Epoch: 84 [5504/14860 (37%)]\tLoss: 0.018505\n",
            "Train Epoch: 84 [5632/14860 (38%)]\tLoss: 0.022463\n",
            "Train Epoch: 84 [5760/14860 (38%)]\tLoss: 0.020329\n",
            "Train Epoch: 84 [5888/14860 (39%)]\tLoss: 0.022922\n",
            "Train Epoch: 84 [6016/14860 (40%)]\tLoss: 0.017603\n",
            "Train Epoch: 84 [6144/14860 (41%)]\tLoss: 0.022224\n",
            "Train Epoch: 84 [6272/14860 (42%)]\tLoss: 0.025017\n",
            "Train Epoch: 84 [6400/14860 (43%)]\tLoss: 0.022926\n",
            "Train Epoch: 84 [6528/14860 (44%)]\tLoss: 0.020906\n",
            "Train Epoch: 84 [6656/14860 (44%)]\tLoss: 0.022271\n",
            "Train Epoch: 84 [6784/14860 (45%)]\tLoss: 0.020506\n",
            "Train Epoch: 84 [6912/14860 (46%)]\tLoss: 0.018344\n",
            "Train Epoch: 84 [7040/14860 (47%)]\tLoss: 0.020662\n",
            "Train Epoch: 84 [7168/14860 (48%)]\tLoss: 0.013965\n",
            "Train Epoch: 84 [7296/14860 (49%)]\tLoss: 0.018021\n",
            "Train Epoch: 84 [7424/14860 (50%)]\tLoss: 0.013050\n",
            "Train Epoch: 84 [7552/14860 (50%)]\tLoss: 0.019596\n",
            "Train Epoch: 84 [7680/14860 (51%)]\tLoss: 0.016435\n",
            "Train Epoch: 84 [7808/14860 (52%)]\tLoss: 0.022423\n",
            "Train Epoch: 84 [7936/14860 (53%)]\tLoss: 0.024560\n",
            "Train Epoch: 84 [8064/14860 (54%)]\tLoss: 0.019001\n",
            "Train Epoch: 84 [8192/14860 (55%)]\tLoss: 0.018990\n",
            "Train Epoch: 84 [8320/14860 (56%)]\tLoss: 0.022770\n",
            "Train Epoch: 84 [8448/14860 (56%)]\tLoss: 0.031788\n",
            "Train Epoch: 84 [8576/14860 (57%)]\tLoss: 0.024396\n",
            "Train Epoch: 84 [8704/14860 (58%)]\tLoss: 0.020830\n",
            "Train Epoch: 84 [8832/14860 (59%)]\tLoss: 0.022494\n",
            "Train Epoch: 84 [8960/14860 (60%)]\tLoss: 0.016662\n",
            "Train Epoch: 84 [9088/14860 (61%)]\tLoss: 0.021323\n",
            "Train Epoch: 84 [9216/14860 (62%)]\tLoss: 0.023474\n",
            "Train Epoch: 84 [9344/14860 (62%)]\tLoss: 0.031000\n",
            "Train Epoch: 84 [9472/14860 (63%)]\tLoss: 0.023377\n",
            "Train Epoch: 84 [9600/14860 (64%)]\tLoss: 0.020087\n",
            "Train Epoch: 84 [9728/14860 (65%)]\tLoss: 0.019835\n",
            "Train Epoch: 84 [9856/14860 (66%)]\tLoss: 0.012968\n",
            "Train Epoch: 84 [9984/14860 (67%)]\tLoss: 0.023766\n",
            "Train Epoch: 84 [10112/14860 (68%)]\tLoss: 0.015483\n",
            "Train Epoch: 84 [10240/14860 (68%)]\tLoss: 0.021958\n",
            "Train Epoch: 84 [10368/14860 (69%)]\tLoss: 0.018504\n",
            "Train Epoch: 84 [10496/14860 (70%)]\tLoss: 0.034464\n",
            "Train Epoch: 84 [10624/14860 (71%)]\tLoss: 0.022064\n",
            "Train Epoch: 84 [10752/14860 (72%)]\tLoss: 0.018752\n",
            "Train Epoch: 84 [10880/14860 (73%)]\tLoss: 0.015240\n",
            "Train Epoch: 84 [11008/14860 (74%)]\tLoss: 0.017807\n",
            "Train Epoch: 84 [11136/14860 (74%)]\tLoss: 0.019393\n",
            "Train Epoch: 84 [11264/14860 (75%)]\tLoss: 0.026391\n",
            "Train Epoch: 84 [11392/14860 (76%)]\tLoss: 0.024220\n",
            "Train Epoch: 84 [11520/14860 (77%)]\tLoss: 0.011426\n",
            "Train Epoch: 84 [11648/14860 (78%)]\tLoss: 0.020488\n",
            "Train Epoch: 84 [11776/14860 (79%)]\tLoss: 0.015139\n",
            "Train Epoch: 84 [11904/14860 (79%)]\tLoss: 0.027924\n",
            "Train Epoch: 84 [12032/14860 (80%)]\tLoss: 0.022586\n",
            "Train Epoch: 84 [12160/14860 (81%)]\tLoss: 0.015159\n",
            "Train Epoch: 84 [12288/14860 (82%)]\tLoss: 0.020612\n",
            "Train Epoch: 84 [12416/14860 (83%)]\tLoss: 0.016768\n",
            "Train Epoch: 84 [12544/14860 (84%)]\tLoss: 0.017001\n",
            "Train Epoch: 84 [12672/14860 (85%)]\tLoss: 0.021408\n",
            "Train Epoch: 84 [12800/14860 (85%)]\tLoss: 0.026525\n",
            "Train Epoch: 84 [12928/14860 (86%)]\tLoss: 0.030515\n",
            "Train Epoch: 84 [13056/14860 (87%)]\tLoss: 0.020586\n",
            "Train Epoch: 84 [13184/14860 (88%)]\tLoss: 0.037633\n",
            "Train Epoch: 84 [13312/14860 (89%)]\tLoss: 0.013611\n",
            "Train Epoch: 84 [13440/14860 (90%)]\tLoss: 0.028380\n",
            "Train Epoch: 84 [13568/14860 (91%)]\tLoss: 0.022978\n",
            "Train Epoch: 84 [13696/14860 (91%)]\tLoss: 0.018843\n",
            "Train Epoch: 84 [13824/14860 (92%)]\tLoss: 0.016925\n",
            "Train Epoch: 84 [13952/14860 (93%)]\tLoss: 0.012201\n",
            "Train Epoch: 84 [14080/14860 (94%)]\tLoss: 0.017296\n",
            "Train Epoch: 84 [14208/14860 (95%)]\tLoss: 0.015099\n",
            "Train Epoch: 84 [14336/14860 (96%)]\tLoss: 0.024846\n",
            "Train Epoch: 84 [14464/14860 (97%)]\tLoss: 0.020101\n",
            "Train Epoch: 84 [14592/14860 (97%)]\tLoss: 0.021191\n",
            "Train Epoch: 84 [14720/14860 (98%)]\tLoss: 0.021406\n",
            "Train Epoch: 84 [1392/14860 (99%)]\tLoss: 0.049896\n",
            "epoch 84 training loss: 0.021865918253285762\n",
            "epoch 84 validation loss: 0.021409673350197927\n",
            "Train Epoch: 85 [0/14860 (0%)]\tLoss: 0.020574\n",
            "Train Epoch: 85 [128/14860 (1%)]\tLoss: 0.033013\n",
            "Train Epoch: 85 [256/14860 (2%)]\tLoss: 0.014629\n",
            "Train Epoch: 85 [384/14860 (3%)]\tLoss: 0.033643\n",
            "Train Epoch: 85 [512/14860 (3%)]\tLoss: 0.023371\n",
            "Train Epoch: 85 [640/14860 (4%)]\tLoss: 0.036014\n",
            "Train Epoch: 85 [768/14860 (5%)]\tLoss: 0.019859\n",
            "Train Epoch: 85 [896/14860 (6%)]\tLoss: 0.024040\n",
            "Train Epoch: 85 [1024/14860 (7%)]\tLoss: 0.026264\n",
            "Train Epoch: 85 [1152/14860 (8%)]\tLoss: 0.028810\n",
            "Train Epoch: 85 [1280/14860 (9%)]\tLoss: 0.025198\n",
            "Train Epoch: 85 [1408/14860 (9%)]\tLoss: 0.016330\n",
            "Train Epoch: 85 [1536/14860 (10%)]\tLoss: 0.025444\n",
            "Train Epoch: 85 [1664/14860 (11%)]\tLoss: 0.026357\n",
            "Train Epoch: 85 [1792/14860 (12%)]\tLoss: 0.034466\n",
            "Train Epoch: 85 [1920/14860 (13%)]\tLoss: 0.020732\n",
            "Train Epoch: 85 [2048/14860 (14%)]\tLoss: 0.021505\n",
            "Train Epoch: 85 [2176/14860 (15%)]\tLoss: 0.034860\n",
            "Train Epoch: 85 [2304/14860 (15%)]\tLoss: 0.018045\n",
            "Train Epoch: 85 [2432/14860 (16%)]\tLoss: 0.037475\n",
            "Train Epoch: 85 [2560/14860 (17%)]\tLoss: 0.021870\n",
            "Train Epoch: 85 [2688/14860 (18%)]\tLoss: 0.025373\n",
            "Train Epoch: 85 [2816/14860 (19%)]\tLoss: 0.020127\n",
            "Train Epoch: 85 [2944/14860 (20%)]\tLoss: 0.018874\n",
            "Train Epoch: 85 [3072/14860 (21%)]\tLoss: 0.023427\n",
            "Train Epoch: 85 [3200/14860 (21%)]\tLoss: 0.021710\n",
            "Train Epoch: 85 [3328/14860 (22%)]\tLoss: 0.022105\n",
            "Train Epoch: 85 [3456/14860 (23%)]\tLoss: 0.012623\n",
            "Train Epoch: 85 [3584/14860 (24%)]\tLoss: 0.020236\n",
            "Train Epoch: 85 [3712/14860 (25%)]\tLoss: 0.019904\n",
            "Train Epoch: 85 [3840/14860 (26%)]\tLoss: 0.016788\n",
            "Train Epoch: 85 [3968/14860 (26%)]\tLoss: 0.022784\n",
            "Train Epoch: 85 [4096/14860 (27%)]\tLoss: 0.019957\n",
            "Train Epoch: 85 [4224/14860 (28%)]\tLoss: 0.025154\n",
            "Train Epoch: 85 [4352/14860 (29%)]\tLoss: 0.024187\n",
            "Train Epoch: 85 [4480/14860 (30%)]\tLoss: 0.019504\n",
            "Train Epoch: 85 [4608/14860 (31%)]\tLoss: 0.016579\n",
            "Train Epoch: 85 [4736/14860 (32%)]\tLoss: 0.023817\n",
            "Train Epoch: 85 [4864/14860 (32%)]\tLoss: 0.024688\n",
            "Train Epoch: 85 [4992/14860 (33%)]\tLoss: 0.025802\n",
            "Train Epoch: 85 [5120/14860 (34%)]\tLoss: 0.026174\n",
            "Train Epoch: 85 [5248/14860 (35%)]\tLoss: 0.021561\n",
            "Train Epoch: 85 [5376/14860 (36%)]\tLoss: 0.020252\n",
            "Train Epoch: 85 [5504/14860 (37%)]\tLoss: 0.015087\n",
            "Train Epoch: 85 [5632/14860 (38%)]\tLoss: 0.023821\n",
            "Train Epoch: 85 [5760/14860 (38%)]\tLoss: 0.017223\n",
            "Train Epoch: 85 [5888/14860 (39%)]\tLoss: 0.018655\n",
            "Train Epoch: 85 [6016/14860 (40%)]\tLoss: 0.020847\n",
            "Train Epoch: 85 [6144/14860 (41%)]\tLoss: 0.013818\n",
            "Train Epoch: 85 [6272/14860 (42%)]\tLoss: 0.014945\n",
            "Train Epoch: 85 [6400/14860 (43%)]\tLoss: 0.015331\n",
            "Train Epoch: 85 [6528/14860 (44%)]\tLoss: 0.026640\n",
            "Train Epoch: 85 [6656/14860 (44%)]\tLoss: 0.016671\n",
            "Train Epoch: 85 [6784/14860 (45%)]\tLoss: 0.017446\n",
            "Train Epoch: 85 [6912/14860 (46%)]\tLoss: 0.019502\n",
            "Train Epoch: 85 [7040/14860 (47%)]\tLoss: 0.021313\n",
            "Train Epoch: 85 [7168/14860 (48%)]\tLoss: 0.013132\n",
            "Train Epoch: 85 [7296/14860 (49%)]\tLoss: 0.019668\n",
            "Train Epoch: 85 [7424/14860 (50%)]\tLoss: 0.016336\n",
            "Train Epoch: 85 [7552/14860 (50%)]\tLoss: 0.018831\n",
            "Train Epoch: 85 [7680/14860 (51%)]\tLoss: 0.021601\n",
            "Train Epoch: 85 [7808/14860 (52%)]\tLoss: 0.016427\n",
            "Train Epoch: 85 [7936/14860 (53%)]\tLoss: 0.024052\n",
            "Train Epoch: 85 [8064/14860 (54%)]\tLoss: 0.017981\n",
            "Train Epoch: 85 [8192/14860 (55%)]\tLoss: 0.036052\n",
            "Train Epoch: 85 [8320/14860 (56%)]\tLoss: 0.036073\n",
            "Train Epoch: 85 [8448/14860 (56%)]\tLoss: 0.023598\n",
            "Train Epoch: 85 [8576/14860 (57%)]\tLoss: 0.032156\n",
            "Train Epoch: 85 [8704/14860 (58%)]\tLoss: 0.012131\n",
            "Train Epoch: 85 [8832/14860 (59%)]\tLoss: 0.018665\n",
            "Train Epoch: 85 [8960/14860 (60%)]\tLoss: 0.017903\n",
            "Train Epoch: 85 [9088/14860 (61%)]\tLoss: 0.025606\n",
            "Train Epoch: 85 [9216/14860 (62%)]\tLoss: 0.017449\n",
            "Train Epoch: 85 [9344/14860 (62%)]\tLoss: 0.019527\n",
            "Train Epoch: 85 [9472/14860 (63%)]\tLoss: 0.022033\n",
            "Train Epoch: 85 [9600/14860 (64%)]\tLoss: 0.033064\n",
            "Train Epoch: 85 [9728/14860 (65%)]\tLoss: 0.025526\n",
            "Train Epoch: 85 [9856/14860 (66%)]\tLoss: 0.016064\n",
            "Train Epoch: 85 [9984/14860 (67%)]\tLoss: 0.016274\n",
            "Train Epoch: 85 [10112/14860 (68%)]\tLoss: 0.016514\n",
            "Train Epoch: 85 [10240/14860 (68%)]\tLoss: 0.009958\n",
            "Train Epoch: 85 [10368/14860 (69%)]\tLoss: 0.022169\n",
            "Train Epoch: 85 [10496/14860 (70%)]\tLoss: 0.034471\n",
            "Train Epoch: 85 [10624/14860 (71%)]\tLoss: 0.022131\n",
            "Train Epoch: 85 [10752/14860 (72%)]\tLoss: 0.021611\n",
            "Train Epoch: 85 [10880/14860 (73%)]\tLoss: 0.025121\n",
            "Train Epoch: 85 [11008/14860 (74%)]\tLoss: 0.025680\n",
            "Train Epoch: 85 [11136/14860 (74%)]\tLoss: 0.018134\n",
            "Train Epoch: 85 [11264/14860 (75%)]\tLoss: 0.023725\n",
            "Train Epoch: 85 [11392/14860 (76%)]\tLoss: 0.018117\n",
            "Train Epoch: 85 [11520/14860 (77%)]\tLoss: 0.020371\n",
            "Train Epoch: 85 [11648/14860 (78%)]\tLoss: 0.020142\n",
            "Train Epoch: 85 [11776/14860 (79%)]\tLoss: 0.024075\n",
            "Train Epoch: 85 [11904/14860 (79%)]\tLoss: 0.018319\n",
            "Train Epoch: 85 [12032/14860 (80%)]\tLoss: 0.028144\n",
            "Train Epoch: 85 [12160/14860 (81%)]\tLoss: 0.018284\n",
            "Train Epoch: 85 [12288/14860 (82%)]\tLoss: 0.027583\n",
            "Train Epoch: 85 [12416/14860 (83%)]\tLoss: 0.024302\n",
            "Train Epoch: 85 [12544/14860 (84%)]\tLoss: 0.017484\n",
            "Train Epoch: 85 [12672/14860 (85%)]\tLoss: 0.021225\n",
            "Train Epoch: 85 [12800/14860 (85%)]\tLoss: 0.019574\n",
            "Train Epoch: 85 [12928/14860 (86%)]\tLoss: 0.019305\n",
            "Train Epoch: 85 [13056/14860 (87%)]\tLoss: 0.017441\n",
            "Train Epoch: 85 [13184/14860 (88%)]\tLoss: 0.014432\n",
            "Train Epoch: 85 [13312/14860 (89%)]\tLoss: 0.022123\n",
            "Train Epoch: 85 [13440/14860 (90%)]\tLoss: 0.023716\n",
            "Train Epoch: 85 [13568/14860 (91%)]\tLoss: 0.021180\n",
            "Train Epoch: 85 [13696/14860 (91%)]\tLoss: 0.024350\n",
            "Train Epoch: 85 [13824/14860 (92%)]\tLoss: 0.022514\n",
            "Train Epoch: 85 [13952/14860 (93%)]\tLoss: 0.022270\n",
            "Train Epoch: 85 [14080/14860 (94%)]\tLoss: 0.014341\n",
            "Train Epoch: 85 [14208/14860 (95%)]\tLoss: 0.035686\n",
            "Train Epoch: 85 [14336/14860 (96%)]\tLoss: 0.028494\n",
            "Train Epoch: 85 [14464/14860 (97%)]\tLoss: 0.018895\n",
            "Train Epoch: 85 [14592/14860 (97%)]\tLoss: 0.016322\n",
            "Train Epoch: 85 [14720/14860 (98%)]\tLoss: 0.029498\n",
            "Train Epoch: 85 [1392/14860 (99%)]\tLoss: 0.008562\n",
            "epoch 85 training loss: 0.021981471106728427\n",
            "epoch 85 validation loss: 0.03034134349869181\n",
            "Train Epoch: 86 [0/14860 (0%)]\tLoss: 0.026208\n",
            "Train Epoch: 86 [128/14860 (1%)]\tLoss: 0.022648\n",
            "Train Epoch: 86 [256/14860 (2%)]\tLoss: 0.033433\n",
            "Train Epoch: 86 [384/14860 (3%)]\tLoss: 0.030278\n",
            "Train Epoch: 86 [512/14860 (3%)]\tLoss: 0.019550\n",
            "Train Epoch: 86 [640/14860 (4%)]\tLoss: 0.028099\n",
            "Train Epoch: 86 [768/14860 (5%)]\tLoss: 0.013217\n",
            "Train Epoch: 86 [896/14860 (6%)]\tLoss: 0.026936\n",
            "Train Epoch: 86 [1024/14860 (7%)]\tLoss: 0.020583\n",
            "Train Epoch: 86 [1152/14860 (8%)]\tLoss: 0.027813\n",
            "Train Epoch: 86 [1280/14860 (9%)]\tLoss: 0.031866\n",
            "Train Epoch: 86 [1408/14860 (9%)]\tLoss: 0.020034\n",
            "Train Epoch: 86 [1536/14860 (10%)]\tLoss: 0.020498\n",
            "Train Epoch: 86 [1664/14860 (11%)]\tLoss: 0.022703\n",
            "Train Epoch: 86 [1792/14860 (12%)]\tLoss: 0.026756\n",
            "Train Epoch: 86 [1920/14860 (13%)]\tLoss: 0.028832\n",
            "Train Epoch: 86 [2048/14860 (14%)]\tLoss: 0.015725\n",
            "Train Epoch: 86 [2176/14860 (15%)]\tLoss: 0.018891\n",
            "Train Epoch: 86 [2304/14860 (15%)]\tLoss: 0.036898\n",
            "Train Epoch: 86 [2432/14860 (16%)]\tLoss: 0.028756\n",
            "Train Epoch: 86 [2560/14860 (17%)]\tLoss: 0.026959\n",
            "Train Epoch: 86 [2688/14860 (18%)]\tLoss: 0.032515\n",
            "Train Epoch: 86 [2816/14860 (19%)]\tLoss: 0.023345\n",
            "Train Epoch: 86 [2944/14860 (20%)]\tLoss: 0.023083\n",
            "Train Epoch: 86 [3072/14860 (21%)]\tLoss: 0.031035\n",
            "Train Epoch: 86 [3200/14860 (21%)]\tLoss: 0.016985\n",
            "Train Epoch: 86 [3328/14860 (22%)]\tLoss: 0.019080\n",
            "Train Epoch: 86 [3456/14860 (23%)]\tLoss: 0.033813\n",
            "Train Epoch: 86 [3584/14860 (24%)]\tLoss: 0.020439\n",
            "Train Epoch: 86 [3712/14860 (25%)]\tLoss: 0.034117\n",
            "Train Epoch: 86 [3840/14860 (26%)]\tLoss: 0.023948\n",
            "Train Epoch: 86 [3968/14860 (26%)]\tLoss: 0.028134\n",
            "Train Epoch: 86 [4096/14860 (27%)]\tLoss: 0.021894\n",
            "Train Epoch: 86 [4224/14860 (28%)]\tLoss: 0.013825\n",
            "Train Epoch: 86 [4352/14860 (29%)]\tLoss: 0.023440\n",
            "Train Epoch: 86 [4480/14860 (30%)]\tLoss: 0.014871\n",
            "Train Epoch: 86 [4608/14860 (31%)]\tLoss: 0.024756\n",
            "Train Epoch: 86 [4736/14860 (32%)]\tLoss: 0.019622\n",
            "Train Epoch: 86 [4864/14860 (32%)]\tLoss: 0.018164\n",
            "Train Epoch: 86 [4992/14860 (33%)]\tLoss: 0.032329\n",
            "Train Epoch: 86 [5120/14860 (34%)]\tLoss: 0.020901\n",
            "Train Epoch: 86 [5248/14860 (35%)]\tLoss: 0.017180\n",
            "Train Epoch: 86 [5376/14860 (36%)]\tLoss: 0.027954\n",
            "Train Epoch: 86 [5504/14860 (37%)]\tLoss: 0.019033\n",
            "Train Epoch: 86 [5632/14860 (38%)]\tLoss: 0.023035\n",
            "Train Epoch: 86 [5760/14860 (38%)]\tLoss: 0.023970\n",
            "Train Epoch: 86 [5888/14860 (39%)]\tLoss: 0.026497\n",
            "Train Epoch: 86 [6016/14860 (40%)]\tLoss: 0.012958\n",
            "Train Epoch: 86 [6144/14860 (41%)]\tLoss: 0.016721\n",
            "Train Epoch: 86 [6272/14860 (42%)]\tLoss: 0.017199\n",
            "Train Epoch: 86 [6400/14860 (43%)]\tLoss: 0.016555\n",
            "Train Epoch: 86 [6528/14860 (44%)]\tLoss: 0.018149\n",
            "Train Epoch: 86 [6656/14860 (44%)]\tLoss: 0.022836\n",
            "Train Epoch: 86 [6784/14860 (45%)]\tLoss: 0.024409\n",
            "Train Epoch: 86 [6912/14860 (46%)]\tLoss: 0.022351\n",
            "Train Epoch: 86 [7040/14860 (47%)]\tLoss: 0.018850\n",
            "Train Epoch: 86 [7168/14860 (48%)]\tLoss: 0.026866\n",
            "Train Epoch: 86 [7296/14860 (49%)]\tLoss: 0.016680\n",
            "Train Epoch: 86 [7424/14860 (50%)]\tLoss: 0.019965\n",
            "Train Epoch: 86 [7552/14860 (50%)]\tLoss: 0.017471\n",
            "Train Epoch: 86 [7680/14860 (51%)]\tLoss: 0.024498\n",
            "Train Epoch: 86 [7808/14860 (52%)]\tLoss: 0.029069\n",
            "Train Epoch: 86 [7936/14860 (53%)]\tLoss: 0.029803\n",
            "Train Epoch: 86 [8064/14860 (54%)]\tLoss: 0.021380\n",
            "Train Epoch: 86 [8192/14860 (55%)]\tLoss: 0.027594\n",
            "Train Epoch: 86 [8320/14860 (56%)]\tLoss: 0.026715\n",
            "Train Epoch: 86 [8448/14860 (56%)]\tLoss: 0.024597\n",
            "Train Epoch: 86 [8576/14860 (57%)]\tLoss: 0.017112\n",
            "Train Epoch: 86 [8704/14860 (58%)]\tLoss: 0.020670\n",
            "Train Epoch: 86 [8832/14860 (59%)]\tLoss: 0.028308\n",
            "Train Epoch: 86 [8960/14860 (60%)]\tLoss: 0.019957\n",
            "Train Epoch: 86 [9088/14860 (61%)]\tLoss: 0.022994\n",
            "Train Epoch: 86 [9216/14860 (62%)]\tLoss: 0.013864\n",
            "Train Epoch: 86 [9344/14860 (62%)]\tLoss: 0.030996\n",
            "Train Epoch: 86 [9472/14860 (63%)]\tLoss: 0.022577\n",
            "Train Epoch: 86 [9600/14860 (64%)]\tLoss: 0.022535\n",
            "Train Epoch: 86 [9728/14860 (65%)]\tLoss: 0.023522\n",
            "Train Epoch: 86 [9856/14860 (66%)]\tLoss: 0.014325\n",
            "Train Epoch: 86 [9984/14860 (67%)]\tLoss: 0.041855\n",
            "Train Epoch: 86 [10112/14860 (68%)]\tLoss: 0.020116\n",
            "Train Epoch: 86 [10240/14860 (68%)]\tLoss: 0.021875\n",
            "Train Epoch: 86 [10368/14860 (69%)]\tLoss: 0.022544\n",
            "Train Epoch: 86 [10496/14860 (70%)]\tLoss: 0.029313\n",
            "Train Epoch: 86 [10624/14860 (71%)]\tLoss: 0.026058\n",
            "Train Epoch: 86 [10752/14860 (72%)]\tLoss: 0.023453\n",
            "Train Epoch: 86 [10880/14860 (73%)]\tLoss: 0.033360\n",
            "Train Epoch: 86 [11008/14860 (74%)]\tLoss: 0.026015\n",
            "Train Epoch: 86 [11136/14860 (74%)]\tLoss: 0.019802\n",
            "Train Epoch: 86 [11264/14860 (75%)]\tLoss: 0.032645\n",
            "Train Epoch: 86 [11392/14860 (76%)]\tLoss: 0.019112\n",
            "Train Epoch: 86 [11520/14860 (77%)]\tLoss: 0.021764\n",
            "Train Epoch: 86 [11648/14860 (78%)]\tLoss: 0.019448\n",
            "Train Epoch: 86 [11776/14860 (79%)]\tLoss: 0.027417\n",
            "Train Epoch: 86 [11904/14860 (79%)]\tLoss: 0.016884\n",
            "Train Epoch: 86 [12032/14860 (80%)]\tLoss: 0.022538\n",
            "Train Epoch: 86 [12160/14860 (81%)]\tLoss: 0.019928\n",
            "Train Epoch: 86 [12288/14860 (82%)]\tLoss: 0.024301\n",
            "Train Epoch: 86 [12416/14860 (83%)]\tLoss: 0.015197\n",
            "Train Epoch: 86 [12544/14860 (84%)]\tLoss: 0.017919\n",
            "Train Epoch: 86 [12672/14860 (85%)]\tLoss: 0.020659\n",
            "Train Epoch: 86 [12800/14860 (85%)]\tLoss: 0.021403\n",
            "Train Epoch: 86 [12928/14860 (86%)]\tLoss: 0.025764\n",
            "Train Epoch: 86 [13056/14860 (87%)]\tLoss: 0.022117\n",
            "Train Epoch: 86 [13184/14860 (88%)]\tLoss: 0.016634\n",
            "Train Epoch: 86 [13312/14860 (89%)]\tLoss: 0.021865\n",
            "Train Epoch: 86 [13440/14860 (90%)]\tLoss: 0.020240\n",
            "Train Epoch: 86 [13568/14860 (91%)]\tLoss: 0.030268\n",
            "Train Epoch: 86 [13696/14860 (91%)]\tLoss: 0.015633\n",
            "Train Epoch: 86 [13824/14860 (92%)]\tLoss: 0.025023\n",
            "Train Epoch: 86 [13952/14860 (93%)]\tLoss: 0.017431\n",
            "Train Epoch: 86 [14080/14860 (94%)]\tLoss: 0.017675\n",
            "Train Epoch: 86 [14208/14860 (95%)]\tLoss: 0.021464\n",
            "Train Epoch: 86 [14336/14860 (96%)]\tLoss: 0.013739\n",
            "Train Epoch: 86 [14464/14860 (97%)]\tLoss: 0.024821\n",
            "Train Epoch: 86 [14592/14860 (97%)]\tLoss: 0.013534\n",
            "Train Epoch: 86 [14720/14860 (98%)]\tLoss: 0.019828\n",
            "Train Epoch: 86 [1392/14860 (99%)]\tLoss: 0.005389\n",
            "epoch 86 training loss: 0.02279666114725873\n",
            "epoch 86 validation loss: 0.026735206781807592\n",
            "Train Epoch: 87 [0/14860 (0%)]\tLoss: 0.019207\n",
            "Train Epoch: 87 [128/14860 (1%)]\tLoss: 0.033106\n",
            "Train Epoch: 87 [256/14860 (2%)]\tLoss: 0.032692\n",
            "Train Epoch: 87 [384/14860 (3%)]\tLoss: 0.019905\n",
            "Train Epoch: 87 [512/14860 (3%)]\tLoss: 0.031554\n",
            "Train Epoch: 87 [640/14860 (4%)]\tLoss: 0.014906\n",
            "Train Epoch: 87 [768/14860 (5%)]\tLoss: 0.019471\n",
            "Train Epoch: 87 [896/14860 (6%)]\tLoss: 0.026512\n",
            "Train Epoch: 87 [1024/14860 (7%)]\tLoss: 0.013117\n",
            "Train Epoch: 87 [1152/14860 (8%)]\tLoss: 0.025156\n",
            "Train Epoch: 87 [1280/14860 (9%)]\tLoss: 0.019628\n",
            "Train Epoch: 87 [1408/14860 (9%)]\tLoss: 0.025092\n",
            "Train Epoch: 87 [1536/14860 (10%)]\tLoss: 0.028873\n",
            "Train Epoch: 87 [1664/14860 (11%)]\tLoss: 0.019173\n",
            "Train Epoch: 87 [1792/14860 (12%)]\tLoss: 0.021474\n",
            "Train Epoch: 87 [1920/14860 (13%)]\tLoss: 0.026351\n",
            "Train Epoch: 87 [2048/14860 (14%)]\tLoss: 0.020238\n",
            "Train Epoch: 87 [2176/14860 (15%)]\tLoss: 0.027114\n",
            "Train Epoch: 87 [2304/14860 (15%)]\tLoss: 0.015231\n",
            "Train Epoch: 87 [2432/14860 (16%)]\tLoss: 0.039504\n",
            "Train Epoch: 87 [2560/14860 (17%)]\tLoss: 0.013060\n",
            "Train Epoch: 87 [2688/14860 (18%)]\tLoss: 0.022045\n",
            "Train Epoch: 87 [2816/14860 (19%)]\tLoss: 0.023547\n",
            "Train Epoch: 87 [2944/14860 (20%)]\tLoss: 0.029379\n",
            "Train Epoch: 87 [3072/14860 (21%)]\tLoss: 0.025593\n",
            "Train Epoch: 87 [3200/14860 (21%)]\tLoss: 0.019396\n",
            "Train Epoch: 87 [3328/14860 (22%)]\tLoss: 0.021779\n",
            "Train Epoch: 87 [3456/14860 (23%)]\tLoss: 0.027684\n",
            "Train Epoch: 87 [3584/14860 (24%)]\tLoss: 0.022107\n",
            "Train Epoch: 87 [3712/14860 (25%)]\tLoss: 0.023513\n",
            "Train Epoch: 87 [3840/14860 (26%)]\tLoss: 0.020511\n",
            "Train Epoch: 87 [3968/14860 (26%)]\tLoss: 0.016177\n",
            "Train Epoch: 87 [4096/14860 (27%)]\tLoss: 0.019720\n",
            "Train Epoch: 87 [4224/14860 (28%)]\tLoss: 0.018255\n",
            "Train Epoch: 87 [4352/14860 (29%)]\tLoss: 0.019844\n",
            "Train Epoch: 87 [4480/14860 (30%)]\tLoss: 0.018150\n",
            "Train Epoch: 87 [4608/14860 (31%)]\tLoss: 0.016632\n",
            "Train Epoch: 87 [4736/14860 (32%)]\tLoss: 0.030562\n",
            "Train Epoch: 87 [4864/14860 (32%)]\tLoss: 0.017917\n",
            "Train Epoch: 87 [4992/14860 (33%)]\tLoss: 0.026598\n",
            "Train Epoch: 87 [5120/14860 (34%)]\tLoss: 0.024246\n",
            "Train Epoch: 87 [5248/14860 (35%)]\tLoss: 0.025882\n",
            "Train Epoch: 87 [5376/14860 (36%)]\tLoss: 0.024289\n",
            "Train Epoch: 87 [5504/14860 (37%)]\tLoss: 0.031122\n",
            "Train Epoch: 87 [5632/14860 (38%)]\tLoss: 0.021303\n",
            "Train Epoch: 87 [5760/14860 (38%)]\tLoss: 0.022300\n",
            "Train Epoch: 87 [5888/14860 (39%)]\tLoss: 0.017826\n",
            "Train Epoch: 87 [6016/14860 (40%)]\tLoss: 0.022605\n",
            "Train Epoch: 87 [6144/14860 (41%)]\tLoss: 0.025653\n",
            "Train Epoch: 87 [6272/14860 (42%)]\tLoss: 0.026084\n",
            "Train Epoch: 87 [6400/14860 (43%)]\tLoss: 0.014980\n",
            "Train Epoch: 87 [6528/14860 (44%)]\tLoss: 0.020096\n",
            "Train Epoch: 87 [6656/14860 (44%)]\tLoss: 0.027564\n",
            "Train Epoch: 87 [6784/14860 (45%)]\tLoss: 0.018521\n",
            "Train Epoch: 87 [6912/14860 (46%)]\tLoss: 0.017890\n",
            "Train Epoch: 87 [7040/14860 (47%)]\tLoss: 0.022610\n",
            "Train Epoch: 87 [7168/14860 (48%)]\tLoss: 0.021100\n",
            "Train Epoch: 87 [7296/14860 (49%)]\tLoss: 0.024196\n",
            "Train Epoch: 87 [7424/14860 (50%)]\tLoss: 0.013239\n",
            "Train Epoch: 87 [7552/14860 (50%)]\tLoss: 0.014970\n",
            "Train Epoch: 87 [7680/14860 (51%)]\tLoss: 0.020641\n",
            "Train Epoch: 87 [7808/14860 (52%)]\tLoss: 0.021101\n",
            "Train Epoch: 87 [7936/14860 (53%)]\tLoss: 0.021885\n",
            "Train Epoch: 87 [8064/14860 (54%)]\tLoss: 0.017836\n",
            "Train Epoch: 87 [8192/14860 (55%)]\tLoss: 0.015486\n",
            "Train Epoch: 87 [8320/14860 (56%)]\tLoss: 0.018718\n",
            "Train Epoch: 87 [8448/14860 (56%)]\tLoss: 0.020320\n",
            "Train Epoch: 87 [8576/14860 (57%)]\tLoss: 0.031098\n",
            "Train Epoch: 87 [8704/14860 (58%)]\tLoss: 0.019798\n",
            "Train Epoch: 87 [8832/14860 (59%)]\tLoss: 0.018888\n",
            "Train Epoch: 87 [8960/14860 (60%)]\tLoss: 0.022832\n",
            "Train Epoch: 87 [9088/14860 (61%)]\tLoss: 0.014295\n",
            "Train Epoch: 87 [9216/14860 (62%)]\tLoss: 0.023114\n",
            "Train Epoch: 87 [9344/14860 (62%)]\tLoss: 0.016467\n",
            "Train Epoch: 87 [9472/14860 (63%)]\tLoss: 0.030787\n",
            "Train Epoch: 87 [9600/14860 (64%)]\tLoss: 0.020579\n",
            "Train Epoch: 87 [9728/14860 (65%)]\tLoss: 0.019566\n",
            "Train Epoch: 87 [9856/14860 (66%)]\tLoss: 0.019996\n",
            "Train Epoch: 87 [9984/14860 (67%)]\tLoss: 0.017427\n",
            "Train Epoch: 87 [10112/14860 (68%)]\tLoss: 0.021757\n",
            "Train Epoch: 87 [10240/14860 (68%)]\tLoss: 0.020879\n",
            "Train Epoch: 87 [10368/14860 (69%)]\tLoss: 0.018860\n",
            "Train Epoch: 87 [10496/14860 (70%)]\tLoss: 0.009320\n",
            "Train Epoch: 87 [10624/14860 (71%)]\tLoss: 0.022088\n",
            "Train Epoch: 87 [10752/14860 (72%)]\tLoss: 0.020687\n",
            "Train Epoch: 87 [10880/14860 (73%)]\tLoss: 0.013860\n",
            "Train Epoch: 87 [11008/14860 (74%)]\tLoss: 0.019310\n",
            "Train Epoch: 87 [11136/14860 (74%)]\tLoss: 0.020288\n",
            "Train Epoch: 87 [11264/14860 (75%)]\tLoss: 0.017491\n",
            "Train Epoch: 87 [11392/14860 (76%)]\tLoss: 0.020941\n",
            "Train Epoch: 87 [11520/14860 (77%)]\tLoss: 0.019430\n",
            "Train Epoch: 87 [11648/14860 (78%)]\tLoss: 0.018527\n",
            "Train Epoch: 87 [11776/14860 (79%)]\tLoss: 0.017863\n",
            "Train Epoch: 87 [11904/14860 (79%)]\tLoss: 0.021739\n",
            "Train Epoch: 87 [12032/14860 (80%)]\tLoss: 0.014249\n",
            "Train Epoch: 87 [12160/14860 (81%)]\tLoss: 0.023503\n",
            "Train Epoch: 87 [12288/14860 (82%)]\tLoss: 0.020285\n",
            "Train Epoch: 87 [12416/14860 (83%)]\tLoss: 0.025600\n",
            "Train Epoch: 87 [12544/14860 (84%)]\tLoss: 0.017510\n",
            "Train Epoch: 87 [12672/14860 (85%)]\tLoss: 0.021513\n",
            "Train Epoch: 87 [12800/14860 (85%)]\tLoss: 0.019861\n",
            "Train Epoch: 87 [12928/14860 (86%)]\tLoss: 0.017794\n",
            "Train Epoch: 87 [13056/14860 (87%)]\tLoss: 0.018607\n",
            "Train Epoch: 87 [13184/14860 (88%)]\tLoss: 0.022000\n",
            "Train Epoch: 87 [13312/14860 (89%)]\tLoss: 0.012492\n",
            "Train Epoch: 87 [13440/14860 (90%)]\tLoss: 0.019334\n",
            "Train Epoch: 87 [13568/14860 (91%)]\tLoss: 0.030775\n",
            "Train Epoch: 87 [13696/14860 (91%)]\tLoss: 0.020332\n",
            "Train Epoch: 87 [13824/14860 (92%)]\tLoss: 0.027115\n",
            "Train Epoch: 87 [13952/14860 (93%)]\tLoss: 0.014132\n",
            "Train Epoch: 87 [14080/14860 (94%)]\tLoss: 0.028396\n",
            "Train Epoch: 87 [14208/14860 (95%)]\tLoss: 0.018053\n",
            "Train Epoch: 87 [14336/14860 (96%)]\tLoss: 0.033369\n",
            "Train Epoch: 87 [14464/14860 (97%)]\tLoss: 0.026894\n",
            "Train Epoch: 87 [14592/14860 (97%)]\tLoss: 0.027835\n",
            "Train Epoch: 87 [14720/14860 (98%)]\tLoss: 0.015966\n",
            "Train Epoch: 87 [1392/14860 (99%)]\tLoss: 0.007133\n",
            "epoch 87 training loss: 0.02140060690844543\n",
            "epoch 87 validation loss: 0.027263758979178515\n",
            "Train Epoch: 88 [0/14860 (0%)]\tLoss: 0.020257\n",
            "Train Epoch: 88 [128/14860 (1%)]\tLoss: 0.022923\n",
            "Train Epoch: 88 [256/14860 (2%)]\tLoss: 0.019172\n",
            "Train Epoch: 88 [384/14860 (3%)]\tLoss: 0.015651\n",
            "Train Epoch: 88 [512/14860 (3%)]\tLoss: 0.024816\n",
            "Train Epoch: 88 [640/14860 (4%)]\tLoss: 0.022134\n",
            "Train Epoch: 88 [768/14860 (5%)]\tLoss: 0.021525\n",
            "Train Epoch: 88 [896/14860 (6%)]\tLoss: 0.015343\n",
            "Train Epoch: 88 [1024/14860 (7%)]\tLoss: 0.026012\n",
            "Train Epoch: 88 [1152/14860 (8%)]\tLoss: 0.014135\n",
            "Train Epoch: 88 [1280/14860 (9%)]\tLoss: 0.017228\n",
            "Train Epoch: 88 [1408/14860 (9%)]\tLoss: 0.014838\n",
            "Train Epoch: 88 [1536/14860 (10%)]\tLoss: 0.016439\n",
            "Train Epoch: 88 [1664/14860 (11%)]\tLoss: 0.012159\n",
            "Train Epoch: 88 [1792/14860 (12%)]\tLoss: 0.024641\n",
            "Train Epoch: 88 [1920/14860 (13%)]\tLoss: 0.020703\n",
            "Train Epoch: 88 [2048/14860 (14%)]\tLoss: 0.025590\n",
            "Train Epoch: 88 [2176/14860 (15%)]\tLoss: 0.017607\n",
            "Train Epoch: 88 [2304/14860 (15%)]\tLoss: 0.020888\n",
            "Train Epoch: 88 [2432/14860 (16%)]\tLoss: 0.016471\n",
            "Train Epoch: 88 [2560/14860 (17%)]\tLoss: 0.022859\n",
            "Train Epoch: 88 [2688/14860 (18%)]\tLoss: 0.020527\n",
            "Train Epoch: 88 [2816/14860 (19%)]\tLoss: 0.018017\n",
            "Train Epoch: 88 [2944/14860 (20%)]\tLoss: 0.017835\n",
            "Train Epoch: 88 [3072/14860 (21%)]\tLoss: 0.024919\n",
            "Train Epoch: 88 [3200/14860 (21%)]\tLoss: 0.017937\n",
            "Train Epoch: 88 [3328/14860 (22%)]\tLoss: 0.015893\n",
            "Train Epoch: 88 [3456/14860 (23%)]\tLoss: 0.024447\n",
            "Train Epoch: 88 [3584/14860 (24%)]\tLoss: 0.022396\n",
            "Train Epoch: 88 [3712/14860 (25%)]\tLoss: 0.021165\n",
            "Train Epoch: 88 [3840/14860 (26%)]\tLoss: 0.025293\n",
            "Train Epoch: 88 [3968/14860 (26%)]\tLoss: 0.014445\n",
            "Train Epoch: 88 [4096/14860 (27%)]\tLoss: 0.018514\n",
            "Train Epoch: 88 [4224/14860 (28%)]\tLoss: 0.019565\n",
            "Train Epoch: 88 [4352/14860 (29%)]\tLoss: 0.018483\n",
            "Train Epoch: 88 [4480/14860 (30%)]\tLoss: 0.017555\n",
            "Train Epoch: 88 [4608/14860 (31%)]\tLoss: 0.025702\n",
            "Train Epoch: 88 [4736/14860 (32%)]\tLoss: 0.028060\n",
            "Train Epoch: 88 [4864/14860 (32%)]\tLoss: 0.022182\n",
            "Train Epoch: 88 [4992/14860 (33%)]\tLoss: 0.029849\n",
            "Train Epoch: 88 [5120/14860 (34%)]\tLoss: 0.020345\n",
            "Train Epoch: 88 [5248/14860 (35%)]\tLoss: 0.021978\n",
            "Train Epoch: 88 [5376/14860 (36%)]\tLoss: 0.014793\n",
            "Train Epoch: 88 [5504/14860 (37%)]\tLoss: 0.027603\n",
            "Train Epoch: 88 [5632/14860 (38%)]\tLoss: 0.017173\n",
            "Train Epoch: 88 [5760/14860 (38%)]\tLoss: 0.028367\n",
            "Train Epoch: 88 [5888/14860 (39%)]\tLoss: 0.022321\n",
            "Train Epoch: 88 [6016/14860 (40%)]\tLoss: 0.014652\n",
            "Train Epoch: 88 [6144/14860 (41%)]\tLoss: 0.019416\n",
            "Train Epoch: 88 [6272/14860 (42%)]\tLoss: 0.015008\n",
            "Train Epoch: 88 [6400/14860 (43%)]\tLoss: 0.026687\n",
            "Train Epoch: 88 [6528/14860 (44%)]\tLoss: 0.019549\n",
            "Train Epoch: 88 [6656/14860 (44%)]\tLoss: 0.024895\n",
            "Train Epoch: 88 [6784/14860 (45%)]\tLoss: 0.018102\n",
            "Train Epoch: 88 [6912/14860 (46%)]\tLoss: 0.016883\n",
            "Train Epoch: 88 [7040/14860 (47%)]\tLoss: 0.023068\n",
            "Train Epoch: 88 [7168/14860 (48%)]\tLoss: 0.017959\n",
            "Train Epoch: 88 [7296/14860 (49%)]\tLoss: 0.022498\n",
            "Train Epoch: 88 [7424/14860 (50%)]\tLoss: 0.017552\n",
            "Train Epoch: 88 [7552/14860 (50%)]\tLoss: 0.020819\n",
            "Train Epoch: 88 [7680/14860 (51%)]\tLoss: 0.021049\n",
            "Train Epoch: 88 [7808/14860 (52%)]\tLoss: 0.025218\n",
            "Train Epoch: 88 [7936/14860 (53%)]\tLoss: 0.016581\n",
            "Train Epoch: 88 [8064/14860 (54%)]\tLoss: 0.025691\n",
            "Train Epoch: 88 [8192/14860 (55%)]\tLoss: 0.021627\n",
            "Train Epoch: 88 [8320/14860 (56%)]\tLoss: 0.020781\n",
            "Train Epoch: 88 [8448/14860 (56%)]\tLoss: 0.023987\n",
            "Train Epoch: 88 [8576/14860 (57%)]\tLoss: 0.020734\n",
            "Train Epoch: 88 [8704/14860 (58%)]\tLoss: 0.020803\n",
            "Train Epoch: 88 [8832/14860 (59%)]\tLoss: 0.025589\n",
            "Train Epoch: 88 [8960/14860 (60%)]\tLoss: 0.017865\n",
            "Train Epoch: 88 [9088/14860 (61%)]\tLoss: 0.031410\n",
            "Train Epoch: 88 [9216/14860 (62%)]\tLoss: 0.013438\n",
            "Train Epoch: 88 [9344/14860 (62%)]\tLoss: 0.034677\n",
            "Train Epoch: 88 [9472/14860 (63%)]\tLoss: 0.019039\n",
            "Train Epoch: 88 [9600/14860 (64%)]\tLoss: 0.017765\n",
            "Train Epoch: 88 [9728/14860 (65%)]\tLoss: 0.012745\n",
            "Train Epoch: 88 [9856/14860 (66%)]\tLoss: 0.016456\n",
            "Train Epoch: 88 [9984/14860 (67%)]\tLoss: 0.019090\n",
            "Train Epoch: 88 [10112/14860 (68%)]\tLoss: 0.020233\n",
            "Train Epoch: 88 [10240/14860 (68%)]\tLoss: 0.027118\n",
            "Train Epoch: 88 [10368/14860 (69%)]\tLoss: 0.020838\n",
            "Train Epoch: 88 [10496/14860 (70%)]\tLoss: 0.021139\n",
            "Train Epoch: 88 [10624/14860 (71%)]\tLoss: 0.014204\n",
            "Train Epoch: 88 [10752/14860 (72%)]\tLoss: 0.018445\n",
            "Train Epoch: 88 [10880/14860 (73%)]\tLoss: 0.012698\n",
            "Train Epoch: 88 [11008/14860 (74%)]\tLoss: 0.015815\n",
            "Train Epoch: 88 [11136/14860 (74%)]\tLoss: 0.015076\n",
            "Train Epoch: 88 [11264/14860 (75%)]\tLoss: 0.019178\n",
            "Train Epoch: 88 [11392/14860 (76%)]\tLoss: 0.022201\n",
            "Train Epoch: 88 [11520/14860 (77%)]\tLoss: 0.020297\n",
            "Train Epoch: 88 [11648/14860 (78%)]\tLoss: 0.021024\n",
            "Train Epoch: 88 [11776/14860 (79%)]\tLoss: 0.038380\n",
            "Train Epoch: 88 [11904/14860 (79%)]\tLoss: 0.018305\n",
            "Train Epoch: 88 [12032/14860 (80%)]\tLoss: 0.025140\n",
            "Train Epoch: 88 [12160/14860 (81%)]\tLoss: 0.017739\n",
            "Train Epoch: 88 [12288/14860 (82%)]\tLoss: 0.024160\n",
            "Train Epoch: 88 [12416/14860 (83%)]\tLoss: 0.027684\n",
            "Train Epoch: 88 [12544/14860 (84%)]\tLoss: 0.015808\n",
            "Train Epoch: 88 [12672/14860 (85%)]\tLoss: 0.024483\n",
            "Train Epoch: 88 [12800/14860 (85%)]\tLoss: 0.019650\n",
            "Train Epoch: 88 [12928/14860 (86%)]\tLoss: 0.031564\n",
            "Train Epoch: 88 [13056/14860 (87%)]\tLoss: 0.024423\n",
            "Train Epoch: 88 [13184/14860 (88%)]\tLoss: 0.018303\n",
            "Train Epoch: 88 [13312/14860 (89%)]\tLoss: 0.015216\n",
            "Train Epoch: 88 [13440/14860 (90%)]\tLoss: 0.019759\n",
            "Train Epoch: 88 [13568/14860 (91%)]\tLoss: 0.016414\n",
            "Train Epoch: 88 [13696/14860 (91%)]\tLoss: 0.017907\n",
            "Train Epoch: 88 [13824/14860 (92%)]\tLoss: 0.017514\n",
            "Train Epoch: 88 [13952/14860 (93%)]\tLoss: 0.015878\n",
            "Train Epoch: 88 [14080/14860 (94%)]\tLoss: 0.017703\n",
            "Train Epoch: 88 [14208/14860 (95%)]\tLoss: 0.019348\n",
            "Train Epoch: 88 [14336/14860 (96%)]\tLoss: 0.019208\n",
            "Train Epoch: 88 [14464/14860 (97%)]\tLoss: 0.020251\n",
            "Train Epoch: 88 [14592/14860 (97%)]\tLoss: 0.020513\n",
            "Train Epoch: 88 [14720/14860 (98%)]\tLoss: 0.015134\n",
            "Train Epoch: 88 [1392/14860 (99%)]\tLoss: 0.014593\n",
            "epoch 88 training loss: 0.02044212619145202\n",
            "epoch 88 validation loss: 0.024666075989351433\n",
            "Train Epoch: 89 [0/14860 (0%)]\tLoss: 0.022433\n",
            "Train Epoch: 89 [128/14860 (1%)]\tLoss: 0.020761\n",
            "Train Epoch: 89 [256/14860 (2%)]\tLoss: 0.019714\n",
            "Train Epoch: 89 [384/14860 (3%)]\tLoss: 0.016973\n",
            "Train Epoch: 89 [512/14860 (3%)]\tLoss: 0.019646\n",
            "Train Epoch: 89 [640/14860 (4%)]\tLoss: 0.020227\n",
            "Train Epoch: 89 [768/14860 (5%)]\tLoss: 0.017685\n",
            "Train Epoch: 89 [896/14860 (6%)]\tLoss: 0.018829\n",
            "Train Epoch: 89 [1024/14860 (7%)]\tLoss: 0.025192\n",
            "Train Epoch: 89 [1152/14860 (8%)]\tLoss: 0.022029\n",
            "Train Epoch: 89 [1280/14860 (9%)]\tLoss: 0.018735\n",
            "Train Epoch: 89 [1408/14860 (9%)]\tLoss: 0.017830\n",
            "Train Epoch: 89 [1536/14860 (10%)]\tLoss: 0.014867\n",
            "Train Epoch: 89 [1664/14860 (11%)]\tLoss: 0.017549\n",
            "Train Epoch: 89 [1792/14860 (12%)]\tLoss: 0.022084\n",
            "Train Epoch: 89 [1920/14860 (13%)]\tLoss: 0.022481\n",
            "Train Epoch: 89 [2048/14860 (14%)]\tLoss: 0.019541\n",
            "Train Epoch: 89 [2176/14860 (15%)]\tLoss: 0.023444\n",
            "Train Epoch: 89 [2304/14860 (15%)]\tLoss: 0.018741\n",
            "Train Epoch: 89 [2432/14860 (16%)]\tLoss: 0.019346\n",
            "Train Epoch: 89 [2560/14860 (17%)]\tLoss: 0.013967\n",
            "Train Epoch: 89 [2688/14860 (18%)]\tLoss: 0.012152\n",
            "Train Epoch: 89 [2816/14860 (19%)]\tLoss: 0.027577\n",
            "Train Epoch: 89 [2944/14860 (20%)]\tLoss: 0.023125\n",
            "Train Epoch: 89 [3072/14860 (21%)]\tLoss: 0.018169\n",
            "Train Epoch: 89 [3200/14860 (21%)]\tLoss: 0.024513\n",
            "Train Epoch: 89 [3328/14860 (22%)]\tLoss: 0.021134\n",
            "Train Epoch: 89 [3456/14860 (23%)]\tLoss: 0.018538\n",
            "Train Epoch: 89 [3584/14860 (24%)]\tLoss: 0.018311\n",
            "Train Epoch: 89 [3712/14860 (25%)]\tLoss: 0.021794\n",
            "Train Epoch: 89 [3840/14860 (26%)]\tLoss: 0.024789\n",
            "Train Epoch: 89 [3968/14860 (26%)]\tLoss: 0.020205\n",
            "Train Epoch: 89 [4096/14860 (27%)]\tLoss: 0.026278\n",
            "Train Epoch: 89 [4224/14860 (28%)]\tLoss: 0.015492\n",
            "Train Epoch: 89 [4352/14860 (29%)]\tLoss: 0.018635\n",
            "Train Epoch: 89 [4480/14860 (30%)]\tLoss: 0.015935\n",
            "Train Epoch: 89 [4608/14860 (31%)]\tLoss: 0.021735\n",
            "Train Epoch: 89 [4736/14860 (32%)]\tLoss: 0.022762\n",
            "Train Epoch: 89 [4864/14860 (32%)]\tLoss: 0.025172\n",
            "Train Epoch: 89 [4992/14860 (33%)]\tLoss: 0.020267\n",
            "Train Epoch: 89 [5120/14860 (34%)]\tLoss: 0.018730\n",
            "Train Epoch: 89 [5248/14860 (35%)]\tLoss: 0.018567\n",
            "Train Epoch: 89 [5376/14860 (36%)]\tLoss: 0.021748\n",
            "Train Epoch: 89 [5504/14860 (37%)]\tLoss: 0.015687\n",
            "Train Epoch: 89 [5632/14860 (38%)]\tLoss: 0.015989\n",
            "Train Epoch: 89 [5760/14860 (38%)]\tLoss: 0.016926\n",
            "Train Epoch: 89 [5888/14860 (39%)]\tLoss: 0.014928\n",
            "Train Epoch: 89 [6016/14860 (40%)]\tLoss: 0.028448\n",
            "Train Epoch: 89 [6144/14860 (41%)]\tLoss: 0.016823\n",
            "Train Epoch: 89 [6272/14860 (42%)]\tLoss: 0.020997\n",
            "Train Epoch: 89 [6400/14860 (43%)]\tLoss: 0.017388\n",
            "Train Epoch: 89 [6528/14860 (44%)]\tLoss: 0.016864\n",
            "Train Epoch: 89 [6656/14860 (44%)]\tLoss: 0.020842\n",
            "Train Epoch: 89 [6784/14860 (45%)]\tLoss: 0.021466\n",
            "Train Epoch: 89 [6912/14860 (46%)]\tLoss: 0.028432\n",
            "Train Epoch: 89 [7040/14860 (47%)]\tLoss: 0.020991\n",
            "Train Epoch: 89 [7168/14860 (48%)]\tLoss: 0.015674\n",
            "Train Epoch: 89 [7296/14860 (49%)]\tLoss: 0.026916\n",
            "Train Epoch: 89 [7424/14860 (50%)]\tLoss: 0.025118\n",
            "Train Epoch: 89 [7552/14860 (50%)]\tLoss: 0.031645\n",
            "Train Epoch: 89 [7680/14860 (51%)]\tLoss: 0.027662\n",
            "Train Epoch: 89 [7808/14860 (52%)]\tLoss: 0.023051\n",
            "Train Epoch: 89 [7936/14860 (53%)]\tLoss: 0.025784\n",
            "Train Epoch: 89 [8064/14860 (54%)]\tLoss: 0.021355\n",
            "Train Epoch: 89 [8192/14860 (55%)]\tLoss: 0.028071\n",
            "Train Epoch: 89 [8320/14860 (56%)]\tLoss: 0.019096\n",
            "Train Epoch: 89 [8448/14860 (56%)]\tLoss: 0.025683\n",
            "Train Epoch: 89 [8576/14860 (57%)]\tLoss: 0.016464\n",
            "Train Epoch: 89 [8704/14860 (58%)]\tLoss: 0.024912\n",
            "Train Epoch: 89 [8832/14860 (59%)]\tLoss: 0.020497\n",
            "Train Epoch: 89 [8960/14860 (60%)]\tLoss: 0.020997\n",
            "Train Epoch: 89 [9088/14860 (61%)]\tLoss: 0.017551\n",
            "Train Epoch: 89 [9216/14860 (62%)]\tLoss: 0.020343\n",
            "Train Epoch: 89 [9344/14860 (62%)]\tLoss: 0.017348\n",
            "Train Epoch: 89 [9472/14860 (63%)]\tLoss: 0.018146\n",
            "Train Epoch: 89 [9600/14860 (64%)]\tLoss: 0.020972\n",
            "Train Epoch: 89 [9728/14860 (65%)]\tLoss: 0.017945\n",
            "Train Epoch: 89 [9856/14860 (66%)]\tLoss: 0.026384\n",
            "Train Epoch: 89 [9984/14860 (67%)]\tLoss: 0.014960\n",
            "Train Epoch: 89 [10112/14860 (68%)]\tLoss: 0.020773\n",
            "Train Epoch: 89 [10240/14860 (68%)]\tLoss: 0.022541\n",
            "Train Epoch: 89 [10368/14860 (69%)]\tLoss: 0.017316\n",
            "Train Epoch: 89 [10496/14860 (70%)]\tLoss: 0.017695\n",
            "Train Epoch: 89 [10624/14860 (71%)]\tLoss: 0.025320\n",
            "Train Epoch: 89 [10752/14860 (72%)]\tLoss: 0.019218\n",
            "Train Epoch: 89 [10880/14860 (73%)]\tLoss: 0.026341\n",
            "Train Epoch: 89 [11008/14860 (74%)]\tLoss: 0.034852\n",
            "Train Epoch: 89 [11136/14860 (74%)]\tLoss: 0.020454\n",
            "Train Epoch: 89 [11264/14860 (75%)]\tLoss: 0.018938\n",
            "Train Epoch: 89 [11392/14860 (76%)]\tLoss: 0.019527\n",
            "Train Epoch: 89 [11520/14860 (77%)]\tLoss: 0.018719\n",
            "Train Epoch: 89 [11648/14860 (78%)]\tLoss: 0.020892\n",
            "Train Epoch: 89 [11776/14860 (79%)]\tLoss: 0.015295\n",
            "Train Epoch: 89 [11904/14860 (79%)]\tLoss: 0.017496\n",
            "Train Epoch: 89 [12032/14860 (80%)]\tLoss: 0.018354\n",
            "Train Epoch: 89 [12160/14860 (81%)]\tLoss: 0.021990\n",
            "Train Epoch: 89 [12288/14860 (82%)]\tLoss: 0.016291\n",
            "Train Epoch: 89 [12416/14860 (83%)]\tLoss: 0.020651\n",
            "Train Epoch: 89 [12544/14860 (84%)]\tLoss: 0.014291\n",
            "Train Epoch: 89 [12672/14860 (85%)]\tLoss: 0.015660\n",
            "Train Epoch: 89 [12800/14860 (85%)]\tLoss: 0.022739\n",
            "Train Epoch: 89 [12928/14860 (86%)]\tLoss: 0.015870\n",
            "Train Epoch: 89 [13056/14860 (87%)]\tLoss: 0.021428\n",
            "Train Epoch: 89 [13184/14860 (88%)]\tLoss: 0.030504\n",
            "Train Epoch: 89 [13312/14860 (89%)]\tLoss: 0.027694\n",
            "Train Epoch: 89 [13440/14860 (90%)]\tLoss: 0.022961\n",
            "Train Epoch: 89 [13568/14860 (91%)]\tLoss: 0.019420\n",
            "Train Epoch: 89 [13696/14860 (91%)]\tLoss: 0.023940\n",
            "Train Epoch: 89 [13824/14860 (92%)]\tLoss: 0.022199\n",
            "Train Epoch: 89 [13952/14860 (93%)]\tLoss: 0.037650\n",
            "Train Epoch: 89 [14080/14860 (94%)]\tLoss: 0.016380\n",
            "Train Epoch: 89 [14208/14860 (95%)]\tLoss: 0.023528\n",
            "Train Epoch: 89 [14336/14860 (96%)]\tLoss: 0.022422\n",
            "Train Epoch: 89 [14464/14860 (97%)]\tLoss: 0.028889\n",
            "Train Epoch: 89 [14592/14860 (97%)]\tLoss: 0.023398\n",
            "Train Epoch: 89 [14720/14860 (98%)]\tLoss: 0.032577\n",
            "Train Epoch: 89 [1392/14860 (99%)]\tLoss: 0.029692\n",
            "epoch 89 training loss: 0.021145002367213752\n",
            "epoch 89 validation loss: 0.03283592806024067\n",
            "Train Epoch: 90 [0/14860 (0%)]\tLoss: 0.028701\n",
            "Train Epoch: 90 [128/14860 (1%)]\tLoss: 0.020460\n",
            "Train Epoch: 90 [256/14860 (2%)]\tLoss: 0.027329\n",
            "Train Epoch: 90 [384/14860 (3%)]\tLoss: 0.022369\n",
            "Train Epoch: 90 [512/14860 (3%)]\tLoss: 0.024137\n",
            "Train Epoch: 90 [640/14860 (4%)]\tLoss: 0.021965\n",
            "Train Epoch: 90 [768/14860 (5%)]\tLoss: 0.023765\n",
            "Train Epoch: 90 [896/14860 (6%)]\tLoss: 0.017960\n",
            "Train Epoch: 90 [1024/14860 (7%)]\tLoss: 0.021593\n",
            "Train Epoch: 90 [1152/14860 (8%)]\tLoss: 0.034267\n",
            "Train Epoch: 90 [1280/14860 (9%)]\tLoss: 0.015929\n",
            "Train Epoch: 90 [1408/14860 (9%)]\tLoss: 0.029579\n",
            "Train Epoch: 90 [1536/14860 (10%)]\tLoss: 0.018514\n",
            "Train Epoch: 90 [1664/14860 (11%)]\tLoss: 0.022202\n",
            "Train Epoch: 90 [1792/14860 (12%)]\tLoss: 0.014329\n",
            "Train Epoch: 90 [1920/14860 (13%)]\tLoss: 0.018078\n",
            "Train Epoch: 90 [2048/14860 (14%)]\tLoss: 0.017950\n",
            "Train Epoch: 90 [2176/14860 (15%)]\tLoss: 0.027095\n",
            "Train Epoch: 90 [2304/14860 (15%)]\tLoss: 0.017301\n",
            "Train Epoch: 90 [2432/14860 (16%)]\tLoss: 0.030046\n",
            "Train Epoch: 90 [2560/14860 (17%)]\tLoss: 0.022069\n",
            "Train Epoch: 90 [2688/14860 (18%)]\tLoss: 0.023286\n",
            "Train Epoch: 90 [2816/14860 (19%)]\tLoss: 0.016367\n",
            "Train Epoch: 90 [2944/14860 (20%)]\tLoss: 0.042679\n",
            "Train Epoch: 90 [3072/14860 (21%)]\tLoss: 0.024006\n",
            "Train Epoch: 90 [3200/14860 (21%)]\tLoss: 0.023469\n",
            "Train Epoch: 90 [3328/14860 (22%)]\tLoss: 0.020304\n",
            "Train Epoch: 90 [3456/14860 (23%)]\tLoss: 0.017439\n",
            "Train Epoch: 90 [3584/14860 (24%)]\tLoss: 0.020787\n",
            "Train Epoch: 90 [3712/14860 (25%)]\tLoss: 0.024193\n",
            "Train Epoch: 90 [3840/14860 (26%)]\tLoss: 0.031219\n",
            "Train Epoch: 90 [3968/14860 (26%)]\tLoss: 0.021825\n",
            "Train Epoch: 90 [4096/14860 (27%)]\tLoss: 0.025495\n",
            "Train Epoch: 90 [4224/14860 (28%)]\tLoss: 0.017800\n",
            "Train Epoch: 90 [4352/14860 (29%)]\tLoss: 0.024391\n",
            "Train Epoch: 90 [4480/14860 (30%)]\tLoss: 0.018103\n",
            "Train Epoch: 90 [4608/14860 (31%)]\tLoss: 0.016419\n",
            "Train Epoch: 90 [4736/14860 (32%)]\tLoss: 0.027290\n",
            "Train Epoch: 90 [4864/14860 (32%)]\tLoss: 0.017964\n",
            "Train Epoch: 90 [4992/14860 (33%)]\tLoss: 0.022763\n",
            "Train Epoch: 90 [5120/14860 (34%)]\tLoss: 0.026144\n",
            "Train Epoch: 90 [5248/14860 (35%)]\tLoss: 0.017099\n",
            "Train Epoch: 90 [5376/14860 (36%)]\tLoss: 0.023320\n",
            "Train Epoch: 90 [5504/14860 (37%)]\tLoss: 0.015435\n",
            "Train Epoch: 90 [5632/14860 (38%)]\tLoss: 0.022716\n",
            "Train Epoch: 90 [5760/14860 (38%)]\tLoss: 0.019980\n",
            "Train Epoch: 90 [5888/14860 (39%)]\tLoss: 0.021732\n",
            "Train Epoch: 90 [6016/14860 (40%)]\tLoss: 0.013988\n",
            "Train Epoch: 90 [6144/14860 (41%)]\tLoss: 0.022798\n",
            "Train Epoch: 90 [6272/14860 (42%)]\tLoss: 0.019701\n",
            "Train Epoch: 90 [6400/14860 (43%)]\tLoss: 0.018378\n",
            "Train Epoch: 90 [6528/14860 (44%)]\tLoss: 0.019376\n",
            "Train Epoch: 90 [6656/14860 (44%)]\tLoss: 0.018884\n",
            "Train Epoch: 90 [6784/14860 (45%)]\tLoss: 0.031728\n",
            "Train Epoch: 90 [6912/14860 (46%)]\tLoss: 0.014057\n",
            "Train Epoch: 90 [7040/14860 (47%)]\tLoss: 0.025336\n",
            "Train Epoch: 90 [7168/14860 (48%)]\tLoss: 0.017316\n",
            "Train Epoch: 90 [7296/14860 (49%)]\tLoss: 0.021791\n",
            "Train Epoch: 90 [7424/14860 (50%)]\tLoss: 0.019492\n",
            "Train Epoch: 90 [7552/14860 (50%)]\tLoss: 0.016247\n",
            "Train Epoch: 90 [7680/14860 (51%)]\tLoss: 0.018680\n",
            "Train Epoch: 90 [7808/14860 (52%)]\tLoss: 0.018362\n",
            "Train Epoch: 90 [7936/14860 (53%)]\tLoss: 0.019856\n",
            "Train Epoch: 90 [8064/14860 (54%)]\tLoss: 0.017394\n",
            "Train Epoch: 90 [8192/14860 (55%)]\tLoss: 0.022255\n",
            "Train Epoch: 90 [8320/14860 (56%)]\tLoss: 0.019723\n",
            "Train Epoch: 90 [8448/14860 (56%)]\tLoss: 0.021361\n",
            "Train Epoch: 90 [8576/14860 (57%)]\tLoss: 0.037474\n",
            "Train Epoch: 90 [8704/14860 (58%)]\tLoss: 0.018461\n",
            "Train Epoch: 90 [8832/14860 (59%)]\tLoss: 0.046838\n",
            "Train Epoch: 90 [8960/14860 (60%)]\tLoss: 0.019114\n",
            "Train Epoch: 90 [9088/14860 (61%)]\tLoss: 0.031327\n",
            "Train Epoch: 90 [9216/14860 (62%)]\tLoss: 0.014813\n",
            "Train Epoch: 90 [9344/14860 (62%)]\tLoss: 0.025602\n",
            "Train Epoch: 90 [9472/14860 (63%)]\tLoss: 0.015228\n",
            "Train Epoch: 90 [9600/14860 (64%)]\tLoss: 0.018417\n",
            "Train Epoch: 90 [9728/14860 (65%)]\tLoss: 0.022031\n",
            "Train Epoch: 90 [9856/14860 (66%)]\tLoss: 0.018214\n",
            "Train Epoch: 90 [9984/14860 (67%)]\tLoss: 0.014172\n",
            "Train Epoch: 90 [10112/14860 (68%)]\tLoss: 0.016761\n",
            "Train Epoch: 90 [10240/14860 (68%)]\tLoss: 0.024309\n",
            "Train Epoch: 90 [10368/14860 (69%)]\tLoss: 0.029831\n",
            "Train Epoch: 90 [10496/14860 (70%)]\tLoss: 0.017839\n",
            "Train Epoch: 90 [10624/14860 (71%)]\tLoss: 0.026753\n",
            "Train Epoch: 90 [10752/14860 (72%)]\tLoss: 0.021126\n",
            "Train Epoch: 90 [10880/14860 (73%)]\tLoss: 0.017617\n",
            "Train Epoch: 90 [11008/14860 (74%)]\tLoss: 0.014908\n",
            "Train Epoch: 90 [11136/14860 (74%)]\tLoss: 0.015577\n",
            "Train Epoch: 90 [11264/14860 (75%)]\tLoss: 0.018028\n",
            "Train Epoch: 90 [11392/14860 (76%)]\tLoss: 0.024153\n",
            "Train Epoch: 90 [11520/14860 (77%)]\tLoss: 0.019491\n",
            "Train Epoch: 90 [11648/14860 (78%)]\tLoss: 0.025638\n",
            "Train Epoch: 90 [11776/14860 (79%)]\tLoss: 0.022951\n",
            "Train Epoch: 90 [11904/14860 (79%)]\tLoss: 0.012992\n",
            "Train Epoch: 90 [12032/14860 (80%)]\tLoss: 0.022237\n",
            "Train Epoch: 90 [12160/14860 (81%)]\tLoss: 0.021474\n",
            "Train Epoch: 90 [12288/14860 (82%)]\tLoss: 0.024161\n",
            "Train Epoch: 90 [12416/14860 (83%)]\tLoss: 0.017287\n",
            "Train Epoch: 90 [12544/14860 (84%)]\tLoss: 0.024991\n",
            "Train Epoch: 90 [12672/14860 (85%)]\tLoss: 0.016101\n",
            "Train Epoch: 90 [12800/14860 (85%)]\tLoss: 0.021164\n",
            "Train Epoch: 90 [12928/14860 (86%)]\tLoss: 0.021450\n",
            "Train Epoch: 90 [13056/14860 (87%)]\tLoss: 0.013917\n",
            "Train Epoch: 90 [13184/14860 (88%)]\tLoss: 0.022945\n",
            "Train Epoch: 90 [13312/14860 (89%)]\tLoss: 0.028818\n",
            "Train Epoch: 90 [13440/14860 (90%)]\tLoss: 0.014915\n",
            "Train Epoch: 90 [13568/14860 (91%)]\tLoss: 0.016588\n",
            "Train Epoch: 90 [13696/14860 (91%)]\tLoss: 0.020015\n",
            "Train Epoch: 90 [13824/14860 (92%)]\tLoss: 0.024151\n",
            "Train Epoch: 90 [13952/14860 (93%)]\tLoss: 0.017794\n",
            "Train Epoch: 90 [14080/14860 (94%)]\tLoss: 0.018834\n",
            "Train Epoch: 90 [14208/14860 (95%)]\tLoss: 0.018756\n",
            "Train Epoch: 90 [14336/14860 (96%)]\tLoss: 0.029817\n",
            "Train Epoch: 90 [14464/14860 (97%)]\tLoss: 0.023731\n",
            "Train Epoch: 90 [14592/14860 (97%)]\tLoss: 0.018799\n",
            "Train Epoch: 90 [14720/14860 (98%)]\tLoss: 0.021392\n",
            "Train Epoch: 90 [1392/14860 (99%)]\tLoss: 0.011961\n",
            "epoch 90 training loss: 0.02150042964798263\n",
            "epoch 90 validation loss: 0.05745840505595357\n",
            "Train Epoch: 91 [0/14860 (0%)]\tLoss: 0.069514\n",
            "Train Epoch: 91 [128/14860 (1%)]\tLoss: 0.019465\n",
            "Train Epoch: 91 [256/14860 (2%)]\tLoss: 0.027337\n",
            "Train Epoch: 91 [384/14860 (3%)]\tLoss: 0.028786\n",
            "Train Epoch: 91 [512/14860 (3%)]\tLoss: 0.023315\n",
            "Train Epoch: 91 [640/14860 (4%)]\tLoss: 0.019455\n",
            "Train Epoch: 91 [768/14860 (5%)]\tLoss: 0.021315\n",
            "Train Epoch: 91 [896/14860 (6%)]\tLoss: 0.022423\n",
            "Train Epoch: 91 [1024/14860 (7%)]\tLoss: 0.020900\n",
            "Train Epoch: 91 [1152/14860 (8%)]\tLoss: 0.020709\n",
            "Train Epoch: 91 [1280/14860 (9%)]\tLoss: 0.015647\n",
            "Train Epoch: 91 [1408/14860 (9%)]\tLoss: 0.018992\n",
            "Train Epoch: 91 [1536/14860 (10%)]\tLoss: 0.027354\n",
            "Train Epoch: 91 [1664/14860 (11%)]\tLoss: 0.014487\n",
            "Train Epoch: 91 [1792/14860 (12%)]\tLoss: 0.018754\n",
            "Train Epoch: 91 [1920/14860 (13%)]\tLoss: 0.011826\n",
            "Train Epoch: 91 [2048/14860 (14%)]\tLoss: 0.019184\n",
            "Train Epoch: 91 [2176/14860 (15%)]\tLoss: 0.022378\n",
            "Train Epoch: 91 [2304/14860 (15%)]\tLoss: 0.027152\n",
            "Train Epoch: 91 [2432/14860 (16%)]\tLoss: 0.023832\n",
            "Train Epoch: 91 [2560/14860 (17%)]\tLoss: 0.020336\n",
            "Train Epoch: 91 [2688/14860 (18%)]\tLoss: 0.019755\n",
            "Train Epoch: 91 [2816/14860 (19%)]\tLoss: 0.014122\n",
            "Train Epoch: 91 [2944/14860 (20%)]\tLoss: 0.019389\n",
            "Train Epoch: 91 [3072/14860 (21%)]\tLoss: 0.022737\n",
            "Train Epoch: 91 [3200/14860 (21%)]\tLoss: 0.024432\n",
            "Train Epoch: 91 [3328/14860 (22%)]\tLoss: 0.017886\n",
            "Train Epoch: 91 [3456/14860 (23%)]\tLoss: 0.018103\n",
            "Train Epoch: 91 [3584/14860 (24%)]\tLoss: 0.013497\n",
            "Train Epoch: 91 [3712/14860 (25%)]\tLoss: 0.017222\n",
            "Train Epoch: 91 [3840/14860 (26%)]\tLoss: 0.022061\n",
            "Train Epoch: 91 [3968/14860 (26%)]\tLoss: 0.025368\n",
            "Train Epoch: 91 [4096/14860 (27%)]\tLoss: 0.025689\n",
            "Train Epoch: 91 [4224/14860 (28%)]\tLoss: 0.014323\n",
            "Train Epoch: 91 [4352/14860 (29%)]\tLoss: 0.024497\n",
            "Train Epoch: 91 [4480/14860 (30%)]\tLoss: 0.016942\n",
            "Train Epoch: 91 [4608/14860 (31%)]\tLoss: 0.018165\n",
            "Train Epoch: 91 [4736/14860 (32%)]\tLoss: 0.020342\n",
            "Train Epoch: 91 [4864/14860 (32%)]\tLoss: 0.020766\n",
            "Train Epoch: 91 [4992/14860 (33%)]\tLoss: 0.020120\n",
            "Train Epoch: 91 [5120/14860 (34%)]\tLoss: 0.028978\n",
            "Train Epoch: 91 [5248/14860 (35%)]\tLoss: 0.022758\n",
            "Train Epoch: 91 [5376/14860 (36%)]\tLoss: 0.019445\n",
            "Train Epoch: 91 [5504/14860 (37%)]\tLoss: 0.028104\n",
            "Train Epoch: 91 [5632/14860 (38%)]\tLoss: 0.026149\n",
            "Train Epoch: 91 [5760/14860 (38%)]\tLoss: 0.021880\n",
            "Train Epoch: 91 [5888/14860 (39%)]\tLoss: 0.017379\n",
            "Train Epoch: 91 [6016/14860 (40%)]\tLoss: 0.020840\n",
            "Train Epoch: 91 [6144/14860 (41%)]\tLoss: 0.013889\n",
            "Train Epoch: 91 [6272/14860 (42%)]\tLoss: 0.010620\n",
            "Train Epoch: 91 [6400/14860 (43%)]\tLoss: 0.017924\n",
            "Train Epoch: 91 [6528/14860 (44%)]\tLoss: 0.024141\n",
            "Train Epoch: 91 [6656/14860 (44%)]\tLoss: 0.022051\n",
            "Train Epoch: 91 [6784/14860 (45%)]\tLoss: 0.024968\n",
            "Train Epoch: 91 [6912/14860 (46%)]\tLoss: 0.020078\n",
            "Train Epoch: 91 [7040/14860 (47%)]\tLoss: 0.020647\n",
            "Train Epoch: 91 [7168/14860 (48%)]\tLoss: 0.014234\n",
            "Train Epoch: 91 [7296/14860 (49%)]\tLoss: 0.022997\n",
            "Train Epoch: 91 [7424/14860 (50%)]\tLoss: 0.019279\n",
            "Train Epoch: 91 [7552/14860 (50%)]\tLoss: 0.021964\n",
            "Train Epoch: 91 [7680/14860 (51%)]\tLoss: 0.017804\n",
            "Train Epoch: 91 [7808/14860 (52%)]\tLoss: 0.020231\n",
            "Train Epoch: 91 [7936/14860 (53%)]\tLoss: 0.019636\n",
            "Train Epoch: 91 [8064/14860 (54%)]\tLoss: 0.020759\n",
            "Train Epoch: 91 [8192/14860 (55%)]\tLoss: 0.026280\n",
            "Train Epoch: 91 [8320/14860 (56%)]\tLoss: 0.020984\n",
            "Train Epoch: 91 [8448/14860 (56%)]\tLoss: 0.022044\n",
            "Train Epoch: 91 [8576/14860 (57%)]\tLoss: 0.022241\n",
            "Train Epoch: 91 [8704/14860 (58%)]\tLoss: 0.015584\n",
            "Train Epoch: 91 [8832/14860 (59%)]\tLoss: 0.023013\n",
            "Train Epoch: 91 [8960/14860 (60%)]\tLoss: 0.020098\n",
            "Train Epoch: 91 [9088/14860 (61%)]\tLoss: 0.028110\n",
            "Train Epoch: 91 [9216/14860 (62%)]\tLoss: 0.020734\n",
            "Train Epoch: 91 [9344/14860 (62%)]\tLoss: 0.033457\n",
            "Train Epoch: 91 [9472/14860 (63%)]\tLoss: 0.016107\n",
            "Train Epoch: 91 [9600/14860 (64%)]\tLoss: 0.021673\n",
            "Train Epoch: 91 [9728/14860 (65%)]\tLoss: 0.018768\n",
            "Train Epoch: 91 [9856/14860 (66%)]\tLoss: 0.017462\n",
            "Train Epoch: 91 [9984/14860 (67%)]\tLoss: 0.017602\n",
            "Train Epoch: 91 [10112/14860 (68%)]\tLoss: 0.025493\n",
            "Train Epoch: 91 [10240/14860 (68%)]\tLoss: 0.014551\n",
            "Train Epoch: 91 [10368/14860 (69%)]\tLoss: 0.018472\n",
            "Train Epoch: 91 [10496/14860 (70%)]\tLoss: 0.025725\n",
            "Train Epoch: 91 [10624/14860 (71%)]\tLoss: 0.029073\n",
            "Train Epoch: 91 [10752/14860 (72%)]\tLoss: 0.021912\n",
            "Train Epoch: 91 [10880/14860 (73%)]\tLoss: 0.016988\n",
            "Train Epoch: 91 [11008/14860 (74%)]\tLoss: 0.025417\n",
            "Train Epoch: 91 [11136/14860 (74%)]\tLoss: 0.017720\n",
            "Train Epoch: 91 [11264/14860 (75%)]\tLoss: 0.019023\n",
            "Train Epoch: 91 [11392/14860 (76%)]\tLoss: 0.012763\n",
            "Train Epoch: 91 [11520/14860 (77%)]\tLoss: 0.024187\n",
            "Train Epoch: 91 [11648/14860 (78%)]\tLoss: 0.024840\n",
            "Train Epoch: 91 [11776/14860 (79%)]\tLoss: 0.024164\n",
            "Train Epoch: 91 [11904/14860 (79%)]\tLoss: 0.021866\n",
            "Train Epoch: 91 [12032/14860 (80%)]\tLoss: 0.021737\n",
            "Train Epoch: 91 [12160/14860 (81%)]\tLoss: 0.024667\n",
            "Train Epoch: 91 [12288/14860 (82%)]\tLoss: 0.027948\n",
            "Train Epoch: 91 [12416/14860 (83%)]\tLoss: 0.014064\n",
            "Train Epoch: 91 [12544/14860 (84%)]\tLoss: 0.027249\n",
            "Train Epoch: 91 [12672/14860 (85%)]\tLoss: 0.020675\n",
            "Train Epoch: 91 [12800/14860 (85%)]\tLoss: 0.025243\n",
            "Train Epoch: 91 [12928/14860 (86%)]\tLoss: 0.020183\n",
            "Train Epoch: 91 [13056/14860 (87%)]\tLoss: 0.029887\n",
            "Train Epoch: 91 [13184/14860 (88%)]\tLoss: 0.023647\n",
            "Train Epoch: 91 [13312/14860 (89%)]\tLoss: 0.027552\n",
            "Train Epoch: 91 [13440/14860 (90%)]\tLoss: 0.018347\n",
            "Train Epoch: 91 [13568/14860 (91%)]\tLoss: 0.031188\n",
            "Train Epoch: 91 [13696/14860 (91%)]\tLoss: 0.020911\n",
            "Train Epoch: 91 [13824/14860 (92%)]\tLoss: 0.027016\n",
            "Train Epoch: 91 [13952/14860 (93%)]\tLoss: 0.022033\n",
            "Train Epoch: 91 [14080/14860 (94%)]\tLoss: 0.022156\n",
            "Train Epoch: 91 [14208/14860 (95%)]\tLoss: 0.022892\n",
            "Train Epoch: 91 [14336/14860 (96%)]\tLoss: 0.022241\n",
            "Train Epoch: 91 [14464/14860 (97%)]\tLoss: 0.024311\n",
            "Train Epoch: 91 [14592/14860 (97%)]\tLoss: 0.024023\n",
            "Train Epoch: 91 [14720/14860 (98%)]\tLoss: 0.035408\n",
            "Train Epoch: 91 [1392/14860 (99%)]\tLoss: 0.024418\n",
            "epoch 91 training loss: 0.021961370817361735\n",
            "epoch 91 validation loss: 0.026315110503328337\n",
            "Train Epoch: 92 [0/14860 (0%)]\tLoss: 0.030057\n",
            "Train Epoch: 92 [128/14860 (1%)]\tLoss: 0.022984\n",
            "Train Epoch: 92 [256/14860 (2%)]\tLoss: 0.015487\n",
            "Train Epoch: 92 [384/14860 (3%)]\tLoss: 0.020540\n",
            "Train Epoch: 92 [512/14860 (3%)]\tLoss: 0.014996\n",
            "Train Epoch: 92 [640/14860 (4%)]\tLoss: 0.018727\n",
            "Train Epoch: 92 [768/14860 (5%)]\tLoss: 0.023801\n",
            "Train Epoch: 92 [896/14860 (6%)]\tLoss: 0.024964\n",
            "Train Epoch: 92 [1024/14860 (7%)]\tLoss: 0.013956\n",
            "Train Epoch: 92 [1152/14860 (8%)]\tLoss: 0.018743\n",
            "Train Epoch: 92 [1280/14860 (9%)]\tLoss: 0.025984\n",
            "Train Epoch: 92 [1408/14860 (9%)]\tLoss: 0.024631\n",
            "Train Epoch: 92 [1536/14860 (10%)]\tLoss: 0.018943\n",
            "Train Epoch: 92 [1664/14860 (11%)]\tLoss: 0.025759\n",
            "Train Epoch: 92 [1792/14860 (12%)]\tLoss: 0.018919\n",
            "Train Epoch: 92 [1920/14860 (13%)]\tLoss: 0.021696\n",
            "Train Epoch: 92 [2048/14860 (14%)]\tLoss: 0.023481\n",
            "Train Epoch: 92 [2176/14860 (15%)]\tLoss: 0.025259\n",
            "Train Epoch: 92 [2304/14860 (15%)]\tLoss: 0.016376\n",
            "Train Epoch: 92 [2432/14860 (16%)]\tLoss: 0.032022\n",
            "Train Epoch: 92 [2560/14860 (17%)]\tLoss: 0.022534\n",
            "Train Epoch: 92 [2688/14860 (18%)]\tLoss: 0.033007\n",
            "Train Epoch: 92 [2816/14860 (19%)]\tLoss: 0.012402\n",
            "Train Epoch: 92 [2944/14860 (20%)]\tLoss: 0.023516\n",
            "Train Epoch: 92 [3072/14860 (21%)]\tLoss: 0.019370\n",
            "Train Epoch: 92 [3200/14860 (21%)]\tLoss: 0.027250\n",
            "Train Epoch: 92 [3328/14860 (22%)]\tLoss: 0.013308\n",
            "Train Epoch: 92 [3456/14860 (23%)]\tLoss: 0.018232\n",
            "Train Epoch: 92 [3584/14860 (24%)]\tLoss: 0.018459\n",
            "Train Epoch: 92 [3712/14860 (25%)]\tLoss: 0.022447\n",
            "Train Epoch: 92 [3840/14860 (26%)]\tLoss: 0.015347\n",
            "Train Epoch: 92 [3968/14860 (26%)]\tLoss: 0.020616\n",
            "Train Epoch: 92 [4096/14860 (27%)]\tLoss: 0.017208\n",
            "Train Epoch: 92 [4224/14860 (28%)]\tLoss: 0.023038\n",
            "Train Epoch: 92 [4352/14860 (29%)]\tLoss: 0.031505\n",
            "Train Epoch: 92 [4480/14860 (30%)]\tLoss: 0.015555\n",
            "Train Epoch: 92 [4608/14860 (31%)]\tLoss: 0.027451\n",
            "Train Epoch: 92 [4736/14860 (32%)]\tLoss: 0.021783\n",
            "Train Epoch: 92 [4864/14860 (32%)]\tLoss: 0.026320\n",
            "Train Epoch: 92 [4992/14860 (33%)]\tLoss: 0.010603\n",
            "Train Epoch: 92 [5120/14860 (34%)]\tLoss: 0.020351\n",
            "Train Epoch: 92 [5248/14860 (35%)]\tLoss: 0.022757\n",
            "Train Epoch: 92 [5376/14860 (36%)]\tLoss: 0.017281\n",
            "Train Epoch: 92 [5504/14860 (37%)]\tLoss: 0.024652\n",
            "Train Epoch: 92 [5632/14860 (38%)]\tLoss: 0.021411\n",
            "Train Epoch: 92 [5760/14860 (38%)]\tLoss: 0.017778\n",
            "Train Epoch: 92 [5888/14860 (39%)]\tLoss: 0.025341\n",
            "Train Epoch: 92 [6016/14860 (40%)]\tLoss: 0.022049\n",
            "Train Epoch: 92 [6144/14860 (41%)]\tLoss: 0.022011\n",
            "Train Epoch: 92 [6272/14860 (42%)]\tLoss: 0.022909\n",
            "Train Epoch: 92 [6400/14860 (43%)]\tLoss: 0.019047\n",
            "Train Epoch: 92 [6528/14860 (44%)]\tLoss: 0.023010\n",
            "Train Epoch: 92 [6656/14860 (44%)]\tLoss: 0.024842\n",
            "Train Epoch: 92 [6784/14860 (45%)]\tLoss: 0.030953\n",
            "Train Epoch: 92 [6912/14860 (46%)]\tLoss: 0.034043\n",
            "Train Epoch: 92 [7040/14860 (47%)]\tLoss: 0.024912\n",
            "Train Epoch: 92 [7168/14860 (48%)]\tLoss: 0.022080\n",
            "Train Epoch: 92 [7296/14860 (49%)]\tLoss: 0.017801\n",
            "Train Epoch: 92 [7424/14860 (50%)]\tLoss: 0.025576\n",
            "Train Epoch: 92 [7552/14860 (50%)]\tLoss: 0.018270\n",
            "Train Epoch: 92 [7680/14860 (51%)]\tLoss: 0.028192\n",
            "Train Epoch: 92 [7808/14860 (52%)]\tLoss: 0.016850\n",
            "Train Epoch: 92 [7936/14860 (53%)]\tLoss: 0.020219\n",
            "Train Epoch: 92 [8064/14860 (54%)]\tLoss: 0.020920\n",
            "Train Epoch: 92 [8192/14860 (55%)]\tLoss: 0.016331\n",
            "Train Epoch: 92 [8320/14860 (56%)]\tLoss: 0.020820\n",
            "Train Epoch: 92 [8448/14860 (56%)]\tLoss: 0.014732\n",
            "Train Epoch: 92 [8576/14860 (57%)]\tLoss: 0.015923\n",
            "Train Epoch: 92 [8704/14860 (58%)]\tLoss: 0.014982\n",
            "Train Epoch: 92 [8832/14860 (59%)]\tLoss: 0.014563\n",
            "Train Epoch: 92 [8960/14860 (60%)]\tLoss: 0.017220\n",
            "Train Epoch: 92 [9088/14860 (61%)]\tLoss: 0.035112\n",
            "Train Epoch: 92 [9216/14860 (62%)]\tLoss: 0.021448\n",
            "Train Epoch: 92 [9344/14860 (62%)]\tLoss: 0.027002\n",
            "Train Epoch: 92 [9472/14860 (63%)]\tLoss: 0.020513\n",
            "Train Epoch: 92 [9600/14860 (64%)]\tLoss: 0.028033\n",
            "Train Epoch: 92 [9728/14860 (65%)]\tLoss: 0.020202\n",
            "Train Epoch: 92 [9856/14860 (66%)]\tLoss: 0.026496\n",
            "Train Epoch: 92 [9984/14860 (67%)]\tLoss: 0.016921\n",
            "Train Epoch: 92 [10112/14860 (68%)]\tLoss: 0.023818\n",
            "Train Epoch: 92 [10240/14860 (68%)]\tLoss: 0.017388\n",
            "Train Epoch: 92 [10368/14860 (69%)]\tLoss: 0.018663\n",
            "Train Epoch: 92 [10496/14860 (70%)]\tLoss: 0.019983\n",
            "Train Epoch: 92 [10624/14860 (71%)]\tLoss: 0.018886\n",
            "Train Epoch: 92 [10752/14860 (72%)]\tLoss: 0.020117\n",
            "Train Epoch: 92 [10880/14860 (73%)]\tLoss: 0.025277\n",
            "Train Epoch: 92 [11008/14860 (74%)]\tLoss: 0.034830\n",
            "Train Epoch: 92 [11136/14860 (74%)]\tLoss: 0.026380\n",
            "Train Epoch: 92 [11264/14860 (75%)]\tLoss: 0.019164\n",
            "Train Epoch: 92 [11392/14860 (76%)]\tLoss: 0.016599\n",
            "Train Epoch: 92 [11520/14860 (77%)]\tLoss: 0.018941\n",
            "Train Epoch: 92 [11648/14860 (78%)]\tLoss: 0.018940\n",
            "Train Epoch: 92 [11776/14860 (79%)]\tLoss: 0.020455\n",
            "Train Epoch: 92 [11904/14860 (79%)]\tLoss: 0.014909\n",
            "Train Epoch: 92 [12032/14860 (80%)]\tLoss: 0.020957\n",
            "Train Epoch: 92 [12160/14860 (81%)]\tLoss: 0.017146\n",
            "Train Epoch: 92 [12288/14860 (82%)]\tLoss: 0.021547\n",
            "Train Epoch: 92 [12416/14860 (83%)]\tLoss: 0.022348\n",
            "Train Epoch: 92 [12544/14860 (84%)]\tLoss: 0.023644\n",
            "Train Epoch: 92 [12672/14860 (85%)]\tLoss: 0.020811\n",
            "Train Epoch: 92 [12800/14860 (85%)]\tLoss: 0.021975\n",
            "Train Epoch: 92 [12928/14860 (86%)]\tLoss: 0.020842\n",
            "Train Epoch: 92 [13056/14860 (87%)]\tLoss: 0.021636\n",
            "Train Epoch: 92 [13184/14860 (88%)]\tLoss: 0.021340\n",
            "Train Epoch: 92 [13312/14860 (89%)]\tLoss: 0.028255\n",
            "Train Epoch: 92 [13440/14860 (90%)]\tLoss: 0.020853\n",
            "Train Epoch: 92 [13568/14860 (91%)]\tLoss: 0.016826\n",
            "Train Epoch: 92 [13696/14860 (91%)]\tLoss: 0.022971\n",
            "Train Epoch: 92 [13824/14860 (92%)]\tLoss: 0.024285\n",
            "Train Epoch: 92 [13952/14860 (93%)]\tLoss: 0.024015\n",
            "Train Epoch: 92 [14080/14860 (94%)]\tLoss: 0.018293\n",
            "Train Epoch: 92 [14208/14860 (95%)]\tLoss: 0.015473\n",
            "Train Epoch: 92 [14336/14860 (96%)]\tLoss: 0.014977\n",
            "Train Epoch: 92 [14464/14860 (97%)]\tLoss: 0.016873\n",
            "Train Epoch: 92 [14592/14860 (97%)]\tLoss: 0.016497\n",
            "Train Epoch: 92 [14720/14860 (98%)]\tLoss: 0.023571\n",
            "Train Epoch: 92 [1392/14860 (99%)]\tLoss: 0.029603\n",
            "epoch 92 training loss: 0.021452286121491183\n",
            "epoch 92 validation loss: 0.02361287360618536\n",
            "Train Epoch: 93 [0/14860 (0%)]\tLoss: 0.024256\n",
            "Train Epoch: 93 [128/14860 (1%)]\tLoss: 0.025477\n",
            "Train Epoch: 93 [256/14860 (2%)]\tLoss: 0.018765\n",
            "Train Epoch: 93 [384/14860 (3%)]\tLoss: 0.022409\n",
            "Train Epoch: 93 [512/14860 (3%)]\tLoss: 0.015827\n",
            "Train Epoch: 93 [640/14860 (4%)]\tLoss: 0.027311\n",
            "Train Epoch: 93 [768/14860 (5%)]\tLoss: 0.022332\n",
            "Train Epoch: 93 [896/14860 (6%)]\tLoss: 0.028273\n",
            "Train Epoch: 93 [1024/14860 (7%)]\tLoss: 0.021810\n",
            "Train Epoch: 93 [1152/14860 (8%)]\tLoss: 0.030279\n",
            "Train Epoch: 93 [1280/14860 (9%)]\tLoss: 0.028644\n",
            "Train Epoch: 93 [1408/14860 (9%)]\tLoss: 0.033803\n",
            "Train Epoch: 93 [1536/14860 (10%)]\tLoss: 0.022869\n",
            "Train Epoch: 93 [1664/14860 (11%)]\tLoss: 0.015093\n",
            "Train Epoch: 93 [1792/14860 (12%)]\tLoss: 0.023451\n",
            "Train Epoch: 93 [1920/14860 (13%)]\tLoss: 0.013524\n",
            "Train Epoch: 93 [2048/14860 (14%)]\tLoss: 0.023341\n",
            "Train Epoch: 93 [2176/14860 (15%)]\tLoss: 0.015936\n",
            "Train Epoch: 93 [2304/14860 (15%)]\tLoss: 0.023329\n",
            "Train Epoch: 93 [2432/14860 (16%)]\tLoss: 0.020983\n",
            "Train Epoch: 93 [2560/14860 (17%)]\tLoss: 0.024014\n",
            "Train Epoch: 93 [2688/14860 (18%)]\tLoss: 0.024793\n",
            "Train Epoch: 93 [2816/14860 (19%)]\tLoss: 0.019107\n",
            "Train Epoch: 93 [2944/14860 (20%)]\tLoss: 0.020488\n",
            "Train Epoch: 93 [3072/14860 (21%)]\tLoss: 0.012615\n",
            "Train Epoch: 93 [3200/14860 (21%)]\tLoss: 0.016886\n",
            "Train Epoch: 93 [3328/14860 (22%)]\tLoss: 0.025186\n",
            "Train Epoch: 93 [3456/14860 (23%)]\tLoss: 0.018995\n",
            "Train Epoch: 93 [3584/14860 (24%)]\tLoss: 0.014903\n",
            "Train Epoch: 93 [3712/14860 (25%)]\tLoss: 0.017467\n",
            "Train Epoch: 93 [3840/14860 (26%)]\tLoss: 0.028243\n",
            "Train Epoch: 93 [3968/14860 (26%)]\tLoss: 0.019434\n",
            "Train Epoch: 93 [4096/14860 (27%)]\tLoss: 0.019617\n",
            "Train Epoch: 93 [4224/14860 (28%)]\tLoss: 0.022258\n",
            "Train Epoch: 93 [4352/14860 (29%)]\tLoss: 0.015736\n",
            "Train Epoch: 93 [4480/14860 (30%)]\tLoss: 0.029563\n",
            "Train Epoch: 93 [4608/14860 (31%)]\tLoss: 0.020809\n",
            "Train Epoch: 93 [4736/14860 (32%)]\tLoss: 0.013187\n",
            "Train Epoch: 93 [4864/14860 (32%)]\tLoss: 0.021374\n",
            "Train Epoch: 93 [4992/14860 (33%)]\tLoss: 0.016979\n",
            "Train Epoch: 93 [5120/14860 (34%)]\tLoss: 0.032881\n",
            "Train Epoch: 93 [5248/14860 (35%)]\tLoss: 0.023802\n",
            "Train Epoch: 93 [5376/14860 (36%)]\tLoss: 0.025467\n",
            "Train Epoch: 93 [5504/14860 (37%)]\tLoss: 0.021070\n",
            "Train Epoch: 93 [5632/14860 (38%)]\tLoss: 0.022184\n",
            "Train Epoch: 93 [5760/14860 (38%)]\tLoss: 0.027839\n",
            "Train Epoch: 93 [5888/14860 (39%)]\tLoss: 0.015770\n",
            "Train Epoch: 93 [6016/14860 (40%)]\tLoss: 0.025131\n",
            "Train Epoch: 93 [6144/14860 (41%)]\tLoss: 0.024644\n",
            "Train Epoch: 93 [6272/14860 (42%)]\tLoss: 0.025308\n",
            "Train Epoch: 93 [6400/14860 (43%)]\tLoss: 0.026021\n",
            "Train Epoch: 93 [6528/14860 (44%)]\tLoss: 0.024337\n",
            "Train Epoch: 93 [6656/14860 (44%)]\tLoss: 0.018542\n",
            "Train Epoch: 93 [6784/14860 (45%)]\tLoss: 0.023828\n",
            "Train Epoch: 93 [6912/14860 (46%)]\tLoss: 0.019322\n",
            "Train Epoch: 93 [7040/14860 (47%)]\tLoss: 0.020019\n",
            "Train Epoch: 93 [7168/14860 (48%)]\tLoss: 0.015299\n",
            "Train Epoch: 93 [7296/14860 (49%)]\tLoss: 0.020043\n",
            "Train Epoch: 93 [7424/14860 (50%)]\tLoss: 0.021077\n",
            "Train Epoch: 93 [7552/14860 (50%)]\tLoss: 0.020641\n",
            "Train Epoch: 93 [7680/14860 (51%)]\tLoss: 0.020527\n",
            "Train Epoch: 93 [7808/14860 (52%)]\tLoss: 0.018585\n",
            "Train Epoch: 93 [7936/14860 (53%)]\tLoss: 0.020055\n",
            "Train Epoch: 93 [8064/14860 (54%)]\tLoss: 0.024194\n",
            "Train Epoch: 93 [8192/14860 (55%)]\tLoss: 0.019817\n",
            "Train Epoch: 93 [8320/14860 (56%)]\tLoss: 0.022370\n",
            "Train Epoch: 93 [8448/14860 (56%)]\tLoss: 0.017827\n",
            "Train Epoch: 93 [8576/14860 (57%)]\tLoss: 0.020747\n",
            "Train Epoch: 93 [8704/14860 (58%)]\tLoss: 0.019640\n",
            "Train Epoch: 93 [8832/14860 (59%)]\tLoss: 0.026970\n",
            "Train Epoch: 93 [8960/14860 (60%)]\tLoss: 0.019978\n",
            "Train Epoch: 93 [9088/14860 (61%)]\tLoss: 0.017426\n",
            "Train Epoch: 93 [9216/14860 (62%)]\tLoss: 0.019096\n",
            "Train Epoch: 93 [9344/14860 (62%)]\tLoss: 0.020747\n",
            "Train Epoch: 93 [9472/14860 (63%)]\tLoss: 0.015246\n",
            "Train Epoch: 93 [9600/14860 (64%)]\tLoss: 0.034056\n",
            "Train Epoch: 93 [9728/14860 (65%)]\tLoss: 0.019342\n",
            "Train Epoch: 93 [9856/14860 (66%)]\tLoss: 0.024488\n",
            "Train Epoch: 93 [9984/14860 (67%)]\tLoss: 0.023759\n",
            "Train Epoch: 93 [10112/14860 (68%)]\tLoss: 0.020098\n",
            "Train Epoch: 93 [10240/14860 (68%)]\tLoss: 0.017338\n",
            "Train Epoch: 93 [10368/14860 (69%)]\tLoss: 0.022720\n",
            "Train Epoch: 93 [10496/14860 (70%)]\tLoss: 0.023823\n",
            "Train Epoch: 93 [10624/14860 (71%)]\tLoss: 0.016131\n",
            "Train Epoch: 93 [10752/14860 (72%)]\tLoss: 0.018573\n",
            "Train Epoch: 93 [10880/14860 (73%)]\tLoss: 0.017753\n",
            "Train Epoch: 93 [11008/14860 (74%)]\tLoss: 0.020680\n",
            "Train Epoch: 93 [11136/14860 (74%)]\tLoss: 0.022170\n",
            "Train Epoch: 93 [11264/14860 (75%)]\tLoss: 0.022880\n",
            "Train Epoch: 93 [11392/14860 (76%)]\tLoss: 0.017942\n",
            "Train Epoch: 93 [11520/14860 (77%)]\tLoss: 0.020386\n",
            "Train Epoch: 93 [11648/14860 (78%)]\tLoss: 0.021750\n",
            "Train Epoch: 93 [11776/14860 (79%)]\tLoss: 0.012935\n",
            "Train Epoch: 93 [11904/14860 (79%)]\tLoss: 0.019379\n",
            "Train Epoch: 93 [12032/14860 (80%)]\tLoss: 0.015711\n",
            "Train Epoch: 93 [12160/14860 (81%)]\tLoss: 0.019908\n",
            "Train Epoch: 93 [12288/14860 (82%)]\tLoss: 0.024347\n",
            "Train Epoch: 93 [12416/14860 (83%)]\tLoss: 0.019819\n",
            "Train Epoch: 93 [12544/14860 (84%)]\tLoss: 0.022740\n",
            "Train Epoch: 93 [12672/14860 (85%)]\tLoss: 0.025041\n",
            "Train Epoch: 93 [12800/14860 (85%)]\tLoss: 0.015804\n",
            "Train Epoch: 93 [12928/14860 (86%)]\tLoss: 0.021474\n",
            "Train Epoch: 93 [13056/14860 (87%)]\tLoss: 0.018963\n",
            "Train Epoch: 93 [13184/14860 (88%)]\tLoss: 0.022835\n",
            "Train Epoch: 93 [13312/14860 (89%)]\tLoss: 0.022299\n",
            "Train Epoch: 93 [13440/14860 (90%)]\tLoss: 0.013129\n",
            "Train Epoch: 93 [13568/14860 (91%)]\tLoss: 0.025236\n",
            "Train Epoch: 93 [13696/14860 (91%)]\tLoss: 0.021191\n",
            "Train Epoch: 93 [13824/14860 (92%)]\tLoss: 0.029561\n",
            "Train Epoch: 93 [13952/14860 (93%)]\tLoss: 0.021594\n",
            "Train Epoch: 93 [14080/14860 (94%)]\tLoss: 0.019750\n",
            "Train Epoch: 93 [14208/14860 (95%)]\tLoss: 0.027343\n",
            "Train Epoch: 93 [14336/14860 (96%)]\tLoss: 0.021047\n",
            "Train Epoch: 93 [14464/14860 (97%)]\tLoss: 0.018107\n",
            "Train Epoch: 93 [14592/14860 (97%)]\tLoss: 0.030906\n",
            "Train Epoch: 93 [14720/14860 (98%)]\tLoss: 0.027905\n",
            "Train Epoch: 93 [1392/14860 (99%)]\tLoss: 0.025117\n",
            "epoch 93 training loss: 0.0215542097376962\n",
            "epoch 93 validation loss: 0.03209271182736819\n",
            "Train Epoch: 94 [0/14860 (0%)]\tLoss: 0.029974\n",
            "Train Epoch: 94 [128/14860 (1%)]\tLoss: 0.013373\n",
            "Train Epoch: 94 [256/14860 (2%)]\tLoss: 0.023251\n",
            "Train Epoch: 94 [384/14860 (3%)]\tLoss: 0.022838\n",
            "Train Epoch: 94 [512/14860 (3%)]\tLoss: 0.021312\n",
            "Train Epoch: 94 [640/14860 (4%)]\tLoss: 0.020723\n",
            "Train Epoch: 94 [768/14860 (5%)]\tLoss: 0.020334\n",
            "Train Epoch: 94 [896/14860 (6%)]\tLoss: 0.028394\n",
            "Train Epoch: 94 [1024/14860 (7%)]\tLoss: 0.016281\n",
            "Train Epoch: 94 [1152/14860 (8%)]\tLoss: 0.025342\n",
            "Train Epoch: 94 [1280/14860 (9%)]\tLoss: 0.019928\n",
            "Train Epoch: 94 [1408/14860 (9%)]\tLoss: 0.015423\n",
            "Train Epoch: 94 [1536/14860 (10%)]\tLoss: 0.018135\n",
            "Train Epoch: 94 [1664/14860 (11%)]\tLoss: 0.021963\n",
            "Train Epoch: 94 [1792/14860 (12%)]\tLoss: 0.013943\n",
            "Train Epoch: 94 [1920/14860 (13%)]\tLoss: 0.015689\n",
            "Train Epoch: 94 [2048/14860 (14%)]\tLoss: 0.014251\n",
            "Train Epoch: 94 [2176/14860 (15%)]\tLoss: 0.026020\n",
            "Train Epoch: 94 [2304/14860 (15%)]\tLoss: 0.020112\n",
            "Train Epoch: 94 [2432/14860 (16%)]\tLoss: 0.021091\n",
            "Train Epoch: 94 [2560/14860 (17%)]\tLoss: 0.024585\n",
            "Train Epoch: 94 [2688/14860 (18%)]\tLoss: 0.021617\n",
            "Train Epoch: 94 [2816/14860 (19%)]\tLoss: 0.023869\n",
            "Train Epoch: 94 [2944/14860 (20%)]\tLoss: 0.021555\n",
            "Train Epoch: 94 [3072/14860 (21%)]\tLoss: 0.021253\n",
            "Train Epoch: 94 [3200/14860 (21%)]\tLoss: 0.025317\n",
            "Train Epoch: 94 [3328/14860 (22%)]\tLoss: 0.019667\n",
            "Train Epoch: 94 [3456/14860 (23%)]\tLoss: 0.025121\n",
            "Train Epoch: 94 [3584/14860 (24%)]\tLoss: 0.032766\n",
            "Train Epoch: 94 [3712/14860 (25%)]\tLoss: 0.026999\n",
            "Train Epoch: 94 [3840/14860 (26%)]\tLoss: 0.023427\n",
            "Train Epoch: 94 [3968/14860 (26%)]\tLoss: 0.017057\n",
            "Train Epoch: 94 [4096/14860 (27%)]\tLoss: 0.024351\n",
            "Train Epoch: 94 [4224/14860 (28%)]\tLoss: 0.026711\n",
            "Train Epoch: 94 [4352/14860 (29%)]\tLoss: 0.019099\n",
            "Train Epoch: 94 [4480/14860 (30%)]\tLoss: 0.022914\n",
            "Train Epoch: 94 [4608/14860 (31%)]\tLoss: 0.012472\n",
            "Train Epoch: 94 [4736/14860 (32%)]\tLoss: 0.021839\n",
            "Train Epoch: 94 [4864/14860 (32%)]\tLoss: 0.020301\n",
            "Train Epoch: 94 [4992/14860 (33%)]\tLoss: 0.023394\n",
            "Train Epoch: 94 [5120/14860 (34%)]\tLoss: 0.019915\n",
            "Train Epoch: 94 [5248/14860 (35%)]\tLoss: 0.021297\n",
            "Train Epoch: 94 [5376/14860 (36%)]\tLoss: 0.016062\n",
            "Train Epoch: 94 [5504/14860 (37%)]\tLoss: 0.016866\n",
            "Train Epoch: 94 [5632/14860 (38%)]\tLoss: 0.021181\n",
            "Train Epoch: 94 [5760/14860 (38%)]\tLoss: 0.021666\n",
            "Train Epoch: 94 [5888/14860 (39%)]\tLoss: 0.022040\n",
            "Train Epoch: 94 [6016/14860 (40%)]\tLoss: 0.021787\n",
            "Train Epoch: 94 [6144/14860 (41%)]\tLoss: 0.024908\n",
            "Train Epoch: 94 [6272/14860 (42%)]\tLoss: 0.020651\n",
            "Train Epoch: 94 [6400/14860 (43%)]\tLoss: 0.017068\n",
            "Train Epoch: 94 [6528/14860 (44%)]\tLoss: 0.014485\n",
            "Train Epoch: 94 [6656/14860 (44%)]\tLoss: 0.019117\n",
            "Train Epoch: 94 [6784/14860 (45%)]\tLoss: 0.021001\n",
            "Train Epoch: 94 [6912/14860 (46%)]\tLoss: 0.023586\n",
            "Train Epoch: 94 [7040/14860 (47%)]\tLoss: 0.019954\n",
            "Train Epoch: 94 [7168/14860 (48%)]\tLoss: 0.025024\n",
            "Train Epoch: 94 [7296/14860 (49%)]\tLoss: 0.015832\n",
            "Train Epoch: 94 [7424/14860 (50%)]\tLoss: 0.018305\n",
            "Train Epoch: 94 [7552/14860 (50%)]\tLoss: 0.025006\n",
            "Train Epoch: 94 [7680/14860 (51%)]\tLoss: 0.020923\n",
            "Train Epoch: 94 [7808/14860 (52%)]\tLoss: 0.024861\n",
            "Train Epoch: 94 [7936/14860 (53%)]\tLoss: 0.014958\n",
            "Train Epoch: 94 [8064/14860 (54%)]\tLoss: 0.032819\n",
            "Train Epoch: 94 [8192/14860 (55%)]\tLoss: 0.020431\n",
            "Train Epoch: 94 [8320/14860 (56%)]\tLoss: 0.021218\n",
            "Train Epoch: 94 [8448/14860 (56%)]\tLoss: 0.018223\n",
            "Train Epoch: 94 [8576/14860 (57%)]\tLoss: 0.022549\n",
            "Train Epoch: 94 [8704/14860 (58%)]\tLoss: 0.019886\n",
            "Train Epoch: 94 [8832/14860 (59%)]\tLoss: 0.020729\n",
            "Train Epoch: 94 [8960/14860 (60%)]\tLoss: 0.015039\n",
            "Train Epoch: 94 [9088/14860 (61%)]\tLoss: 0.015024\n",
            "Train Epoch: 94 [9216/14860 (62%)]\tLoss: 0.019405\n",
            "Train Epoch: 94 [9344/14860 (62%)]\tLoss: 0.021746\n",
            "Train Epoch: 94 [9472/14860 (63%)]\tLoss: 0.017545\n",
            "Train Epoch: 94 [9600/14860 (64%)]\tLoss: 0.017877\n",
            "Train Epoch: 94 [9728/14860 (65%)]\tLoss: 0.021623\n",
            "Train Epoch: 94 [9856/14860 (66%)]\tLoss: 0.017871\n",
            "Train Epoch: 94 [9984/14860 (67%)]\tLoss: 0.022262\n",
            "Train Epoch: 94 [10112/14860 (68%)]\tLoss: 0.019057\n",
            "Train Epoch: 94 [10240/14860 (68%)]\tLoss: 0.024878\n",
            "Train Epoch: 94 [10368/14860 (69%)]\tLoss: 0.018973\n",
            "Train Epoch: 94 [10496/14860 (70%)]\tLoss: 0.024589\n",
            "Train Epoch: 94 [10624/14860 (71%)]\tLoss: 0.017744\n",
            "Train Epoch: 94 [10752/14860 (72%)]\tLoss: 0.024794\n",
            "Train Epoch: 94 [10880/14860 (73%)]\tLoss: 0.019131\n",
            "Train Epoch: 94 [11008/14860 (74%)]\tLoss: 0.028256\n",
            "Train Epoch: 94 [11136/14860 (74%)]\tLoss: 0.029349\n",
            "Train Epoch: 94 [11264/14860 (75%)]\tLoss: 0.022924\n",
            "Train Epoch: 94 [11392/14860 (76%)]\tLoss: 0.022419\n",
            "Train Epoch: 94 [11520/14860 (77%)]\tLoss: 0.026630\n",
            "Train Epoch: 94 [11648/14860 (78%)]\tLoss: 0.021310\n",
            "Train Epoch: 94 [11776/14860 (79%)]\tLoss: 0.025642\n",
            "Train Epoch: 94 [11904/14860 (79%)]\tLoss: 0.019279\n",
            "Train Epoch: 94 [12032/14860 (80%)]\tLoss: 0.021241\n",
            "Train Epoch: 94 [12160/14860 (81%)]\tLoss: 0.031618\n",
            "Train Epoch: 94 [12288/14860 (82%)]\tLoss: 0.021125\n",
            "Train Epoch: 94 [12416/14860 (83%)]\tLoss: 0.024768\n",
            "Train Epoch: 94 [12544/14860 (84%)]\tLoss: 0.016189\n",
            "Train Epoch: 94 [12672/14860 (85%)]\tLoss: 0.021693\n",
            "Train Epoch: 94 [12800/14860 (85%)]\tLoss: 0.011870\n",
            "Train Epoch: 94 [12928/14860 (86%)]\tLoss: 0.012410\n",
            "Train Epoch: 94 [13056/14860 (87%)]\tLoss: 0.016811\n",
            "Train Epoch: 94 [13184/14860 (88%)]\tLoss: 0.015661\n",
            "Train Epoch: 94 [13312/14860 (89%)]\tLoss: 0.017756\n",
            "Train Epoch: 94 [13440/14860 (90%)]\tLoss: 0.022153\n",
            "Train Epoch: 94 [13568/14860 (91%)]\tLoss: 0.016559\n",
            "Train Epoch: 94 [13696/14860 (91%)]\tLoss: 0.019109\n",
            "Train Epoch: 94 [13824/14860 (92%)]\tLoss: 0.021934\n",
            "Train Epoch: 94 [13952/14860 (93%)]\tLoss: 0.023127\n",
            "Train Epoch: 94 [14080/14860 (94%)]\tLoss: 0.024345\n",
            "Train Epoch: 94 [14208/14860 (95%)]\tLoss: 0.020495\n",
            "Train Epoch: 94 [14336/14860 (96%)]\tLoss: 0.029739\n",
            "Train Epoch: 94 [14464/14860 (97%)]\tLoss: 0.016071\n",
            "Train Epoch: 94 [14592/14860 (97%)]\tLoss: 0.025080\n",
            "Train Epoch: 94 [14720/14860 (98%)]\tLoss: 0.023963\n",
            "Train Epoch: 94 [1392/14860 (99%)]\tLoss: 0.046529\n",
            "epoch 94 training loss: 0.02135598708071515\n",
            "epoch 94 validation loss: 0.035200670614080914\n",
            "Train Epoch: 95 [0/14860 (0%)]\tLoss: 0.040436\n",
            "Train Epoch: 95 [128/14860 (1%)]\tLoss: 0.017644\n",
            "Train Epoch: 95 [256/14860 (2%)]\tLoss: 0.019416\n",
            "Train Epoch: 95 [384/14860 (3%)]\tLoss: 0.018884\n",
            "Train Epoch: 95 [512/14860 (3%)]\tLoss: 0.021933\n",
            "Train Epoch: 95 [640/14860 (4%)]\tLoss: 0.022206\n",
            "Train Epoch: 95 [768/14860 (5%)]\tLoss: 0.021695\n",
            "Train Epoch: 95 [896/14860 (6%)]\tLoss: 0.021957\n",
            "Train Epoch: 95 [1024/14860 (7%)]\tLoss: 0.023725\n",
            "Train Epoch: 95 [1152/14860 (8%)]\tLoss: 0.029242\n",
            "Train Epoch: 95 [1280/14860 (9%)]\tLoss: 0.039181\n",
            "Train Epoch: 95 [1408/14860 (9%)]\tLoss: 0.015381\n",
            "Train Epoch: 95 [1536/14860 (10%)]\tLoss: 0.032053\n",
            "Train Epoch: 95 [1664/14860 (11%)]\tLoss: 0.023577\n",
            "Train Epoch: 95 [1792/14860 (12%)]\tLoss: 0.028223\n",
            "Train Epoch: 95 [1920/14860 (13%)]\tLoss: 0.022142\n",
            "Train Epoch: 95 [2048/14860 (14%)]\tLoss: 0.015797\n",
            "Train Epoch: 95 [2176/14860 (15%)]\tLoss: 0.021182\n",
            "Train Epoch: 95 [2304/14860 (15%)]\tLoss: 0.024053\n",
            "Train Epoch: 95 [2432/14860 (16%)]\tLoss: 0.018888\n",
            "Train Epoch: 95 [2560/14860 (17%)]\tLoss: 0.018684\n",
            "Train Epoch: 95 [2688/14860 (18%)]\tLoss: 0.027626\n",
            "Train Epoch: 95 [2816/14860 (19%)]\tLoss: 0.025090\n",
            "Train Epoch: 95 [2944/14860 (20%)]\tLoss: 0.023675\n",
            "Train Epoch: 95 [3072/14860 (21%)]\tLoss: 0.032010\n",
            "Train Epoch: 95 [3200/14860 (21%)]\tLoss: 0.021138\n",
            "Train Epoch: 95 [3328/14860 (22%)]\tLoss: 0.031056\n",
            "Train Epoch: 95 [3456/14860 (23%)]\tLoss: 0.020114\n",
            "Train Epoch: 95 [3584/14860 (24%)]\tLoss: 0.025050\n",
            "Train Epoch: 95 [3712/14860 (25%)]\tLoss: 0.021705\n",
            "Train Epoch: 95 [3840/14860 (26%)]\tLoss: 0.021587\n",
            "Train Epoch: 95 [3968/14860 (26%)]\tLoss: 0.014760\n",
            "Train Epoch: 95 [4096/14860 (27%)]\tLoss: 0.022620\n",
            "Train Epoch: 95 [4224/14860 (28%)]\tLoss: 0.022630\n",
            "Train Epoch: 95 [4352/14860 (29%)]\tLoss: 0.020163\n",
            "Train Epoch: 95 [4480/14860 (30%)]\tLoss: 0.021083\n",
            "Train Epoch: 95 [4608/14860 (31%)]\tLoss: 0.018213\n",
            "Train Epoch: 95 [4736/14860 (32%)]\tLoss: 0.024810\n",
            "Train Epoch: 95 [4864/14860 (32%)]\tLoss: 0.020521\n",
            "Train Epoch: 95 [4992/14860 (33%)]\tLoss: 0.018499\n",
            "Train Epoch: 95 [5120/14860 (34%)]\tLoss: 0.015977\n",
            "Train Epoch: 95 [5248/14860 (35%)]\tLoss: 0.018639\n",
            "Train Epoch: 95 [5376/14860 (36%)]\tLoss: 0.020116\n",
            "Train Epoch: 95 [5504/14860 (37%)]\tLoss: 0.017965\n",
            "Train Epoch: 95 [5632/14860 (38%)]\tLoss: 0.014224\n",
            "Train Epoch: 95 [5760/14860 (38%)]\tLoss: 0.035923\n",
            "Train Epoch: 95 [5888/14860 (39%)]\tLoss: 0.032696\n",
            "Train Epoch: 95 [6016/14860 (40%)]\tLoss: 0.022412\n",
            "Train Epoch: 95 [6144/14860 (41%)]\tLoss: 0.028929\n",
            "Train Epoch: 95 [6272/14860 (42%)]\tLoss: 0.021458\n",
            "Train Epoch: 95 [6400/14860 (43%)]\tLoss: 0.027662\n",
            "Train Epoch: 95 [6528/14860 (44%)]\tLoss: 0.026580\n",
            "Train Epoch: 95 [6656/14860 (44%)]\tLoss: 0.015362\n",
            "Train Epoch: 95 [6784/14860 (45%)]\tLoss: 0.029766\n",
            "Train Epoch: 95 [6912/14860 (46%)]\tLoss: 0.018376\n",
            "Train Epoch: 95 [7040/14860 (47%)]\tLoss: 0.019630\n",
            "Train Epoch: 95 [7168/14860 (48%)]\tLoss: 0.017256\n",
            "Train Epoch: 95 [7296/14860 (49%)]\tLoss: 0.017986\n",
            "Train Epoch: 95 [7424/14860 (50%)]\tLoss: 0.016267\n",
            "Train Epoch: 95 [7552/14860 (50%)]\tLoss: 0.012947\n",
            "Train Epoch: 95 [7680/14860 (51%)]\tLoss: 0.021377\n",
            "Train Epoch: 95 [7808/14860 (52%)]\tLoss: 0.019637\n",
            "Train Epoch: 95 [7936/14860 (53%)]\tLoss: 0.022457\n",
            "Train Epoch: 95 [8064/14860 (54%)]\tLoss: 0.018812\n",
            "Train Epoch: 95 [8192/14860 (55%)]\tLoss: 0.020339\n",
            "Train Epoch: 95 [8320/14860 (56%)]\tLoss: 0.021487\n",
            "Train Epoch: 95 [8448/14860 (56%)]\tLoss: 0.023687\n",
            "Train Epoch: 95 [8576/14860 (57%)]\tLoss: 0.017398\n",
            "Train Epoch: 95 [8704/14860 (58%)]\tLoss: 0.023071\n",
            "Train Epoch: 95 [8832/14860 (59%)]\tLoss: 0.017184\n",
            "Train Epoch: 95 [8960/14860 (60%)]\tLoss: 0.016307\n",
            "Train Epoch: 95 [9088/14860 (61%)]\tLoss: 0.023410\n",
            "Train Epoch: 95 [9216/14860 (62%)]\tLoss: 0.023201\n",
            "Train Epoch: 95 [9344/14860 (62%)]\tLoss: 0.022038\n",
            "Train Epoch: 95 [9472/14860 (63%)]\tLoss: 0.018377\n",
            "Train Epoch: 95 [9600/14860 (64%)]\tLoss: 0.021092\n",
            "Train Epoch: 95 [9728/14860 (65%)]\tLoss: 0.019310\n",
            "Train Epoch: 95 [9856/14860 (66%)]\tLoss: 0.014610\n",
            "Train Epoch: 95 [9984/14860 (67%)]\tLoss: 0.019729\n",
            "Train Epoch: 95 [10112/14860 (68%)]\tLoss: 0.013771\n",
            "Train Epoch: 95 [10240/14860 (68%)]\tLoss: 0.012651\n",
            "Train Epoch: 95 [10368/14860 (69%)]\tLoss: 0.018446\n",
            "Train Epoch: 95 [10496/14860 (70%)]\tLoss: 0.015841\n",
            "Train Epoch: 95 [10624/14860 (71%)]\tLoss: 0.021200\n",
            "Train Epoch: 95 [10752/14860 (72%)]\tLoss: 0.014243\n",
            "Train Epoch: 95 [10880/14860 (73%)]\tLoss: 0.022692\n",
            "Train Epoch: 95 [11008/14860 (74%)]\tLoss: 0.021158\n",
            "Train Epoch: 95 [11136/14860 (74%)]\tLoss: 0.022084\n",
            "Train Epoch: 95 [11264/14860 (75%)]\tLoss: 0.016766\n",
            "Train Epoch: 95 [11392/14860 (76%)]\tLoss: 0.020763\n",
            "Train Epoch: 95 [11520/14860 (77%)]\tLoss: 0.015862\n",
            "Train Epoch: 95 [11648/14860 (78%)]\tLoss: 0.019575\n",
            "Train Epoch: 95 [11776/14860 (79%)]\tLoss: 0.017029\n",
            "Train Epoch: 95 [11904/14860 (79%)]\tLoss: 0.019892\n",
            "Train Epoch: 95 [12032/14860 (80%)]\tLoss: 0.026475\n",
            "Train Epoch: 95 [12160/14860 (81%)]\tLoss: 0.026255\n",
            "Train Epoch: 95 [12288/14860 (82%)]\tLoss: 0.016326\n",
            "Train Epoch: 95 [12416/14860 (83%)]\tLoss: 0.017441\n",
            "Train Epoch: 95 [12544/14860 (84%)]\tLoss: 0.018962\n",
            "Train Epoch: 95 [12672/14860 (85%)]\tLoss: 0.015104\n",
            "Train Epoch: 95 [12800/14860 (85%)]\tLoss: 0.024050\n",
            "Train Epoch: 95 [12928/14860 (86%)]\tLoss: 0.018765\n",
            "Train Epoch: 95 [13056/14860 (87%)]\tLoss: 0.024025\n",
            "Train Epoch: 95 [13184/14860 (88%)]\tLoss: 0.020505\n",
            "Train Epoch: 95 [13312/14860 (89%)]\tLoss: 0.023292\n",
            "Train Epoch: 95 [13440/14860 (90%)]\tLoss: 0.018756\n",
            "Train Epoch: 95 [13568/14860 (91%)]\tLoss: 0.018409\n",
            "Train Epoch: 95 [13696/14860 (91%)]\tLoss: 0.017025\n",
            "Train Epoch: 95 [13824/14860 (92%)]\tLoss: 0.022495\n",
            "Train Epoch: 95 [13952/14860 (93%)]\tLoss: 0.022167\n",
            "Train Epoch: 95 [14080/14860 (94%)]\tLoss: 0.019265\n",
            "Train Epoch: 95 [14208/14860 (95%)]\tLoss: 0.030046\n",
            "Train Epoch: 95 [14336/14860 (96%)]\tLoss: 0.017892\n",
            "Train Epoch: 95 [14464/14860 (97%)]\tLoss: 0.026314\n",
            "Train Epoch: 95 [14592/14860 (97%)]\tLoss: 0.019929\n",
            "Train Epoch: 95 [14720/14860 (98%)]\tLoss: 0.014789\n",
            "Train Epoch: 95 [1392/14860 (99%)]\tLoss: 0.006168\n",
            "epoch 95 training loss: 0.021186092470446203\n",
            "epoch 95 validation loss: 0.02412390449145227\n",
            "Train Epoch: 96 [0/14860 (0%)]\tLoss: 0.022824\n",
            "Train Epoch: 96 [128/14860 (1%)]\tLoss: 0.025434\n",
            "Train Epoch: 96 [256/14860 (2%)]\tLoss: 0.021197\n",
            "Train Epoch: 96 [384/14860 (3%)]\tLoss: 0.022885\n",
            "Train Epoch: 96 [512/14860 (3%)]\tLoss: 0.018351\n",
            "Train Epoch: 96 [640/14860 (4%)]\tLoss: 0.016997\n",
            "Train Epoch: 96 [768/14860 (5%)]\tLoss: 0.014424\n",
            "Train Epoch: 96 [896/14860 (6%)]\tLoss: 0.014975\n",
            "Train Epoch: 96 [1024/14860 (7%)]\tLoss: 0.025560\n",
            "Train Epoch: 96 [1152/14860 (8%)]\tLoss: 0.024757\n",
            "Train Epoch: 96 [1280/14860 (9%)]\tLoss: 0.021799\n",
            "Train Epoch: 96 [1408/14860 (9%)]\tLoss: 0.026552\n",
            "Train Epoch: 96 [1536/14860 (10%)]\tLoss: 0.027707\n",
            "Train Epoch: 96 [1664/14860 (11%)]\tLoss: 0.022284\n",
            "Train Epoch: 96 [1792/14860 (12%)]\tLoss: 0.015801\n",
            "Train Epoch: 96 [1920/14860 (13%)]\tLoss: 0.029781\n",
            "Train Epoch: 96 [2048/14860 (14%)]\tLoss: 0.020156\n",
            "Train Epoch: 96 [2176/14860 (15%)]\tLoss: 0.023311\n",
            "Train Epoch: 96 [2304/14860 (15%)]\tLoss: 0.021305\n",
            "Train Epoch: 96 [2432/14860 (16%)]\tLoss: 0.026692\n",
            "Train Epoch: 96 [2560/14860 (17%)]\tLoss: 0.022405\n",
            "Train Epoch: 96 [2688/14860 (18%)]\tLoss: 0.036917\n",
            "Train Epoch: 96 [2816/14860 (19%)]\tLoss: 0.019186\n",
            "Train Epoch: 96 [2944/14860 (20%)]\tLoss: 0.022620\n",
            "Train Epoch: 96 [3072/14860 (21%)]\tLoss: 0.011201\n",
            "Train Epoch: 96 [3200/14860 (21%)]\tLoss: 0.022230\n",
            "Train Epoch: 96 [3328/14860 (22%)]\tLoss: 0.017433\n",
            "Train Epoch: 96 [3456/14860 (23%)]\tLoss: 0.026277\n",
            "Train Epoch: 96 [3584/14860 (24%)]\tLoss: 0.016018\n",
            "Train Epoch: 96 [3712/14860 (25%)]\tLoss: 0.019751\n",
            "Train Epoch: 96 [3840/14860 (26%)]\tLoss: 0.011206\n",
            "Train Epoch: 96 [3968/14860 (26%)]\tLoss: 0.021158\n",
            "Train Epoch: 96 [4096/14860 (27%)]\tLoss: 0.018163\n",
            "Train Epoch: 96 [4224/14860 (28%)]\tLoss: 0.027268\n",
            "Train Epoch: 96 [4352/14860 (29%)]\tLoss: 0.020566\n",
            "Train Epoch: 96 [4480/14860 (30%)]\tLoss: 0.018450\n",
            "Train Epoch: 96 [4608/14860 (31%)]\tLoss: 0.024165\n",
            "Train Epoch: 96 [4736/14860 (32%)]\tLoss: 0.025902\n",
            "Train Epoch: 96 [4864/14860 (32%)]\tLoss: 0.019270\n",
            "Train Epoch: 96 [4992/14860 (33%)]\tLoss: 0.018610\n",
            "Train Epoch: 96 [5120/14860 (34%)]\tLoss: 0.015817\n",
            "Train Epoch: 96 [5248/14860 (35%)]\tLoss: 0.027574\n",
            "Train Epoch: 96 [5376/14860 (36%)]\tLoss: 0.024007\n",
            "Train Epoch: 96 [5504/14860 (37%)]\tLoss: 0.017706\n",
            "Train Epoch: 96 [5632/14860 (38%)]\tLoss: 0.017706\n",
            "Train Epoch: 96 [5760/14860 (38%)]\tLoss: 0.022380\n",
            "Train Epoch: 96 [5888/14860 (39%)]\tLoss: 0.021965\n",
            "Train Epoch: 96 [6016/14860 (40%)]\tLoss: 0.016252\n",
            "Train Epoch: 96 [6144/14860 (41%)]\tLoss: 0.018614\n",
            "Train Epoch: 96 [6272/14860 (42%)]\tLoss: 0.019072\n",
            "Train Epoch: 96 [6400/14860 (43%)]\tLoss: 0.024619\n",
            "Train Epoch: 96 [6528/14860 (44%)]\tLoss: 0.024249\n",
            "Train Epoch: 96 [6656/14860 (44%)]\tLoss: 0.034050\n",
            "Train Epoch: 96 [6784/14860 (45%)]\tLoss: 0.019902\n",
            "Train Epoch: 96 [6912/14860 (46%)]\tLoss: 0.018344\n",
            "Train Epoch: 96 [7040/14860 (47%)]\tLoss: 0.023017\n",
            "Train Epoch: 96 [7168/14860 (48%)]\tLoss: 0.020091\n",
            "Train Epoch: 96 [7296/14860 (49%)]\tLoss: 0.026950\n",
            "Train Epoch: 96 [7424/14860 (50%)]\tLoss: 0.020470\n",
            "Train Epoch: 96 [7552/14860 (50%)]\tLoss: 0.022957\n",
            "Train Epoch: 96 [7680/14860 (51%)]\tLoss: 0.028116\n",
            "Train Epoch: 96 [7808/14860 (52%)]\tLoss: 0.025687\n",
            "Train Epoch: 96 [7936/14860 (53%)]\tLoss: 0.017144\n",
            "Train Epoch: 96 [8064/14860 (54%)]\tLoss: 0.027647\n",
            "Train Epoch: 96 [8192/14860 (55%)]\tLoss: 0.016910\n",
            "Train Epoch: 96 [8320/14860 (56%)]\tLoss: 0.023922\n",
            "Train Epoch: 96 [8448/14860 (56%)]\tLoss: 0.022432\n",
            "Train Epoch: 96 [8576/14860 (57%)]\tLoss: 0.016233\n",
            "Train Epoch: 96 [8704/14860 (58%)]\tLoss: 0.024751\n",
            "Train Epoch: 96 [8832/14860 (59%)]\tLoss: 0.012616\n",
            "Train Epoch: 96 [8960/14860 (60%)]\tLoss: 0.021610\n",
            "Train Epoch: 96 [9088/14860 (61%)]\tLoss: 0.021238\n",
            "Train Epoch: 96 [9216/14860 (62%)]\tLoss: 0.015469\n",
            "Train Epoch: 96 [9344/14860 (62%)]\tLoss: 0.021603\n",
            "Train Epoch: 96 [9472/14860 (63%)]\tLoss: 0.022799\n",
            "Train Epoch: 96 [9600/14860 (64%)]\tLoss: 0.015322\n",
            "Train Epoch: 96 [9728/14860 (65%)]\tLoss: 0.018592\n",
            "Train Epoch: 96 [9856/14860 (66%)]\tLoss: 0.018585\n",
            "Train Epoch: 96 [9984/14860 (67%)]\tLoss: 0.023991\n",
            "Train Epoch: 96 [10112/14860 (68%)]\tLoss: 0.019040\n",
            "Train Epoch: 96 [10240/14860 (68%)]\tLoss: 0.022186\n",
            "Train Epoch: 96 [10368/14860 (69%)]\tLoss: 0.021123\n",
            "Train Epoch: 96 [10496/14860 (70%)]\tLoss: 0.024073\n",
            "Train Epoch: 96 [10624/14860 (71%)]\tLoss: 0.019395\n",
            "Train Epoch: 96 [10752/14860 (72%)]\tLoss: 0.020800\n",
            "Train Epoch: 96 [10880/14860 (73%)]\tLoss: 0.013563\n",
            "Train Epoch: 96 [11008/14860 (74%)]\tLoss: 0.036317\n",
            "Train Epoch: 96 [11136/14860 (74%)]\tLoss: 0.024652\n",
            "Train Epoch: 96 [11264/14860 (75%)]\tLoss: 0.038445\n",
            "Train Epoch: 96 [11392/14860 (76%)]\tLoss: 0.018287\n",
            "Train Epoch: 96 [11520/14860 (77%)]\tLoss: 0.032750\n",
            "Train Epoch: 96 [11648/14860 (78%)]\tLoss: 0.025096\n",
            "Train Epoch: 96 [11776/14860 (79%)]\tLoss: 0.027295\n",
            "Train Epoch: 96 [11904/14860 (79%)]\tLoss: 0.020180\n",
            "Train Epoch: 96 [12032/14860 (80%)]\tLoss: 0.012801\n",
            "Train Epoch: 96 [12160/14860 (81%)]\tLoss: 0.029283\n",
            "Train Epoch: 96 [12288/14860 (82%)]\tLoss: 0.019021\n",
            "Train Epoch: 96 [12416/14860 (83%)]\tLoss: 0.026747\n",
            "Train Epoch: 96 [12544/14860 (84%)]\tLoss: 0.023085\n",
            "Train Epoch: 96 [12672/14860 (85%)]\tLoss: 0.020167\n",
            "Train Epoch: 96 [12800/14860 (85%)]\tLoss: 0.026433\n",
            "Train Epoch: 96 [12928/14860 (86%)]\tLoss: 0.018502\n",
            "Train Epoch: 96 [13056/14860 (87%)]\tLoss: 0.019580\n",
            "Train Epoch: 96 [13184/14860 (88%)]\tLoss: 0.022655\n",
            "Train Epoch: 96 [13312/14860 (89%)]\tLoss: 0.024751\n",
            "Train Epoch: 96 [13440/14860 (90%)]\tLoss: 0.017844\n",
            "Train Epoch: 96 [13568/14860 (91%)]\tLoss: 0.024257\n",
            "Train Epoch: 96 [13696/14860 (91%)]\tLoss: 0.020283\n",
            "Train Epoch: 96 [13824/14860 (92%)]\tLoss: 0.025460\n",
            "Train Epoch: 96 [13952/14860 (93%)]\tLoss: 0.018007\n",
            "Train Epoch: 96 [14080/14860 (94%)]\tLoss: 0.020773\n",
            "Train Epoch: 96 [14208/14860 (95%)]\tLoss: 0.017084\n",
            "Train Epoch: 96 [14336/14860 (96%)]\tLoss: 0.018316\n",
            "Train Epoch: 96 [14464/14860 (97%)]\tLoss: 0.019451\n",
            "Train Epoch: 96 [14592/14860 (97%)]\tLoss: 0.022694\n",
            "Train Epoch: 96 [14720/14860 (98%)]\tLoss: 0.020842\n",
            "Train Epoch: 96 [1392/14860 (99%)]\tLoss: 0.014064\n",
            "epoch 96 training loss: 0.02168632718997124\n",
            "epoch 96 validation loss: 0.04625909207230908\n",
            "Train Epoch: 97 [0/14860 (0%)]\tLoss: 0.031334\n",
            "Train Epoch: 97 [128/14860 (1%)]\tLoss: 0.034984\n",
            "Train Epoch: 97 [256/14860 (2%)]\tLoss: 0.051889\n",
            "Train Epoch: 97 [384/14860 (3%)]\tLoss: 0.019982\n",
            "Train Epoch: 97 [512/14860 (3%)]\tLoss: 0.032136\n",
            "Train Epoch: 97 [640/14860 (4%)]\tLoss: 0.023681\n",
            "Train Epoch: 97 [768/14860 (5%)]\tLoss: 0.022127\n",
            "Train Epoch: 97 [896/14860 (6%)]\tLoss: 0.031129\n",
            "Train Epoch: 97 [1024/14860 (7%)]\tLoss: 0.016531\n",
            "Train Epoch: 97 [1152/14860 (8%)]\tLoss: 0.033086\n",
            "Train Epoch: 97 [1280/14860 (9%)]\tLoss: 0.022828\n",
            "Train Epoch: 97 [1408/14860 (9%)]\tLoss: 0.027447\n",
            "Train Epoch: 97 [1536/14860 (10%)]\tLoss: 0.028296\n",
            "Train Epoch: 97 [1664/14860 (11%)]\tLoss: 0.022812\n",
            "Train Epoch: 97 [1792/14860 (12%)]\tLoss: 0.029837\n",
            "Train Epoch: 97 [1920/14860 (13%)]\tLoss: 0.016315\n",
            "Train Epoch: 97 [2048/14860 (14%)]\tLoss: 0.029055\n",
            "Train Epoch: 97 [2176/14860 (15%)]\tLoss: 0.029029\n",
            "Train Epoch: 97 [2304/14860 (15%)]\tLoss: 0.023205\n",
            "Train Epoch: 97 [2432/14860 (16%)]\tLoss: 0.022383\n",
            "Train Epoch: 97 [2560/14860 (17%)]\tLoss: 0.017810\n",
            "Train Epoch: 97 [2688/14860 (18%)]\tLoss: 0.026058\n",
            "Train Epoch: 97 [2816/14860 (19%)]\tLoss: 0.016063\n",
            "Train Epoch: 97 [2944/14860 (20%)]\tLoss: 0.026485\n",
            "Train Epoch: 97 [3072/14860 (21%)]\tLoss: 0.023646\n",
            "Train Epoch: 97 [3200/14860 (21%)]\tLoss: 0.019408\n",
            "Train Epoch: 97 [3328/14860 (22%)]\tLoss: 0.016242\n",
            "Train Epoch: 97 [3456/14860 (23%)]\tLoss: 0.021557\n",
            "Train Epoch: 97 [3584/14860 (24%)]\tLoss: 0.023943\n",
            "Train Epoch: 97 [3712/14860 (25%)]\tLoss: 0.019353\n",
            "Train Epoch: 97 [3840/14860 (26%)]\tLoss: 0.024777\n",
            "Train Epoch: 97 [3968/14860 (26%)]\tLoss: 0.020162\n",
            "Train Epoch: 97 [4096/14860 (27%)]\tLoss: 0.022133\n",
            "Train Epoch: 97 [4224/14860 (28%)]\tLoss: 0.022132\n",
            "Train Epoch: 97 [4352/14860 (29%)]\tLoss: 0.020009\n",
            "Train Epoch: 97 [4480/14860 (30%)]\tLoss: 0.023433\n",
            "Train Epoch: 97 [4608/14860 (31%)]\tLoss: 0.029136\n",
            "Train Epoch: 97 [4736/14860 (32%)]\tLoss: 0.034789\n",
            "Train Epoch: 97 [4864/14860 (32%)]\tLoss: 0.023090\n",
            "Train Epoch: 97 [4992/14860 (33%)]\tLoss: 0.028864\n",
            "Train Epoch: 97 [5120/14860 (34%)]\tLoss: 0.029023\n",
            "Train Epoch: 97 [5248/14860 (35%)]\tLoss: 0.018029\n",
            "Train Epoch: 97 [5376/14860 (36%)]\tLoss: 0.032715\n",
            "Train Epoch: 97 [5504/14860 (37%)]\tLoss: 0.021362\n",
            "Train Epoch: 97 [5632/14860 (38%)]\tLoss: 0.022511\n",
            "Train Epoch: 97 [5760/14860 (38%)]\tLoss: 0.023416\n",
            "Train Epoch: 97 [5888/14860 (39%)]\tLoss: 0.034442\n",
            "Train Epoch: 97 [6016/14860 (40%)]\tLoss: 0.036392\n",
            "Train Epoch: 97 [6144/14860 (41%)]\tLoss: 0.020865\n",
            "Train Epoch: 97 [6272/14860 (42%)]\tLoss: 0.027273\n",
            "Train Epoch: 97 [6400/14860 (43%)]\tLoss: 0.016538\n",
            "Train Epoch: 97 [6528/14860 (44%)]\tLoss: 0.020482\n",
            "Train Epoch: 97 [6656/14860 (44%)]\tLoss: 0.023961\n",
            "Train Epoch: 97 [6784/14860 (45%)]\tLoss: 0.020766\n",
            "Train Epoch: 97 [6912/14860 (46%)]\tLoss: 0.019387\n",
            "Train Epoch: 97 [7040/14860 (47%)]\tLoss: 0.019606\n",
            "Train Epoch: 97 [7168/14860 (48%)]\tLoss: 0.009596\n",
            "Train Epoch: 97 [7296/14860 (49%)]\tLoss: 0.016349\n",
            "Train Epoch: 97 [7424/14860 (50%)]\tLoss: 0.017587\n",
            "Train Epoch: 97 [7552/14860 (50%)]\tLoss: 0.024061\n",
            "Train Epoch: 97 [7680/14860 (51%)]\tLoss: 0.017717\n",
            "Train Epoch: 97 [7808/14860 (52%)]\tLoss: 0.032389\n",
            "Train Epoch: 97 [7936/14860 (53%)]\tLoss: 0.022810\n",
            "Train Epoch: 97 [8064/14860 (54%)]\tLoss: 0.030596\n",
            "Train Epoch: 97 [8192/14860 (55%)]\tLoss: 0.016720\n",
            "Train Epoch: 97 [8320/14860 (56%)]\tLoss: 0.016087\n",
            "Train Epoch: 97 [8448/14860 (56%)]\tLoss: 0.024528\n",
            "Train Epoch: 97 [8576/14860 (57%)]\tLoss: 0.022009\n",
            "Train Epoch: 97 [8704/14860 (58%)]\tLoss: 0.029220\n",
            "Train Epoch: 97 [8832/14860 (59%)]\tLoss: 0.029635\n",
            "Train Epoch: 97 [8960/14860 (60%)]\tLoss: 0.017852\n",
            "Train Epoch: 97 [9088/14860 (61%)]\tLoss: 0.028005\n",
            "Train Epoch: 97 [9216/14860 (62%)]\tLoss: 0.020460\n",
            "Train Epoch: 97 [9344/14860 (62%)]\tLoss: 0.014729\n",
            "Train Epoch: 97 [9472/14860 (63%)]\tLoss: 0.019834\n",
            "Train Epoch: 97 [9600/14860 (64%)]\tLoss: 0.024585\n",
            "Train Epoch: 97 [9728/14860 (65%)]\tLoss: 0.017598\n",
            "Train Epoch: 97 [9856/14860 (66%)]\tLoss: 0.018566\n",
            "Train Epoch: 97 [9984/14860 (67%)]\tLoss: 0.018244\n",
            "Train Epoch: 97 [10112/14860 (68%)]\tLoss: 0.023225\n",
            "Train Epoch: 97 [10240/14860 (68%)]\tLoss: 0.020384\n",
            "Train Epoch: 97 [10368/14860 (69%)]\tLoss: 0.022246\n",
            "Train Epoch: 97 [10496/14860 (70%)]\tLoss: 0.018153\n",
            "Train Epoch: 97 [10624/14860 (71%)]\tLoss: 0.014257\n",
            "Train Epoch: 97 [10752/14860 (72%)]\tLoss: 0.023494\n",
            "Train Epoch: 97 [10880/14860 (73%)]\tLoss: 0.022173\n",
            "Train Epoch: 97 [11008/14860 (74%)]\tLoss: 0.023999\n",
            "Train Epoch: 97 [11136/14860 (74%)]\tLoss: 0.018982\n",
            "Train Epoch: 97 [11264/14860 (75%)]\tLoss: 0.014369\n",
            "Train Epoch: 97 [11392/14860 (76%)]\tLoss: 0.034569\n",
            "Train Epoch: 97 [11520/14860 (77%)]\tLoss: 0.017087\n",
            "Train Epoch: 97 [11648/14860 (78%)]\tLoss: 0.022754\n",
            "Train Epoch: 97 [11776/14860 (79%)]\tLoss: 0.021673\n",
            "Train Epoch: 97 [11904/14860 (79%)]\tLoss: 0.022301\n",
            "Train Epoch: 97 [12032/14860 (80%)]\tLoss: 0.026025\n",
            "Train Epoch: 97 [12160/14860 (81%)]\tLoss: 0.025335\n",
            "Train Epoch: 97 [12288/14860 (82%)]\tLoss: 0.021593\n",
            "Train Epoch: 97 [12416/14860 (83%)]\tLoss: 0.022465\n",
            "Train Epoch: 97 [12544/14860 (84%)]\tLoss: 0.028817\n",
            "Train Epoch: 97 [12672/14860 (85%)]\tLoss: 0.021530\n",
            "Train Epoch: 97 [12800/14860 (85%)]\tLoss: 0.028884\n",
            "Train Epoch: 97 [12928/14860 (86%)]\tLoss: 0.014985\n",
            "Train Epoch: 97 [13056/14860 (87%)]\tLoss: 0.024298\n",
            "Train Epoch: 97 [13184/14860 (88%)]\tLoss: 0.034210\n",
            "Train Epoch: 97 [13312/14860 (89%)]\tLoss: 0.022426\n",
            "Train Epoch: 97 [13440/14860 (90%)]\tLoss: 0.025652\n",
            "Train Epoch: 97 [13568/14860 (91%)]\tLoss: 0.015321\n",
            "Train Epoch: 97 [13696/14860 (91%)]\tLoss: 0.014392\n",
            "Train Epoch: 97 [13824/14860 (92%)]\tLoss: 0.024591\n",
            "Train Epoch: 97 [13952/14860 (93%)]\tLoss: 0.015232\n",
            "Train Epoch: 97 [14080/14860 (94%)]\tLoss: 0.027562\n",
            "Train Epoch: 97 [14208/14860 (95%)]\tLoss: 0.018734\n",
            "Train Epoch: 97 [14336/14860 (96%)]\tLoss: 0.028698\n",
            "Train Epoch: 97 [14464/14860 (97%)]\tLoss: 0.017161\n",
            "Train Epoch: 97 [14592/14860 (97%)]\tLoss: 0.013003\n",
            "Train Epoch: 97 [14720/14860 (98%)]\tLoss: 0.018387\n",
            "Train Epoch: 97 [1392/14860 (99%)]\tLoss: 0.016670\n",
            "epoch 97 training loss: 0.02315174982461155\n",
            "epoch 97 validation loss: 0.027094748782187917\n",
            "Train Epoch: 98 [0/14860 (0%)]\tLoss: 0.036029\n",
            "Train Epoch: 98 [128/14860 (1%)]\tLoss: 0.018470\n",
            "Train Epoch: 98 [256/14860 (2%)]\tLoss: 0.022603\n",
            "Train Epoch: 98 [384/14860 (3%)]\tLoss: 0.020666\n",
            "Train Epoch: 98 [512/14860 (3%)]\tLoss: 0.019881\n",
            "Train Epoch: 98 [640/14860 (4%)]\tLoss: 0.032043\n",
            "Train Epoch: 98 [768/14860 (5%)]\tLoss: 0.023930\n",
            "Train Epoch: 98 [896/14860 (6%)]\tLoss: 0.021576\n",
            "Train Epoch: 98 [1024/14860 (7%)]\tLoss: 0.018758\n",
            "Train Epoch: 98 [1152/14860 (8%)]\tLoss: 0.023332\n",
            "Train Epoch: 98 [1280/14860 (9%)]\tLoss: 0.022389\n",
            "Train Epoch: 98 [1408/14860 (9%)]\tLoss: 0.023120\n",
            "Train Epoch: 98 [1536/14860 (10%)]\tLoss: 0.022455\n",
            "Train Epoch: 98 [1664/14860 (11%)]\tLoss: 0.017156\n",
            "Train Epoch: 98 [1792/14860 (12%)]\tLoss: 0.019073\n",
            "Train Epoch: 98 [1920/14860 (13%)]\tLoss: 0.031379\n",
            "Train Epoch: 98 [2048/14860 (14%)]\tLoss: 0.020839\n",
            "Train Epoch: 98 [2176/14860 (15%)]\tLoss: 0.026545\n",
            "Train Epoch: 98 [2304/14860 (15%)]\tLoss: 0.019831\n",
            "Train Epoch: 98 [2432/14860 (16%)]\tLoss: 0.025933\n",
            "Train Epoch: 98 [2560/14860 (17%)]\tLoss: 0.019011\n",
            "Train Epoch: 98 [2688/14860 (18%)]\tLoss: 0.018695\n",
            "Train Epoch: 98 [2816/14860 (19%)]\tLoss: 0.026508\n",
            "Train Epoch: 98 [2944/14860 (20%)]\tLoss: 0.014374\n",
            "Train Epoch: 98 [3072/14860 (21%)]\tLoss: 0.021184\n",
            "Train Epoch: 98 [3200/14860 (21%)]\tLoss: 0.023653\n",
            "Train Epoch: 98 [3328/14860 (22%)]\tLoss: 0.021992\n",
            "Train Epoch: 98 [3456/14860 (23%)]\tLoss: 0.021267\n",
            "Train Epoch: 98 [3584/14860 (24%)]\tLoss: 0.022180\n",
            "Train Epoch: 98 [3712/14860 (25%)]\tLoss: 0.016302\n",
            "Train Epoch: 98 [3840/14860 (26%)]\tLoss: 0.020807\n",
            "Train Epoch: 98 [3968/14860 (26%)]\tLoss: 0.026956\n",
            "Train Epoch: 98 [4096/14860 (27%)]\tLoss: 0.020815\n",
            "Train Epoch: 98 [4224/14860 (28%)]\tLoss: 0.018852\n",
            "Train Epoch: 98 [4352/14860 (29%)]\tLoss: 0.019663\n",
            "Train Epoch: 98 [4480/14860 (30%)]\tLoss: 0.026773\n",
            "Train Epoch: 98 [4608/14860 (31%)]\tLoss: 0.013746\n",
            "Train Epoch: 98 [4736/14860 (32%)]\tLoss: 0.021720\n",
            "Train Epoch: 98 [4864/14860 (32%)]\tLoss: 0.022393\n",
            "Train Epoch: 98 [4992/14860 (33%)]\tLoss: 0.020269\n",
            "Train Epoch: 98 [5120/14860 (34%)]\tLoss: 0.018327\n",
            "Train Epoch: 98 [5248/14860 (35%)]\tLoss: 0.023242\n",
            "Train Epoch: 98 [5376/14860 (36%)]\tLoss: 0.023185\n",
            "Train Epoch: 98 [5504/14860 (37%)]\tLoss: 0.025763\n",
            "Train Epoch: 98 [5632/14860 (38%)]\tLoss: 0.024337\n",
            "Train Epoch: 98 [5760/14860 (38%)]\tLoss: 0.017048\n",
            "Train Epoch: 98 [5888/14860 (39%)]\tLoss: 0.019203\n",
            "Train Epoch: 98 [6016/14860 (40%)]\tLoss: 0.024177\n",
            "Train Epoch: 98 [6144/14860 (41%)]\tLoss: 0.023223\n",
            "Train Epoch: 98 [6272/14860 (42%)]\tLoss: 0.026437\n",
            "Train Epoch: 98 [6400/14860 (43%)]\tLoss: 0.030138\n",
            "Train Epoch: 98 [6528/14860 (44%)]\tLoss: 0.024504\n",
            "Train Epoch: 98 [6656/14860 (44%)]\tLoss: 0.030152\n",
            "Train Epoch: 98 [6784/14860 (45%)]\tLoss: 0.019195\n",
            "Train Epoch: 98 [6912/14860 (46%)]\tLoss: 0.023891\n",
            "Train Epoch: 98 [7040/14860 (47%)]\tLoss: 0.020302\n",
            "Train Epoch: 98 [7168/14860 (48%)]\tLoss: 0.024970\n",
            "Train Epoch: 98 [7296/14860 (49%)]\tLoss: 0.024430\n",
            "Train Epoch: 98 [7424/14860 (50%)]\tLoss: 0.033957\n",
            "Train Epoch: 98 [7552/14860 (50%)]\tLoss: 0.029611\n",
            "Train Epoch: 98 [7680/14860 (51%)]\tLoss: 0.015583\n",
            "Train Epoch: 98 [7808/14860 (52%)]\tLoss: 0.023888\n",
            "Train Epoch: 98 [7936/14860 (53%)]\tLoss: 0.023735\n",
            "Train Epoch: 98 [8064/14860 (54%)]\tLoss: 0.029911\n",
            "Train Epoch: 98 [8192/14860 (55%)]\tLoss: 0.023608\n",
            "Train Epoch: 98 [8320/14860 (56%)]\tLoss: 0.018896\n",
            "Train Epoch: 98 [8448/14860 (56%)]\tLoss: 0.021965\n",
            "Train Epoch: 98 [8576/14860 (57%)]\tLoss: 0.018594\n",
            "Train Epoch: 98 [8704/14860 (58%)]\tLoss: 0.019469\n",
            "Train Epoch: 98 [8832/14860 (59%)]\tLoss: 0.018206\n",
            "Train Epoch: 98 [8960/14860 (60%)]\tLoss: 0.020202\n",
            "Train Epoch: 98 [9088/14860 (61%)]\tLoss: 0.020602\n",
            "Train Epoch: 98 [9216/14860 (62%)]\tLoss: 0.014477\n",
            "Train Epoch: 98 [9344/14860 (62%)]\tLoss: 0.021723\n",
            "Train Epoch: 98 [9472/14860 (63%)]\tLoss: 0.028189\n",
            "Train Epoch: 98 [9600/14860 (64%)]\tLoss: 0.016659\n",
            "Train Epoch: 98 [9728/14860 (65%)]\tLoss: 0.019594\n",
            "Train Epoch: 98 [9856/14860 (66%)]\tLoss: 0.020516\n",
            "Train Epoch: 98 [9984/14860 (67%)]\tLoss: 0.018356\n",
            "Train Epoch: 98 [10112/14860 (68%)]\tLoss: 0.025348\n",
            "Train Epoch: 98 [10240/14860 (68%)]\tLoss: 0.022049\n",
            "Train Epoch: 98 [10368/14860 (69%)]\tLoss: 0.017753\n",
            "Train Epoch: 98 [10496/14860 (70%)]\tLoss: 0.014879\n",
            "Train Epoch: 98 [10624/14860 (71%)]\tLoss: 0.025207\n",
            "Train Epoch: 98 [10752/14860 (72%)]\tLoss: 0.023652\n",
            "Train Epoch: 98 [10880/14860 (73%)]\tLoss: 0.018449\n",
            "Train Epoch: 98 [11008/14860 (74%)]\tLoss: 0.016651\n",
            "Train Epoch: 98 [11136/14860 (74%)]\tLoss: 0.021978\n",
            "Train Epoch: 98 [11264/14860 (75%)]\tLoss: 0.029162\n",
            "Train Epoch: 98 [11392/14860 (76%)]\tLoss: 0.026359\n",
            "Train Epoch: 98 [11520/14860 (77%)]\tLoss: 0.015825\n",
            "Train Epoch: 98 [11648/14860 (78%)]\tLoss: 0.016228\n",
            "Train Epoch: 98 [11776/14860 (79%)]\tLoss: 0.021539\n",
            "Train Epoch: 98 [11904/14860 (79%)]\tLoss: 0.015178\n",
            "Train Epoch: 98 [12032/14860 (80%)]\tLoss: 0.014652\n",
            "Train Epoch: 98 [12160/14860 (81%)]\tLoss: 0.016890\n",
            "Train Epoch: 98 [12288/14860 (82%)]\tLoss: 0.015690\n",
            "Train Epoch: 98 [12416/14860 (83%)]\tLoss: 0.017129\n",
            "Train Epoch: 98 [12544/14860 (84%)]\tLoss: 0.021200\n",
            "Train Epoch: 98 [12672/14860 (85%)]\tLoss: 0.025687\n",
            "Train Epoch: 98 [12800/14860 (85%)]\tLoss: 0.014886\n",
            "Train Epoch: 98 [12928/14860 (86%)]\tLoss: 0.017427\n",
            "Train Epoch: 98 [13056/14860 (87%)]\tLoss: 0.016308\n",
            "Train Epoch: 98 [13184/14860 (88%)]\tLoss: 0.017360\n",
            "Train Epoch: 98 [13312/14860 (89%)]\tLoss: 0.015365\n",
            "Train Epoch: 98 [13440/14860 (90%)]\tLoss: 0.022382\n",
            "Train Epoch: 98 [13568/14860 (91%)]\tLoss: 0.013695\n",
            "Train Epoch: 98 [13696/14860 (91%)]\tLoss: 0.018842\n",
            "Train Epoch: 98 [13824/14860 (92%)]\tLoss: 0.021890\n",
            "Train Epoch: 98 [13952/14860 (93%)]\tLoss: 0.020392\n",
            "Train Epoch: 98 [14080/14860 (94%)]\tLoss: 0.014700\n",
            "Train Epoch: 98 [14208/14860 (95%)]\tLoss: 0.019810\n",
            "Train Epoch: 98 [14336/14860 (96%)]\tLoss: 0.026242\n",
            "Train Epoch: 98 [14464/14860 (97%)]\tLoss: 0.024055\n",
            "Train Epoch: 98 [14592/14860 (97%)]\tLoss: 0.020682\n",
            "Train Epoch: 98 [14720/14860 (98%)]\tLoss: 0.026225\n",
            "Train Epoch: 98 [1392/14860 (99%)]\tLoss: 0.026340\n",
            "epoch 98 training loss: 0.02155161872665342\n",
            "epoch 98 validation loss: 0.044679483836268685\n",
            "Train Epoch: 99 [0/14860 (0%)]\tLoss: 0.032640\n",
            "Train Epoch: 99 [128/14860 (1%)]\tLoss: 0.018498\n",
            "Train Epoch: 99 [256/14860 (2%)]\tLoss: 0.033392\n",
            "Train Epoch: 99 [384/14860 (3%)]\tLoss: 0.020765\n",
            "Train Epoch: 99 [512/14860 (3%)]\tLoss: 0.019819\n",
            "Train Epoch: 99 [640/14860 (4%)]\tLoss: 0.021042\n",
            "Train Epoch: 99 [768/14860 (5%)]\tLoss: 0.021795\n",
            "Train Epoch: 99 [896/14860 (6%)]\tLoss: 0.028392\n",
            "Train Epoch: 99 [1024/14860 (7%)]\tLoss: 0.020188\n",
            "Train Epoch: 99 [1152/14860 (8%)]\tLoss: 0.021536\n",
            "Train Epoch: 99 [1280/14860 (9%)]\tLoss: 0.020479\n",
            "Train Epoch: 99 [1408/14860 (9%)]\tLoss: 0.020691\n",
            "Train Epoch: 99 [1536/14860 (10%)]\tLoss: 0.022371\n",
            "Train Epoch: 99 [1664/14860 (11%)]\tLoss: 0.017171\n",
            "Train Epoch: 99 [1792/14860 (12%)]\tLoss: 0.015853\n",
            "Train Epoch: 99 [1920/14860 (13%)]\tLoss: 0.017492\n",
            "Train Epoch: 99 [2048/14860 (14%)]\tLoss: 0.031009\n",
            "Train Epoch: 99 [2176/14860 (15%)]\tLoss: 0.018571\n",
            "Train Epoch: 99 [2304/14860 (15%)]\tLoss: 0.021130\n",
            "Train Epoch: 99 [2432/14860 (16%)]\tLoss: 0.021973\n",
            "Train Epoch: 99 [2560/14860 (17%)]\tLoss: 0.014527\n",
            "Train Epoch: 99 [2688/14860 (18%)]\tLoss: 0.010964\n",
            "Train Epoch: 99 [2816/14860 (19%)]\tLoss: 0.018991\n",
            "Train Epoch: 99 [2944/14860 (20%)]\tLoss: 0.020233\n",
            "Train Epoch: 99 [3072/14860 (21%)]\tLoss: 0.024106\n",
            "Train Epoch: 99 [3200/14860 (21%)]\tLoss: 0.022235\n",
            "Train Epoch: 99 [3328/14860 (22%)]\tLoss: 0.023112\n",
            "Train Epoch: 99 [3456/14860 (23%)]\tLoss: 0.024004\n",
            "Train Epoch: 99 [3584/14860 (24%)]\tLoss: 0.025794\n",
            "Train Epoch: 99 [3712/14860 (25%)]\tLoss: 0.029586\n",
            "Train Epoch: 99 [3840/14860 (26%)]\tLoss: 0.020134\n",
            "Train Epoch: 99 [3968/14860 (26%)]\tLoss: 0.029573\n",
            "Train Epoch: 99 [4096/14860 (27%)]\tLoss: 0.019696\n",
            "Train Epoch: 99 [4224/14860 (28%)]\tLoss: 0.027552\n",
            "Train Epoch: 99 [4352/14860 (29%)]\tLoss: 0.027750\n",
            "Train Epoch: 99 [4480/14860 (30%)]\tLoss: 0.024675\n",
            "Train Epoch: 99 [4608/14860 (31%)]\tLoss: 0.019957\n",
            "Train Epoch: 99 [4736/14860 (32%)]\tLoss: 0.017160\n",
            "Train Epoch: 99 [4864/14860 (32%)]\tLoss: 0.023260\n",
            "Train Epoch: 99 [4992/14860 (33%)]\tLoss: 0.018298\n",
            "Train Epoch: 99 [5120/14860 (34%)]\tLoss: 0.019088\n",
            "Train Epoch: 99 [5248/14860 (35%)]\tLoss: 0.027087\n",
            "Train Epoch: 99 [5376/14860 (36%)]\tLoss: 0.026088\n",
            "Train Epoch: 99 [5504/14860 (37%)]\tLoss: 0.037211\n",
            "Train Epoch: 99 [5632/14860 (38%)]\tLoss: 0.015452\n",
            "Train Epoch: 99 [5760/14860 (38%)]\tLoss: 0.042641\n",
            "Train Epoch: 99 [5888/14860 (39%)]\tLoss: 0.016534\n",
            "Train Epoch: 99 [6016/14860 (40%)]\tLoss: 0.018205\n",
            "Train Epoch: 99 [6144/14860 (41%)]\tLoss: 0.019944\n",
            "Train Epoch: 99 [6272/14860 (42%)]\tLoss: 0.017826\n",
            "Train Epoch: 99 [6400/14860 (43%)]\tLoss: 0.026103\n",
            "Train Epoch: 99 [6528/14860 (44%)]\tLoss: 0.020121\n",
            "Train Epoch: 99 [6656/14860 (44%)]\tLoss: 0.013796\n",
            "Train Epoch: 99 [6784/14860 (45%)]\tLoss: 0.028554\n",
            "Train Epoch: 99 [6912/14860 (46%)]\tLoss: 0.030281\n",
            "Train Epoch: 99 [7040/14860 (47%)]\tLoss: 0.019454\n",
            "Train Epoch: 99 [7168/14860 (48%)]\tLoss: 0.021781\n",
            "Train Epoch: 99 [7296/14860 (49%)]\tLoss: 0.013137\n",
            "Train Epoch: 99 [7424/14860 (50%)]\tLoss: 0.025737\n",
            "Train Epoch: 99 [7552/14860 (50%)]\tLoss: 0.014461\n",
            "Train Epoch: 99 [7680/14860 (51%)]\tLoss: 0.020808\n",
            "Train Epoch: 99 [7808/14860 (52%)]\tLoss: 0.027414\n",
            "Train Epoch: 99 [7936/14860 (53%)]\tLoss: 0.017193\n",
            "Train Epoch: 99 [8064/14860 (54%)]\tLoss: 0.020338\n",
            "Train Epoch: 99 [8192/14860 (55%)]\tLoss: 0.020071\n",
            "Train Epoch: 99 [8320/14860 (56%)]\tLoss: 0.020164\n",
            "Train Epoch: 99 [8448/14860 (56%)]\tLoss: 0.022194\n",
            "Train Epoch: 99 [8576/14860 (57%)]\tLoss: 0.017212\n",
            "Train Epoch: 99 [8704/14860 (58%)]\tLoss: 0.025178\n",
            "Train Epoch: 99 [8832/14860 (59%)]\tLoss: 0.019623\n",
            "Train Epoch: 99 [8960/14860 (60%)]\tLoss: 0.030123\n",
            "Train Epoch: 99 [9088/14860 (61%)]\tLoss: 0.027730\n",
            "Train Epoch: 99 [9216/14860 (62%)]\tLoss: 0.025438\n",
            "Train Epoch: 99 [9344/14860 (62%)]\tLoss: 0.019238\n",
            "Train Epoch: 99 [9472/14860 (63%)]\tLoss: 0.022641\n",
            "Train Epoch: 99 [9600/14860 (64%)]\tLoss: 0.014888\n",
            "Train Epoch: 99 [9728/14860 (65%)]\tLoss: 0.021501\n",
            "Train Epoch: 99 [9856/14860 (66%)]\tLoss: 0.024925\n",
            "Train Epoch: 99 [9984/14860 (67%)]\tLoss: 0.031195\n",
            "Train Epoch: 99 [10112/14860 (68%)]\tLoss: 0.015547\n",
            "Train Epoch: 99 [10240/14860 (68%)]\tLoss: 0.025155\n",
            "Train Epoch: 99 [10368/14860 (69%)]\tLoss: 0.020442\n",
            "Train Epoch: 99 [10496/14860 (70%)]\tLoss: 0.024969\n",
            "Train Epoch: 99 [10624/14860 (71%)]\tLoss: 0.021949\n",
            "Train Epoch: 99 [10752/14860 (72%)]\tLoss: 0.014255\n",
            "Train Epoch: 99 [10880/14860 (73%)]\tLoss: 0.030489\n",
            "Train Epoch: 99 [11008/14860 (74%)]\tLoss: 0.017359\n",
            "Train Epoch: 99 [11136/14860 (74%)]\tLoss: 0.035447\n",
            "Train Epoch: 99 [11264/14860 (75%)]\tLoss: 0.021578\n",
            "Train Epoch: 99 [11392/14860 (76%)]\tLoss: 0.020109\n",
            "Train Epoch: 99 [11520/14860 (77%)]\tLoss: 0.025347\n",
            "Train Epoch: 99 [11648/14860 (78%)]\tLoss: 0.015244\n",
            "Train Epoch: 99 [11776/14860 (79%)]\tLoss: 0.020373\n",
            "Train Epoch: 99 [11904/14860 (79%)]\tLoss: 0.016313\n",
            "Train Epoch: 99 [12032/14860 (80%)]\tLoss: 0.014036\n",
            "Train Epoch: 99 [12160/14860 (81%)]\tLoss: 0.033594\n",
            "Train Epoch: 99 [12288/14860 (82%)]\tLoss: 0.020329\n",
            "Train Epoch: 99 [12416/14860 (83%)]\tLoss: 0.023189\n",
            "Train Epoch: 99 [12544/14860 (84%)]\tLoss: 0.018201\n",
            "Train Epoch: 99 [12672/14860 (85%)]\tLoss: 0.020528\n",
            "Train Epoch: 99 [12800/14860 (85%)]\tLoss: 0.025597\n",
            "Train Epoch: 99 [12928/14860 (86%)]\tLoss: 0.016781\n",
            "Train Epoch: 99 [13056/14860 (87%)]\tLoss: 0.029883\n",
            "Train Epoch: 99 [13184/14860 (88%)]\tLoss: 0.020074\n",
            "Train Epoch: 99 [13312/14860 (89%)]\tLoss: 0.018043\n",
            "Train Epoch: 99 [13440/14860 (90%)]\tLoss: 0.033088\n",
            "Train Epoch: 99 [13568/14860 (91%)]\tLoss: 0.019351\n",
            "Train Epoch: 99 [13696/14860 (91%)]\tLoss: 0.031736\n",
            "Train Epoch: 99 [13824/14860 (92%)]\tLoss: 0.022222\n",
            "Train Epoch: 99 [13952/14860 (93%)]\tLoss: 0.030272\n",
            "Train Epoch: 99 [14080/14860 (94%)]\tLoss: 0.022504\n",
            "Train Epoch: 99 [14208/14860 (95%)]\tLoss: 0.015177\n",
            "Train Epoch: 99 [14336/14860 (96%)]\tLoss: 0.021745\n",
            "Train Epoch: 99 [14464/14860 (97%)]\tLoss: 0.019933\n",
            "Train Epoch: 99 [14592/14860 (97%)]\tLoss: 0.023122\n",
            "Train Epoch: 99 [14720/14860 (98%)]\tLoss: 0.022636\n",
            "Train Epoch: 99 [1392/14860 (99%)]\tLoss: 0.012238\n",
            "epoch 99 training loss: 0.02227900357136869\n",
            "epoch 99 validation loss: 0.020508611894981623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yp_test=[]\n",
        "with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
        "    for batch_idx, (X, Y) in enumerate(dataloader_test):\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        Yp = model(X)#forward pass\n",
        "        Yp_test.append(Yp.detach().cpu().numpy())\n",
        "Yp_test=np.concatenate(Yp_test, axis=0).squeeze()"
      ],
      "metadata": {
        "id": "YA8tewumUl3f"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluate model on testing set')\n",
        "mse_test, mae_test,mape_test = test(model, dataloader_test, device)\n",
        "print('MSE=', mse_test)\n",
        "print('MAE=', mae_test)\n",
        "print('MAPE=', mape_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgxcXmHfUrMx",
        "outputId": "f494e58b-addf-4de5-eb22-69b4bf9bd6c9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on testing set\n",
            "MSE= 0.019383713935119236\n",
            "MAE= 0.10092782079018364\n",
            "MAPE= 0.2616167352643124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
        "ax.plot(np.arange(0,len(mae_val_list)), mae_val_list, '-r', label='validation accuracy')\n",
        "ax.set_xlabel('epoch',fontsize=16)\n",
        "ax.legend(fontsize=16)\n",
        "ax.grid(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "ygbX0UuKUtu_",
        "outputId": "2cabf9be-c896-44c5-d568-ae9de5d1d0bf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=housing.drop(['median_house_value'], axis=1)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "wXIDnu4lUxPj",
        "outputId": "edaad6c7-dc96-44f8-fde7-e7f081293706"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
              "0       322.0       126.0         8.3252                          0   \n",
              "1      2401.0      1138.0         8.3014                          0   \n",
              "2       496.0       177.0         7.2574                          0   \n",
              "3       558.0       219.0         5.6431                          0   \n",
              "4       565.0       259.0         3.8462                          0   \n",
              "\n",
              "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
              "0                       0                       0                         1   \n",
              "1                       0                       0                         1   \n",
              "2                       0                       0                         1   \n",
              "3                       0                       0                         1   \n",
              "4                       0                       0                         1   \n",
              "\n",
              "   ocean_proximity_NEAR OCEAN  \n",
              "0                           0  \n",
              "1                           0  \n",
              "2                           0  \n",
              "3                           0  \n",
              "4                           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a862545d-6e26-4687-9bd7-7b4fcedf3b9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
              "      <th>ocean_proximity_INLAND</th>\n",
              "      <th>ocean_proximity_ISLAND</th>\n",
              "      <th>ocean_proximity_NEAR BAY</th>\n",
              "      <th>ocean_proximity_NEAR OCEAN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a862545d-6e26-4687-9bd7-7b4fcedf3b9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a862545d-6e26-4687-9bd7-7b4fcedf3b9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a862545d-6e26-4687-9bd7-7b4fcedf3b9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c71f0f3-6e1d-44e6-85b9-9f8435a7be97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c71f0f3-6e1d-44e6-85b9-9f8435a7be97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c71f0f3-6e1d-44e6-85b9-9f8435a7be97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0035317235025882,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571153,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.58555761211165,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582795,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 419.26659232552373,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1924,\n        \"samples\": [\n          1126.0,\n          1842.0,\n          1116.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132.462121765341,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          4169.0,\n          636.0,\n          3367.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.32975283161073,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452688,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          5.0286,\n          2.0433,\n          6.1228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_<1H OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_INLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_ISLAND\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR BAY\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity_NEAR OCEAN\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=housing['median_house_value']\n",
        "Y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blX6TiXjUzjd",
        "outputId": "c0928e20-d0da-492f-9ba2-4cbbe85f29b9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    452600.0\n",
              "1    358500.0\n",
              "2    352100.0\n",
              "3    341300.0\n",
              "4    342200.0\n",
              "Name: median_house_value, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_columns=X.columns #store the column names\n",
        "X=X.values\n",
        "Y=Y.values"
      ],
      "metadata": {
        "id": "yi-sDk3VU2Sw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "#split X_train and Y_train into a 'pure' training set and a validation set\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
        "print('train:', X_train.shape, Y_train.shape)\n",
        "print('validation:', X_val.shape, Y_val.shape)\n",
        "print('test:', X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXJT2nEZU4XO",
        "outputId": "db5b401e-5cc8-43e8-e8b7-a82f6fb4b627"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (14860, 13) (14860,)\n",
            "validation: (1652, 13) (1652,)\n",
            "test: (4128, 13) (4128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "scaler.fit(X_train) # think about why fit to X_train, not X ?\n",
        "X_train=scaler.transform(X_train)\n",
        "X_val=scaler.transform(X_val)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tV48xN50U6bv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost.sklearn import XGBRegressor\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier(n_estimators=20, random_state=0, objective='reg:squarederror')"
      ],
      "metadata": {
        "id": "Jon49QLaU8zp"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth=30\n",
        "\n",
        "max_depth_list=np.arange(1,max_depth+1)\n",
        "\n",
        "max_depth_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxtTX5ceU-ub",
        "outputId": "2d21bad4-66f4-40ff-9bf9-785a6d9a18f7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_train_list=[]\n",
        "MAE_val_list=[]\n",
        "\n",
        "for k in max_depth_list:\n",
        "    model=xgb.XGBRegressor(n_estimators=20,max_depth=k,random_state=0, objective='reg:squarederror')\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    Y_val_pred=model.predict(X_val)\n",
        "    MAE_val = np.mean(np.abs(Y_val - Y_val_pred))\n",
        "\n",
        "    Y_train_pred=model.predict(X_train)\n",
        "    MAE_training = np.mean(np.abs(Y_train - Y_train_pred))\n",
        "\n",
        "    MAE_train_list.append(MAE_training)\n",
        "    MAE_val_list.append(MAE_val)"
      ],
      "metadata": {
        "id": "lQrjJY6NVBMW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
        "ax[0].plot(max_depth_list, MAE_train_list, 'b')\n",
        "ax[0].set_xlabel('max_depth')\n",
        "ax[0].set_ylabel('training accuracy')\n",
        "ax[0].set_title('max_depth v.s. training accuracy')\n",
        "ax[0].grid(True)\n",
        "\n",
        "ax[1].plot(max_depth_list, MAE_val_list, 'r')\n",
        "ax[1].set_xlabel('max_depth')\n",
        "ax[1].set_ylabel('validation accuracy')\n",
        "ax[1].set_title('max_depth v.s. validation accuracy')\n",
        "ax[1].grid(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "kUBqiFxBVEGB",
        "outputId": "d1c15d17-1a14-4937-83a8-8d9e407384b0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Temp1 = np.argmin(MAE_val_list,axis=0)\n",
        "max_depth_best =(max_depth_list[Temp1])\n",
        "max_depth_best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9IgGZwlVG6D",
        "outputId": "d0b1a70c-dd11-438c-a647-994ea50adb6c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBRegressor(n_estimators=20,max_depth=max_depth_best,random_state=0, objective='reg:squarederror')\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "print('Evaluate model on traning set')\n",
        "MSE_XGBoost = np.mean((Y_train - Y_train_pred)**2)\n",
        "MAE_XGBoost= np.mean(np.abs(Y_train - Y_train_pred))\n",
        "MAPE_XGBoost =  np.mean(np.abs(Y_train - Y_train_pred)/Y_train)\n",
        "print('MSE=', MSE_XGBoost )\n",
        "print('MAE=', MAE_XGBoost)\n",
        "\n",
        "\n",
        "print('Evaluate model on testing set')\n",
        "MSE_XGBoost = np.mean((Y_test - Y_test_pred)**2)\n",
        "MAE_XGBoost= np.mean(np.abs(Y_test - Y_test_pred))\n",
        "MAPE_XGBoost =  np.mean(np.abs(Y_test - Y_test_pred)/Y_test)\n",
        "print('MSE=', MSE_XGBoost)\n",
        "print('MAE=', MAE_XGBoost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlh2mYTAWMn_",
        "outputId": "a7115734-861d-4436-9369-cbc37beac5cd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate model on traning set\n",
            "MSE= 304213803.6713753\n",
            "MAE= 11723.399843723713\n",
            "Evaluate model on testing set\n",
            "MSE= 2291837107.90727\n",
            "MAE= 31851.727587322857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MLP model', 'MSE=',round(mse_test,9),'MAE=',round(mae_test,8), 'MAPE=',round(mape_test,8))\n",
        "print('XGBoost  ', 'MSE=',MSE_XGBoost, 'MAE=',MAE_XGBoost, 'MAPE=',MAPE_XGBoost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ9dXs2JWRCx",
        "outputId": "feed43e4-065e-48f6-9ef2-6a38b4448b24"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP model MSE= 0.019383714 MAE= 0.10092782 MAPE= 0.26161674\n",
            "XGBoost   MSE= 2291837107.90727 MAE= 31851.727587322857 MAPE= 0.17896494918430192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "print('MLP model',statistics.mean(mae_val_list))\n",
        "\n",
        "print('XGBoost',MAE_val_list[max_depth_best])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85HpAQTAWTho",
        "outputId": "68947378-2f03-4b85-9191-d0c2bae93209"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP model 0.13198574133127133\n",
            "XGBoost 33908.955179801\n"
          ]
        }
      ]
    }
  ]
}